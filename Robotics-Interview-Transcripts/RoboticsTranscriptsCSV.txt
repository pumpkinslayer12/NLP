"Alan Winfield","Interviewer","Okay, so if you could just start by introducing yourself and tell us where you were born and where you grew up."
"Alan Winfield","Interviewee","Sure, I am Alan Winfield. I was born in Burton on Trent, which is in the midlands of England, in 1956. "
"Alan Winfield","Interviewer","And where did you go to school?"
"Alan Winfield","Interviewee","Burton on Trent Grammar School, in fact, one of the last of the grammar schools in England. "
"Alan Winfield","Interviewer","And university?"
"Alan Winfield","Interviewee","University of Hull in a not far from where we are now. So, it is Yorkshire, East Yorkshire. "
"Alan Winfield","Interviewer","What did you study there?"
"Alan Winfield","Interviewee","I studied electronic engineering. In fact, it was I knew I wanted to do microelectronics. So, I looked for university courses that were specifically microelectronics. And there were very few at that time. So, I at the time, I regarded anything as more than five volts and half an amp as pair electronics. So, I did not want to do that."
"Alan Winfield","Interviewer","What made you decide to go into microelectronics?"
"Alan Winfield","Interviewee","Because ever since I was a kid, I was fascinated by electronics. I took things to pieces. So, from a young age, I was taking apart radios, and Gramophones, record players, sometimes putting them back together again and was just utterly fascinated. In fact, I remember speaking to my careers teacher at school when it came to choosing what to do at university. And I was delighted when he said why do not you do electronics? I had no idea that you could even do a university course in electronics."
"Alan Winfield","Interviewer","Did you go straight to graduate school after university?"
"Alan Winfield","Interviewee","I did, yes. So, I went straight from a Bachelors to a PhD. "
"Alan Winfield","Interviewer","And where was that, in ?"
"Alan Winfield","Interviewee","It was also in Hull. I was very lucky in that I did a final year project in error correcting codes. In fact, my major in electronics was communications engineering. And it just so happened that the school I was in had offered a prize of a PhD scholarship to whoever came top of the class, if they wanted it. And because I had loved final year project so much, then it felt very natural for me to continue in that, into a PhD. So, I ended up doing a PhD in digital communications information theory and error correcting codes. "
"Alan Winfield","Interviewer","Who was your advisor?"
"Alan Winfield","Interviewee","A guy called Rod Goodman, Rodney Goodman who is still I am still in touch with Rod, an outstanding PhD supervisor and long-term kind of friend and a mentor. Yeah, I had a very, very happy experience as a graduate student. And in fact, I remember at an IEEE conference on neural networks, it must have been about I guess around 1979 or 1980, and the guest of honor was Claude Shannon. And I, being a rather brash PhD student, I just marched up to him and introduced myself. We ended up having an interesting conversation. So, of course, it was only after that that all the professors said, Oh, do you realize who that was? The guy is a legend. You can not just walk up to him and introduce yourself. Well, I did. So, that was a pleasure to he is one of my scientific heroes. And I have to say that even now, as a roboticist, I am always looking for the information theoretic kind of perspective."
"Alan Winfield","Interviewer","So, where did you go after your PhD?"
"Alan Winfield","Interviewee","Well, in fact, I left academia and started a business. So, I became an entrepreneur. I, almost as a kind of side project during my PhD, I had invented a computer architecture, and patented it, and decided to see if we could commercialize this with in fact, with my PhD supervisor, and the third guy who was the financial guy. We started a spin-out company. So, I ran that for the best part of ten years. "
"Alan Winfield","Interviewer","So, what was the company?"
"Alan Winfield","Interviewee","The company was initially called MetaForth Computer Systems. And we designed, at the time, the world's fastest single board processor. It was running just under seven million Forth instructions per second. It ran a computer language called Forth but at a machine level. Forth was the native instruction set for this computer. Commercially, it was not a success. But the company, in fact, continued and continues to this day not in computers, but in safety critical data communications. So, in a sense, the my original specialism, which was communications was the thing that the company became successful in doing. And I am very proud of the I never I did not make any money from it, but I am proud of the fact that it persisted and now employs about a hundred and twenty people. Yeah, that is nearly thirty years old. "
"Alan Winfield","Interviewer","How did you get back into academia?"
"Alan Winfield","Interviewee","Yeah, basically after, as I say, running the business well, in fact I stopped being managing director after about five years and then became technical director. But it was exhausting and I by this time, I had a young family. And I really felt that I wanted to provide my family with a bit more security than was possible in this crazy, still young, start up company that was constantly having cash flow crises and so on. So, I decided to look for a job back in academia, and applied for and got the post that I essentially currently have at UWE Bristol. "
"Alan Winfield","Interviewer","And what would you consider your first robotics project?"
"Alan Winfield","Interviewee","Yeah, I got into robotics really because of meeting two people. And between us, we founded what is now the Bristol Robotics Lab. Initially, it was called the Intelligent Autonomous Systems Lab. One was, or is Chris Melhuish who is now the director of the lab. But the third member of the three of us was Owen Holland. And Owen still is a great friend and really, I would say, provided the inspiration to both Chris and myself as I mean I was not a roboticist twenty years ago, except I suppose in the sense of still harboring, if you like, science fiction inspired dreams of cybernetics and so on. So, I suppose there was some robotics in me but unrealized. And meeting Owen, in particular, really opened my eyes to the potential of this kind of new robotics, new wave robotics, which was bio inspired, biomimetic. You could almost say biological robotics. And I think that was true of Chris, as well. there is another dimension, if you like, to the story, which is that I had been hired as head of research in the faculty of engineering, a faculty that really did not have very much research. And my brief was to create a new research activity for the faculty. Now, I knew the communications research very well. In fact, just down the road at University of Bristol there was a big, still is a big coms lab. And I knew that there was no point in us creating a coms lab. So, I was looking for a research activity that was not represented in the region, in the southwest of England, in fact really not very well represented in the UK at all. So, it was a kind of happy meeting if you like. Chris and Owen, in particular, provided that inspiration from robotics. He was the only kind of one of the three of us who was already a kind of proper roboticist. And we needed I needed strategically a new research direction. So, the common two things fitted."
"Alan Winfield","Interviewer","And when did that lab start?"
"Alan Winfield","Interviewee","1993. Yep. So, this is its this year is its twentieth anniversary. Yeah, and quite literally we started in a little kind of space that we managed to beg in the department. In fact, some of the first work I got involved in was designing and building little our own mobile robots. I mean we in those days, you could not buy research robots. You had to build your own. And so, I was really using taking advantage, if you like, of my electronics background in embedded microprocessors and software engineering and all of that stuff. And because we have no space to do experimental work, we actually used the sort of space in the corridor outside the lab to do some swarm robotics experiments. And this was in fact, the swarm work really came from Owen Holland who previously had already had been doing work with some swarm guys in Belgium. So, and Chris Melhuish, in fact, ended up doing this for his PhD work. And so, I got involved really in the initially in the design of the electronics for the robots helping to design the electronics. And it was only really, as it were, during the next I suppose five years or so that I started to become deeply interested in the algorithms, the whole question of the nature of emergence and self-organization really fascinated me. And it still does. So, I it was that that I can not say there was a specific project. It was, in a sense, the work of the lab when there was only a handful of us found itself I think because of Owen's Owen Holland's work. We found ourselves doing, if you like, some of the early work in swarm robotics. And I was hooked then. "
"Alan Winfield","Interviewer","And what were some of the early questions and experiments that you were looking at? "
"Alan Winfield","Interviewee","Well, the early focus of that work was minimalist swarm robotics. So, we were really asking questions about what are the simplest robots in terms of their behaviors, both the physically simplest and behaviorally simplest, that could collectively do something interesting. And Owen did some of the pioneering work in clustering, puck pushing, where effectively a bunch of robots with only two or three rule and these are identical robots. And they only have two or three rules, behavioral rules, would collectively sort and cluster little night lights, little candles and so on pushing them around. And so, the initial focus was very much on the minimalist kind of approach. So, I then ended up designing co-designing with Owen the first Linux robots. We called them Linuxbots. And, in fact, we had collaborations with a number of other labs including the collaboration with Caltech, who and we designed a number of we supplied Caltech with a bunch of these Linux robots."
"Alan Winfield","Interviewer","When was that? And who are you collaborating with? "
"Alan Winfield","Interviewee","So, that was in fact, by this time, Rod Goodman, my PhD supervisor, was a professor at Caltech. And his post doc who I still work with to this day is was Alcherio Martinoli. Alcherio is now at EPFL in Lausanne. So, we designed these robots, which are rather large. They are about the size of a dinner plate, robots. But I remember in about 1998, installing Linux on the robot. And we and Owen Holland and I wrote a paper about these robots forming a wireless network. So, again, you see the communications kind of coming in. So, I think we were one of the first labs to actually have a wireless networked swarm of autonomous Linux robots. And it but it was very clunky. I mean this was before Wi-Fi. So, we were using the kind of first generation of Wi-Fi. And the drivers had not been written for Linux so I ended up hacking finding whatever kind of semi-working drivers I could find and hacking them and trying to make them work. So, it was fun. I mean it was pretty hardcore electronic engineering, as well. Yeah, yeah. "
"Alan Winfield","Interviewer","Were there other collaborations during that period?"
"Alan Winfield","Interviewee","Sure, yes we I mean, for instance, we collaborated with BAE systems, who also had a well they still have, in fact, a lab in Bristol. And they were very interested in mobile robot and we again the same physical robots. They ended up with a bunch of those too. So, in fact, one of the the Caltech collaboration was, at least part of that collaboration was, funded by a DARPA grant. And it was part of the I think it was called the or at least not this was not the scientific name, but it was called the dog's nose project. So, it was effectively a project concerned with humanitarian de-mining. And I think the scientific question that we were trying to answer for DARPA was is there some advantage imagine that you have a land mine. And it is unexploded, and it is leaking. Essentially, you have some vapor. So, it is essentially an odor tracking problem. So, the question is, is it better to have or was, the question was is it better to have a single robot that tracks to the source of the chemical plume, rather like a dog would track by kind of going backwards and forwards and somehow honing in, or to have a bunch of robots that each sample the odor from wherever they are and then share the information wirelessly, and effectively, collectively compute the source of the odor. So, the scientific question was really very interesting. It was a kind of is it better to be collective or single robot. what is the I ended up coming up with the notion of sort of collective gain, is there some kind of notion of collective gain."
"Alan Winfield","Interviewer","And what is the answer? "
"Alan Winfield","Interviewee","Well, it swings in roundabouts because of course the you need to look carefully at the energy balance because obviously, collectively, a bunch of robots, although they might individually move less than a single robot that has to whiz all over the place, collectively of course you still might have five or ten robots instead of one. So, it was a qualified yes, I would say. But I recall a particularly interesting it was a new experience for me, of course, going to a DARPA principle investigators meeting where you had to bring all of your robots. And they were they had to do their stuff, and perform. But that was very, very interesting. Yeah, very interesting."
"Alan Winfield","Interviewer","When was that? "
"Alan Winfield","Interviewee","That was 1999, 2000, that period. Mm-hmm, yeah. "
"Alan Winfield","Interviewer","So, what were some other of the more interesting swarm problems that you worked on?"
"Alan Winfield","Interviewee","More or less that time excuse me, I it is cold in here. More or less at that time, I became interested in mathematical modeling of swarm behavior. And I suppose I suppose I because this kind of biological robotics so you have this extremely interesting kind of interface between the biologist, and in our case, the ant biologists who are kind of hypothesizing about the rules, the behaviors of the ants in order to do this amazing foraging and collective behaviors, and so on. And because there was the kind of biology and also artificial life thing going on and I felt a little bit uncomfortable at the time. I remember feeling uncomfortable going to conferences kind of simulation of adaptive behavior and the early a-life thing. And I was thinking well there is not much engineering science going on here. There was far too much of what I call proof by video, that someone would give a paper and show a really cool video of these robots doing stuff. And they'd say, Well, That is it I have finished. is not it great? But of course being a kind of old fashioned electronics engineer from having and having worked in industry, particularly on kind of safety-critical production engineered systems, I really felt that there was a missing component, an engineering science component. And I remember writing a paper, which I think it is pretty well cited now, where I was asking for a kind of new discipline of what I call swarm engineering. I was setting out the a more disciplined methodology for engineering real world systems based on the principles of swarm intelligence. And part of that methodology I was suggesting that we needed quite a number of new methods. And one of them was mathematical modeling. And the guy that I mentioned, Alcherio Martinoli, he his PhD work was in mathematical modeling. I was very attracted by the methods that he'd been working on, and started to see if I could extend those approaches, and develop this kind of probabilistic mathematical modeling that he'd initially worked on. And not the only one, but there are not very many people, there still are not very many people in the world who are interested in trying to mathematically model self-organizing systems. I think I was also attracted by the fact that this modeling almost abstracts away from the fact that these are robots. So, I was interested in the idea that you are not just doing robotics, you are doing science. And you are kind of doing thinking about emergent and self-organizing systems in the abstract. So, I think that was another thing that attracted me to the mathematical modeling aspect. "
"Alan Winfield","Interviewer","And when you got into that, did you find similarities to parallel search algorithms or other kinds of computational algorithms? Or were you really trying to look at say complexity analysis of these things or their optimization potentials?"
"Alan Winfield","Interviewee","Yeah we there were several things we were trying to do. It certainly there was an optimization aspect to this. We were I mean essentially but fundamentally, I was interested in trying to do, if you like, a validation exercise. Rather than just saying look here is a swarm, either a real swarm of robots swarm of real robots or in simulation, look it works. What I was trying to say was yeah, but here is the math that actually validates these behaviors and shows mathematically how the macroscopic properties of the swarm are related to the microscopic behaviors of the individual robots. And, of course, as part of that, you are parameterizing. you are looking at the boundary conditions. And hence, you are able to optimize. So, for instance, the most recent work I did with a PhD student was looking at mathematically modeling an adaptive a swarm doing adaptive foraging. So, in other words, the swarm was foraging with adaptive division of labor. So, this is a very interesting property of ants not all, but some ants. That the that ants this surprised me when I first learned this. Some ants have a kind of labor pool. So, in the ant colony, there are some ants who are just milling around waiting for something to do. And it turns out that for these particular ants that if there is a lot of food in the environment, then more ants will be recruited from the labor pool to go foraging, whereas if there is limited food in the environment, then more ants will stay at home in the nest and fewer will be foraging. And somehow the colony adapts the ratios of foragers to resters according to the amount of food forage, in the environment. And we were not the first to develop foraging algorithms, but I think we were the first to mathematically model these algorithms. But what was, if you like, the icing on the cake was that we were able to put the mathematical model inside a genetic algorithm in order to do parameter optimization, which was something That is really hard to do in swarm systems."
"Alan Winfield","Interviewer","So, were you starting from the ants' algorithm? Or were you trying to prove a more efficient algorithm then what they used?"
"Alan Winfield","Interviewee","Yeah, that is a good question. I mean we my observation of swarm intelligence research is that very rarely does one do swarm robotics researchers actually directly implement, if you like, the behaviors hypothesized by ant biologists. More often what you do is that you are inspired. So, you kind of you have a rather abstract idea of how the ants may do this. I mean bearing in mind of course that we can not make robots like ants with pheromones and pheromone concentrations and so on. So, effectively, you are kind of inventing a robotics version, which does not really bear direct one to one comparison with the ant behaviors. And often, in fact, I have actually had this experience. The ant biologist will come along and say wow, you have come up with the same behavior, but with the same collective behavior, but with fewer individual rules. So, in other words, we the ant biologists may hypothesize a rather more complex ant than we end up demonstrating with the robots. Yeah."
"Alan Winfield","Interviewer","And did you go back to robots after mathematical modeling?"
"Alan Winfield","Interviewee","Yeah, I mean I have stayed in swarm robotics, but I have kind of diverged in moved into several new directions. So, for one thing, I felt that swarm robotics has potential beyond, if you like, swarm intelligence. So, I became very interested in social intelligence. And I am still convinced that if you want to build smart robots, really smart robots, it is crazy to just make one. The smartest animals on the planet as far as we know are human beings. And we are a profoundly social species. We would not have all of this culture, and language, and art, and music, and science, and stuff if it were not for the fact that we are social animals. And it is always felt me as being struck me as being very odd when people try and work on cognitive or learning robots, but they only ever make one. So, what I have been trying to go in the direction of is a higher level of cognition in swarm. So, in a sense, make the transition from swarm robotics to social robotics where these are not social in the sense of human robot interaction but in the sense of robot robot interaction, which again is a little bit abstract but so, for instance, I just finished last year a four and a half year project called the emergence of artificial culture in robot societies and what we did with that project was to implement social learning. In fact, learning by imitation, embodied imitation. So in other words, robots were able to watch each other's behaviors and then imitate them, but because it was embodied imitation, the robots imitated imperfectly. In fact for precisely the same reason that you and I imitate imperfectly. it is because all we have is our own first-person perception. We have to infer each other's movement if we are trying to imitate a dance, for instance. I have to infer how you move your body if I want to copy your dance moves and inevitably I will get it wrong. So the interesting thing is that by implementing social learning, imitation learning in this way in real physical robots where the robots have to use their own senses and sensorium to do the imitation then you find that you have imperfect imitation, but because you have a swarm of robots and because They are imitating each other and of course you have robots imitating a behavior and then another robot imitates that behavior and then another one imitates that behavior then what we have is well, firstly we have variation, which we get for free just through embodiment, we have heredity because we have multiple generation social learning, and in fact we also implement very simple selection. So a robot will imitate several behaviors of other robots, but will then decide which of those learned behaviors to enact. In fact, the simplest selection operator is simply to choose at random with equal probability which is surprisingly powerful, actually, is the selection operator. So what we did, of course when you have those three things you have the three Darwinian evolutionary operators and sure enough we demonstrated I think for the first time anywhere embodied memetic evolution and it was open-ended memetic evolution. So in other words, we could not predict where evolution would go and we certainly demonstrated some interesting, novel, new behaviors."
"Alan Winfield","Interviewer","Memes, huh?"
"Alan Winfield","Interviewee","Memes. Yeah, That is right. "
"Alan Winfield","Interviewer","So what were they able to achieve. What kind of behaviors ?"
"Alan Winfield","Interviewee","I mean we are talking about very simple behaviors. I mean the robots were raw, if you like, pathological imitators. that is all they do. So they just copy and then reenact and then copy and so on. So what we found was that we seeded behaviors and the behaviors in this case are the simplest case were just movement patterns. So we seeded like a little square move, these little wheeled robots. we are now onto Eperks which are little miniature Swiss open source robots and so what we found is a number of very interesting things is we found that behaviors would emerge that were quite different to the original seeded behaviors, but they would become persistent in the population. So you could think of them as a kind of new behavioral fashion or a tradition. I think I prefer the word tradition and certainly we found that if for instance by happenstance you had a very poor quality imitation, so a behavior was very heavily distorted, there is a large degree of variation, but then if that highly distorted behavior was then copied with high fidelity and if this happened early in evolutionary history then you found that sometimes this very new and different dance became persistent. So what I am saying is you saw the emergence of novelty just by virtue of a very poor fidelity imitation instance of social learning being copied by chance by a series of very high fidelity instances of social learning. Another interesting thing, well firstly we found that the memetic evolution tended to drift towards sets of behaviors that somehow seemed to fit the sensorium and morphology of the robots. In other words, bearing in mind the robots have no sense of utility or value or ease with which the behaviors are learned, nevertheless those behaviors that seemed to be easier to learn and to pass on seemed to become dominant in the population. Perhaps the most interesting outcome or result was that we tested different memory strategies. So we tried these experiments with for instance no memory, with infinite memory, or with limited memory, and the interesting thing is that we found that with limited memory where a robot essentially has no choice but to forget the oldest of its learned behaviors, we found that the limited memory case gave rise to the smallest number of large clusters of related behaviors, which is very interesting. It seems to suggest that forgetting might play a role in the persistence of behavioral traditions. "
"Alan Winfield","Interviewer","So traditions are more resilient with limited memory."
"Alan Winfield","Interviewee","If you are to believe this. I mean this is a kind of very abstract but nevertheless embodied model and I have become very interested in the idea of robots as if you like and this is really referring to the Dennett, Dan Dennett's idea of a constructionist approach to science. So my journey in a sense has taken me from engineering, engineering science, and now to almost pure science in the sense that I am now much more interested in using robots to try and understand the nature of intelligence, evolution. I have not mentioned the work, but I am also doing an evolutionary robotics and even culture by building working models. That is really the thing That is now grabbing my attention more than anything else, the idea of trying to understand what intelligence is by building very simple working models. I mean They are not actually simple. They are rather complicated with lots of robots doing interesting things, but nevertheless compared with animals, most of all humans, these are really very simple models."
"Alan Winfield","Interviewer","But you had to go back to the material robot, but not just the mathematical simulation."
"Alan Winfield","Interviewee","Yes. I mean I have not lost the engineering science aspect, but so analysis is still very important, but nevertheless, in a sense my journey in robotics is much more toward using robots as working models for you could think of it as experimental philosophy."
"Alan Winfield","Interviewer","But you need the materiality to give you the right kind of variation."
"Alan Winfield","Interviewee","Yes. I mean I am perfectly convinced that doing all of this in simulation is not appropriate and I mean we are talking about complex systems. So with unexpected emergence. I have certainly seen lots of examples of unexpected emergence that firstly you would be really hard pressed to predict just theoretically or with pen and paper and you certainly would not see in an agent based model or a simulation."
"Alan Winfield","Interviewer","So tell us a bit about your work in evolutionary robotics."
"Alan Winfield","Interviewee","Sure. So again I have become fascinated by artificial evolution and evolutionary robotics, of course, has been around for a little while, but more recently the question of how can you evolve swarm behaviors, how can you evolve collective behaviors, and I became involved and still am involved in a European Union funded project so called future emerging technologies project called Symbrion which stands for Symbiotic Evolutionary Robot Organisms. So it is a different kind of direction. it is still arguably about modeling, but of a different sort. So here what we are trying to do in Symbrion is to build a swarm of robots that can act as a swarm independently. They can do interesting self organizing collective behaviors of the kind that I have been discussing, but if the robots or if one of the robots, for instance, discovers that there is an obstacle in the environment that it cannot overcome on its own, then it can seed, if you like, the formation of a new organism that the robots therefore can autonomously physically self assemble and then once they have self assembled in two dimensions, they can then lift themselves up and form a kind of three-dimensional artificial organism that somehow can overcome. Imagine climbing over a wall That is too high for a single robot. Well, a bunch of the robots can self assemble and stand up and then climb over the wall and then once They are over the wall, they can go back to being a swarm. So it is a sort of two-way process. So this is modeling of a different kind. we are now modeling almost kind of the process of embryogenesis. So you could think of the individual robots of the swarm as stem cells. So when the organism forms and you have this kind of morphogenesis, the individual robots have to assume a particular function in the organism. Some become foot bots, some knee bots, and some sensory bots, and that is a deeply interesting question. How can you build a self organizing system where the individual robots will differentiate, taking the analogy from cell differentiation, but again going back to evolutionary robotics, we are very interested in modeling the process of the formation of multicellularity. So I mean we have not yet got this, but we are still working on the project, but my dream for this project, well our dream for this project I am not the author of all of these ideas. One or two of them, perhaps, but is that we can create an artificial environment where these robots are acting as a swarm. What environmental conditions would prompt them to evolve multicellularity? Under what conditions would it be better for these robots to form multicellular organisms than to remain as individual cells? that is a kind of pretty interesting question which really speaks to the origin of multicellularity. Yeah."
"Alan Winfield","Interviewer","So maybe you could just tell us about some of the PhD students you have supervised and where they have gone off to."
"Alan Winfield","Interviewee","So yeah, I mean in fact several of my early PhD students are now themselves professors in the lab, which is really great. So I am very, very proud of that fact. One of my PhD students in fact was at the meeting. When I say former PhD students was at the meeting on robot ethics that we were at today and he is now on the international standards organization committee defining the new standard in personal care robots. So I regard him as a "
"Alan Winfield","Interviewer","what is his name?"
"Alan Winfield","Interviewee","That is Chris Harper. So yes, Chris is, well, a very successful professional roboticist that I am proud to have been his PhD supervisor. But I have several PhD students who one is now a post-doc and more or less immediately after graduating got a post-doc position in EPFL and he is still there. Another student who "
"Alan Winfield","Interviewer","Can you give us his name?"
"Alan Winfield","Interviewee","Oh sure. That is Julian Lambrini . So he was a Swiss mathematician who came to do swarm robotics with me and worked on those big Linux bots and very unruly robots, but did some really interesting work on kind of emergent morphology control. Sort of showed how you can get very interesting morphological variation in a swarm of robots just from single parameters that you vary a little bit. You get the difference between radial axial morphologies. Again almost hinting towards this kind of developmental biology kind of analogy. A much more recent student who worked on my artificial culture project that I mentioned earlier, he went back to Turkey and he now has his first junior faculty position as a roboticist in Turkey."
"Alan Winfield","Interviewer","And his name?"
"Alan Winfield","Interviewee","That is Mehmet Erbas, E-R-B-A-S. "
"Alan Winfield","Interviewer","Okay, and what was it like working with Owen Holland?"
"Alan Winfield","Interviewee","Oh, an absolute pleasure and he and I still keep in touch and I regard Owen as one of the handful of most interesting people that I know on the planet and Owen is someone for whom it is impossible not to have an interesting conversation with. "
"Alan Winfield","Interviewer","And who else influenced you theoretically, whether just in writing or through teaching or collaboration?"
"Alan Winfield","Interviewee","In robotics, well let me say in general, scientifically Arthur Koestler. One of the best science books I read years ago, his history of science, The Sleepwalkers. I also read a number of his other books which still influence me a little bit. The Act of Creation, for instance. I was inspired much more directly and almost personally by W. Grey Walter. Now there is some interesting history there because Grey Walter, as you may know, designed and built arguably the world's first electromechanical autonomous mobile robots and certainly again there were only two, but nevertheless, the first to do robot-robot interaction with Elmer and Elsie and his lab was very close to our lab in Bristol. It was literally just within a mile down the road. Now Owen Holland in I think about 1995 took it upon himself to track down the whereabouts of the six robot tortoises. Walter called them tortoises after Lewis Carroll because they taught us, and he managed to discover the whereabouts of all of them and only I can not remember. Two or three still existed. One in the Smithsonian, but he contacted Grey Walter's son Nicholas and discovered that Nicholas still has one of the tortoises in fact in a basement in Islington and persuaded Nicholas to lend the tortoise to the lab. So around 1995-1996 we had on loan this tortoise and Owen and some of the other guys in the lab, in particular the technician Ian Horsefield, got it working. So restored it to full working order, but still very fragile. I mean remember this robot was built in 1950. It was built basically for the festival of Britain 1951. So Grey Walters' technician, a guy called Bunny Warren who amazingly was still around in 1995-1996 for us to consult with and he gave us some original parts and so on. So we not only were able to borrow this robot, but to make some replicas. So we built two as faithful as we could replicas and my brief involvement, apart from being inspired by these robots, was that I then became involved in the lab was commissioned by I kind of led the project to build some simulacra of these robots for the millennium dome exhibition, the millennium exhibition at the turn of the century and at that time I corresponded directly with Nicholas Walter who was still alive and had a very interesting correspondence and became fascinated, I think as anyone would be by that particular piece of robotics history. So Grey Walter definitely an inspiration. Remarkable that he more or less invented, I suppose you could say, in a minimalist robotics connectionist robotics behavior based you could argue approach and collective robotics. I mean all of that stuff which was not really rediscovered I think properly until Rodney Brooks in the 1980s. "
"Alan Winfield","Interviewer","And did that shape how you structured your lab in Bristol?"
"Alan Winfield","Interviewee","It certainly influenced us. I mean for one thing it made us rather humble because wow, our marvelous robots with microprocessors really were not much more capable or interesting initially than these 1949-1950 robots that have three vacuum tubes and two motors. Three vacuum tubes and two motors, but extraordinarily rich behaviors. I mean certainly I was very influenced I think we all were by the richness of the emergent behaviors and by the again observation by Walter that the richness of the environment contributes massively to the complexity and richness of the behaviors of the robots. Yeah."
"Alan Winfield","Interviewer","So at the time you started the lab in Bristol, what other robotics labs were operating around England?"
"Alan Winfield","Interviewee","Well, perhaps the best known not so much robotics, but cognitive systems was the lab in Sussex, which is still of course the very well known lab and also in Edinburgh and in Oxford. So I would say there were three very well established labs. I mean of course artificial intelligence lab started by Don Michie of course who worked with Alan Turing. I met Michie on a couple of occasions. Remarkable guy, really one of the founders of modern AI in the UK. So he was the founder of the Edinburgh AI lab which then became robotics and then of course the robotics lab of Michael Brady in Oxford which although Michael is retired, but that is still a very strong lab, arguably responsible for inventing SLAM and a number of other groundbreaking developments in robotics. Yeah, so not many. I mean there are more robotics labs now in the UK, but not many big ones."
"Alan Winfield","Interviewer","What was Sussex known for?"
"Alan Winfield","Interviewee","Well, Sussex really known for cognitive systems in robotics and really for co-inventing evolutionary robotics. So I think Phil Husbands and Inman Harvey were kind of coming up with the ideas of evolutionary robotics more or less the same time as Dario Floreano and Stefano Nolfi. So there was obviously something in the air, I guess, but yes, really groundbreaking work in evolutionary robotics. I mean you are asking. I have kind of become a bit distracted by Grey Walter, but as an inspirational figure, but I have also been inspired by Susan Blackmore, the psychologist, for her work in both consciousness and memetics and certainly from a philosophical and methodological point of view strongly inspired by Daniel Dennett. "
"Alan Winfield","Interviewer","Great. So the other question we kind of wind down with is for young people who are interested in a career in robotics, what kind of advice do you have for them?"
"Alan Winfield","Interviewee","Gosh. Well, I would say think about the science. Think about the big questions. Something that people sometimes ask me is I want to do important work. What should I do? Well, the answer is work on important problems. So even for someone who is starting out in robotics, I think it is a good thing to think about the longer term. Think about the big picture. Do you want to be the one who cracks artificial consciousness? Do you want to be the one who figures out how to put a swarm of robots on Mars that would build a human habitat? I would say do not limit your thinking to the problems of industry here and now. I think robotics is in a sense too important and too interesting, too fascinating, too far reaching, too inspirational to be, as it were, shackled by the economic needs of this or that company. I mean of course those are important things, but think longer term. And I would also say of course you need to do mathematics and programming and physics and you need to understand some principles I think to be a roboticist, but at the same time I would say think broadly. Robotics is no longer a discipline of mechanical and electronic and software engineering. It stopped being just mechanical, electronics, and software engineering nearly 20 years ago. So a robotics lab like ours now has neuroscience. It has biochemistry. It has psychology and philosophy and material science and animal ethology and so do not think of robotics as a narrow traditional set of disciplines. it is now much broader than that and for that reason, read widely. Read evolutionary biology. Read philosophy. Read Dennett. Read Richard Dawkins. Read Stephen Jay Gould. Read about the theory of mind. do not limit yourself to just becoming an engineer. Of course That is important, but think broadly because really the big questions in robotics and artificial intelligence are really very big questions indeed."
"Alan Winfield","Interviewer","Great. Is there anything you would like to add or anything we missed?"
"Alan Winfield","Interviewee","Well, no. I think you have just about covered almost everything I can think of. So yeah."
"Alan Winfield","Interviewer","Great. Thank you very much."
"Alan Winfield","Interviewee","you are very welcome."
"Aude Billard","Interviewer","If you could just start by telling us where you were born and where you grew up and went to school."
"Aude Billard","Interviewee","So I was born here, in fact, in Lausanne, and I grew up here, and I went to school, all of my high school here in Lausanne. And then when I started university, I started university here also at EPFL, and then I moved to Zurich for an exchange, at the ETH Zurich. So I was studying physics there. And after graduating from the bachelor/master in physics, then I went to the University of Edinburgh, where I did my PhD."
"Aude Billard","Interviewer","Who did you work with at Edinburgh?"
"Aude Billard","Interviewee","So, at Edinburgh I worked mostly with Gillian Hayes and John Hallam. "
"Aude Billard","Interviewer","What kind of projects were you working on?"
"Aude Billard","Interviewee","That was robotics. It was the early days of apply to robotics. So that was my thesis, basically. Neural networks. I also worked partly with David Willshaw, who was more on the connectionist side. And I also had a close interaction with Alan Bundy when I was doing my master, was more in automated reasoning, a field that I was interested in, but finally I went to robotics. I mean, automated reasoning is more the theoretical part of machine learning, and so finally I opted for the more practical application of robotics. "
"Aude Billard","Interviewer","What year did you get to Edinburgh?"
"Aude Billard","Interviewee","How did I get there? Well, , I was looking for a way to practice my English, go away from Switzerland, but I was not eager to go to the U.S. So Edinburgh seemed like a good compromise. It was a great school, highly ranked. It was I mean, the way they advertised for their program in artificial intelligence was to say that they were the sole department with the MIT that was offering that throughout the world. I actually had a scholarship to go to MIT, but I turned that down to go to Edinburgh. Shall I say that, by pure prejudices against the U.S., as an European? And yeah. I mean, the University of Edinburgh is a great place to be. So I have no regret over that. It was a great place to be, great people, and yeah, and it is beautiful country. "
"Aude Billard","Interviewer","Who were some of the other graduate students who were in the program when you were there?"
"Aude Billard","Interviewee","Yeah, That is so, Yiannis Demiris is one, and he is currently senior lecturer at Imperial College, London. And so he was one year senior from me, and he actually was the one who suggested . So That is the closest person I worked with. There were a few others, but I do not know their name. I mean, I cannot recall their right now."
"Aude Billard","Interviewer","And what was the state of robotics research at Edinburgh when you arrived there? Were there a lot of people working in that area?"
"Aude Billard","Interviewee","Yeah, I think it was really one of these departments that were a bit unique in this respect because they were putting a lot of money and especially for the U.K. in terms of just hardware. So they had a workshop with about ten people that were working there to build robots, to help us build robots. And there are a few institutions that actually afford that, so it was I mean, they really wanted to have robots. They were also trying to purchase robots out of the shelf, but of course it was difficult because at the time we had the first robots called Gillespie, which is this robot wheel-based, but it was before the pioneer robots came out. Myself, I had to entirely build robots because we could not I mean, I wanted to have a humanoid robots, and that did not exist except for Cog, so I built a Lego type of robot. I used Lego to build a small humanoid robot, to just have a platform that will fit my needs. The state of robotics at the time was all about wheel-based robots, sort of car-like robots. And maybe because I am a girl, I was not too much into car-like robots. I thought it was a bit especially I was interested in artificial intelligence in more cognitive processes, so with a car, it is really difficult to try to have some complexity. I wanted to teach language to robots, and two cars that talked to each other is is a bit odd. Yeah. "
"Aude Billard","Interviewer","Were many people trying to apply neural networks to the machine learning techniques?"
"Aude Billard","Interviewee","Say that again, sorry?"
"Aude Billard","Interviewer","Were other people trying to use neural networks research with robotics?"
"Aude Billard","Interviewee","That is correct. So neural networks were a very hot topic, bio-inspired type of robotics. At the time, at least in this department, was really sort of seen as the way to go. So there were different ways of being bio-inspired. Some people did a lot of reinforcement learning, which was already seen as bio-inspired, just from the idea of real-world signal. But there was this group, this large group, with David Willshaw and a lot of people that were trying to model the brain from a connectionist viewpoint. And since they were already next door, there were a lot of interaction between the AI people and these people. We were very inspired also by concepts from psychology. Hot topics were modeling language of bees, insect type of behavior, collective robotics. So yes, connectionist models in general were viewed as one approach that one should pursue. So some of the graduate students were looking at genetic algorithms as one way to evolve the neural network. I personally took more of a theoretical road. I was trained in physics, so I was more trying to develop the math behind the network itself, how we could exploit temporal and spatial information at best, and changing classical Hebbian to increase the capacity of the network. So I was taking a more systematic approach to this, which of course scaled down the scope of the application of the neural network that I could do compared to people who were using genetic algorithm and had a larger variety of application and complexity in the type of application."
"Aude Billard","Interviewer","And what was the application? What were you trying to get the robot to learn?"
"Aude Billard","Interviewee","So, the application that I did was to have a robot learn from human guidance a simple vocabulary. And so you would have either a leader robot that knew how to label all sort of things or places or direction or commands motor commands, going left and right. You had a leader robot and then you had a follower robot, so you had two robots that will follow each other, and the follower, which is a little bit like a baby following a mother, will hear the mother talk and try to associate its perception of the environment with the speech of the mother. So it was the early days of what is called a simple grounding problem how could you ground words into various perception from the viewpoint of a robot? And this perception could entail sensory perception as well as motor perception. And there were basic problems, such as simply the mother being a bit ahead I mean, seeing things before the follower or the child will see them; will speak before the child will actually see or perceive the same thing. And this is what you find in nature too. So I thought it was very interesting to try to embed in a connectionist how does the brain, in effect, use this temporal delay between we talk about drawing attention. We say that we both look at the same thing at the same time. it is not true; there is always some type of delay. How do we encapsulate that in a relatively generic manner? So the application was language. We also worked, together with Kerstin Dautenhahn, who became then my second official advisor, even though she was not in Edinburgh at the time. We looked at how we could apply the same type of algorithm to teach a humanoid robot so a little doll robot a language. And so basically the application was grounding, simple grounding, or teaching a simple vocabulary. it is not really language; it is a proto-language."
"Aude Billard","Interviewer","But there were not a lot of people working in language learning within robotic systems at that time."
"Aude Billard","Interviewee","No. The only person who had done something at the time was Holly Yanco, during her Master's thesis at the MIT. But there were a lot of people talking about language and trying to develop model, but it was mostly linguistic people. So you had Steven Pinker, had written a very important book. You had Bickerton. You had a number of people. And these people also came to U.K., came to Edinburgh, so if you want to the spirit was there, but in robotics, no, very few people were looking at that."
"Aude Billard","Interviewer","And what year did you finish your PhD?"
"Aude Billard","Interviewee","I finished my PhD very rapidly. In fact, I did my PhD in really exactly the amount of time that was obligatory so three years, but that includes also the Master's, so it was really I finished in 1998. In September 1998."
"Aude Billard","Interviewer","And where did you go from there?"
"Aude Billard","Interviewee","I was actually contacted by Maja Mataric for doing a postdoc with her, but then for six months I first came back to Switzerland, in between we were formalizing the contract to go to USC. So I worked here in Switzerland at the EPFL with Professor Nicoud. We actually to create a startup that is now studying the robot doll that I created during my thesis. And then I went for a postdoc with my Maja Mataric at the University of Southern California for a year. And then I was promoted as an assistant professor there, and I worked together with Stefan Schaal and Michael Arbib."
"Aude Billard","Interviewer","So the doll that you worked on here with Nicoud, that was an experimental doll or a custom doll, or ?"
"Aude Billard","Interviewee","No, so yeah, we so I had built a doll that was made of Lego when I was in , and then when Jean Nicoud saw that, he said, Oh, we need to redesign that. We should be able to miniaturize that. We have everything at EPFL. We have workshop for this. And so I wanted to really keep the aesthetic aspect of the doll, and so I simply went to shops and purchased a classical doll that you can find, and took everything out and then replaced that with well, we kept some of the original motors. We changed some of the motors, we changed the gearing, and we changed the electronics to enable full control while keeping the complete aesthetic of the doll that is created by classical manufacturer. So."
"Aude Billard","Interviewer","Did you try to encode facial expression?"
"Aude Billard","Interviewee","That would have meant to redesign entirely the doll, because it is very difficult. You need to have skin. So I was very interested in that, but there was no time and not really competencies at the time. And of course you needed to have a lot of tiny motors . I did purchase at the time that what was it called? Amazing Baby? Or there was this doll created by Rod Brooks."
"Aude Billard","Interviewer","My Real Baby?"
"Aude Billard","Interviewee","It was My Dream Baby and My Real Baby. You had My Dream Baby that was created by Hasbro, and it was a competition with My Dream Baby. And so we purchased My Dream Baby to have the facial expression, and we tried to the same thing, but no. Yeah, I mean, it stopped there, so did not get the chance to go further. Finally, I mean, we created a smaller, simpler doll, which had five degrees of freedom and we produced about 40 of these, which were sold to various museums and educational purpose. "
"Aude Billard","Interviewer","So in terms of the degrees of freedom and the relation to language, so things like eye direction and pointing and what are the essential elements?"
"Aude Billard","Interviewee","Yeah, we tried to look into that, but basically the language at the time was only about sensory input and simple motor commands, so just turning the head left and right, moving the limbs, or have a notion of what is on your left side and on your right side of the body; what does it mean to lift up, so what is this relationship in terms of the central point of your body. We did not look at eye I mean, direction of the eyes. We did build I should show you that we did build small eyes that can rotate and we embedded them with cameras, but we never I mean, we never used that for language learning."
"Aude Billard","Interviewer","How did the field of language grounding evolve from then?"
"Aude Billard","Interviewee","I left it, so I do not know. it is funny that you ask me that, because I discussed I was at just last week and I met two people from Nick Roy's lab, and I am so surprised to see that They are moving into more of language now. There again, , I am so glad that people are revisiting that in a different viewpoint. So I think that people left a little bit that field for quite some years, and They are revisiting now this field from more a planning viewpoint, grounds, language commands. You also had people in Germany that were looking at using language as a formalism to guide the robots through steps in programming by demonstration. So I have not followed the field that closely. My impression is that it did not progress much as far as robotics is concerned. There is a lot of work being done more in AI or simulation, but in real robots I think that I mean, of course there is the RISE group that is doing a lot of work in this respect, and there was Jun Tani's group also that continued "
"Aude Billard","Interviewer","Luke Steele's has been ."
"Aude Billard","Interviewee","Luke Steele's, but my impression is that he stopped working with robots. I may be mistaken, again. I remember where the two talking heads, and then "
"Aude Billard","Interviewer","I do not know. I interviewed him, but."
"Aude Billard","Interviewee","You interviewed him?"
"Aude Billard","Interviewer","I did not see any robots, but."
"Aude Billard","Interviewee","No, no. I think that he moved away from robots. Yeah."
"Aude Billard","Interviewer","So when you got to USC and you were working with Maja, what was the project?"
"Aude Billard","Interviewee","So there, we were really focused more on imitation of motion. So we were interested in designing, again, I mean, a bio-inspired controller that could explain the way you process visual information and then you transform that into motor commands. So this is closely related to the so-called Carussman problem. it is a very broad topic in programming by demonstration. it is one thing to interpret other people's motion; it is another thing to actually be able to reproduce this. Even though we may have the same body structure, there is still a lot of Carussman's issue that needs to be resolved. So we looked at that from a connectionist viewpoint. Together with Michael Arbib we also looked at how this could relate to some brain areas and connectivity across different brain areas. A hot topic at the time was a mirror neuron system, and what role does it have in transforming this information, simplifying to some extent this Carussman's problem, maybe at the level of action rather than the level of detailed motor commands. So that was the topic. "
"Aude Billard","Interviewer","And what kind of system did you build to explore that?"
"Aude Billard","Interviewee","We did not build any system. We were very much in simulation at the time. At USC. We used so together with Stefan Schaal, we got the opportunity to go to Japan at ATR in Mitsuo Kawato's group, and use the platform that was called DB. it is a very power or was a very powerful humanoid platform, completely hydraulic, that enabled very smooth control of the motion. So the work was put onto the other platform, but there was no creation I mean, there was no hardware design at the time. In fact, if you contrast That is what I said at the beginning. In Edinburgh, they really put a lot of money to have technicians to build the hardware, but this is very rare, and USC was more of a computer science department, so there was no actual workshop. So hardware had to be purchased ready-made."
"Aude Billard","Interviewer","And how long were you at USC?"
"Aude Billard","Interviewee","So, I was at USC for three years. A little more than three years, yeah."
"Aude Billard","Interviewer","And then how long were you in Japan?"
"Aude Billard","Interviewee","Oh, in Japan, I visited while I was at USC, so for a period of one month or more."
"Aude Billard","Interviewer","And did you have other collaborations while you were at USC?"
"Aude Billard","Interviewee","Well, within USC we had a very large network of collaboration. I will say at large, within the different departments, I think it was it was just a fantastic period and everybody recalls it as such. You had a group from for instance, you had Gerry Loeb, who was doing all of this very detailed model of the way motor control is done at the level of the muscles. And then you had all the department from physical therapy that was looking at how impairment following from stroke resulted in impairment in motor control, especially imitation. And so there were a lot of collaboration between these departments at large. And I also collaborated briefly with the University of Notre Dame. With Steve Boker. Yeah."
"Aude Billard","Interviewer","What was Maja like to work with?"
"Aude Billard","Interviewee","I would like to skip this question."
"Aude Billard","Interviewer","What was Michael Arbib like to work with?"
"Aude Billard","Interviewee","He is very fascinating in a way. Really, he is I think he is extremely smart and has a very good understanding of the issues at stake that nobody really looked at, that we are passing by all the time. I think he was one of the best person I had to review my papers. He is really the best reviewer you could ever had before you actually send your paper out for review. So it was very enjoyable."
"Aude Billard","Interviewer","And what was John Holland like as an advisor?"
"Aude Billard","Interviewee","I am sorry, who?"
"Aude Billard","Interviewer","Holland, as an advisor."
"Aude Billard","Interviewee","John Hallam? He was not directly my advisor. Sorry, John Hallam, not Holland. Yeah. "
"Aude Billard","Interviewer","Who was your direct advisor?"
"Aude Billard","Interviewee","So, I mean, it was really Kirsten Dautenhahn and Gillian Hayes. "
"Aude Billard","Interviewer","What were they like to work with?"
"Aude Billard","Interviewee","Gillian Hayes was I mean, is a physicist by training, so she was very helpful in terms of providing guidance in the development of the mathematics of the model. And of course she was a very gentle and nice person, kind, to work with. Kirsten Dautenhahn provided a lot of just the background that I was interested in as a general aspect in terms of the biology behind imitation learning, she had a bit like Michael Arbib she had this extensive knowledge that I lacked because I came with this more mathematical background, and she was providing the other view of the topic that I wanted to tackle, which is what do animal do how do they come to imitate; what does that mean; what is imitation; what is all of these terms that come from psychology or biology or zoology in general. But she also I mean, I think that she was really a pioneer at the time by bringing together robotics and core notion of biology. She wrote a core paper in 1995 which I see a lot of people not necessarily quoting but literally reusing the same ideas, so I do not think this is the best way to show how pioneering the ideas were, because people heard them and maybe they they forgot who wrote that in the first place. But they were so powerful and so clear that you see them in most papers these days. The correspondence problem she was the first person to point it out in imitation learning, and you would think it is obvious; everybody talks about it in various ways these days, if people are talking about it in terms of transfer of force control, impedance control. At the time she was just talking about it in a much more generic sense, but if you read her paper she was already detailing it at the level of either, indeed, body motion, low-level type of control, or very high-level type of control. So I think that she was more than inspiring. I mean, she was and she has always been a support to me."
"Aude Billard","Interviewer","How would you describe the correspondence problem?"
"Aude Billard","Interviewee"," How would I describe the correspondence problem? Hmm. Basically it is you look like me but you are not like me, so what is the difference? "
"Aude Billard","Interviewer","Why is that such a hard problem for robotics?"
"Aude Billard","Interviewee","it is to define the difference and to be able to still find similarities and find some common ground so that we can relate to each other. So this is not easy, because it is highly task-dependent. it is body-dependent. it is context-department. There is no generic rule. And robots, this is no generic body; there is no generic kinematic for robots. We keep building these. As we all know, just determining the dynamics of a robot is an open problem. it is called system identification. So this is the same for humans. We constantly identify our own dynamics; it changes from day to day, depending on tiredness or other factors. So this creates a problem. You have to identify what you want to reproduce in a behavior that you observe from an expert that is teaching you a new behavior, and then you have to learn how to adapt your own controller to achieve the . And learning how to adapt your control to achieve is extremely difficult. This correspondence problem is phrased differently. People call that also inverse reinforcement learning, for instance. it is part of defining the cost function what is important and finding the optimal control policy to achieve this. So there are different way of phrasing the same problem, but it is a core problem. it is a core problem in engineering. Once you have defined the cost function, then you will say, Okay, now all the problem is just optimizing the , assuming that you have a good model and optimizing the policy, the controller call it what you want. But there are various ways to optimize that. And if you made a poor choice regarding a cost function, then everything needs to be redone. So people are I mean, people are discovering now that the two problems are really tightly linked. And That is why it is very interesting to see that there are people that try to learn at the same time the cost function as they do the controller. And so the correspondence problem is in effect this issue. it is two questions. it is where is the correspondence, and how do I achieve correspondence?"
"Aude Billard","Interviewer","And how does this relate to the challenges of human-robot interaction?"
"Aude Billard","Interviewee","it is core to that, because if you want to interact you need to have a way of exchanging signals that are meaningful both ways. And this is also related to some extent to language. I mean, language is there as a way to ground even though you have different perception to ground them into something that we will agree upon. So usually we have a single word to define the same thing even though we may perceive it very differently. So human-robot interaction implies that we interact. So we will share the same environments we may not perceive it the same way and we may act together onto the same set of objects. So what does that really mean? Because we will have to exchange, interpret other people's behavior, so the robots will have to interpret the human behavior. To interpret the human behavior needs to have either a good model of the human, or to relate this model to its own behavior. And so in the particular case of using the human as a teacher for teaching the robot to do things, which is one particular aspect of human-robot interaction, then the correspondence problem takes over its place, like I explained before."
"Aude Billard","Interviewer","In that regard, is it an easier problem if the robot is a humanoid form, or does that make it harder?"
"Aude Billard","Interviewee"," Of course in a way it is easier. it is easier because if you can embody the robot, as we say, or doing so-called kinesthetic teaching where you assume that the robot is so you can actually move the limbs, then it is much easier because usually the human robot will have about the same size as you do, so you could almost transmit each of your drawing's motion to the robot's; you will have just the problem of scaling, to some extent. If you contrast this with an articulated arm that is planar in its motion like most of robots or some of them that we have in the lab then the only way you can actually guide a robot is by using the end-effector, because the drawings I mean, the construction of the drawings is so different that it is and also the size of the robots, and maybe the robot is also too powerful so it is becoming dangerous to actually guide a robot. So in this respect, just from a pure experimentation viewpoint, it is easier. it is also easier for humans to sort of predict the motion of the robots the first time they see it. At least That is what they expect is that they expect motion that will look similar to human, and That is the idea with human robot is that we will generate motion that are closely related to that of human. Just the workspace of the robot is similar to the workspace of the human, so you know that the end-effector will move within some sphere and following a continuum that is similar to the continuum that you have seen in human motion. Or else if you see a robot that does not look like a human than you need to look at it for quite some time to get a sense of the kinematic of this robot, its dynamics. So it is a bit like watching a I do not know a spacecraft for children, or a car simply learning the design. it is not just any animal. So it is easier in this respect. But still it is not easier because the correspondence is still there. Humanoid robot is still very different from a human. Joints are usually attached linearly. We do not have ball joints, clear ball joints, as we simulate them. Yeah, we do not have this idea of the synergy of muscles for driving the joints. The size is not the same. The dexterity is not the same. So maybe the difference almost subtle, their model level of the dynamics of the control or the range of motion, rather than the kinematic. So it solves only part of the problem."
"Aude Billard","Interviewer","And in terms of the language I mean, I think intentionality would be a big factor, and that sort of gets you into this problem of other minds and things like that. Do you worry about those?"
"Aude Billard","Interviewee","No, I think I would like to skip the question, because intentionality is such a difficult problem, so you are I have not studied really psychology and philosophy, so I stay away from these terms because I am not sure I have the right definition."
"Aude Billard","Interviewer","Well, in terms of language grounding, this issue of pointing at something, and the idea that an animal or a robot would pay attention to the object that you are pointing at instead of the end of your finger sort of making that leap about "
"Aude Billard","Interviewee","So your question is do we get "
"Aude Billard","Interviewer","Is that the kind of problem when you are dealing with language learning in these correspondence systems that you try to deal with? Like how do you get from pointing at something instead of just holding out a finger?"
"Aude Billard","Interviewee","We do not. We build that in. I know it is a stage in development in children that is very important, and that I mean, it is something that differentiates some species from other species in terms of the complexity of their understanding and, yes, this is related to the theory of mind. Yeah, I think that we are very far from that in robotics at this point in time. So we have not addressed that properly. Either we provide a robot with already this competence of not looking at the finger but looking at where the finger is pointing at. So that we did at some point in the lab; we looked at that from just a probabilistic matter. I mean, you will use the direction that is being pointed at as one way to narrow the attention of the robot, so to decrease the amount of information that a robot is provided with by simply looking at at the intersection between the cone if you look at your finger and you added some uncertainty then you can look at this as a cone; then you look at the intersection between this cone and the first planar surface that you find that has some interesting properly or either it is endowed with objects that could be interesting. But again, all of that is built in. So it is providing the robot with a lot of prior knowledge as to what is interesting in the world. So it is bypassing several stages of development."
"Aude Billard","Interviewer","And over the time that you have been working on this problem, have you seen an evolution in the sort of complexity and the sophistication of the approaches? What have been sort of the milestones of problems you have solved, and then sort of built more on another level?"
"Aude Billard","Interviewee","Well, I realize that instead of growing in terms of the complexity as we call of complexity of the competencies, I am going the other way around. I am going lower and lower level by the day. So it is growing in complexity but in different way. So I started with language, which is very symbolic, very high-level type of understanding. Went down to having sequence of motion, so you will say moving away from language to just pure motion. And now we are at the level of just doing force control. So we are just trying to get a robot to solve the correspondence problem for doing a simple trajectory. And it seems so basic, but I really want to understand this well before I go back up, and to try to have a very good understanding of basic law of motion and how we control our body and how we can use this for also perceiving motions of other entities. So it is sort of growing in the complexity of the low-level controller that we have in our brain or elsewhere that we need to endow the robot with, and make sure that this piece is well understood before climbing back the ladder and then going to more complex type of interaction. So."
"Aude Billard","Interviewer","And in doing that, do you look a lot to human and animal models of development?"
"Aude Billard","Interviewee","Unfortunately, no. We are moving away from that, because very little is known about how animals really control I mean humans control their body. And to some extent well, That is not true, actually. Scrub that. Because it is not really we still use the human all the time as the teacher, and we try to infer a level of control, even at the level of force control, from the human. But if you take simple impedance controller, there is a lot of debate as to whether a human actually controls their muscles and their limbs this way. So I will say we use state-of-the-art type of controller in robotics and use the human as a way of identifying the open parameters. But that does not mean that the human is actually using that for controlling his or her own body. I mean, we do look also at doing computational model of the way human process information, so that is always one part of the work that we do in the lab. So, recently we had Biljana Petreska who just graduated; she is at Harvard now as a postdoc. And she did very interesting model of the way the brain is affected after lesion following from stroke, and how this lead to apraxia, and apraxia is one particular form of inability to control one's limb. You put in a request so it is formation of imitation. So, yeah, we do a little bit, of course."
"Aude Billard","Interviewer","And it is very much on sort of the boundary between perception and motion, right? I mean, you have really both sides of the problem. You have all the problems of perception and all the problems of control."
"Aude Billard","Interviewee","Yes, but it is tightly linked, especially if you think in terms of control. I mean, there is the perception of the external world and there is the perception of your own motion, and they probably rely on the same mechanism. So yes, we tend to think that this is a continuum and not two separate process. Sorry, I think we are drifting into "
"Aude Billard","Interviewer","Yeah, yeah, yeah. So you mentioned a student who just went to Harvard. Who have been some of your students, and where have they gone?"
"Aude Billard","Interviewee","So, Sylvain Calinon is a senior researcher at the Italian Institute of Technology. I think he is by now very well respected for the work that he did during his thesis in programming by demonstration, especially tackling one part of this correspondence at large, the so-called what to imitate so what is important to extract in a demonstration; what should you pay attention to. He got a couple of awards for his studies in this respect. So, I mean, these are two major people."
"Aude Billard","Interviewer","And who are some other people you have collaborated with?"
"Aude Billard","Interviewee","I collaborate currently with Jacqueline Nadel, who is a psychologist, but this is a different topic in the lab, where we developed a wearable camera that you put on the forehead of children to monitor their gaze behavior. This has application possibly for early diagnosis of autism. So trying to monitor whether children very early on tend to not look directly at other people's eyes, which is one particular deficit that is relatively widespread in the autism spectrum disorder. That is it. "
"Aude Billard","Interviewer","And in terms of funding, where do you who is been sponsoring your research?"
"Aude Billard","Interviewee","Right, of course. So, in Europe, we get a lot of funding from the European Commission, and of course this each time entails collaboration with various people in Europe, but also in the world. So I should have mentioned that we have been collaborating now for three years also with AIST and the JRL Lab in AIST with Abdurahman Khadr, who is a director there. And we worked with the HRP-2 platform on developing control for enabling a robot and a human to carry collaboratively a load. So we get a lot of funding from the European Commission. I will say two-third of the funding comes from the European Commission. The rest comes from the Swiss National Science Foundation. We also get a little bit of funding from industry, but it is very minor."
"Aude Billard","Interviewer","And was that similar when you were at Edinburgh?"
"Aude Billard","Interviewee","When I was at Edinburgh, I had a scholarship. Yeah."
"Aude Billard","Interviewer","And also at USC?"
"Aude Billard","Interviewee","At USC no, I was paid by USC. But I was paid by the National Science Foundation the U.S. National Science Foundation at USC."
"Aude Billard","Interviewer","So what are some of the other humanoids that you have been working with?"
"Aude Billard","Interviewee","I think I listed all of them. There is the iCub, HRP-2, the DB robot, and of course the robot that we built here. So Robota, we have various version of this. And the Fujitsu HOAP-2 and HOAP-3 robot. And yep. That is it."
"Aude Billard","Interviewer","What do you think of the iCub?"
"Aude Billard","Interviewee","I think it is a wonderful platform. it is really unique. it is funny, because before we went onto having robot Cub, the first project that created this I mean, we had a conversation over dinner at AISB in what was it? 2003, I think. It was Giulio Sandini, is the person who really created this. And we brainstormed over the dinner that it would be so wonderful to have a humanoid platform that will be completely open source, both at the level of the hardware and the software, because we so much needed that. At the time we had only Honda; you had the QRIO robot, but they were protected; nobody could actually access the hardware, so it was impossible to duplicate it. They cost a lot of money. And so we thought it was really hindering research in human robots, and we needed to have that. And then we got lucky. I mean, there was this funding that came, and Giulio and his team did a great work building this platform with other people. And so now you have this robot is being duplicated lots of places. Of course it is a prototype, so I will not very frequently. We fix that all the time, but I do not mind, because it offers an opportunity to explore a complexity in terms of hardware and control that is not existing for any other humanoid robot, as far as I know. And there are great platform to make a robot is great, and I think this is the closest platform in terms of complexity, but it does not have legs. It does not allow you to have the full scope of motion. You have this bigger platform, like HRP-2 or now the new robot that they have at TTR, which has . But again, They are so incredibly expensive that very few labs can have them, and they do not have this open source framework. So we benefit a lot from this open source because we post, of course, the code that we develop all the time, but we also benefit from the code that is being posted by other people. We were lucky also to be part of different project that improved the current version of the robot, and the new project on endowing the iCub with skin, tactile sensing. I mean, it is offered us the ability to explore new ways of doing manipulation without having the classical forced closure approach, which is what I love in the iCub is that it is inherently noisy and it breaks, and I love this, because that forces us to really tackle the complexity of having very robust controller, not something that relies on perfect sensing and perfect actuation. The type of control that we have in humans our sensing is extremely noisy. Even our actuation is very noisy. People never over the same trials repeat exactly the same kinematic. Still, we manage very precise, skillful behavior. And so the iCub, in this respect, offers the complexity in terms of the number of degrees of freedom and the complexity in terms of the sensing and the actuation, that is really forcing research to go one step forward in designing controllers that are truly robust."
"Aude Billard","Interviewer","In terms of the open source, is it an open source operating system, the kind that the Willow Garage kind of brought us, or is it a different model?"
"Aude Billard","Interviewee","Yeah. In fact, as far as I understand, YARP and ROS are very similar. In fact, because we were in two European project, one needed to have everything coded in YARP, the other in ROS. We are forced to now pass from one to the other all the time in the lab. And so we have , and it is relatively straightforward. So That is the same principle they have, SVN is it SVN? repository, where you can post all of the codes. it is fully documented. So YARP is sort of this I am not really a computer scientist, so I do not know what the terms are, but it is really sort of middleware. it is very similar to ROS, offers the same type of modularity. I think that sort of the major difference between ROS and YARP is we do not have I guess the YARP people do not have as much money as the ROS people, so they do not advertise as much. And I think it would be sad if they were not to collaborate in the long run. My understanding is that ROS was to some extent the revision of YARP, but do not quote me on that. So it is similar. I think the advantage of ROS is that a lot of people now are really posting a lot of code for also Vision . Not necessarily directly robotics, a lot just for the sensing part. And we have benefited from that in many ways here in the lab. I guess most of the codes right now that is being developed for the iCub under YARP is really dedicated for the iCub platform, whereas ROS seems to be applied to more type of robotic platform than just the PR2. There is the one Barrett one, I think, at least, and maybe other platform. "
"Aude Billard","Interviewer","Great. And what about QRIO? Is that a good humanoid platform or does that have limitations that the iCub will not?"
"Aude Billard","Interviewee","I wanted to have a QRIO, but as you know they stopped producing these. it is finished, since they changed CEO two years ago and they closed down the Sony Research Lab. So I do not know. It seemed that it was a fantastic platform, but nobody really could had the chance to really use it."
"Aude Billard","Interviewer","Yeah, some things happened with the Sony humanoid as well."
"Aude Billard","Interviewee","Say that again?"
"Aude Billard","Interviewer","The Sony humanoid for the "
"Aude Billard","Interviewee","But That is the QRIO. QRIO is the Sony."
"Aude Billard","Interviewer","Oh, That is the Sony."
"Aude Billard","Interviewee","Yeah, That is the Sony one. Yeah. Maybe you meant the Fujitsu HOAP? So the HOAP-2 and HOAP-2 robot, or the Nao, Aldebaran?"
"Aude Billard","Interviewer","Nao. Yeah, the little "
"Aude Billard","Interviewee","So, we never got a chance to really work with Nao, but we know well Aldebaran Robotics. I mean, all the feedback I heard from people using it is that it is a very variable platform and very I mean, very well, very well made. I think people use it mostly for soccer, right? So we did not purchase it because it is not meant for manipulation and we were really doing a proper control, and so it is small, so it is not a platform; it is just not meant for that. You know that They are designing a new platform which will be called Romeo . And I believe it will be about one-meter-thirty centimeter. So in this respect, it is probably sort of a replacement of the QRIO. Or not. The Fujitsu HOAP-2 and HOAP-3 were fantastic platform. They really worked immediately on the first day of use. People came here, they installed the PC, it was open source, running real-time . This is the easiest platform we have ever used. We had never a single problem, not even on the level of the hardware. And I really insist on that, because I cannot say the same about much more expensive platforms, such as the Barrett. Which is a real problem."
"Aude Billard","Interviewer","And what do you see as the big problems in the future of human-robot interaction and imitation and correspondence?"
"Aude Billard","Interviewee","that is a tough question. I do not know. I am not good answering these questions. Can I skip?"
"Aude Billard","Interviewer","Sure. Then I will just ask you what do you think are going to be the big applications and breakthroughs in robotics?"
"Aude Billard","Interviewee","Yeah, but these are the type of questions . You really need to have that from everyone?"
"Aude Billard","Interviewer","it is one of my questions. I mean, where do you see it going? What do you think is going to be the exciting problems that you want to work on in the next few years?"
"Aude Billard","Interviewee","I mean, it is not the current breakthrough that we are living through is really and doing all of these platforms with tactile sensing. I think this really changes a lot the type of interaction we can have with robot. There are so many different groups that are trying to develop now tactile sensing that is very modular, which you could then place on arbitrary type of robot. So if and I am pretty certain that this will happen within the next few years, because there are also companies that are working on this. And this will provide so much more flexibility in terms of the control, starting with just the robot being able to discover when it is hitting itself as basic as that. When it is also there are people working on technology that can differentiate between touching an object, non-living object, and a living object, meaning sensing temperature, either from a distance or directly through direct contact. I mean, this offers one possibility for a robot to distinguish between hitting an obstacle and hitting a human, and then acting accordingly, which is things that people have looked at in the framework of impedance control, but from purely sensing forces, and this is much more natural. Again, if you endow the complete body with this, this will be very important in human-robot interaction. It will provide some level of safety and coherence in the behavior. So this is a breakthrough in sensing that we are undergoing right now, and will probably offer a lot of avenues of research within the next, I do not know, 25 years. Following that, I do not know. I personally am very intrigued you mentioned facial expression. I am very intrigued by what people manage to do in terms of complex facial expression and expression of emotion or recognition of emotion in others. I have never done it myself it is bizarre, because people contact me sometimes to review papers on this. I have never, ever written on that topic, ever. I have expressed interest. I do not know why people that I should be doing that. But I am intrigued, and We will try to see how much this could be used in the framework of the interaction with humans. So when the human teaches a robot, it is often difficult to see what the robot is really learning from what you are teaching, especially as you go lower and lower level. When you teach information such as force, these are not information that you can really spell out. You cannot tell the robot, Apply 10 newton meter more. However you can say, Move 10 centimeter away from this. So it is so the notion of force is there. We can show the right force to be applied. We have a very clear idea of where the force is, but we cannot express it. And now the problem is: Is the robot now interpreting correctly what I am saying, and how could the robot express that back in a way that I could understand it? And so we may look at facial expression in this respect and maybe my feeling is that maybe there is a little bit of a split between people doing more emotion-based, psychology type of work in robotics, and the pure control people, and they talk to each other. it is a bit like splitting between pure technical approach and human science, and I do not know why there is such a split. And so possibly if people manage to convince each other that They are doing valuable research then this will be probably a step forward for robotics. But how to bridge that, I have no idea, and this will take years. There are a lot of people that believe in flexible actuators, passive compliance, etcetera. So, it seems to be the way to go these days."
"Aude Billard","Interviewer","In terms of the tactile sensing, do you think the big technological hurdles are primarily the materials or the integration of the sensory data? Or a bit of both?"
"Aude Billard","Interviewee","it is probably both, and the interpretation of the data. Because you have tons of it, then you are really you have again the what question. What is important, and when, and what for? So I mean, from a technology viewpoint, there are so many people working on this that suddenly they will find various solutions very rapidly. I mean, capacity sensing is and there are plenty of solutions these days. There are people looking at how to sense stretch, which is something that is very useful to . So I think the challenge are, at both level, as you improve the hardware and provide more and more information, whether it is temperature, the direction of the forces, the flexibility of the material flexible material means also that you do not want it to break, to have this flexibility and keep this flexibility over time, like the skin does. Replacing these I am scared what will happen if we have these robot at a and then one patch breaks. Can we just plug in in plug and play? So yeah, there is this aspect, and there is a sensing aspect, and just providing all this information in real time. And then finally there is the interpretation of this information. In real-time. So, yeah, That is why there is room for research in the years ahead."
"Aude Billard","Interviewer","So young people who might be interested in robotics research, what would you recommend? What would you advise them to study?"
"Aude Billard","Interviewee","You mean prior so what type of undergraduate studies they should be doing? My advice is really to go to I mean, I think without a strong background in math, you will need feel comfortable. So my advice is to take core engineering degrees. does not mean that they cannot do a secondary degree in psychology afterwards or other things, but this is not something that you read at bedtime. You have to have taken classes. You have to have been trained. And if you do not have that, our problem is that often you find works that are not where people simply do not have the background and sort of miss out on simple solutions from just the mathematical standpoint. I mean, sometimes they math is just math. it is not difficult, but it takes time to understand a mathematical equation. You have to get used to that. it is like a new language. So you have to train yourself. And once you are familiar with this, then it is easy to understand it. And I see too frequently that with some of the computer science degree that are being given out, They are somewhat too light in terms of the math studies provided, and ultimately the graduate student suffers from this, because yeah, because they just do not know where to look for the answer, how to train themselves. it is too late. So That is my advice. it is strong advice. I know it is tough, but it is really to their advantage. it is only to their advantage."
"Aude Billard","Interviewer","And how did you make that sort of switch back from graduate school from physics into interest in neural networks and psychology?"
"Aude Billard","Interviewee","But I did my master at CERN, which is the European center for particle physics, so I specialized in particle physics. And at the time, people were using artificial networks as an alternative to other statistical technique for extracting out of the massive data that we are getting one particular peak that will represent one particular split in the particles. And bizarrely enough, artificial networks were not being taught to physicists, even though most of the theory has been developed by physicist. So it was not part of the curriculum, and so I did not feel comfortable using this tool, just as a tool, without understanding the math behind that. And so I went to do a Master's thesis of the University of Edinburgh because they were offering a Master's in so-called knowledge-based system that was teaching the basic math behind all of these so-called artificial intelligence type of technique that were viewed as alternative to other classical statistical technique to analyze multidimensional data sets. So I went to Edinburgh for doing this master, and one of the class that was compulsory there was a class on robotics. And that was taught by John Hallam. And I spent hours building a robot with my partner at the time. We won the competition. And so it was implementing a type of non-connectionist controller, and I thought I do not want to just do physics any longer. I want to build things also. So That is where I went to robotics. Yeah."
"Aude Billard","Interviewer","Is there anything we missed or anything you would like to add?"
"Aude Billard","Interviewee","No, I think as far as I am concerned I am good."
"Aude Billard","Interviewer","Good. Well, thank you very much."
"Bernie Roth","Interviewer","Okay. Can you just start by. "
"Bernie Roth","Interviewee","Do you want me to sit back? "
"Bernie Roth","Interviewer","Whatever is comfortable for you. "
"Bernie Roth","Interviewee","Okay. "
"Bernie Roth","Interviewer","And That is kind of from here just about where your hands are. "
"Bernie Roth","Interviewee","you are getting my chest? "
"Bernie Roth","Interviewer","it is flesh tone. It will match. "
"Bernie Roth","Interviewee","Okay. do not matter. "
"Bernie Roth","Interviewer","But you can just start by telling us where you were born, where you grew up. "
"Bernie Roth","Interviewee","Sure. I was do you want my name also? "
"Bernie Roth","Interviewer","Sure. "
"Bernie Roth","Interviewee","Sure. I am Bernie Roth, and I was born in the Bronx, New York City, and I grew up there. I went to school there and stayed there until after I finished my PhD. Do you want me to go back into the details of schools there? "
"Bernie Roth","Interviewer","Yeah. Whatever you can. "
"Bernie Roth","Interviewee","Sure. I went to high school in New York, and I started a high school called Stuyvesant High School. And then I, at one point, transferred to a local high school called Christopher Columbus High School, where I graduated from. After that I went to City College in New York, and I studied mechanical engineering there. And when I graduated, I got a job as a lecturer at the City College of New York and also as a lecturer in the art department at Hunter College in New York. And I picked up a wife shortly before that, and then started my graduate work. And the way it worked in those days, people would teach at the city college during the day and then sort of go to evening school. It was not really night school. The classes at Columbia University would start, like, at four in the afternoon or six. So, I did my Master's that way, teaching at City College and studying at Columbia, also in mechanical engineering. And then I went on for my PhD under a similar system. And when I got to within, say, two years of the end of my PhD, I left the job at City College and got some financial support through a fellowship at Columbia and finished my PhD there. And then after I graduated, by then I had accumulated two children in addition to the wife, and moved out to California, to Stanford, to take my job this 1962. And here I am, never left since. So That is kind of. "
"Bernie Roth","Interviewer","What was your PhD thesis work on? "
"Bernie Roth","Interviewee","It was an area called kinematics. It was the science of motion. And I did something called synthesis of mechanisms, which was basically the idea of someone gives you some requirements, and you figure out what the dimensions of the mechanisms should be. And in that, I developed something called continuation method, which became kind of a very famous mathematical way of solving nonlinear equations. So it was basically using computers very early on. I was probably the first of my cohorts to use computers. And the machines we used were the IBM 650s, that had 2000-word memory. And somewhere in my thesis that was not big enough, so I found a machine with a double memory, so with 4000 words. And it was up in a physics lab Upstate New York, where they were looking at bubble chambers, so they needed to have better calculations. But if you went at three in the morning, so from three to five in the morning, I could get the machine. So, that was my life as a graduate student. "
"Bernie Roth","Interviewer","Where was it in Upstate New York? "
"Bernie Roth","Interviewee","it is right near where the Headless Horseman was. "
"Bernie Roth","Interviewer","Sleepy Hollow. "
"Bernie Roth","Interviewee","That is right. Sleepy Hollow, all that. it is on the Hudson. It was I forget what it was called. It was a little bit above Hastings on the Hudson, but it was, I forget the name of the city. But Columbia University had a lab there, and That is where it was, yeah. "
"Bernie Roth","Interviewer","And how did you wind up at Stanford? "
"Bernie Roth","Interviewee","Oh, that is an interesting story, in that there is no way I was going to leave New York, because they offered me assistant professorship at Columbia, and I was pleased to take it. And my professor was like, it was the best place to be for the field. But the problem was I was saddled with this wife, who, she was switched at birth, and she ended up in New York, but she was not supposed to be. So, but basically, in spite of that, I was going to stay there. And my thesis professor at the time, before the Columbia thing was settled, said, You know, you would better hedge your bets, so probably you could stay here, but let us look around a little bit. And among the things he said, You know, I met some guy from Stanford at conference, and you know, They are building up. Maybe I should contact him. So, he contacted him, and it turns out the guy he met was there were two people at Stanford with the same name. And this one fellow had come to this conference even though it was not his field, but it was a free trip to Yale. So he went there, and it was totally the wrong guy. But when the request came, he was decent enough to pass it on to the right person. And so I came out thinking, you know, it was just a free trip to California, which the world owed me after I had worked so hard on my thesis. And we came here in August, and it was a little bit unbelievable in the way people get jobs now are very you have to give talks and all this stuff. But somehow I met these people, and we talked, and they gave me lunch. And one guy asked me a trick question, and then after lunch they shook my hand and offered me a job at the princely sum of 8000 dollars a year. And so, then I had this job. But I had this other job at Columbia University. So, all, we went by train. I was afraid to fly in those days. So, all the way back, I stewed with, what am I going to do? it is my thesis advisor. This is the end of August, and Columbia, they start the beginning of September. it is like two weeks away. So, when I came back, they said, What happened? I said, Well, they offered me a job. And they said, Well, we have been talking about it, and Stanford's really building up. it is the place of the future. You should take it. So, it kind of took the burden off me, you know. So, I took it, which was so, we packed up and three weeks later, we were in California. So, it was kind of a quick thing. And my life has been happily ever after here. And I have been pining away from New York, but I have been enjoying it a lot here also. "
"Bernie Roth","Interviewer","So, who were the people you had lunch with that day? "
"Bernie Roth","Interviewee","Oh, it was funny. One was the dean, a guy, Joe Pettit , who eventually became president of Georgia Tech. So, he was the dean. And a guy Bob Cannon, who was sort of a hero, astro controls guy, who actually ended up doing some work for robotics. And Tom Cane, who was a professor, a young full professor in dynamics, and he had graduated from Columbia, so he was some of the connection. But he is the one who asked me the trick question, because his field was close to mine, you know. And then there was Bill Kays , who was the chairman of mechanical engineering. So, those were the people I had lunch with. "
"Bernie Roth","Interviewer","Do you remember the question? "
"Bernie Roth","Interviewee","I do. I do. Yeah. The question is: If you have a particle moving in a circle, what is its angular velocity. And the answer is: Particles do not have angular velocities, only bodies do. That was the trick question. "
"Bernie Roth","Interviewee","But then to hedge my bet, I said, But you could imagine, you know, connecting a rod to it and going around, and then the rod would have an angular velocity, and you could get it. That was that. But many years later, when Tom retired here, I went to his retirement party, and he pulled me aside. He said, You know, I did not regret for one day at all that you came here. So, I mean, he was happy I had passed the trick question. "
"Bernie Roth","Interviewer","And so you joined the mechanical engineering department. "
"Bernie Roth","Interviewee","I joined the mechanical engineering department. And actually, I was very interested in dynamics and stuff, but the way Stanford worked at that time, the department was broken into different groups called divisions. And there was an applied mechanics division, and they controlled dynamics; in fact, Tom did there. So, there was no real space to teach that stuff. So I ended up teaching the kinematics, which was kind of what my thesis was on also. So I became Stanford's kinematics guy. And that was that. And then I was the job, though, to get the job, I had to kind of exaggerate my interest in design, which was not very existing at the time. But so I had to exaggerate in the letter how I would be interested in that. And like life is, once you exaggerate, you become that. So, then I became much more both involved in and interested in design; it is become the biggest part of my career, but it did not start that way. My career was more towards what is called applied mechanics. That was more the value system I had been educated with. "
"Bernie Roth","Interviewer","And so, you mentioned that previously you had been at Hunter College in art. "
"Bernie Roth","Interviewee","Yeah. Art, yeah, that was a great thing. "
"Bernie Roth","Interviewer","How did, yeah, what did you. "
"Bernie Roth","Interviewee","Well, I taught drafting. I taught drafting. But the great thing about there, this was like, this was, you know, in the late 1950s. There was a woman chairman and a male secretary. It was kind of ahead of its time. So, that was the most distinguishing thing about the art department at Hunter. But I taught, I sort of people would always do that, thinking New York has so many school, so you teach in one and then you would kind of moonlight in another. But I for many years taught drafting at Hunter in the art department. "
"Bernie Roth","Interviewer","How did you first become involved with robotics? "
"Bernie Roth","Interviewee","Yeah. that is another one of these life things which are accidents that change your whole life. I was a young professor. I had been here, say, two years, if that long. I was minding my own business, and I got a phone call. And at the other end was this august figure, Fredrick Turman , who was provost to his, like, famous and sort of autocratic reputation. And, you know, it is yes, sir. And it turns out that John McCarthy, who was the professor of computer science, also a young professor, he had gotten a big grant, like a million dollars, which was a lot of money in those days, to start what was called the Stanford Artificial Intelligence Laboratory. And part of the thing was that they were going to build robots. And somehow, Turman , who kind of had his ear to all the vibrations, got some word from someone that John was a great mathematician but maybe not the right guy to build mechanical things and that he ought to provide some backup or something like that. So, he called me and he suggested I get in touch with John McCarthy. And I think he called John and suggested he get in touch with me. And so we got in touch with each other, and the rest is history. So, you know, we met and I sort of took on the part of the projects that would involve building mechanical arms, which is what we called robots in those days. And, you know, I had no knowledge of it or interest in it or anything about it, but it seemed really nice and seemed something that would be in the area that I easily handle the stuff. So, I started to essentially supply and the idea was supply mechanical arms that they could whiz around with the computers. And they had the illusion, the computer guys, that they could do anything. And, you know, you did not have to worry about the mechanical things. They just could do anything at any speeds, and they had all these exaggerated notions of catching flies in the way and stuff like that. So, you know, we decided we would do that. And they were very anxious to get started. So, the first thing I did is I knew of a prosthetic arm. it is sort of like an arm brace, essentially, but it had electric motors. It was for people that were paralyzed, and it had a tongue switch. So, with your tongue, you could control the motors and you could get your arm to move. And there were some people down in Los Angeles, or Rancho Los Amigos Hospital that had this thing. So, and I had some contact with them. So I contacted them, and they agreed to sell us one. I think, I do not remember the price, it was maybe two thousand dollars, maybe less. So, they sold us this arm, and my students and I kind of adapted it for computer control. And we called it the Rancho Arm because That is where it came from. And it turns out it was very, very flimsy because it relied on the structure of the human arm to give it, you know, strength and stability. So, without an arm in it, if you moved it, it would vibrate, you know. So, after a while, we would get the people who called it Shaky. And then when we put a mechanical we put a hand on it, it would drop stuff, so they called it Butter Fingers. It had various different names at the time. But basically, that got us into the business very quickly of being able to have a computer control an arm. And that was the objective, to just get going as quickly as we could. And a series of experiments were done, and there were movies, very early movies made. And I always laugh about one of them. There was a fellow, his name was, I think, Gary Feldman, Gary, who became this physician afterward. And Gary was the ace film maker. And we are up there filming one night, and he was, as a film maker, you know, you do a lot of cuts and stuff like that. And so, I said to Gary at one point, Gary, this film is one big fraud. And he said, No, no, Bernie, it is a lot of little Frauds, which I always remembered, which is, you know, kind of film, so, you know, you cover something and you would stop it and you would move the blocks and all that. But there were serious experiments which had to do with stacking blocks and using there was another part of the project which had to do with vision. So they used the cameras and tried to detect the world and use vision to measure where things were. So the idea was to merge the two projects and use vision to essentially direct where you move the arm and then pick up blocks and move them. And there was a whole series of experiment. And they were kind of nice little movies made that way of block stacking. And then there was always this those were the days of the Beatles and all this, so it was always just tongue in cheek, you know. Help, you know that movie? You know, the movie's always got to be a little bit out of control, which was different from most technical movies. And it was a kind of nice thing I liked a lot. All the movies that were made here were kind of, they had a little bit of pizzazz in them and, you know, not only the music but . So, there was this stacking of the blocks, and you know, it is doing this whole thing. And then there is this cut. And then there is like a picture of what is impossible. Like the block is so cantilevered off, it could not possibly be standing there, you know. it is a kind of, you know, visual joke or stuff like that. So, there were a lot of things like that. So, we had a lot of fun. We had make them all night long. It was a lot of fun doing that. And in addition to that, the thought was to make an arm more suitable to the computer. And the idea came up, well, the computer is digital, basically, so why are we taking the efforts to convert the digital information to analog information to control these motors? Why do not we just make a digital arm? And the idea evolved with, we had little bags, so you kind of basically blow them up. And there'd be two positions. The bag would either be deflated or totally inflated. So That is how we arranged it. And so, we made an arm which made all these little baggies, which were actuators and by just actuating on, off and all that, it was just very snake-like structure, and you could get it to go from one position to the other, of course. And when it went from one to the other, it would move dramatically. It was not like slight motions and stuff like that. So, we had that time a graduate student here from Norway, and he said we were trying to think of a name for this thing and he said, The Norwegian word for snake is orm, O-R-M. So that was it, naturally. So, this became the ORM, you know, and very clever, right? You know, as opposed to the arm, right? So, we worked with that for a while, and it turned out to be not a great idea at the time, and it had a lot of issues. But, it did have the idea of this digital control in the segments. And many years later, some people picked it up, and specially at Johns Hopkins did a lot of work with that. He had different actuaries, but it was a similar structure thing, but we were ahead of our time with that one. But we did have the idea that the speed was supposed to be the issue, because the computers were going to do everything so quickly. So, the other projects which we moved on were some used hydraulics, which could give us the most speed possible, and we built a hydraulic arm. And we had to design the actuators and all that, and that was quite successful. And it was scary, because it was this really powerful thing, and there was always a lot of concern about people getting hurt. So, we built a room around this arm, and we put the hydraulic room in, and I was very cautious. So, I made sure the students bought shatter-proof glass to put in, especially near the controller. Some years later, I found out that they had dropped a piece of the shatter-proof glass on the way in and they did not want to tell me, so they replaced the one right in front of the controller with ordinary glass. But nothing had happened, so that was okay. There were remarkably few accidents, I must say, given what went on. And there was always this stuff of having to get into the room and, you know, you try and put safety locks and people did not want to take the trouble and stuff like that. But we did get the hydraulic arm working. And there was a student who wrote his thesis on that, Mike Conn on this, and it turned out to be the first thesis on dynamics of manipulators and control and stuff like that. And that was good, and it was nice work. And before that, there had been, or sort of simultaneously, it was Don Piper, who was another student of mine who, he worked on the kinematic issues of just arms in general. So, I had this idea, like, you know, we ought to make a science out of this thing, not just build devices. And so, the idea was to try and just start and look at stuff very basically and build up a theory. And I had a good background because I had been working on three-dimensional mechanisms. And an arm is basically a three-dimensional mechanism. So it was very easy to apply a lot of the things that I was teaching and familiar with into this work. So, it kind of was a good, good fit that way. So, Don Piper did his thesis basically on the kinematics of arms in general and how you could control these, we call them serial manipulators. So, if you wanted to go from here to there, how much do you have to move the motors and stuff, and that is all the direct problem. And then there was the inverse kinematic problem, which is the hard one, which is: If you know where you are, how do you figure out where all the motors should be to get the hand where you want it to be? So we worked on that and we had some good progress on that. And we had Mike Conn's dynamics, so it was a really good start on the basic idea, the kinematics, descriptions and stuff. And I remember at one point, I think it was Mike had finished, John McCarthy at some meeting said, You know, we have turned out a few really good theses in mechanical engineering. Why do not we turn out something in computer science, which is what the lab was about; it was the AI lab. And they did. But I remember, we were kind of a little bit ahead of the curve on that stuff. He quipped that way. I always remembered that remark. But then the people came along, and we kept working. There was Lou Paul, who became very famous and kind of wrote the first book. And that was kind of interesting, because I always thought of the subject as being, you know, if you are going to learn robotics, you should learn kinematics. You should learn dynamics. You should learn controls. These are all subjects, and They are all right. And then Lou came along, and he kind of stuck it all in one book. And I thought, Well, you know, That is kind of like, you know, it is not really thorough and dense and all that kind of stuff. And, you know, it took some convincing, but he was right, so it was probably the way to go. And some years later, I actually paid one of my researchers, John Craig, wrote a book, which was kind of a follow-up on , so I actually funded it. So I believed in it. But I must say, when it started out, I thought it was too much like a survey course. I did not like that idea. I thought it should be more in depth. It is a survey course, and I have taught it many times here. And it is not in depth, but it seems to work well, so it is fine. So, let us see. What else? You know, a lot of people came along. I do not know if you want me to go through. "
"Bernie Roth","Interviewer","Yeah. "
"Bernie Roth","Interviewee","let us go through. Okay. "
"Bernie Roth","Interviewer","Yeah. And if you could even tell us the names of some of the people. Like, so, who were all of the students? "
"Bernie Roth","Interviewee","Say it again? "
"Bernie Roth","Interviewer","Maybe you do not remember all the students. "
"Bernie Roth","Interviewee","Yeah. Sure I do. "
"Bernie Roth","Interviewer","But who are the other students who worked on these things? "
"Bernie Roth","Interviewee","Yeah. Sure. Well, as I said, my original students, actually this is a little complicated story, but it goes like this. So, I had Don Piper, and he finished up, and Mike Conn was still working. He was a little bit behind. You know, he had an experimental thing, the arm and just . So I had my sabbatical, I had my first sabbatical, and I was not going to miss that. So I went off to Holland. And before that, Vick Shyman came along, and we were going to build another arm. And this was going to be an electric arm. And so, we started to work on that, and Vick was, he was kind of acting like a contractor, but he was working for the project and all that. And he was going to do a PhD. So, I had Vick and Mike, and I was going off on sabbatical, so what to do. So I had another graduate student, Ken Waldren , who later on became very famous in walking machines and stuff. And Ken was actually my second PhD student, but Ken's work was in the kinematics area. He really was not working in robotics. But I was going on sabbatical, and the idea was Ken was just finishing up, would kind of replace me and teach my courses, and he would be like an acting assistant professor. And he would kind of take over and all that. So, Ken kind of took over. I went away. I went to Holland, and I was at Technical University of Delft. And Ken was working with Vick basically. And Vick ended up doing what we call an engineer's degree, which has this kind of thesis to it, or a Master's. I forget exactly if it is a Master's. But at any rate, Ken kind of ended up doing that, then supervising Vick on writing the see, I guess it was an engineer's degree. I am not exactly sure. So Vick did this arm, which got called the Shyman arm, which was this electric arm, which became sort of our bread and butter arm for many years. And he sold some other copies. And being Vick, instead of making four gears, it was cheaper to make ten gears, so he got more parts than he needed actually, and then he started to make them. And he actually started a little company called Vicom . He then got involved with Marvin Minski, who was sort of the MIT twin to John McCarthy. And Marvin had started a similar project, the artificial project in MIT. But he did not really have any arm people there, so he kind of hired Vick. And Vick, who had had at MIT, always loved MIT much more than he loved Stanford, I think, and so he was glad to go back there, and he worked for Marvin for a year or so. And he made a small version of the, we called the Shyman arm. He made a small arm for Marvin. He made another kind of arm that folded. So he did some designs there, and then he came back here and eventually started his company here. And so, we had the electric arm that Vick had on the Shyman arm. Then he built force. He built one of the early force risk forced six axis forced torque measuring devices, built hands. We had other students. I had one student, Lung Nguyen Sai who did a kinematics degree, but it was hard. He was from Taiwan. It was a little tough time to get a job. So, to keep him on ice for a while, we put him in the lab, and he built the fixtures for what we called the flashlight factory. It was a film we made of assembling a flashlight using the arm, the electric arm. And Lung Nguyen built all the fixtures that designed. So, we had a lot of students who helped out in different ways on that. And Vick was really close to Bruce Shimano, who was another graduate student of mine. And Bruce was kind of the did a lot of the programming for Vick's company and all that. it is still going on to this day. So Bruce was involved. Bruce did a really nice thesis, which was sort of the kinematics of the arms. He showed what position it is in when it reaches furthest out, what the conditions are, and things like that. And so he was there. I am trying to think who else came along then. Oh, Jeff Kerr was another student. He worked on the hand. We did let us go back. I skipped so before Ken Salisbury, who is also around as you know, Ken was working with me on the hand. And at about the same time there was an electrical engineering student named John Craig who was working at the AI project. And he had some difficulty there. And eventually he came over, and he became my advisee. So I had John and I had Jeff Kerr. And there was Bruce Shimano, who was kind of just finished up. And then I had a fellow Madhu Raghavan who was also there at the same time. And so Jeff was working on hands, following up the work that Ken Salisbury had done on hands. So Ken did like the original thesis on hands and the original kinematics about the hands and all of that. And then Jeff got into like the forces, the gripping, the control. So Ken was So Salisbury was more the structure of the hand, how many fingers, and how many joints, and that kind of thing, and what the different poses are. And Jeff was more into the how you hold it and those kind of things. And then John Craig was interested in control of the hand of the arm and stuff like that. So John worked in that way. And Madhu was just doing a kinematics thing and all that. And then it turned out when he was done, he could not get a job for a while, so we put him on hold. And he did this thing where he kind of cracked open the problem of the inverse kinematics that we were working on for a long time. And that was after his thesis. That was just while he was on hold. So then he became kind of a robotics person. And he is at GM research now doing quite well. So eventually John finished, and he was going to become a professor at Berkeley in EE. And at the last minute he got cold feet and took a job with a start up company where they were doing software, which he had been freelancing with. And he decided he'd stay with his friends in Silicon Valley. So he was there. And then just trying to there is so many pieces. I am trying to get it all in some sort of an order, but Vic After Vicarm , Vic sort of got involved with Joe Engelberger who it is a little bit complicated, so We will just go back a little bit. there is a guy called Devol . And he had a very strong tie with Engelberger. And Devol's idea was the buy up all possible patents and control robotic patents and stuff like that. And when he heard that we were doing work in robotics, he came out here. He was very interested, and he sort insisted on giving money for fellowship for a student. And I used that to support Vic Scheinman . So Vic kind of got to know George Devol, and through that we got to know Joe Engelberger. And so when Vic started his company, Joe knew him and all that. And at one point, Joe sort of asked Vic's company He sort of bought Vic's company and made it the West Coast division of his company, Unimation. So he made the West Coast wing of his company, and he got a contract with General Motors to make what became called the Puma arm. And so Vic, essentially, designed that there. And at one point Vic was going to take a partner. And I knew this partner. And I knew Vic very well. And I thought this is the world's biggest disaster about to happen. So I am usually very passive with my children and my students. But I felt his required an intervention. And so this young man walked into my office who was doing a dual degree in electrical engineering and mechanical engineering, who I thought very highly of and who was interested in starting a furniture company, and all that. And I told him, You ought to talk to Vic. And I brought them together. And that was Brian. And so Brian Carlisle . And he went to work with Vic. And then, eventually, Bruce graduated. He went to work there. So the three of them were together. And they were the West Coast division of Unimation. And then Vic had a buddy who he knew from family ties and all that, who was starting a company, Automatix. So he kind of went to Automatix to help with this company, left Brian and Bruce alone. And then eventually, Engelberger sold Unimation to Westinghouse, and that did not work out. So they made a deal, Brian and Bruce, for Westinghouse to essentially be able to keep their intellectual property for exchange for some shares to Westinghouse. And then they started their company out here. So that was kind of how all that kind of shook out. And Vic kind of was busy with his Automatix company. And they went off that way. So, let us see what else at the same time? Who else? I am sure I am forgetting some people that are very important in my life in robotics. I am trying to think what other students worked in robotics. I mean at a lot of points a lot of the kinematics and robotics, and the controls kind of melded. So it is really hard to say who distinctly was in one area. But I am trying to think "
"Bernie Roth","Interviewer","When did you start calling it robotics?"
"Bernie Roth","Interviewee","When did we start ? Well, it was it always bothered me somewhat, the whole idea of the robot arm thing. And many of my early papers I kept using the word manipulative mechanical arm, and stuff like that. And, eventually, it was just a losing battle. So I stopped worrying about it. But it is what is a robot? I think I have said this many times. A robot is if your dishwasher has a little computer in it, is it a robot? So it just turns out it became what was convenient for commercial interests to call it, and for interests to want to get grants to call it. So if robotics was in, then you call it robot. If it was not, then you would call it a mechatronic device, or electrical-mechanical device. So there was a kind of political things to it. But, you know, it is life. But it is just a shorthand word. "
"Bernie Roth","Interviewee","Let me think about who else. Oh, yeah, actually Vic is still a good friend of his, Lawrenson , Irv Lawrenson. Yeah. Vic actually visits him and stays at his house in Norway. Actually he went last year and totally ruined his back on a cross-country ski trip there. Yeah, you can ask Irv Lawrenson was the "
"Bernie Roth","Interviewer","Is he still in robotics?"
"Bernie Roth","Interviewee","Irv? No, he is sort of medical he was just helping us out here. He was just doing a Master's thesis not a thesis, just a Master's degree. And he was just in the lab helping us out. I think, I would say he was always in healthcare kind of things. But Vic knows him much better than I do. I have seen "
"Bernie Roth","Interviewer","When you were at Delft where you building a robotics system there?"
"Bernie Roth","Interviewee","No, Delft was pure math. I was with the guy I was with was a mathematician who was mainly it was the beginning of a book I wrote called Theoretical Kinematics. And That is what I was doing at Delft. So it was basically sort of algebraic geometry and stuff like that. So some of the tools we used, but it really had nothing to do with that. Yeah. So the interesting I should mention, when I was in Delft, I went to a conference toward the end of my stay there, which was the founding conference of an international organization called IFTOMM, the International Federation of the Theory of Machines and Mechanisms. And at that conference I presented one of the movies We had made at the AI lab about robot one of these movies of stacking blocks and stuff like that. And I presented some of the stuff that we developed for Don Pieper's thesis, and some of Vic's stuff, so just a little summary of our work. And one of the people there was a guy called Ivan Ivanovich Artobolevskii . And he was a very, very prominent in the Soviet Union. He was a member of the Supreme Soviet, which is and he was not a member of the party, which was really very unusual. And so he was like a very he was sort of the head of the mechanical sciences for the Academy of Science. And he was very taken by the pr he came up and congratulated me afterward, and all that. And I actually went after that I had a some months after that I was still on sabbatical. My wife and I went to the Soviet Union. I had a U.S.-Soviet Academy exchange. And I went there and I met this Artobolevskii had an apartment one block from the Kremlin, you know, it was heavy-duty stuff. And there was with him a fellow, Kobrinsky Aron Kobrinsky, who I met for the first time. And it was kind of funny. So I met him and we formed a kind of close friendship because there was this incident where it was something about an Easter egg or something. Artobolevskii invited us to his apartment for lunch. And there was something about an Easter egg. And my wife, says, Oh no we do not cel He said, Do you celebrate Easter? I said, No, we do not celebrate Easter, we are Jewish. And afterward Kobrinsky came to us he said, Oh I was so proud when you said you were Jewish. He was Jewish, but he was undercover. So there was formed this big bond. And probably also got me watched by got followed by guys in raincoats just like in the movies, and all that. But we started a discussion about there should be a kind of East-West exchange in robotic area and all that. And that led, eventually, there was a meeting about yeah, about four years later there was a meeting in Yugoslavia, second IFTOMM World Congress. And these guys were ready when I got there. They had prepared this whole idea of making a set of conferences on robotics and housing it in a place call CISM , which is in Italy, which is in CISM is That is Italian, C is Center International Science Scienta Mechanica. So it is a was an international center for mechanical sciences in northern Italy, in a city called Udine. And they brought to this meeting the guy who is the head of that. And it was kind of we came together. We decided to form a steering committee and to have a set of meetings. And my friend Kobrinsky who was very brilliant and very imaginative, he said, let us call it Romansy. For Ro robot, Manipulated, Symposium. And the Italian guy said, No, no That is not serious. It was so funny. It was total culture you would think the Italian guy would say Romans but he was sort of uptight. But anyway it became Romansy and to compromise we put a period after Ro and after the n. so it was not one word, but everyone calls it Romansy. And shortly thereafter, after Yugoslavia meeting, two years after that we started the Romansy series of meetings. And they were quite good in that they actually broke this East-West thing, where we could actually be at meetings and talk about that. And the Russians starting building up a lot. They were very good in walking machines and stuff like that. And the Yugoslavs came. So that was a nice series and I was nice to be involved. A really funny thing about it, which is kind of an interesting sideline, is I was in charge of the U.S. thing, but they were nervous because I was very young. And I had very long hair. They said they thought I was a guitar player or something like that. So they did not know I was just fashionable. So they said somehow could not I get another American . So they got Dan Whitney who was at MIT he ended up at Draper Labs , at the time he was at MIT. So Dan and I became the U.S. committee. And Dan never kind of did much with it. You know he kind of but that was the first conference. So Dan and I were the U.S. committee. And then at the end of the first conference we had and they had made Kobrinsky the chairman of the first meeting. But they did not let him come. They would not give him an exit visa, which was kind of I was irate. And these guys would come up to me and I would say, Where is Aron? And they'd say, Well his brother's very sick. You know just pure bullshit, lying right to your face. And it was like, oh god. But, you know, that was their circumstance. Anyway, so I was sitting there at we had a lunch, like a committee lunch at the end of the meeting. And Artobolevskii's out front. And I am sitting in the back enjoying the wine, kind of flaked out. He says and this is like the voice of god, this guy. I mean he was like a very powerful figure. And he says for the next chairman I propose professor Roth. And I am kind of I wake up. I was this young guy. It was like the most charitable act. You know, it was good for my career and all that. But it was like this guy, he did not have to do it, you know. He was, you know, Russians had a turn a turn and all that. So that was kind of a very moving thing for me. And so I became the chairman of this thing and the committee and all that. And I was involved with it for a very long time. And at it I met two young guys. One was this very tall Italian guy who was chasing all the girls, called Bruno Siciliano . And he was a graduate student. And I met earlier a fellow called Oussama Khatib who was presenting his thesis by putting the slides down for his professor to talk about it. And Oussama spoke no English at the time, but somehow said could he come to Stanford for post-doc. And I said that was fine. So that was my connection with him. And then, actually, I also met at one of those conferences, Jadran Lenarcic . You may or may not know Jadran, but he is the head of the biggest lab in Slovenia now, the biggest research lab. And so I met at this conference I met various people, kind of was nice place to meet- who became very good friends and stuff like that. So there was a whole series of conferences. And then they moved. They would go it turns out the CISM people had membership from different countries. But the Eastern European countries, especially the Poles paid with their currency, which was not convertible at the time. So CISM had a lot of money in Eastern Europe that they could not do anything with. So they wanted to put meetings there, and they could buy you tickets on Airlines to fly from New York to Poland. So I made a lot of trips to Poland, which I enjoyed a lot. And we had a lot of meeting and committee meetings there. And we would move the Romansy would go from Poland it was every two years, the meeting. And it would go, every fourth year it would come back to Udine and go there. Now they have moved it to it goes all over. So eventually, I figured I have been there long enough and someone else should take over. So Ken Waldron had joined the committee, and then Oussama when I left Oussama Khatib because he was at Stanford, he came on the committee and all that. So Oussama and Ken have been very instrumental in that. And they have moved it all over the world. But in my days it was just always in those two places. And then Jadran, this fellow I mentioned to you, came to me and said, Well, I want to start a thing on robot kinematics, and I would like you to be the scientific chair. So, he was a good friend. I could not say no. So I do that. And that has been great, too. So we have that now every two years. And it is this thing it goes it is in Slovenia, and then it goes somewhere else. And originally it was supposed to be just in the area around what they call Alma-ata , the Alps around the Alps in that area. But it is moved around a little bit more. it is been down to Bologna . And it is been in France. it is been in Spain. And that is a nice meeting, but it focuses on just a specialty of robot kinematics. Romansy was a more general meeting, also robotics sort of with a mechanical twist to it, but it had controls, it had some vision, it had walking machines, it had more of that. And it had a lot more dynamics and controls. So those are two meetings the sort of sprung out of this kind of activity and the visiting of and it all kind of in my mind sprung from this first visit to this my sabbatical where I was not doing robotics. But it ended up, at this IFTOMM meeting, it all switched that way for me. "
"Bernie Roth","Interviewer","What year was that first meeting?"
"Bernie Roth","Interviewee","That meeting was 60 the sabbatical was 1968, 1969. So that meeting must have been in the spring of 1969. Yeah. So, yeah. let us see what else I can tell you. Oh, yes so the Chinese guy so I had three like one, two, three students from the mainland China in sequence and somewhat together. They basically worked on robotics also in terms of hands and kind of just the grasp problems and things like that. And that was kind of fun, in one way. I have this one student, he was very unusual. He was very non-Chinese. Most Chinese students come here, they save their money, and They are going to go home. And They are very serious. And this guy was like I always meet my students once a week. And this guy was not showing up, and on and on. So I finally told him, I said, You know, I do not think this is working out. I think you ought to get another advisor. He says, No, no, no, no. And I said, All right, well, you have got to come to the meeting. And if you miss another meeting, we are finished. And he was so Westernized that he says, That is not fair. He says, We should do like the By now he had a car. He said, We should do like they do with the motor vehicle bureau. it is like certain points for certain offenses. And I have to be allowed the maximum of points, which I loved. How could you not love it? So it worked our fine, but I always remember that. "
"Bernie Roth","Interviewer","Did he go into politics later?"
"Bernie Roth","Interviewee","That was great. Shows he was very americanized. But it was funny. Yeah. Then I had a guy from Bulgaria who was also kind of interesting. He came and he did a nice thing on thesis on sort of the problem of manipulator workspace kind of manipu workspace kind of problem. But had to do with multiple telescoping arms and things like that. And the thing I liked about him, which is these cultural experiences for me, this guy comes here, and he figures out right away he can not do anything without a credit card. So he says would I co-sign a credit card with him? Co-own. So I said okay, but I will not use it at all, just it is your card, your responsibility, but I will co-sign with you. And then he comes to me and he says, You know, there is this thing I can if I give them ten dollars I can by virtue since I bought the card, if I give them ten dollars, I can enter the Canadian lottery, and all that. And I go, that is a sucker thing. You do not want to do that. So, of course, he did not listen to me. And he won 60 thousand dollars, which is so funny. Which, you know, who would do that kind of thing? So that was great. "
"Bernie Roth","Interviewer","did not give you half, though."
"Bernie Roth","Interviewee","No, he did not. But he used it to get married. It was kind of a funny story. He married one of the he was TAing for me, and somehow it is kind of a funny story. So anyway all of these things are kind of cute along the way. let us see what are who are the I am sure I am missing some students. I should probably take a moment out and go look at my list of papers and see if I am leaving someone out. Would that be good for you?"
"Bernie Roth","Interviewer","Sure, if you would like to."
"Bernie Roth","Interviewee","Yeah, is that all right?"
"Bernie Roth","Interviewer","Sure, no problem."
"Bernie Roth","Interviewee","And I am trying to think who would be alive. Artobolevskii's dead. I mean all our whole group that I was a young guy. I was this young kid. And they were all they got there ahead of me. So I am trying to think who there is a guy he probably does n there is a guy, Alizade, who is a he is not a Russian, he is a Azerbaijani. And he works in Turkey now, in Ismir . he is a professor at Ismir. But he was young, I do not know what he knows but he may know them all. He might be worth His first name is Rasim, Rasim Alizade. I could probably get you his email if you need it. A-L-I-Z-A-D-E. "
"Bernie Roth","Interviewer","I can probably find it online. If I can not, I will just email you and ask."
"Bernie Roth","Interviewee","So and there is also Yuri Sarkisyan . he is Armenian. And Yuri knew them all very well. He became the head of a school he is like a politician, but he knew these people. And he is kind of older. So let me just looking at all my co-authors to make sure I have not missed anyone. I do not know; how do you want to do this? Should I just do it in and you will cut it in or "
"Bernie Roth","Interviewer","Yeah, We will edit the whole thing. do not worry about "
"Bernie Roth","Interviewee","So another student I had is his name was Morgan Ohwovoriole . And he came from Africa, in Nigeria. And I told him when I learned how to pronounce his name he could graduate. And he actually, he was interested in politics. So he actually changed his name from Morgan to Ejevo so he'd have a tribal name when he went back. His father and his grandfather had been chiefs and all that. And he did a thesis, which I loved a lot, having to do with the grasping, and the forces, and the idea of grasp and stuff like that. And no body could understand that, so Mike Brady and some other people at MIT once said, Why do not you write a paper that we could all understand? or something like that. So I wrote a paper where I loved the title. And the title was, Screws, Wrenches, and Motors that you cannot find at the hardware store. And the idea is these are mathematical names for things. And that was based on the work I did with Ejevo. Unfortunately, he just died last year. So but that was one that we left out. I am leaving out all my kinematics guys because we are just interested in robots. So Jeff, Jeff, Jeff "
"Bernie Roth","Interviewee","Okay, so at one point I got invited to go to Paris to have a laboratory of robotics at Paris and to spend a month there every year, basically. And so I started doing that, and I the first year I was there there was a graduate student there from he was Greek student who was a foreign student in France. And he was getting his Master's thesis. And I ended up supervising his thesis. So I gave him a robotics problem having to with sort of different ways that can describe a wrist, positions and stuff. And that was successful and all that. And when I came back, he wanted to do a Ph.D. thesis the next year. He started doing that. And he was interested in the kinds of things I was interested. So I ended up supervising it. So I had this funny situation where I had this Greek student in France where he had French thesis then at one point I went to Japan for some time, so he came to Japan. He came to Stanford. He kind of followed me all around the world. And he ended up with a thesis, which had to do with special geometries for manipulators and all that. His name's Mavroidis, and he is a professor he actually afterward, he went to MIT. And he worked as a research associate with Steve Dubowsky for awhile. Then he was a professor in New Jersey. And now he is at Northeastern University. And so that was just an interesting very pleasurable kind of unusual association that way. let us see what else I can figure out. I omitted Yeah I had well there was a lot of people came like as post docs and stuff like that. We did little things together, but in terms of doctoral students I had a fellow from Brazil, Mitone . I had another American, Neilson . We worked on different problems. I think that is about Yeah, I think that is about So, the main thing is that That is kind of missing from the story. We will not go there a lot is that there are a lot of people like Mike McCarthy, for example, who did a thesis with me in pure kinematics and then their careers turned out to be robotics, a lot and stuff like that. So there'd be people like that all over the place. And I have not mentioned those. So, sorry guys. It just I wanted to just stick with the direct robotics story. And, yeah."
"Bernie Roth","Interviewer","Who else did you collaborate with in terms of faculty or other labs?"
"Bernie Roth","Interviewee","Here? Well, there were different things that I spent I twice had a fellowship in Japan. So I worked there with Professor Inoue in Tokyo, and then also just a series of people there that Shigeo Hirose was a very close friend and contact of mine. I worked in his lab. I was in France at LAAS it is in Toulouse. it is a big robotics lab. George Hirault was the head of that. Raja Chatila is the head now, we are very good friends. There were a lot of people there I worked with a little bit. So just I have gone around the world a lot of times. So there've been a lot of places I have worked for some time. I was a visiting professor in India a couple of times, in Bangalore. One of my ex-students that I mentioned Ashitava Ghosal he is a professor there. He does a lot of robotic work. The work he did with me here was more kinematics. he is another example. So I have been to India a lot of times. I was visiting professor at Kanpur, Bangalore, and New Dehli. I have been to all the Iit is there. And I used to go to Eastern Europe a lot. I have been to Turkey a lot of times, Middle Eastern Technical University. So I do not know, just endless. So I would say, the only Oussama Khatib who came here as my post doc, without speaking English. In the first year we kind of mainly had French around because John Craig spoke French and Oussama spoke French. And yeah there was a lot of French around. So you know I have collaborated a lot with Oussama afterward when he became I tell him he is the man who came for dinner and never left. And so he is been so I have collaborated with him a lot in recent years. With him we had some students that Mike Zin we did this we just did a thing on special ways of driving manipulators so that you do not have as many inertial effects and things like that. And Mike is now a professor at Wisconsin. So Oussama and I co-advised Mike. I do not know. So there is a lot. But, in general, these are all short Oussama and that collaboration with that lab goes way back from John McCarthy, so it is just always different people there. And Stanford's a place That is really nice in that there is a lot of permeability between the boundaries in departments. So often like Joel Burdick who I did not mention Joel Burdick was my student. And he got his Ph.D. in ME, but mainly he worked in the lab there. And he worked very closely with Oussama. And he did at thesis, which was basically based on he did enough to do two or three theses. But basically it had to do with manipulator kinematics. He did a dynamics work and stuff. But he was an example of someone who is basically based down in that lab in computer science, but was an ME student. And there is a whole generation of many generations of students of like that. Ken Salisbury was that way. Shimano was that way. There are just a whole string of them who did that. So That is in a way a collaboration, but it is internal. I did not really have externally, well there were people like Casey Gupter at the University of Illinois. He was a student of mine. we have over the years written a lot of papers together, some of them on robotics. Although Casey's original work was on kinematics. So it kind of I do not know. Bahram Ravani up at Davis, another ex-student. As I said, Mike McCarthy down at Irvine is another ex-student. I do not know they were all over the place. there is this one Neilson who just graduated a few years back. So, I do not know what else I can tell you."
"Bernie Roth","Interviewer","So what other kind of robotic mechanisms did you work with? You mentioned in the beginning a few different iterations of hands. Did they get built?"
"Bernie Roth","Interviewee","Well, the arms was the main our main thing here was always the kinematics of the arm. And then it became like measured forces on it. So the specialty of this lab here that I have been cooperating for all these years has been force control manipulation. And we always were trying to develop arms that would facilitate that. So there is this whole series of arms that were developed. And I would say the main thing, the hands, the arms. Other people like Ken Waldron went off to the walking machines, that nature. Trying to think what else. Yeah I do not know I think That is it. I do not know."
"Bernie Roth","Interviewer","What machines were you working with in, say, the 1980s?"
"Bernie Roth","Interviewee","Oh, the 1980s, well we mainly had the the 1980s. I forget when Romeo and Juliet came along, that was in those were just these what we did is took the arms that we got from Brian, these do you know what was called the essentially what there was the Puma and then there were the replacement arms for those. And we mounted those on moving bases. So that became a series of experiments that way. But we were always developing something. Like with Mike Zin we tried to develop this thing, which would not hurt people. So if it hit you it would not hurt you and things like that which would reduce the inertia and those kind of issues. There was always like little gadgets and little things being developed and controlled. Ken Salisbury went off on the PHANTOM and these virtual reality things. Those became very big in the lab then."
"Bernie Roth","Interviewer","How do you feel the work in robotics and kinematics kind of fed each other?"
"Bernie Roth","Interviewee","yeah, well I I think if I had not been working in the kinematics of special things, all the stuff of the way we described all that stuff would not have happened the way it did. So I was working in the kinematics, then it seemed obviously the way to describe all these things is to use what we call Denavit and Hartenberg notation. So I have told Jaques Denavit, I am the guy who made you famous, because no body knew about any of that stuff. But it seemed to me the natural nice way to do it. Now you do not have to it that way. Now it seems like the way to do it. But it was just a natural thing because of the work in kinematics. So it fed very directly into the work in robotics. The work in robotics what kind of more interested in different kind of mechanisms, and kind of opened up a lot of different areas. So they fed back and forth. The questions of work space and stuff like that. People did not usually think about that in mechanisms. Now they do. So it is just the nomenclatures, the people going back and forth. So it is and really it is we talked about the name robotics. All these things are just mechanisms, really. They are just spatial mechanisms. So it is always what we have been doing, it is just relabeling a lot of it and stuff. And once you go away from classical machines just had a one degree of freedom thing and one motor turning something. And you could say that is a mechanism and maybe not a robot. But once you go away from that you start to add more than one degree of freedom and you control with a computer, then is it a mechanism or a robot. You get to choose. So it becomes the same thing, really. So of course they feed on each other. And all the mathematical tools, and all that stuff. So my main interest really was always the tools rather than the specific hardware things. And I felt applying your same question to the hardware versus the theory, I felt that was a really good marriage. It does not work that way so well in other fields, but in robotic or kinematics, whatever you want to call it, it is like perfect because the theory kind of lets you do sort of stuff and all that and then when you build a device it is, Well, how do I this? And, Hey, that is an interesting question. I never thought to ask myself that question. And so it all sort of came up. So, for example, people started to build manipulators. And then they six joints. And then someone put a seventh joint on it. And then suddenly you have a redundant manipulator, and what do you with that extra degree of freedom? How do you use it and stuff? So that brings up a whole bunch of problems. And then this whole idea of once it can move around, there are obstacles. How do you avoid obstacles? So there are all sorts of things, which are kind of always there, but we did not really they were not significant for those specific devices. But then when you get this whole new class of devices, they become interesting. And always in kinematics there multi-degree of freedom devices, but they were sort of a backwater. No one was kind of interested in them. So it kind of made these things, which maybe existed you can find some literature on it. They made them much more significant. They put them much more up front. And that kind of worked really well in the robotics, kinematics area. And the controls area, also works really good that way, and dynamics. It was really a fruitful kind of thing."
"Bernie Roth","Interviewer","How much did the influence of cybernetics or artificial intelligence come into your work?"
"Bernie Roth","Interviewee","Yeah. I do not think it came into anyone is work until maybe recently. It was always this you know we worked in the AI lab, That is where all this work took place. And there really was not any much what I would call AI. Again, what is AI? So, again, it is big fights as to what it means and all that sort of stuff. But basically what their big hits were early on like expert systems and stuff like that, which is not really AI, as they started to talk about it. So just as robotics the same guys who talked about catching flies and moving all that were talking about all these other fantasy things. And you know They are just hard to come by, and they took a long time. And there is some of that now. And, again, it is a matter of definition. But I would say the influence of real hardcore AI on robotics was very minimal for most of the years. I wish it was not that way, but it was just easier to do things the other way and more defined. But people tried, Rod Brooks and Swans and that kind made the AI stuff and all that. it is useful ideas. I do not know exactly how much of these vacuum cleaners AI has used, maybe use a lot of it, but certainly in the factories it was not the case. But the communities were kind of close, but did not really talk to each other. But it really was not the not talking because everyone was aware. And if there was something that they felt could be used, people would use it. You had a lot of very aggressive people wanting to do stuff. And it just did not seem appropriate at the time. And things have changed. I do not know. We will see. "
"Bernie Roth","Interviewer","How do you see things changing in robotics? Where do you see it going?"
"Bernie Roth","Interviewee","Well, there are fads in it. The sort of latest fad is this humanoid robotic kind of thing. That is big. Before that there was the safety things. there is so they come and go. it is partially funding agencies, it is partially driven by Korea and Japan. They seem to be able to get national projects and all of that. And then they get nervous in the West and in Europe. And they want to catch up, which is kind of good. We help each other that way. But it is so hard to say what catches on and where you go. But there is this thing of fascination, the laboratory and this thing about real things out there at a price that people are willing spend and all that. My own feeling is it is kind of really the main things is to understand we have robotics. My iPhone is a robotic device. So it just depends how you define it. The computer chip and all those ideas and all that are there. And a lot of it does move mechanical things. So if you have this idea, it is sort of the basic idea of robotics. So it is all around us in every which way, in your car and all that stuff. You know I used to able to repair my car. I can not do that anymore. it is too robotic. So it is taken over. it is that way. But there is always I will tell you the truth. My definition of robotics is the following, it is something you are never going you are never going to get there. And the reason if you look back I used to love to quote this. If you look back at the Encyclopedia Britannica, they had those before Wikipedia. If you look back something like in 1929 or 30, and you look up something like robo you will find a gyrocompass. And they got this gyrocompass, and They are talking about it like it is a robot. Okay? And it was amazing because this was an automatic way to drive a ship, which did not exist before. Now, it is not a robot because it is old hat. it is the technology. And so, it is always this thing that you think people can do and machines can not do that you attribute to robots. Once the machines can do it, it is no longer a robot. it is just what machines do. So I always That is the way I look at it. it is like a never ending thing. And maybe you will get something that walks and does this stuff and call it a robot. But really That is what it gets down to. it is just a walking machine. Once it walks, it is a walking machine. And it just becomes politics and the word. But I think it is this whole idea of something that only people can do or living things can do and then suddenly a machine can do it. That is what the robot is. But once it can do it, it loses its uniqueness. So That is kind of the way I hold it. I am not going to fight anyone to the death about it. But That is made more sense to me than anything else. I remember on the other end it is so political. I remember I do not remember exactly where the meeting was, but there was a meeting. And we were discussing the definition of robotics. This was a high thing we are going to write it down once and forever. And this one guy who was selling a device, which was I think it was an arm for a man-machine thing for nuclear reactors, or something like that. He wanted the definition to be his thing because he wanted to be selling robots, and all that. So I kind of was flippant. I said he said, Well, it is this controllable, changeable thing, all that. I said I will not say his name. I said, You know it sounds to me like a radio. I mean if you took the words exactly like controllable, changeable, it was a radio. So it is but he meant his device. So if he just abstracted the words of the properties of what the thing does, it could be a lot of things. So you have some image in your mind of what you are talking about. And usually when you do that it is a political game because you have a vested interest in selling or advertising this specific thing. And that is always been the problem with it, I think. But, you know who cares. it is fine. You want to call it a robot, That is fine. But, I think we have them. I think we are going to have them more. And the world's going to have more and more automatic devices, and some will interact with people, some will not, and That is going to keep going. There was always a kind of hype to it, which is kind of wish it was not there, but it is. And some is visionary, and some is just airy, and stuff. "
"Bernie Roth","Interviewer","Where did you get most of your funding over the years?"
"Bernie Roth","Interviewee","In my case I was kind of lucky. You know everyone dreams of having a rich uncle or something like that. I do not really have a rich uncle, but what happened is basically I got my funding through NSF. And John McCarthy got his stuff from DARPA and all that. And I do not do any military work. So I never took any salary or stuff for that. But the students did and That is their But at some point there was essentially a phone call and there was a foundation called the Systems Development Foundation. And someone had given them my name as a really good guy. And I was invited to give them a proposal, which was was not compet I just wrote down whatever and they bought me a Sun-1 computer, which was the first one I had seen. And I had money. And I had money to let John Craig write his book and all that sort of stuff. So I had money for a bunch of years, which was just this gift from the gods, basically was foundation. And then they went out of money. As this thing was set up to go out of business in ten years. And They are the ones who set up the International the Journal of Robotics Research and all that. It all came out of that foundation. So they helped a lot in the early robotics thing. And then kind of after that I got some more NSF money. So basically NSF has been the except for this one period of whatever years when this money just came raining down one me, which was kind of nice. And then occasionally companies have been nice to me. People know they have given me small amounts of money, various companies. But That is kind of where it is. But I have never I have never done like a huge research operation with a lot I have always kind of had one or two or three students at a time. And lived with very I am a kind of cheap skate. I do not spend a lot of money and stuff like that. I try and stay in cheap hotels, but it is hard with some of my friends. will not mention any names. So yeah it is not been a big issue for me. "
"Bernie Roth","Interviewer","How did you get involved with the d.school?"
"Bernie Roth","Interviewee","Yeah, well it is another it is a funny I am a passive guy minding my own business in the world. So I have a friend Dave Kelley who I kind of was the person who got his promotions to the university, so he thinks of me as understanding how the university works. So when he had this idea of the d.school, he asked me to join the founding group. And the reason was not my great design abilities, but my ability to understand the university and to help with that part of it. So I was part of the founding group and going along it was not a big part of my life and all that. And then he got ill. He got cancer. And the dean called me up and he said he would like someone to be an interim director while Dave's getting well. And he asked me to do that. So I started to do that. And I ended up loving it very much. And when Dave got well, he said, Did you like it? I said, Yeah. He says, Well let us job share, basically. So That is what we are doing. So That is my life has changed completely now. And I put all my energy and time into this. And build stuff for people who make a dollar a day as opposed to thousands of dollars a day. it is very gratifying. And are these devices robotic? I do not know. I doubt it, but it is a lot of the same principles and stuff. "
"Bernie Roth","Interviewer","What kinds of projects have you done in here, recently?"
"Bernie Roth","Interviewee","Well, we do a lot of stuff here that are amazing. Some of our amazing stories the most high tech one is "
"Bernie Roth","Interviewee","came up with an app for reading on the iPad, reading it is called Pulse, reading newspapers. And it was a biggest selling app on the iPad for the first week or two. So these two students sold 26,000 apps at four dollars a shot. And Steve Jobs took his cut, and then they became the second biggest seller on the iPhone. they have just now They are giving away because they have gotten so so that is and exciting thing. But more it is things like incubators for premature children that are very inexpensive and totally new way to do it, lighting That is LED driven lighting, curing children with jaundice by just wrapping LEDs around them, making tread water pumps for Myanmar, stuff like that. But they have also done stuff for helping Jet Blue get better customer relations. it is all over the place. it is helping VISA more creative way for people to save, getting Wal-mart help the employees think that they really are growing green, which they are. No one believes, stuff like it is all over the place. Just exciting. But They are just kind of They are more like ideas and just getting things into people's hands and stuff like that. that is a different way to work. I no longer have a private office here. I have a family of twenty people. So it is a different situation, yeah."
"Bernie Roth","Interviewer","Even in the AI lab at least the students are in a very open space."
"Bernie Roth","Interviewee","Yeah, the AI is close. it is sort of close, but the ME is not that way. Everyone has their private office. This has some which are some of the things I liked about the AI lab. We were kind of all there together. I like that set up a lot, yeah."
"Bernie Roth","Interviewer","And when you look back at your career what do you consider to be your biggest accomplishments or breakthroughs or the systems that had the biggest impact?"
"Bernie Roth","Interviewee","There are like specific little discoveries and all that, which kind of feel good. I am really proud of the book I wrote. But it is more the human thing, the relationships, the people, those kind of things, the funny stories, the crazy incidents and stuff like that. But there are things that, just being part of them felt really good. And I like teaching a lot so that has been a really nice thing for me. And there are certain things I teach that I do very well at that I never was trained to do. And that has been very successful thing. I do a lot of work on creativity and problem solving and that has been really nice. So I do not know. it is a nice mix of stuff. But there are specific things. there is always a moment when you get the a ha paper and all that. And sometimes you write it up and everyone thinks it is fantastic. And sometimes you write it up and no one notices how wonderful it is. But it is very personal, just a feeling of it is the moment really, for me, at any rate, That is You know, you put a lot of energy into stuff and that suddenly that whole snap is kind of very gratifying."
"Bernie Roth","Interviewer","Great. I do not know if we have missed anything that you would like to share?"
"Bernie Roth","Interviewee","Yeah, I do not know. I should mention, maybe, that in the early days there was a lot of it started out with John Craig, there a kind of thing we had going, which was playing tricks on each other in public. And that was kind of a lot of fun. I used to do this thing when I had give this lecture saying if you do not do you are going to get a call from god if you do this thing. So John and his buddies arranged to signal that when I said it, suddenly the phone rang in the classroom. Everyone laughed and all that. So then I had to get back at him, and he had to get back at me. And they made movies. And we did all sorts of things. So there was just a lot of fun in terms of to the job. They kind of it was a kind of spirit to the place, which is not around all the time. But those are the old days. Now it is a whole other kind of game."
"Bernie Roth","Interviewer","What ever happened to all the films?"
"Bernie Roth","Interviewee","We have them. We have the films. We have all the I actually still have The AI lab people converted a lot of them to DVDs and stuff like that. If you want any of them, I am sure Les Ernest has You know Les, at all? Yeah. Les Ernest is his name. L-E-S E-R-N-E-S-T. Vic is very you are going to talk to Vic on Sunday? Vic has his phone Vic sees him all the time. So—"
"Bernie Roth","Interviewer","And he has them? "
"Bernie Roth","Interviewee","I have the original film versions, but he has I have the original film versions, but Les has, I am sure, the DVD versions, or he knows where they are. "
"Bernie Roth","Interviewer","Have you ever shown them?"
"Bernie Roth","Interviewee","Not in years and years. So They are around. I actually have DVDs of these jokes we used to play. I have some of those. A lot of the lectures were filmed, you know, we used to We had have this thing where we broadcast the classes and stuff. So there was automatic filming going on in the classroom. So we have a lot of that stuff. But yeah see what Les has. he will have the official AI movies. You ought to get those."
"Bernie Roth","Interviewer","I know it would be great to if we could add some of those to the collection."
"Bernie Roth","Interviewee","Yeah and then we gave a lot of hardware to the computer museum and all that. They have a lot of that stuff. Yeah, so."
"Bernie Roth","Interviewer","Yeah, I have been to the computer museum. it is amazing."
"Bernie Roth","Interviewee","Good, okay?"
"Bernie Roth","Interviewer","Thank you so much."
"Bernie Roth","Interviewee","My pleasure. Thank you."
"Bob Bolles","Interviewer","Why do not we start? You can introduce yourself, tell us where you were born and where you grew up."
"Bob Bolles","Interviewee","Okay, I am Bob Bolles. I was born in Baltimore, Maryland in 1945. I moved to Florida, Gainesville, Florida, when I was two and a half, so I really grew up in Gainesville, Florida. My father had been a professional flutist. He'd gone to Juilliard and played professionally in New York City for ten years, and then decided when he was going to have family, that was not going to work, that playing at night meant there was going to be no family life. So he went back to school and got a doctorate in education and then became a professor of music at the University of Florida."
"Bob Bolles","Interviewer","Where did you do your undergraduate studies?"
"Bob Bolles","Interviewee","So undergraduate studies at Yale. let us see, okay, yeah."
"Bob Bolles","Interviewer","What did you study there?"
"Bob Bolles","Interviewee","So I studied in mathematics. At that time let me go back a little bit. In high school, there were two things that were real important about high school for me. One was, sort of surprising, the University of Florida had a rule that said only one of a couple could work at the university as a professor. So there were a lot of teachers in my high school whose spouses were at the university. As a result, I think we had just superb teachers in high school. The second thing was, by the time my senior year, I had already taken all the science classes in high school, and so they set up a program where we could go be an intern over at the University of Florida. I was an intern for a professor in mathematics, Ralph Selfridge, and I showed up the first day and he said, I would like you to write a computer program to try out this idea about how to solve high water polynomial equations, find the roots of higher equations. And he said, there is a programming course starting next week. So I took a course, in 1966, to learn to program Fortran II and that sort of launched me off in computers and things like that. When I got to Yale, a couple of things happened. One is, they did not have a computer science major, so I majored in mathematics. I also got a job, sort of through the university, to work ten hours a week to earn a little money, supplement things, where I wrote programs for the educational testing company not company, what is it? Educational testing institute at Yale. So I wrote programs there and then I took a number of computer science classes, a couple from Professor Rosen who was quite an amazing person in testing, in stretching us. My recollection was, every time he'd hand us a homework assignment, I had look at it and say, I do not have a clue how to do this. Then after working, we were allowed to work together, We had work, talk, talk to him. We had figure out how to do it. We had get it written, get in gone and We had say, Anything he gives us now, we have got it knocked. Whatever he gives us, we know how to do it. Sure enough, next one he'd give us one, We had say, I do not have any idea. So that was really nice. In high school, I had had a couple of teachers that were like that, that would generate bonus questions. I do not think they were even for credit, but they were just extra hard problems that they would give us and I would spend most of my time doing those. I did all right in the other things too, but those were things that were really motivational."
"Bob Bolles","Interviewer","How did you first become interested in robotics?"
"Bob Bolles","Interviewee","So let us see, it is a long story here. So I went from Yale to the University of Pennsylvania and there again, they did not directly have computer science. They had let us see it was a Master's in electrical engineering and I ended up having to leave I was in a PhD program. Because it was in Vietnam time, I was going to have to join the military. My little draft board in Gainesville, Florida, was going to take me. I was physically fit and that was all they required. So I ended up leaving, after finishing a Master's degree there, and going into the navy. In the navy, somebody had figured out that computer science was a big upcoming thing and they pulled six of us most of us had Master's degrees, one or two had PhDs and sent us to the naval postgraduate school in Monterrey. So I was there for almost four years, teaching computer science to virtually everybody that was getting a Master's degree there. The navy had this foresight that they wanted everybody to learn about this new thing. One of the people that was there was Garry Kildall, who later became famous for writing CPM, which was the first operating system for microprocessors. there is a famous story about him not accepting a bid and Bill Gates winning who was going to write the operating system, and stuff like that. He was a great guy and I learned a lot from him. I would sit in on his compiler classes, operating system classes and so forth. When I finished my navy duty, I went to Stanford to finish, or actually, to earn a PhD at that point. I got assigned to Professor Feldman, who was doing language work, which I had been interested in, but he was also doing languages for robots and so That is really how I got into robots, was that Professor Feldman, Jerry Feldman, was developing description languages for robots. Then one of the people working with him was a research associate, Lou Paul, and he had finished there, I do not know, probably a year or two before I got there, but he was like a post doc there. He had the knack to pick a problem that was hard enough to really stretch you, but not impossible. He was real good at picking things that were sort of fun and interesting. So almost right when I got there, he had chosen a problem to automatically assemble a Ford Model T water pump. He thought that would be symbolic, to have a Model T, that we could have the robot arm assemble. So I worked on the perception part of that, because he did the manipulation, control and things like that. We used an arm then called the Stanford arm. We had a gold one and a blue one that Vic Scheinman had developed. We were using the gold one and we developed a program to pick up the parts and assemble them, screw them together and things like that. We went on to do several things from there. The next thing we did is we went down to visit McCullough Chainsaw Engines down in LA. They gave us one and we then worked on assembling some parts of that. So Lou Paul was an excellent colleague the long whole way. Actually later, it was a big step for me in my career when he and Mike Brady organized the first international symposium on robotics research, and he invited me to come and talk about some of the work I had done. At that, I then met and talked with a lot of people. These were great meetings, because they were small enough, probably 50 people, so they were small enough, you got to listen to every single talk. You would talk to them and there was a lot of encouragement to meet and do outside activities. Every afternoon was free to go fly kites, take hikes with your other colleagues, so you knew them completely differently than if you just heard their technical talk."
"Bob Bolles","Interviewer","Do you remember when and where that first symposium was?"
"Bob Bolles","Interviewee","That was at Bretton Woods and I think like 1981. it is going on 30 years. I have gone to those meetings virtually every time and at the third one, I realized that they were sort of rotating round and the next one would be in the United States. So I talked to Professor Bernie Roth at Stanford and said, Hey, we should host this, you know. we have got robotic stuff here. He agreed, so we hosted the fourth one here, which was UC Santa Cruz, which was wonderful. After that, I got on the board of the group and then continued to go to the meetings and meet people and things. So that really opened up my scientific career from being more local here in the US, to more all the way around the world."
"Bob Bolles","Interviewer","Prior to that, what kind of conferences would roboticists go to, or where would you see robotic work being done?"
"Bob Bolles","Interviewee","So conferences in general, over my lifespan, have gone from the ACM, which was everything as a student, I went and that was the only thing that had anything to do with computer science and then it sort of specialized to IJCAI, which is the International Joint Conference on Artificial Intelligence, and it had a part of robotics. And then that split into much more specific robotics conferences and computer vision conferences like CVPR and other, IEEE, PAMI related conferences and things. So I sort of look back, that I started with ACM and I then progressively got more and more specialized in computer vision and robotics."
"Bob Bolles","Interviewer","The meetings, you mentioned that allowed you to expand internationally. Where did the various participants come from?"
"Bob Bolles","Interviewee","So for this particular meeting, ISRR, there are three parts of the world, United States, Europe and then Asia, including Australia and things. So Peter Cork, I met at this meeting. Ray Jarvis is also Australian. let us see. And then a number of people in Japan I have gotten to know well, like Professor Takeo Kanade who now is at CMU. He and I happened to be working on some similar things, so we talked a lot. He invited me later to be one of the editors for the National Journal of Computer Vision, which I did for three years. I was never very good at it. Technically, I was fine, but journal editing was hard for me, because I had other pressing things to do, and if I did it tomorrow, it was just the same. But after a few weeks of pushing it off, I had end up with a pile of papers and I had panic and I never was very good at that. So yeah, I have met people from France and Germany that we still coordinate. I have not actually done I have done more discussions and things. we have done less direct, say, joint projects. I have done some joint projects with people from other countries, but not directly from that. At a CVPR meeting recently, we met. We put in a proposal for an IARPA contract recently with a group from the University of Amsterdam, and won, so there we are working with that. we are working with a group from University of Leeds on a project. Actually it is called Mind's Eye, because they have done representations for regions in time and other types of elements that we need for this reasoning, to couple it with the perception. Because perception, we are more focused with kind of starting with pixels and working our way up, but we clearly need to be able to understand occlusion and the permanence of objects and things that they represent, that we typically have not."
"Bob Bolles","Interviewer","What kind of vision system were you working on, on the first projects?"
"Bob Bolles","Interviewee","So the very first project, like this Model T assembly work, we had a color camera. We would locate mostly black and white things, because we simplified the world, to detect objects of certain known previously modeled objects, in pretty much like an industrial application. At that time, there were no industrial robots. When I came to SRI, Charlie Rosen was head of the AI Center and a fellow working with him, David Nitzen, the two of them had a large NSF project called the Industrial Affiliates Program. The whole point was to explore and distribute ideas about how to use robotics and computer vision in US industry. So the affiliates program had companies like General Motors and Ford and Deck and Scott Paper and all sorts of companies. I think at the height, it probably had 30 of these companies, maybe more. We had get together once every quarter. Every other meeting was here at SRI and the other one, so two times a year, We had go to one of these companies and see their industrial line, see what they need, what were their problems. It was real interesting, we would hear from the managers. They'd often say, Our problem is this. We had go see the line and talk to the managers. They'd say, Our problem is that. Then We had say, Can you send us some copies of the good ones and the bad ones? or whatever. They would do that and then We had work on them for a little bit and send back ideas for them. And it also meant that it gave us ideas what they really needed. During that time, three or four of us developed a program here to recognize parts that were mostly flat. They were viewed from above so they were two dimensional parts being viewed in two dimensional images, but still they were complicated enough. They had lots of holes and indents and things, and sometimes they needed to be inspected to make sure the had all the flanges and things on them. So we wrote a thing called the local feature focus method that would do that. One aspect of that, that was sort of fun, that I liked to continue to do, but we really have not done as much, is you could show it a part and it would automatically pick out the distinguishing features for that part, relative to maybe upside down or some other part or a set of ten parts. So it picked out the distinctive features automatically, and then use those to distinguish them. And if it could not, it would say, I can not tell part A from part B. Maybe the color was the only thing that was different. It could not tell that very reliably."
"Bob Bolles","Interviewer","How many pixels were you basing the decision on?"
"Bob Bolles","Interviewee","Ah! So originally, we were 128 by 128 and the cameras cost $10,000. Some place around here, we have got collections of cameras. The original cameras are these great big things. Well, actually, the one at Stanford is actually a box this big. Now of course, you can have them in your sunglasses in the middle of your nose."
"Bob Bolles","Interviewer","It was just black and white?"
"Bob Bolles","Interviewee","It was black and white originally. We graduated to color, but quite a bit later. it is astounding. That dimension, now, as you know, HD is plausible. You can have really nice resolution. As a computer vision person, I always want more resolution and better dynamic range, so it handles highlights and dark things a lot better."
"Bob Bolles","Interviewer","Contrasts. What was your actual dissertation thesis?"
"Bob Bolles","Interviewee","So it was on verification vision, and the idea was that if I had a model ahead of time, could I use that to predict what I am going to see, so that when I go looking for it, I am constrained enough that I can reliably detect it and use that model to verify that I actually have the right thing. Now at the time, we did it just, We had move, stop and look at it, take a while to think about it and say yes or no. Then if it is right, I measure its position and then maybe move. Now of course, the computational power and things are such that we can do this in real time. In fact, the ARM project which we just started about two months ago is to do exactly that. Is to marry real time perception with real time control. So far, a lot of robotics, there is a lot of nice real time perception and real time arm, but not much where they really marry them together. So this project is to try to do that, something I would loved to have been able to do 30 years ago, but now we are able to do it."
"Bob Bolles","Interviewer","what is the project?"
"Bob Bolles","Interviewee","This project is a DARPA program, and it is called ARM. there is ARM-S for software and ARM-H for hardware. SRI won a software contract and a hardware contract. Hardware people are developing a new hand and the idea is, you want to have a new hand That is capable but relatively inexpensive, and they have some interesting ways of using flat tendons and things for grabbing and holding and measuring. They also have some electrostatic techniques, where you can pick up a cup by just touching it to the side and turning on, and picking up the cup that way, so you do not have to be able to surround it like most grasps do. On our ARM project, we are working with Columbia University, which has done a lot of work on grasping, and Carnegie Mellon, so Matt Mason."
"Bob Bolles","Interviewer","Who are you working with at Carnegie Mellon?"
"Bob Bolles","Interviewee","So Matt Mason and Sid Srinavasa who is at Intel, but he is on the CMU campus in an Intel building, so they work really closely and have a lot of CMU graduate students working in the lab and things. So we work with both of them."
"Bob Bolles","Interviewer","Matt Mason's at Columbia?"
"Bob Bolles","Interviewee","No, Matt Mason's at CMU. Peter Allen is the main contact at Columbia."
"Bob Bolles","Interviewer","When did you come to SRI?"
"Bob Bolles","Interviewee","So I finished in 1976, so I came here in 1976. Actually, I did not get my degree, it was not conferred until 1977. My wife and I, I am from Florida and she is from Atlanta, we both sort of viewed this as a four, five year post doc, maybe. But then I liked the group so much and we were doing a lot of interesting things, that I could not see at that time, there were not equivalent things in the south. Now there are, things at Georgia Tech, things in North Carolina, even Florida and other places, but at that time there were not. I was not really ready to start something new. Now we certainly could, but at that time, I wanted to join a group and add to it. So I ended up staying here; I am still here."
"Bob Bolles","Interviewer","What kind of things did you start working on when you came to SRI?"
"Bob Bolles","Interviewee","So I worked on two different things. One was this, industrial applications. The program that I mentioned, this local feature focus method for finding things that are essentially flat, was picked up by Adept Corporation here. That is because I had known Brian Carlisle and Bruce Shimano at Stanford and they wanted to provide a vision system for their robot, for the industrial case. So they re-implemented, but they used a lot of the basic ideas. That was kind of interesting to see and fun to see people starting to really use it. The other side I was more aerial video analysis, where we started out using stereo and other things to build 3D maps. We then transitioned to trying to recognize the objects like the roads in the buildings and build 3D models of them, which still is an important problem. I still do that here now. So I have the ARM project that we are working on, Mind's Eye, which is more ground level. there is no robot involved. it is just video watching something and trying to learn and understand and . We do aerial video work as well. About two or three years ago, We had developed some technology for watching a scene from the air. So when you are in the air, of course, the camera's always moving. So things like parallax on tall buildings and trees look like things are changing, but They are not movers. So we were detecting we had a technique for handling that. The idea is, for the military, they'd like to know, can you detect some humans or vehicles moving? They always want to do it with the widest field of view, which means you have got the fewest pixels. So you have got to be able to do it with four or five pixels on a car, or four or five pixels on a person. We had developed a basic technique and refined it. Then at the last phase of that, we worked as a subcontractor to Raytheon, where we actually ported it to the hardware on the Predator. So it runs now on the UAV and it is being tested. it is kind of in hiatus. it is not directly been deployed. I think they eventually want to get it, but they have had other priorities. Hopefully, That is going to come back around. The idea there is that one application would be, say a squad picks up a cell phone off some ridge over there. They'd actually visually see them. The humans can do it better than we can, but even on a 640 by 480, they still focus at the middle. They do not notice things around the edge and they get tired after ten minutes. And we can do it all night. So the computers, They are still better at it than we are in the short term, for a few minutes, but we can cover massive areas and do it. We can say, What about this? and they can look at it and say, No, That is just something, you know. Ah, okay, let us watch that. So it is a cuing mechanism."
"Bob Bolles","Interviewer","What are some of the biggest technical challenges you have had in that kind of system?"
"Bob Bolles","Interviewee","In that particular system, the biggest challenge was, they had a particular computing box that had a low speed power PC in it. We had to port our stuff to run on that particular board. We could not add much to it because there were heating constraints too. Even though there was room for more things, they could not really handle it. So real world problems pop up when you are porting it to an existing device. let us see, what else? One of the advantages of that, We had done a number of projects where you analyze the data that had been sent down by telemetry. it is often compressed in some way, so the data we get down on the ground is never as good. There are break ups and other things. So we have always wanted to work, actually up on board. So there was one of the opportunities we could do that. we have ported the same sort of software to run on the ground for the little teeny things like Raven B, where the hand launched UAVs. Sarnoff which is a company that SRI owns, and is going to be merged into SRI here January 1st, they have developed a chip to do a lot of the computer vision algorithms. So the hope is, they'd be able to make the whole processing unit small enough to run up on board the Raven B and again, save the bandwidth and get higher quality images."
"Bob Bolles","Interviewer","What were some of the other robots you started working on in the early days at SRI?"
"Bob Bolles","Interviewee","We had a Unimate robot, made by Joe Engelberger, which started the Unimation company, which he'd used for a long time. It was mainly a large pick and place. It could pick up 100 pounds and move it. We worked on some perception algorithms for them to detect big parts. I think there was a lot of concern there for human factors. If people could pick up the engine block, but they would ruin their back. So the idea is, could you do it in a way that would save them they could basically do the more technical things and have the big weights being used by the Unimate arm. What other robots have I used? SRI had developed the shaky robot, which I did not work on. It was pretty much finished by the time I came. It was developed at the end of the 1960s and shown through the early 1970s. we have worked on some other mobile robots. Three or four years ago, we had a program from Darpa called the learning applied to ground robots, LAGR, and the goal there was essentially a race. They would put you in a place and give you a GPS coordinate and say, Go there. There could be fences and hedges and paths and tall weeds and all sorts of things, and the idea was, could you learn what the properties of these are, so that you could know that it is safe to go across this, and not over this deep sand or water or whatever. One of the things that we developed for that, that turned out to be a really important key, was a technique for locating the robot. The way the race worked is they would let you run this course three or four times and then throw out the worst one. Whoever had the lowest cumulative score wins. So if you could help map something in the first one and could remember it and find your way back there, then you would know that this is a good way, or this is a blocked way. But you have to be able to do that pretty precisely. So if there is a fence and you are a meter off, and you think you are on one side of the fence and you are not, then your map does not do you much good. So we developed we, Modey Agerwald who works here, developed a visual odometry system that used the stereo cameras on board the robot to visually watch and measure how fast it is moving and detect where it is going, to do essentially SLAM, simultaneous localization and mapping. But he used the other sensors as well. So he had wheel odometry, but it would get confused every now and again. It would slip in sand going up a hill, or if things were wet, it would slip. We had IMU, which would drift. It was basically good over short periods of time, but over long periods of time, it would drift. We had GPS, which worked, except when we were inside buildings or under really heavy trees. And we had visual odometry, and it would work most of the time unless you are looking at a plain wall with no texture on it that it could not see any features. So that mix of those four sensors made it so our team could locate itself quite precisely and reliably over this few hundred meter course. So that meant we really could reuse the data We had gotten in the previous runs, so we could get better and better. That was critical. I think there is a lesson there. Everybody has talked about robots that have redundancy, multiple ways to do things, but the expenses and the size and the complexity has been such that not many people have really done it. So I think we are now at the place where we are going to be able to have robots that have multiple ways to do things and they cross check each other. They can sort of be self aware. Probably one of the biggest troubles on all the robots is that they break. When they break, sometimes you do not know whether it is hardware, electronics, software or something. We do not usually use the industrial robots. we are usually using an experimental one. Like with ARM, we are running Barrett Arms, which are the LAM arms and they have been used for a number of things, but they break. Frequently we can jam the fingers and do things. you would like a system That is self aware enough to say, My left finger is jammed, or, The software to control the neck did not boot up right. There ought to be something that basically automatically diagnoses the thing, because otherwise, in the past, you would often come in and say, I have got the whole day to work on this thing, and then something's not working. You spend the whole day just debugging what it is, and you just felt like, Well, gee, the gods did not want me to work today. I will come back. We will try to debug it today and come back tomorrow. Again, I think there we are getting close. Like the WAM arms now have temperature sensors on all the joins, so they have a direct way to measure things. They can measure the location, of course, the positions of things. I think looking at things, to look at the hand and say, Wait a minute, your fingers are not all open. You commanded them to be open but They are not and your position device, something's messed up, because it says it is open but it is not. That kind of cross checking, and I think this one where they were using basically four sensors to cross check each other and figure out what the fusion should be is probably the way we are going to be going."
"Bob Bolles","Interviewer","What kind of psychological theories or visual perception theories were influential on your work in robot vision?"
"Bob Bolles","Interviewee","So David Marr, way back when, had theories on perception that influenced all of us, I think, in terms of how to do the pixels, to symbolic information. There are a couple of fellows here at SRI actually, when I came, Marty Tennenbaum and Harry Barrow, who came out with a little different theory called intrinsic images, where the idea was that the world really is 3D. To understand it, you have to understand the surface normals and the textures and the colors and the lighting and all of those things rolled together. Sometimes you may be in a controlled lighting situation, but not know the texture. Other times, you know exactly what the texture is, but you do not know where it is. So their point was to show this general interrelationship of all these aspects, and sometimes you might know a couple of these that would narrow it down and help you locate the others. Biology in general is pretty humbling, to see how effective throughout the whole career, you would often show a demo to somebody like my mother or my father, and they would say, it is turned around, obviously. it is upside down. Just because everybody does it so easily."
"Bob Bolles","Interviewer","Did you take much inspiration from JJ Gibson, ecological perception, the sort of embodied kinds of vision?"
"Bob Bolles","Interviewee","Yes. Harry and Marty Tennenbaum took it quite seriously, so sort of by osmosis, we were the group here. Our group has gone from ten up to maybe 15 or 20. it is now at about eight or ten, so it floats around. People in the group have different feelings. Some are much more computational. They do not care whether it is biologically inspired. I like it to be biologically inspired, but I am a pragmatist, so I am quite happy to do it in a way that they do not. For example, early on, after we did this two dimensional recognition, we started doing there was a group there that had developed a LIDAR sensor, one of the very first. It was very slow, took an hour to scan the whole scene or something, but it was a range sensor, not biologically inspired, unless you think of acoustical things, like dolphins, bats, things like that. But yeah, so in that sense, it could be, but it was not in the human inspired sort of sense. But I was quite happy to use 3D range data however I got it. If it was from stereo, That is fine. That is biologically inspired, or trinocularly. it is a little bit stretching it, but there are multifaceted or multi eyed things. So I was quite happy to work on range data. My feeling was pretty simple. The objects are 3D, you want 3D data. Otherwise you are starting one D behind already. So you really wanted to have it. Nowadays, I had predicted that range sensors this was 30 years ago were going to take five, ten years, and we are just now seeing practical lasers and stereo and flashlight R.s and things like that, that are becoming practical. They all still have a few quirks and stuff. Back then, sometimes at a conference, I would be viewed as a heretic for using laser data. it is not fair to them. I did not care. I had a problem to solve. I was quite happy to do it from engineering."
"Bob Bolles","Interviewer","Did you use a lot of sonars, range finders of other kinds?"
"Bob Bolles","Interviewee","A little. I personally have not. Our group had used those some, but They are pretty poor. So when planar laser scanners like SIC and even now the Hokuyu and some of those, they are so much better that sonar was kind of a poor stepping stone in that direction."
"Bob Bolles","Interviewer","What about the use of visual flow? Do you need real time data to do that?"
"Bob Bolles","Interviewee","Yes. Harlan Baker and I, maybe 20 something years ago, took a sequence of maybe 100 or so images where you had to take one image at a time, move it. So that was video 20 years ago, right? It took forever to do it. But we developed something called the epipolar plane image analysis, which essentially showed the paths of the features in the scene, that there were patterns to them that you could capitalize on them and locate where they were in 3D. So it is like structure from motion, but we took it we did not start with a general case. We started with the case where we were moving in a line. In a line, we could show all the features were moving in lines too. And if the features were in line, you could find lines pretty easily. From that, you could then compute where it was in 3D. So motion, that was the first thing we really had done in structure for motion. Since then, we have done a number of things. The visual odometry is essentially doing that. For the robot, since they had stereo cameras, we were using stereo, so we have a monocular version as well. So you can take a camera and move it around and get a picture of the world."
"Bob Bolles","Interviewer","What were the evolutionary steps in between that you built on to get to this visual odometry?"
"Bob Bolles","Interviewee","let us see. So the things that were most important were finding local features, tracking them and then doing the mathematics. There had been a lot of local feature kinds of things, and as you know, local features have gotten better and better. Probably the most popular ones now are SIFT, which have a description about them in their local area. But they often take too much time to computer even now. So here at SRI, we have developed censure E features, which are similar to that, but much faster to compute. it is not intellectually the most important thing, but it is something you need to be able to detect and then track them over time. Once you have these threads of tracks, then you need to do the mathematics to compute where the camera went and what the structure of the world is. When you have stereo for it, then you can compute 3D locations of all these features directly, and now tracking how you are moving through 3D features is pretty easy. So we did that first. In fact, That is what I mentioned on the LAGR robot. Going from there to single, monocular cameras, the mathematics was a little more complicated. there is a group at Sarnoff and some other places that showed that you could do this in a nice way. We had jumping way back another fellow and I here at SRI, had worked on the problem of computing where the camera is relative to some scene. So we developed a new closed form solution for, if we knew objects in the scene and we could project them, we could compute directly the six degrees of freedom of the pose of this. Now the photogramaters had done that for years, but they required a human to point out and say, That is the corner of the building, That is the top of the wall, That is the other corner of the building, here is the door. So the humans were involved in doing the feature association and they did not make many mistakes. I mean, a few. Sometimes it is hard to tell exactly where the point is, but basically they did not have many mistakes. But when we were doing it automatically, trying to figure out where this camera was, the computer matching problem would generate a lot of mistakes. So We had have a lot of good points and a lot of mistakes. So we wanted to compute where this was. So we came up with a technique called RANSAC, for random sample consensus, that would sort through this bag of feature matches that you have and pick out the ones that were that could be interpreted in a way to compute a coherent position for the camera. We wrote a paper back in early 1980s that described it. It was actually ACM magazine at that point. We were the most proud about our closed form solutions for these, because they were complicated mathematics. But the thing that really stuck was the RANSAC method and now RANSAC's used for all sorts of computer vision things all over the world. we have become famous for that, not our nifty, cool mathematics. So you never know, see what is going on. I guess a few years ago, there was a special workshop just on RANSAC. They were celebrating the 25 years of RANSAC. That was fun. I went and presented a paper and things. I have not kept up with all the variations that people have done to improve it. In different situations, there are ways to be even better at it."
"Bob Bolles","Interviewer","What are some of the big applications today that use the RANSAC?"
"Bob Bolles","Interviewee","So almost any fitting thing That is done. So for example, if you have range data off this table, and you know that sometimes there will be points like on the pen or on the cup or something like that, but a large percentage of them are on the table, then people use the RANSAC method. they will take a handful of these points, fit a plane, find out how many other so if you had a point up here and it fitted a plane, you would not have many other coherent ones. But if you get points on the table, we get a whole bunch of coherent ones. You say, That is bad. That is not on it. This is not, that is not, and so forth. So fitting of anything, ellipses, lines, geometric parts, it is sort of a standard tool now that they use, knowing that there are what we called gross errors. There are a lot of gross errors mixed in with the really good data. This is a standard technique That is easy to understand and I think probably easy to implement, so it was picked up."
"Bob Bolles","Interviewer","What are some of the other mobile robotics or arms that you might have worked on in the 1980s or 1990s?"
"Bob Bolles","Interviewee","It might have been late 1990s, there was a group here at SRI that had a project to do with Darpa to explore an unknown building and map it, and then find people in it, and then sort of guard it, watch it. So the approach that they used and I was only on the side of this project, but a little bit involved where it was called the centabots, because they literally used 100 robots to explore. This floor here, there is actually the third floor of the building next door that was not being used, so they used that as one of their main things. For the actual test, they went to some abandoned warehouse in Texas and they hid some things and people in this. They said, One, two, three, go, and they sent the robots in. So some of the robots had these laser scanners that they could map and do really well. Others just had sonar, so they were going around by themselves, and they had sort of primitive monocular cameras, so they could detect somebody moving. They knew where they were, and they set up communication chains. The idea was, basically, to send robots into a building before you send people, so you could go in and say, there is a person there, a person there, and this one's moving. That one's going there. So we still have probably 20 of those robots around. We were involved with a robot with Kurt Conelage who was here, called Flaky. It was hereditary, with Shaky being the original one in the late 1960s. Flaky, you could talk to it and it would follow you and do some initial things, initial tasks. The idea was to say, Flaky, go bring me a bagel. On Wednesdays, they sell bagels here. The idea was for it to be able to navigate itself, avoiding the people and things, and go get a bagel and come back. The speech recognition worked fine, except that when anything went wrong, your pitch and excitement would you had taught it, say, Stop. But when you really needed it, you said, Stop! It said, Excuse me? Say it again. That was not very helpful. they have worked on that. That was one of those clear examples. Alan Alda came for Scientific American Frontiers or something and filmed during the day. They had Flaky following him around and sending things to people and stuff like that. They wanted a little clip of Flaky actually pushing him against the wall, which we did not want to do. I think they eventually took a still of it. Flakey was about garbage can size. it is in the front room, up where we got nametags. I clearly come down on the side of helpful robots, constructive, keeping people from hurting their backs, not the monster versions that attack people and push them against the wall. We were not so pleased about that. I understand why they want to do it. it is not our real choice."
"Bob Bolles","Interviewer","Where has your funding come from over the years?"
"Bob Bolles","Interviewee","Most of my funding, starting at Stanford and here, has been through Darpa, Defense Advanced Research Project Agency, largely because they have had substantial resources to explore some of these things. Now the funding has transitioned dramatically over the last 30, 40 years, from robotics and computer science is real important. This is not quite true, but basically, do good stuff and explore some interesting, novel things, to now, They are much more focused on a lot of them. Although, like the ARM project, the idea is, a lot of the current arms that are being used in the military, like for bomb disposal, what they really can do is pick up the bomb, by tele operation. They do not do it automatically, and they can not do things that are very delicate, like separate two wires and cut the red one. That is the sort of thing the goal for ARM is, to be able to do things in a more delicate way, one. Two, to be able to adapt to whatever it is. If the wires get stuck and you are trying to separate them, then you need to be able to do something a little differently. Or if the part's not exactly the right size or it has different weight or something, you need to be able to do it. Ultimately, this redundancy, they'd like you to be able to reach inside like a gym bag and feel around, without normal visual perception and say, let us see, there is my baseball, or there is my whatever it is. So it is pretty fundamental. As I say, the thing That is exciting to me is this marriage of real time perception and real time control that in this manipulation world manipulation's pretty hard. Again, people do it very easily. It makes it look easy and our attempts are not at that level, anywhere close."
"Bob Bolles","Interviewer","One of the biggest challenges of trying to realize machine manipulation?"
"Bob Bolles","Interviewee","One is this adjusting for the position. There are always calibration errors and things like that. One way to do it is to literally watch your hand reach around something so you do not hit it. You watch it go down and grasp it. Once you have done it, you feel it. Your fingers are in the right place. You can see it come up with you. it is not still lying there. So it is this multi checking that We had like to be able our goal is to develop a generic way to do that kind of multi checking. So you tell me about a part. It may not be exactly the same thing, or it may be full of water or not, so it weighs different amounts, that we need to be able to adjust and say, Ah, it is a little heavier. And to be able to automatically do that. In industrial applications, things are very tightly constrained, so the weights of things are known and the lighting's known and all that sort of stuff. Here we are trying to do away with all those constraints."
"Bob Bolles","Interviewer","what is the difficulty of coupling the vision there? Is it the bandwidth, the amount of information?"
"Bob Bolles","Interviewee","The difficulty is, all the different components have quirks, meaning computer vision can not handle some very smooth surfaces like this. it is much harder to recognize than this, which is kind of counterintuitive. you would think that the easier objects, like nice smooth blocks would be the easiest ones. Well, They are not. They have the least amount of features on them so They are actually, from a perception point of view, hard to measure and detect. That was an interesting comment on the original robotics work done at MIT and Stanford and other places, where they would literally worked in a blocks world, thinking it simplified things. But in fact, it made it harder. If you had the world with lots of nice textures, you could actually see it more easily. Similarly, probably, for touching things. If it is really slippery, it is hard to hold onto those. If you have got a softer object That is got more texture, you can pick it up and manipulate it more easily. So one is dealing with the artifacts and knowing what the uncertainties are and how to deal with them. So for one of the sensors, we have a flash LIDAR, the sensor is much better at locating things left and right than it is along the beam. The range data itself is not that wonderful. To grab things, then, you ought to take that into account. You ought to know that you can grab it this way better than trying to grab it that way. Then there is a number of things in the actual communication between the devices. Bandwidth's not quite right, but it is the representation of all the information and artifacts that I am getting out of this sensor, maybe merging with another sensor, and trying to deal with things in real time. As I mentioned, one of our main goals is to try to come up with a generic way to represent the tasks and the object so that we can automatically insert these checking steps. Because we could do it now, but there is so many things that you would like to check, that you do not want to have to list them all, all the time. you would like the compiler, in a sense, to compile them in and so when you pick up something, you verify it is there, you check that your hand's correctly positioned, that your fingers touch it, the weight's right, that you did not collide with things. All of that ought to be essentially built right in for any object here. There are special cases, if you are trying to pick up a piano or something, but for a lot of things, you would like a generic way that just gets applied."
"Bob Bolles","Interviewer","In terms of that kind of software development, do you see movement towards more unified kinds of robotic operating systems and scripted languages?"
"Bob Bolles","Interviewee","Yes. For the ARM project, they provided everything to us in ROS. We had done a little bit but not that much. it is nice, because open source, it is well supported. Brian Gerke was actually here at SRI for a while. he is now over at Willow Garage . it is nice, because it provides a lot of the infrastructures that you would need. It seems to have taken over completely from the Microsoft robotics part, which was being treated rather differently. So ROS seems to be taking over the world. I have not checked around the world to make sure That is the case, but locally, certainly, it seems to be doing well."
"Bob Bolles","Interviewer","Why do you think it was treated differently than the Microsoft system?"
"Bob Bolles","Interviewee","Well, I think part of it was that they wanted to provide an open source community support and they really did it. That is, they would react in a day or an hour. If you sent in a comment saying, I am having trouble with such and such, either Brian or somebody else in the community would react quickly. That kind of support you can not beat. Microsoft was not doing that kind of thing. Microsoft also had much more, I would say and I am not the fellow next door. Regis knows a whole lot more about these things than I do. I understand that it provided a number of things that were good, but in a more fixed way. ROS opens it up and you can define your own robots easily, so That is good."
"Bob Bolles","Interviewer","What kinds of changes have you seen in SRI through the years?"
"Bob Bolles","Interviewee","I guess the easiest thing to say there is that we see waves of things. So one wave is the fundamental and applied versions. It seems to go in stages. there is a reaction that you say, Hey, you have done a lot of fundamental things. What can you do for me on this particular thing? You do that for a while and then you realize, Wait a minute. there is some fundamental things I still do not know. So now we do ARM and Mind's Eye and stuff like that. Then there is another, Okay, you are doing well there. let us see the applications. That is happened here. In the AI Center itself, which is about 80 people now. When I was first here, it was maybe 35 or something like that. there is also been a wave of how big projects we are working on. Are we getting money for five person, 10 person projects, or are we getting money for one person or half a person projects? We see sometimes funding has gone through waves like that. we have also seen things, some associated with this fundamental versus applied, is how much engineering obliviously is really required. How critical is it to make it so somebody else can use your code? The atmosphere here hasn't changed that much in terms of ten years ago, we had to start wearing badges. People did not like that. But from the government's accountability thing, they needed to make sure. We do do some classified. A number of us have clearances so we do things that are occasionally classified. We have the capabilities to do it. So some of the time we have done that, like in mapping and things. we have done a project in the open and then we use our clearances to take the real data and run them in special computers and see how they work and then improve and enhance and so forth, so see where they can be really applied. that has been sort of nice. We do not normally do a completely black program. There are parts of SRI that do that, but in our group here, we have not done that."
"Bob Bolles","Interviewee"," so every time we get together, we—"
"Bob Bolles","Interviewer","So, who have been your most important collaborators or people that you have had a lot of intellectual exchange with over the years?"
"Bob Bolles","Interviewee","Right, so, I mentioned before, Lou Paul at Stanford was probably the most influential one. I would say his knack for picking out good next projects to work on was really inspirational. Tom Binford, who was another professor at Stanford, or he was a research associate. He had a very definite aesthetics on the quality of computer vision, and you were talking about Gibson and things like that. Those things he knew well, and he wanted all of us to consider seriously. Here at SRI, I mentioned Harry Barrow and Marty Tenenbaum also generated their idea of how computer vision could be viewed and was certainly important. I have had Marty Fischler, the fellow who I worked with he was actually my boss for a good while, but the two of us worked for 10 or 15, 20 years together. He just recently retired. He and I developed RANSAC, but we did a lot of other things. He had a lot of really ingenious ways of looking at a problem, and then I started out doing a lot of the implementation and then sort of worked up to so we could compare notes and improve ideas. So, that worked out really well. let us see, people outside of this outside of SRI and Stanford, I have had there was some people working on a robot when we worked on Autonomous Land Vehicle for Martin Marietta outside of Denver. We were doing a stereo project and two other groups were doing a stereo. So, we worked closely with them. One with Keith Nishihara, locally here in Palo Alto, and JPL. And so we were developing stereo to be run in real time to detect obstacles in front of this robot. Now the Autonomous Land Vehicle looked like a bread truck, because this was back in the middle eighties, I guess. I do not remember exactly the timing, but the computers were big, and the and then they needed big cooling, and the sensors were big. The laser scanner was like this big. The cameras, again, were sort of big. So, we were doing stereo on this and laser scanner analysis, but for stereo, we worked with JPL and Keith Nishihara here. JPL team went on to do work that went into the rovers that are on both Opportunity and Spirit on Mars. So, we have stayed in touch with them. We still do similar things. We worked on robots through General Dynamics Robot Systems in Maryland. We were part of the Robotics Consortium, and we focused there on obstacle detection and classification. What is it? it is a big lump, but is it something I am interested in? Is it just tall grass or is it brick wall? And, also people detection from the moving robot. So, the army rightfully said, Hey, you guys are able now to navigate. Well, you can go around this course. it is 10 kilometers long, and you can keep doing it well, and things the weather changes and range and all that sort of stuff. you are doing that well, but what about safety? What if we have got people around? How are you going to detect them? And, if They are walking around, That is one thing, but if They are lying down. There are mechanics in the garage. How are you going to detect these things? So, they looked at infrared and motion and geometry and changes and things like that. So, we worked on that project with them, as well."
"Bob Bolles","Interviewer","Were you involved with the DARPA challenge? "
"Bob Bolles","Interviewee","I was not. I went down to both of them, the well, I guess there were three runs. So, I usually went down ahead of time, and we talked to the people and because we know a lot of the people doing the work. We did not originally, because in the first couple in the desert, because they the rule was if they if DARPA was funding you, then you could not participate, because they felt that was unfair, right. For the Urban Challenge, they changed that so you could do it, but we did not quite get our act together soon enough, and so I just enjoyed watching some Sebastian Thrun and Stanford people. We went down and cheered them on, and things like that. I mean, along that line, as you know, not too long ago Google announced that Sebastian's been working on that, and they have a fleet of six or ten cars that they have logged, whether it is 160,000 they said or some huge amount. So, my wife is counting on the robotics navigation systems to get good enough in the next 15 years so that she will not have to drive. So, whenever we meet some of these people, she says, Hey! Are you on track to get this done? I am counting on this by the time I am, you know, whatever, but I do not want to have to drive. Because, right now her mom is 87 or something, and it is dangerous. She still drives."
"Bob Bolles","Interviewer","I have a new excuse for not having a license."
"Bob Bolles","Interviewee","Right."
"Bob Bolles","Interviewer","So, apart from the self-driving cars, what do you see as the other big applications for robotics and robotic perception?"
"Bob Bolles","Interviewee","So, we were talking about waves and things. So, in the seventies, there was when robots and computers and things started getting built, real ones, like Shakey and stuff, there was a huge media push. it is coming. it is going to take over all your jobs. it is going to be great in your home and it is going to do all these things, but we could not deliver. It was just too hard to do it. All these easy things quote easy for humans that they have learned are really hard to do from a robot. So, then there were after this big hype, there was kind of a low period, and now in the last 10 or 15 years, robots have kind of infiltrated everything, and if you look around in medical things, now They are like endoscopy, the da Vinci robot, which actually is a company that SRI started, spun off. We still have da Vinci next generation da Vinci things in the basement in the floor below us. And so, in medical things, they can do it better. That is more tele-operated, but turns out things like hip replacement Russ Taylor, one of the fellows I knew at Stanford is now at Johns Hopkins, and there the robots can do better at hip placement because they than a human, because they can make the joints smoother, which they means they heal faster, more reliably, less infection, and all that sort of stuff. So, in medicine, in cars now there are automatic cruise control that'll slow you down if you get and warn you about a lot of things. So, it is sneaking in there. it is sneaking in education. there is robots now Lego robots in elementary school, First Robotics in high school. So, if everywhere you look, there are robots, and it hasn't been this huge media hype, fortunately, but they have sort of come back around. I think some of the things that are going happen there is obviously the elderly care, which needs help. I think probably initially it is going to be some monitoring and communications. There are now several companies like Willow Garage, and, oh geez, Anybots and things like that that have little robots. So, you can essentially send a robot down and you can now watch the meeting or attend a meeting, and you are just your robot's in the meeting, but you are actually watching it. so, I think that kind of communication for elderly is going to come in first. Then there are going to be things where it can monitor the did they fall down in some way? Do they need help? And later It will start doing things where it can go get things, check on medicines, and later even than that, probably be cleaning the house and doing dishes. I mean, That is what the cartoons all showed, right, was doing dishes and cleaning the house, but That is probably the third wave of even for the elderly. Of course, manufacturing robots have infiltrated that and have been very active there for a long time. let us see, what else? Perception is probably going to take off here, too. As you know, everybody's cell phones now have cameras, and those cameras are dramatically better than those 128 x 128 cameras that we started with. So, I think there is going to be more and more applications of things where you can use your camera to do something other than just take a picture and post it on Facebook. I remember, a few years ago there was a group in Japan that you could take a picture of a barcode, and it would tell you what the product is, who makes it, what it costs, where he could find it cheapest on the web and all sorts of things. that is a little niche thing, but I think there are going to be more and more things that and probably 3D, too. I think the 3D movies there is been waves of that, too, but I think the capability now to do real-time stereo and the world is 3D. Actually it is 4D, because They are moving. You really want something that, just like I was saying, 2D and you have 2D image, That is okay; 3D and 3D data, That is okay. For motion and 3D world, you really need something that deals in that inherently. You do not want to have to deduce it all, because you make mistakes. That is my bias, but."
"Bob Bolles","Interviewer","So, where do you see your own work going in the near and somewhat further future?"
"Bob Bolles","Interviewee","Mm-hm. let us see, I am hoping, like in both Mind's Eye and ARM are projects that I am excited about. ARM has already said, I like this idea of mixing and really getting control and perception together. And by perception, I mean touch and weight, forces and things like that. Not just visual. And I think That is now's the right time to do that. we have got devices that are reliable enough to really run experiments and do it, and there are a lot of control issues in how do you again people do it very easily. They can insert their hand in something pretty narrow and avoid obstacles and stuff, but That is still not thoroughly known, and how where I might so, for example, one little not so little problem but is How should I place my hand knowing that I want to see it, as well as grab the object? Alright, That is, again, a simply stated problem, and we can do it in a lot of easy cases, but in general, how do you do it, knowing that they have got six florescent lights here. what is that going to do to my image? And if I am using infrared laser spots, what does that do and so forth. Though you really want to be able to do the comp basically use full access to computer graphics to predict what it is going to look like and what you can see, what you can not see and what is occluded, and how you might get feedback to do the next little delicate thing I need to do. How can I see that the wires are separated? So, when I cut them, I do not get them both. I only get one, because I not only have to get access for my fingers, but I have to get access to the perception and know the taking into all the quirks, the artifacts. I think That is we are stuck with that. I do not think we are ever going to get away from devices that have strengths and weaknesses. That is just sort of the basic thing. So, I so, this marriage of control and perception is one. The other is a deeper reasoning. Perception, a long, long time ago talked about top-down with models and things, and we have done it in industrial cases where we have very specific models, but we have done less with generic a priori information that we know is going. We really need to have a better marriage of perception and this reasoning. As I mentioned, there are not many computers that know that if I put some like the perception of an object, I put it behind there, and any two-year-old knows it is there. They are not surprised when it pops back out again. Computer vision, They are still surprised. They still do not really reason at that level, and so I think so there the ontology and representation people, the reasoning people, the theorem-proving side of the house and things, They are they have pretty much been in stovepipe of their own. They have not really dealt with real problems. There are exceptions, of course, but in general they have this whole thing is separate and perception's been separate. I think That is got to get together, too. So, you know a container. You know what that means. There are tops and it holds certain things, and it holds some kinds of things better than others, and the way you get in if you the view the house as a container, you can get in through the door, you can get in through the windows, you can get in if you are air, you can get in through this, that and the other. That is yet to come. Mind's Eye is the first little step in that direction, but I think's That is it is going to make when we can do that in a pretty solid way, I think we are going to be much better off. It will also help this checking part, because then they will be able to say the common sense saying, I did this. This should happen. One part that we have in ARM that we would love to do, but we are so busy doing other things we are not going to do it, is we have microphones on the robot. So, if we drop something, we can say, Hey, I just heard something hit. We have the capability to do that, but we do not have that integrated yet. That sort of thing, people all the time if there is a certain kind of noise, you look. you are well-trained, because That is what you do, and the robot ought to be able to do the same thing. It ought to be able to deal with all those things in a coherent way. "
"Bob Bolles","Interviewer","Do you have any concerns about some of the potential military applications of your work or as these technologies may go to other kinds of militaries who are developing robotic systems?"
"Bob Bolles","Interviewee","So far, I have focused mostly on the detection and me, personally, and I have been pretty comfortable with that. Or, I am helping at least I view myself as helping the U.S. hopefully save lives by finding out more information about what is out there. So, do not send somebody into a house unless you know what is in there, and there are things, again, from a biological term, that turns out there are radars and stuff where you can look through walls so you can tell that and go on in. I would just as happy to do that sort of thing. Am I worried clearly there is a potential that (a) somebody could use it for more nefarious, more dangerous things. it is possible. I have not I do not see I think it is still a pretty long way away before there is a serious danger. I guess the closest thing might be detecting and tracking somebody and shooting, actually having autonomous shooting in that sense. The U.S., the rules on engagement that that does not happen. there is still a person in the loop, but you could imagine something whether it would work. Still a ways away, but."
"Bob Bolles","Interviewer","I just had one final one, I think, that related to your previous discussion about bringing together this reasoning perception of these different disciplines or different groups that were interested in different kinds of aspects of robots, like control and representation or these various things. So, what do you think were the reasons why this did not come together earlier? Were they mainly technical or were there were particular kind of social reasons for that or how the universities or something were organized?"
"Bob Bolles","Interviewee","So, I think what happened was that they started out together, and so they said, Geez, we need a system that does top-down, bottom-up and all this sort of reasoning and representation and everything, but then they realized, Wait a minute. This is much harder than we thought. there is Minsky had a little summer project, and they were going to do perception and they were going to finish it that summer, and then do the rest of it. And I think that was true of all of these different areas that when you got into them, you realized, Wait a minute. Time, I thought was pretty easy. it is linear, but James Allen came out with his representation of temporal intervals and things, and that took a lot of thought, and it is been adopted by other things. But then there is regions and areas and all sorts of things that other people have added to it, and it is taken years. So, I think what happened when you start out together and, you are, Woo, this is really hard. here is an interesting way to solve this problem. Then, there is a little group that forms around that, and then here is another interesting way to solve the time problem, and the people get interested in that. So, I think there is a natural specialization. So, it takes some special insight to say, Hey, it is time to put these together. Now, in putting them together, it is often hard, because there is completely different languages, like the representation I was talking about. Ontologies, you go and ask them, Well, how do you represent your ontologies? Well, they have OWL and nine different kinds of languages on top of each other, and I am thinking, All I wanted to know is this thing a kind of plant or is it a And they do the same thing with vision. They say, You mean, you can not tell that is a cup? it is on its side, but you still ought to be able to tell it is a cup. So, there is communication, and you have to set up an agreement on it is okay to ask dumb questions and find out what is capable and what is not, and that really is a barrier. it is true with us in control, meaning us meaning perception, because some things I think theycan surely do, but they can not. it is hard to do it. They can maybe do it, but it is special purpose or something. it is not a general way to do it. Similarly with us when they look at us. So, when I say the time is ripe, I think (a) these communities have matured pretty well in the representation, control and perception, and I think there is the benefits from putting them together are going to be substantial, not just a little increment. In the past, I think, Well, geez, just a I might get a little bit from it, but I have to learn this whole new language and stuff, and I do not That is too much trouble. So, I think the maturity level is important. So, you can get to something that you really could use, and when you bring in a little group That is helping you do it, then, and They are you have to have this mutual agreement. As I say, you have to have a negotiation that says, Okay, I do not understand what you are I do not understand what is hard."
"Bob Bolles","Interviewer","I am also curious as to whether this part of the reason why these things are now having to be put together is also this focus on real world applications in a lot of different ways, where it is not easy to say like, Okay, I will not worry about that one. I will fix it with by making sure that the environment is very structured or something. "
"Bob Bolles","Interviewee","Right. So, they handle it another way where they constrain it to do away with it. One of my pet peeves with this is sort of related to what we are talking about. At DARPA when they do a project, they often want to they want to make sure it is self-contained. So, that means they can get the data for it, that they can set up some milestones and see progress and say, Hey, we are doing it better, more precisely, faster, whatever, but because of that, they often do not want to give you everything that you might have available. So, for example, if you are sending a robot out ahead of me to scout around, the soldiers all have good maps. They have depending on where they are and how recently it is been done and things, but they might have lidar scans nowadays. They might have good can satellite and aerial images. you have got good topographic, and so my thought is, If I am sending a robot out there, I ought to get all that, too. And sometimes they have been able to do that, but often they say, Nah, it is too much trouble for me to get all that information. You just start here. Where, that seems wrongheaded-thinking to me. If a soldier has that when They are going out there, the robot ought to have it, and the robot can enhance it and improve it and send it back. And the soldiers, when they come along a little later, can use it. So, and I That is changing now again partly because some of these communities, again, their representations of all this information is getting better. it is more prevalent that you have these different kinds of maps and where the roads and buildings and heights and things are, but it is people have had perception has often had to do a lot more than I think they should have. So, if you start with a model, it is a whole lot easier to say, Oh, there is that building, then trying to construct one from scratch. And so I some of the practical applications, you really do come in with a lot of information, and you are not adding any new constraints, you are just using information that is available and could simplify things in a both for robustness and speed capabilities. "
"Bob Bolles","Interviewer","So, apart from RANSAC, what do you look back on and see as your biggest accomplishment or the thing with the biggest impact? "
"Bob Bolles","Interviewee","Well, the industrial part recognition, probably, the 2D and 3D things. They were LFF and the 3D we called 3DPO, which was fun. let us see, one of the things I view (it is not as well known) is the epipolar-plane image analysis, because that was sort of the first structure for motion where we showed that we can convert things into linear. let us say, if you can detect lines, you can then detect how far things are in the world, which is important. One of the it is still not a solved problem to take an arbitrary world with sensors and build a good 3D model. There are lots of applications. We had a company maybe ten years ago come and say, Geez, we spend a lot of money with picking up sofas that we have delivered to somebody's house because when they get it there, it does not look the way they want it. So, if you could just go scan their house for us and we could stick this in there virtually, then they could say, Hey, I like that. It would be better if it was a little longer or it is a little shorter or a little or if you did not have that purple pillow on it. it is still not quite possible. With laser scans you can do pretty well, but and it is even getting where you are going to probably be able to take your iPhone and do this and get a model of it, but it is still not quite there yet. So, there is plenty for us to do in the future. let us see, things the motion detection from a moving object like a robot or a plane or something like that, That is we were certainly not the only ones to be doing that, but that is an important step, because then you do not have to worry about physically having your camera fixed. You can zoom and pan and fly it around and bounce over things and stuff. That was a big step. Hopefully, We will be able to brag about some things with ARM and Mind's Eye, but have not gotten there yet. "
"Bob Bolles","Interviewer","We will come back to that later."
"Bob Bolles","Interviewee","Right."
"Bob Bolles","Interviewer","I think we are done with all the questions we had, but if you have anything you would like to add or anything you have missed."
"Bob Bolles","Interviewee","I guess, one it is not earth shaking, except that we found that pairs of people work the best. So, on a project we often have projects that might be five or eight-person projects, but still pairs seem to be the best, and part of the reason, it seems, that it is hard to keep a third person up to speed. So, if there are two of you, you can go knock on his door and get excited, and you guys talk about it, and you change your idea this way. If there is a third person over here, They are behind already, and then so somebody has to go get them up to speed on that area, and if they go off, then you are behind, right, and then so, pairs are easier than threes and pairs are better than ones, because one people tend, including me, tend to go off sometimes. So, I need corrections to come back and say, Wait a minute. that is a cool idea, but the real problem is over here. So, from a working point of view, we have tried to encourage mixing and matching, and one side effect of that that we need to do better on is to have people that do not just work on one project at a time, because by working as a pair with some other thing, (a) it broadens you and gives you new ideas, but often things there is correlation between things that come back that kind of give you a new way to look at it. So, having a person work on two, but probably not more than two once it gets to three or four, then there is change in gears so frequently during the week, that they it is hard to make progress. So, twos and not just focusing on one thing at a time, partly because if you get blocked on one, you can not figure out how to solve it, go work on the other one and see what is going on. Or, if the person you are working with here is off, you can work on something else."
"Bob Bolles","Interviewer","I think That is good advice for any kind of work, really."
"Bob Bolles","Interviewee","Well, except that when I was in school and even in college, you had to do your own work. we are not allowed to talk anybody. Sometimes they'd do joint projects, but it was almost always do your own work, but the world is not that way, at least this world is not that way. You really having somebody else to work with and bounce ideas on and check your sanity is dramatically better. I think That is changed. I think our children had more opportunities to do joint things in a constructive way than we ever did."
"Bob Mcgee","Interviewer","You know the various people you collaborated with, the projects you worked on. That kind of thing. So you can start and then we can ask you questions."
"Bob Mcgee","Interviewee","Right. It will be highly rigged and you ask anything you like."
"Bob Mcgee","Interviewer","Okay."
"Bob Mcgee","Interviewee","Okay. I was born in Detroit, Michigan in 1929. I grew up in that area and in northern Ohio around Toledo, Ohio. I did my undergraduate work at the University of Michigan, graduating in February of 1952. I got married on that date and after a few months I was called to active duty as an ordinance core officers with the United States Army. I served as a guided missile maintenance officer for three years and then I was fortunate to get a scholarship for my graduate program from Hughes Aircraft company. I moved to California, started studying at the University of Southern California and I received my Master's degree in 1957. And then with further help from Hughes and their PhD program I completed a PhD in 1963. I joined the faculty at University of Southern California at that time and in 1968 I moved to Ohio State University in the Department of Electrical Engineering in both cases. And I was at Ohio State University until 1986 when I moved to the Naval Postgraduate School. I retired from the Naval Postgraduate School in 19 no, in 2005- 2005. So That is my educational background. My research my mainline of research arose from my curiosity at a very early age to try to understand animals as machines, animals and humans as machines. And that aspect of my research interest got going in a really solid way in 1964 when I was at the University of Southern California. Professor Rajko Tomovic of the University of Belgrade was visiting and he got me very interested in the use of electronics to build improved lower extremity prosthesis with electronic joint coordination. That led to a general interest in human and animal locomotion and to a series of walking robots, which carried me until about 1990 I stopped working on walking robots. After that, my research was centered on unmanned submarines and especially on navigation and mission specification and control for unmanned submarines. So I have there are many collaborators I have not mentioned at all of these institutions. And I received outstanding support from the National Science Foundation over a long period of time for my research and also from the defense projects Defense Advance Research Project Agency as well as many other smaller grants and support from the universities I worked for."
"Bob Mcgee","Interviewer","So when was the first time that you became interested in robots?"
"Bob Mcgee","Interviewee","In what we normally call robots, walking robots, 1964. But before that guided missiles, in those days, were considered to be a kind of robot. So I became interested in guided missiles when I went into the army in 1952 and I worked in that field at Hughes Aircraft Company and what I learned about avionics and dynamics as it related to missiles carried directly over into studies of walking."
"Bob Mcgee","Interviewer","Is there something particular that got you interested when you were working in the army about the guided missiles? What kind of "
"Bob Mcgee","Interviewee","No, I was just generally fascinated by how it was possible to imitate human function in a machine. I was involved in while in the army, I was involved in ballistic missiles, which got me interested in inertial guidance while working at Hughes Aircraft Company I worked on air-to-air and i-tank missiles. I found that fascinating and everything I learned carried over to the study of human posture and human walking and animal walking."
"Bob Mcgee","Interviewer","Were you aware of cybernetics and, if so, were you interested in that?"
"Bob Mcgee","Interviewee","Yes. Yes. There was a book called Cybernetics that appeared with a very well-known author from Cal Tech, a Chinese gentleman who is name has flown out of my head. And that was engineering cybernetics and Norbet Wiener's book called, Cybernetics, was read by a lot of people then. Yeah, that was inspirational definitely."
"Bob Mcgee","Interviewer","Chen I think."
"Bob Mcgee","Interviewee","Chen, right. Wonderful book."
"Bob Mcgee","Interviewer","And what was the first robotics system that you worked on or the first thing that you called a robot."
"Bob Mcgee","Interviewee","If yeah, the first thing we called a robot was a machine called the phony pony at USC and actually George Becky and I worked on that project together along with a wonderful graduate student Andrew Frank whose now on the faculty at UC Davis and the phony pony was, I believe, the world's first electronically coordinated walking vehicle. It walked in 1966. "
"Bob Mcgee","Interviewer","Why was it a pony?"
"Bob Mcgee","Interviewee","Because it was not real. "
"Bob Mcgee","Interviewer","So what is your definition of a robot?"
"Bob Mcgee","Interviewee","The definition Dr. Becky used today and his talk was rather good, I think, a machine that senses, processes information, and acts- acts physically within the environment, interacts with the physical world. That is good enough."
"Bob Mcgee","Interviewer","I was curious have you seen kind of the definition of robotics change at all through time?"
"Bob Mcgee","Interviewee","Yes, I think I have. I think when I first began working in the field robots were thought of as humanoid machines they appeared in science fiction and the, of course, the word originates from Capek's play, R.U.R. And it then as industrial robots came into being the term acquired a broader meaning and I think Dr. Becky's definition is as good as any for what the contemporary notion of a robot is."
"Bob Mcgee","Interviewer","And so after the phony pony what other projects did you work on?"
"Bob Mcgee","Interviewee","Okay. The phony pony was a very successful project in the sense that it established that a finite state machine could coordinate the motions of a walking vehicle and that machine could be either synchronous or a-synchronous. It also showed us that that was not enough for any kind of useful vehicle. We thought it would be enough to control lower extremity prosthesis and That is turned out to be the case. Those prosthesis have come into widespread using all in the past couple of years. They do use finite-state controls so far as I can tell. Very much like what we postulated in 1966, but in terms of a vehicle That is not enough. We realize right away that underneath the finite-state control we needed some kind of coordination. No, That is not precise enough. We needed to have continuous state space taken into account and we needed kinematic and dynamic control of leg motion in order to create any create a walking vehicle that might be useful for something. The phony pony was nothing more than a technology demonstration, very important. It showed that finite state was sufficient to coordinate walking, but does not get very good results all by itself. So the next machine built based on the phony pony experience and with wonderful financing from the national science foundation was dubbed the bionic bug. It was a six-legged, 300 pound walking machine that had supervisory control, continuous state space control of foot trajectories and which, very importantly, utilized horse feedback to achieve artificial compliance electronic compliance and used gyros for attitude stabilization of the body. It was a supervisor control machine controlled by a joystick, but all of the leg coordination was accomplished by a computer that was the next machine. And that machine produced a lot of basic results and a number of PhD dissertations and provided the basis for the next project, which was the DARPA Adaptive Suspension Vehicle."
"Bob Mcgee","Interviewer","People that one. Who worked on the bionic bug with you?"
"Bob Mcgee","Interviewee","Oh, lots and lots of people. it is impossible to give everyone credit. Mostly graduate students. Mostly myself and graduate students. One person comes out as a standout, in my mind, and that effort That is Professor David Orin of Ohio State. He did some of the most basic work, but there were many other graduate students who contributed to various aspects of the project."
"Bob Mcgee","Interviewer","And the next one?"
"Bob Mcgee","Interviewee","So the success of the bionic bug, which by the way I got the Center Proxmire Annual Award, Golden Fleece award because of that name. It was not well thought out and because of that experience we did not call we did not use the word walking at all in the description of the Adaptive Suspension Vehicle. We wanted a dull name and we found it and we were never investigate. The purpose of the Adaptive Suspension Vehicle was to scale up the bionic bug to a useful size and what DARPA asked us to do was to see if we could produce a walking vehicle, capable of keeping up with infantry and carrying a thousand pound 2,000 pounds, pardon me. So because of the payload requirement and it was intended to have a human driver. Because of the payload requirement, it had to be a big machine and it was. It weighed 7,000 pounds and that was a really big effort. That effort produced 30 PhDs and about an equal number of Master's degrees. And I had my most important collaborator in that work was Dr. Kenneth Waldron who is now at Stanford and who still works on walking vehicles. "
"Bob Mcgee","Interviewer","What were some of the main challenges, both technical and in terms of the intellectual side?"
"Bob Mcgee","Interviewee","The biggest challenge perhaps was finding an efficient means of applying torques to the or actually force as it turns out linear actuators of applying with sufficient bandwidth and energy efficiency controlling the motion of 18 joints. And it required very innovative developments in hydraulic system design and we succeeded. We operated 18 joints with a motorcycle engine. That was the biggest challenge. The second biggest challenge was integrating information from an optical radar system to coordinate stepping motions and on even terrain. We succeeded in doing that also. And then there were many challenges that we can say were technological rather than scientific. Personal computers had just appeared and that made the project feasible. We built the Adaptive Suspension Vehicle just as soon as it was technologically feasible. It had, as I recall, 16 PC boards in it and one special purpose computer. So that was a big technological challenge and that all worked."
"Bob Mcgee","Interviewer","So before it all worked and you came to the tests, were there some avenues that you turned to that were not quite as successful?"
"Bob Mcgee","Interviewee","Oh, sure. We tried everything. Oh, we tried everything. There are many alternatives for mechanical design and we settled on a particular design that was Dr. Waldron's idea that worked out very well. And there were many approaches to coordination. We did not understand at the beginning that legs in a supporting phase should be operated on pure force feedback mode. The bionic bug had used electronic compliance, artificial compliance. But the Adaptive Suspension Vehicle used what, I think, Mark Raibert hybrid control for legs and contact with the ground. They were operated on pure force feedback mode. The position of the supporting leg did not matter. If it slipped, it did not matter. But legs in the of the ground were operated in position feedback mode, velocity and position feedback. And we used Jacobian control. We never used inverse dynamics on that was a big accomplishment in the bionic bug. We did not use inverse dynamic inverse kinematics, pardon me. We used Jacobian control."
"Bob Mcgee","Interviewer","And so how did that and feedback feed into?"
"Bob Mcgee","Interviewee","The ASV?"
"Bob Mcgee","Interviewer","Yeah."
"Bob Mcgee","Interviewee","Same way except the except it applied it was simpler. The ASV kinematics were simpler. It used a linkage mechanism, which the bionic bug did not. But well, I think That is enough on that subject."
"Bob Mcgee","Interviewer","And so you had mentioned in the beginning this whole notion of looking at animals and humans as key. "
"Bob Mcgee","Interviewee","Right."
"Bob Mcgee","Interviewer","And how did those ideas feed into some of the work that you are describing?"
"Bob Mcgee","Interviewee","Okay. Very much so. Our experience with the phony pony showed us that if we wanted a heavy-lift walking machine and if it were going to be so big that it could not crash. If you have a 7,000-pound vehicle That is 10 feet tall, it will not sustain a crash. So this not a laboratory experiment. This was an outdoor vehicle and so from studying animal locomotion we understood that the requirements for dynamic balancing in four-legged creatures was not something we could match at that point and time. it is too demanding. So that told us clearly we should go to six legs. The question was what gates to use, so we studied animal gates to get some idea on that subject. And prior to that some Russians, Basonoff in particular had shown the optimality of a class of gates called wave gates. And we used those exclusively on our on the ASV except for walking through obstacle fields. And there we used what we a free gate online optimization, not periodic."
"Bob Mcgee","Interviewer","What particular animals did you?"
"Bob Mcgee","Interviewee","We looked at grasshoppers and They are the only animals in which we actually did original research. And we discovered, which was not known to biologists. We discovered that grasshoppers switch gates when they encounter obstacles. They tend to pair their legs when dealing with obstacles. And in ordinary walking on smooth services they typically use tripod gates or some other wave gate. So we adapted that to our walking machine gates."
"Bob Mcgee","Interviewer","And were some of the places where you tested out the machine?"
"Bob Mcgee","Interviewee","Oh, it was tested in an outdoor environment at Ohio State University. We also took it to, in the latter stages of the project, to the Piedmont area of Virginia and tested its capabilities on the soft soils found there."
"Bob Mcgee","Interviewer","And did it end up going in was it applied?"
"Bob Mcgee","Interviewee","Never applied. Never applied. John Deere Corporation advertised a six-legged walking vehicle that I think was designed in Finland. I think was I think Professor Hallmay was and the University of Helsinki was involved in that design but no one bought any. The only successful applications I know of up to the present time of walking machines in the most general sense is the very great success achieve in the past couple of years in powered-lower extremity prosthesis. They are now accepted. Now, paid for by Medicare and the Veteran's Administration. So that was our original mode motivation. That is what I started out with Tomovic. Our first paper dealt with coordination of motion for powered lower extremity prosthesis and our position was we thought that neuro-feedback was not required. That the interface between a powered, lower extremity prosthesis and a human being could be purely mechanical. Turned out to be true."
"Bob Mcgee","Interviewer","And so after the ASV, what came?"
"Bob Mcgee","Interviewee","Submarines. The ASV had a human driver or was more like a pilot. Driving it was like flying a fly-by wire airplane. And it was very easy to drive, but we required a pilot. And I became interested in how we could automate the pilot has function. So I got a good offer from the Naval Postgraduate School and I came here to work on submarines. And I worked in two areas on submarines, submerged navigation and mission specification and mission control. So we did succeed in replacing all of the functions of a human crew in a unmanned submarine. I think we were the first to do. I think we were the first to include explicit mission planning and control. And I think we well, we did it because we are a naval institution. We replicated the division of responsibilities on a submarine, electronically. And it led us to a tri-lingual software system. An imperative language for the for what amounts to the work of the crew physically controlling parts of a submarine. Lisp or some functional language for coordination of the activities of the members of the crew, so the bottom level we call the execution level. Middle level, we call the tactical level. And then at the top level, we use Prologue to specify an operational doctrine and to write mission orders. Reason for choosing Prologue is we felt and I feel that it is a language that a naval officer can read without being a programmer."
"Bob Mcgee","Interviewer","So did you work with the Naval officers while you were developing this?"
"Bob Mcgee","Interviewee","Oh, yes. Submarine officers were the primary people who worked in our project here and there were many of them, 30 or 40. It was a perfect environment for that work and we did operate our submarine in Monterey Bay with, I do not tri-lingual paradigm, a sun spark workstation running Prologue on top. We did not use Lisp in the Bay, I do not think. I do not think so, but we used Prologue at the top level and then functional programming at the next level, and imperative programming running a separate processor. We separated the real-time the hard real-time parts ran on its own processor written in C++, I think. And the strategic level, the function of the captain, was written in Prologue and ran on real time with no problems."
"Bob Mcgee","Interviewer","What was the hardest kind of officer human task to automate through your system?"
"Bob Mcgee","Interviewee","Good question. Probably I do not know. It was a very big team effort. It was hard to get two processor at that time, to get two processors with different operating systems running different languages, it was hard to get them all to work together. That is the difficulty I was most aware of. Not hard now. I am still playing with this and Lisp and Prologue run together fine on my $300 netbook and at that level, the physical submarine just looks like a line printer or a mouse or something else. it is very natural. "
"Bob Mcgee","Interviewer","So who were some of the people who worked with you on this particular part of the project. You mentioned there were a lot of officers?"
"Bob Mcgee","Interviewee","The submarine project? Yeah, I can really only mention faculty in that case. My co-investigator and most of the time the leader of the project, in fact, all of the time the leader of the project was of the main project, was Dr. Anthony Healey of the Mechanical Engineering Department who is now retired.So besides that, a very important person up to the present time is Professor Brutzman, who was at that time a naval officer and is now a faculty member, Profession Donald Brutzman, who is a faculty member in the moves curriculum at the Naval Postgraduate School, and many other faculty and technicians, too many to name."
"Bob Mcgee","Interviewer","And so that let you to what is the next?"
"Bob Mcgee","Interviewee","Okay. Well, it led me to retirement, but I did not stop at retirement. On a volunteer basis I still work with the postgraduate school. Most of all in the lab where we are and what we have done in this lab is adapt submarine inertial navigation technology to human foot tracking and that is an area that shows great promise and I am very interested in right now. Recently I have been trying to revive our work on trilingual, we call it rational behavior architecture, trilingual control approach as a means of achieving transparency and accountability in military robots. I still believe that a naval officer can learn to read prolog in less than a day and would be able, as a naval officer, to say, yes, this operational doctrine is correct. Yes, this mission is correct. I accept responsibility for it. That is what I want to achieve. If we field lethal robots, military officers should be able to assume the same responsibilities as they assume with respect to human soldiers or human sailors, and I think that requires a language that can be understood by any naval officer during court-martial proceedings or whatever ensues. "
"Bob Mcgee","Interviewer","For a normal officer, they would have to know human fallibilities. Would an officer, even if they were able to prolog, would not they also need to learn the type of fallibilities? "
"Bob Mcgee","Interviewee","I think all naval officers know about human fallibility. Go ahead."
"Bob Mcgee","Interviewer","What about the technical fallibilities of the robots?"
"Bob Mcgee","Interviewee","Sure. They have to know something about that. that is a very good question. Knowing something about fallibilities is different from knowing the details of how a task is accomplished. I suspect well, I do not know how naval officers are trained. Probably they, I am sure they put their hands on the submarine and they drive the submarine themselves. So I think any naval officer who would be involved in using autonomous submarines would know about the physical fallibilities of such a submarine. He would not typically know all the details about say, what could go wrong with execution level software. He might not understand real time systems. But the whole idea of task abstraction and language abstraction in this setting is to allow people with different specialties to assume responsibility at different levels. So a senior officer would, in an ideal world from my perspective, and prolog is just the current state of the art as far as I am concerned, no doubt better languages will appear. But an officer at the level of a submarine commander would say, I accept responsibility for mission specification and mission control written in prolog. Then an officer at the level of officer of the deck would have to learn LISP, or whatever language was involved, and say, I accept responsibility for the LISP code. It does correctly implement functions like, go to the surface, return home, find a target. I sign off on that and assume responsibility for it, and then another person at a different level would have to say, yes, we have tested the real time control system in the laboratory. The control surfaces moved like They are supposed to. we have done at-sea trials. The GPS works. I sign off on that. It would be three different people at least and each of them would understand functionality at their level of responsibility. "
"Bob Mcgee","Interviewer","How far do you feel that you have gotten towards this goal?"
"Bob Mcgee","Interviewee","I think we are ready to do it. we have done it. We did it in the bay in the late 1990s and then things happened in my life so that I disappeared for a while. Family problems took me out of circulation for a while and now I hope we can get something going again at that level. NPS has a very successful and active program in unmanned, undersea vehicles. But at this time, the focus is not on mission control. "
"Bob Mcgee","Interviewer","What are they focusing on?"
"Bob Mcgee","Interviewee","I am not well-informed. It would be better to talk to somebody in that area. But I know they have more advanced submarines, that in the past few months they took delivery of a larger, more-effective submarine, and their concern is from the perspective of irrational behavior architecture, their concern is with the tactical level and the execution level, not with the strategic level, so far as I can tell. it is not a criticism. They know what They are doing and They are pursuing their goals effectively."
"Bob Mcgee","Interviewer","What were some of the reactions when you succeeded and actually "
"Bob Mcgee","Interviewee","When I did what?"
"Bob Mcgee","Interviewer","What were the reactions to your success of actually getting things working?"
"Bob Mcgee","Interviewee","Boredom. No one has picked it up. it is been lying there for ten years and I would like to get work going again. Well, That is not quite true. I am aware that there is a large Air Force program to standardize natural military language across the branches of the service and I have forgotten the name of the program exactly, but I right. Okay, let us come back to that. Are we ready?"
"Bob Mcgee","Interviewee","Okay. As to why this did not catch on, first of all, I dropped the ball. It was for personal reasons. Things happened in my family. I had to take time out, very serious things. So I dropped the ball. Another thing was there were hardware problems. It was not very easy to combine a hard real time JUSPAQ computer operating under OS-9. It was not easy to combine that with a Sparkworks station running UNIX and it was only because of the skill of our officer students and Don Brutzman that we managed to make it work. So then Quintus Prolog went out of business and until five years ago, or six years ago, there was no, in my opinion, no really viable PC prolog around that had the capabilities of Quintus Prolog. Now there is and it is wonderfully combined seamlessly with common LISP. Alegra Prolog and Common Lisp work together beautifully. So I have been doing simulation studies in the past few, about a year. "
"Bob Mcgee","Interviewer","And do you have a feeling maybe for how the officers felt about it?"
"Bob Mcgee","Interviewee","They were very enthusiastic and then they went back to their normal duties, except for Don Brutzman who is still here. So no doubt there are other reasons that it did not succeed. Prolog generally was not accepted any place and so it fell out of fashion. that is a factor."
"Bob Mcgee","Interviewer","What do you think it was not accepted?"
"Bob Mcgee","Interviewee","Well, the Japanese Fifth Generation Computer Project failed spectacularly and that kind of poisoned the well for prolog for quite a while. I do not think prolog is the be-all and end-all. it is just the best language I know that I believe can be read with a person with no programming experience. "
"Bob Mcgee","Interviewer","And that has been in terms of when you have tried it with people and your experience proves that to be so? But this is what you have learned from your experience of actually working with "
"Bob Mcgee","Interviewee","Working with naval officers."
"Bob Mcgee","Interviewer","Yeah."
"Bob Mcgee","Interviewee",".I found they could read prolog code. it is hard to write. it is not hard to read. Prolog has only about 50 primitive functions. When you learn that, That is it, and those are English words. They are words like abolish now why am I having trouble with it? Is, you know, what is the meaning of is? Well, we know what is means in prolog. They are words like assert. They are words with common English meanings. it is remarkably easy to read, not to write— remarkably easy to read and has a built-in inferencing capability. "
"Bob Mcgee","Interviewer","Going back a little bit. Why did you decide to go to Ohio? "
"Bob Mcgee","Interviewee","Ah, yeah. Good question. They made me an offer I could not refuse. Really, they gave me an opportunity to become head of a research laboratory, which I was then able to use to greatly broaden by, not only my interest in robots, but other interests, pattern recognition and those were the two main areas, robotics and pattern recognition. So I was very well-supported physically and financially. "
"Bob Mcgee","Interviewer","Was there anyone else doing robots or vision at Ohio when you got there?"
"Bob Mcgee","Interviewee","No, not when I got there. I was able to attract some good people but not at the time I got there."
"Bob Mcgee","Interviewer","Well, who are some of the PhD students who trained while you were at Ohio?"
"Bob Mcgee","Interviewee","Oh, wow. There are too many of them. First and second person whose name comes to my mind is V.J. Jazwa , who did not go into academia. He went into robotics for General Motors. But V.J. was responsible for the mechanical design and construction of the bionic bug. He was an electrical engineering PhD student who apprenticed himself to a machinist for a year. Then he physically constructed a rather complex machine and wrote the first real time software. So he played a absolutely crucial role. There were many others. There was a masters degree student names James Bucket who did a wonderful design of the onboard electronics. The bionic bug was already very energy-efficient. It used A/C drill motors to power 18 joints and it ran 18 of them on about three kilowatts, which was very efficient and that was due to James Bucket. There are many others I could mention, too many to try to recall. "
"Bob Mcgee","Interviewer","And what kind of computational hardware were you using for the bionic bug?"
"Bob Mcgee","Interviewee","At first a PDP-9 computer and then a PDP-10. No, not a 10, 1170, from the PDP-90 we went to a PDP-11 something and we ended up with an 1170, and that was in about 1980 and we had a whole megabyte of memory, which was stunning to everyone. "
"Bob Mcgee","Interviewer","And how much of the processing was, you know, real time versus offline?"
"Bob Mcgee","Interviewee","All real time."
"Bob Mcgee","Interviewer","All real time, and what was the hardest part of achieving that kind of real time processing ?"
"Bob Mcgee","Interviewee","Properly partitioning the tasks and I did not make any contributions there. The PDP-1170 memory was partitioned into 64K sections, and those computations had to be coordinated and I made no contribution there. "
"Bob Mcgee","Interviewer","That was your students?"
"Bob Mcgee","Interviewee","Students did it, right."
"Bob Mcgee","Interviewer","What kind of vision systems were integrated?"
"Bob Mcgee","Interviewee","The bionic bug had two CCD cameras, low-resolution, about 100X100 pixels in each camera, and it had limited vision capabilities. We used a laser pointer to indicate points on the terrain, by hand, where we wanted it to step and it did. So that was a way of coordinating its motion over uneven terrain, and that then was generalized in the ASV where we had a real optical radar and could classify terrain. That is where I first encountered prolog by the way, and I think I have not mentioned another very important student, Sayoung Kwak, K-W-A-K. Sayoung was the person, who in his PhD dissertation, showed the effectiveness of prolog in solving the problem of non-periodic gates, in online optimization of foot placements in rough terrain. So I have forgotten the question, but I am sure glad I mentioned his name. I learned about prolog from him. "
"Bob Mcgee","Interviewer","Just how you are doing the visual processing at that time?"
"Bob Mcgee","Interviewee","In the ASV? Okay. As I said, we used an optical radar. It was made for us by ERIM Corporation and it gave us, roughly as I remember it, 100X100 range image at a two hertz rate and we processed the range information to derive average terrain slopes so that the vehicle could adapt its body orientation to terrain in advance without waiting for forced feedback. That did a lot to give it a smooth ride and it was remarkably affective. We also were able to classify terrain cells as suitable foot holes or not, but only in a laboratory environment. We never tested that in an outdoor environment. So if we put cardboard boxes on the floor, the scanner we called it, the laser scanner could find the boxes and we could walk through them without stepping on one. We ran out of time, ran out of money, I left, everything changed and we never got further than that with the vision aspects of the problem. But the free gate problem is logically very complicated and we were never able to explain what we were doing to anyone except by writing it in prolog, then we published it. It was in about 1988 or thereabouts. "
"Bob Mcgee","Interviewer","Where did you publish?"
"Bob Mcgee","Interviewee","In the Advanced Robotics, the journal of the robotics society of Japan. "
"Bob Mcgee","Interviewer","What were some of the other important journals and conferences where robots was being done?"
"Bob Mcgee","Interviewee","Okay, IEEE Transactions, most important of all in my opinion, Transactions on Systems, Man, and Cybernetics. Then later the Robotics Transactions after that society was formed. That was maybe the most important place to publish. But before that, in biomedical engineering journals, my gosh, what was that one called? Well, there was the IEEE Transactions on Biomedical Engineering and other journals. Those are the most important ones. "
"Bob Mcgee","Interviewer","And going back to the 1960s, like, what were the conferences that you were going to and where people were discussing robotics, and did they even call it robotics then?"
"Bob Mcgee","Interviewee","No. The first conference of which I presented any results in robotics was held in Yugoslavia and the organizer was Professor Rico Tomovich and it was a conference on, what was it called, Robots, Man and Systems, ROMONSI I think it was called, or at least it came to be called that and first work I presented there was on models for human postural control. That was another whole branch of research. I did work with the otolaryngology department at Ohio State and that was published in the IEEE Biomedical Engineering Journal. It dealt with a potential diagnostic tool for vestibular dysfunction using a multi-linked dynamic model for postural control. It worked, but better means were found. it is not used today, as far as I know."
"Bob Mcgee","Interviewer","So were there any other really interesting robotics projects that ?"
"Bob Mcgee","Interviewee","Oh, many, many. That is where I became aware of Russian work, especially Russian work on gates and I had the very good fortune of going to the Soviet Union twice. In 1974 and in 1976 I visited Professor Oketsimpski's laboratory at Moscow State University. I gave a talk there and he and I adopted common configuration for our walking machines so we could share results. That worked very well. "
"Bob Mcgee","Interviewer","And what was some of the work that he was doing, or some of the other Russians that you encountered while working?"
"Bob Mcgee","Interviewee","Oketsimpski was definitely doing basic research. He wanted to demonstrate that computer coordination of a six-legged walking machine was feasible and hoped that there would be an application. He did succeed in such a demonstration. He was hampered by the very poor quality of Soviet computers at that point in time. To control their walking machine, they used in part a very large analog computer, huge analog computer and it was limited in adaptability by that constraint. So I guess That is the answer to that question."
"Bob Mcgee","Interviewer","Were there other Russians?"
"Bob Mcgee","Interviewee","Yes. Yes, there was group in Leningrad who I also visited, Professor Ignatiaf . I never saw one of his machines walk. So I do not know what happened to his work. Olketsimpski's efforts were successful, and there was a group in Tbilisi who was interested in walking machines for forestry applications. They did have a small scale model walking, but with mechanical coordination, not electronic. After the late 1970s I lost contact and I do not think that they were very seriously involved in walking machines after that. I never heard of a project in the Soviet Union comparable to the adaptive suspension vehicle program in the United States. "
"Bob Mcgee","Interviewer","What about elsewhere in Europe?"
"Bob Mcgee","Interviewee","In Finland Professor Halmay at the University of Helsinki, I believe. I know he worked with Rama Repila , I believe is the firm and I think it was that work, as far as I know, that led to the at the same time. We were both assistant professors and he invited Rajko Tomovich from University of Belgrade because he knew of Tomovich's work on artificial hands. Purely by chance, when I took my language exams for my PhD, I took a French exam and a Russian exam, and for the French exam, I used a translation of one of Tomovich's books called, Repetitive Analog Computers. So I already knew about him when he came to USC and because of that, we became acquainted and he had just published a paper on creeping gates for the possibility of using caterpillar kind of creeping gates for a robot, a machine, and I was very interested in that. So he said, do you think we could build a quadropad? I said, I think we could. Well, first he said a bipad. I said, no. That is too hard. He said, how about a quadropad? I said, I think so. So we started working together and That is how it got started. "
"Bob Mcgee","Interviewer","And what were some of the other works that were influential that had an influence on you and how you approached "
"Bob Mcgee","Interviewee","Okay. There was not much going on at that time. I had a connection with Rancho Los Amigos Rehabilitation Hospital and through that connection I became better aware of the existing state of prosthesis, Lord , Germany Prosthesis and the functional requirements. That was important, and it is very pleasing to me that That is come to fruition now in clinical applications. Much later, Japanese research I became aware of Japanese research and had a joint research project, NSF project with the Porton Harbor Research Institute. This was in about 1992. The Japanese had a machine called Aqua robot, which they constructed specifically for the inspection of seawall foundations and they wanted to improve their machine and we wanted to work with them and we did work together and it looked promising until the Japanese economy tanked and they lost their funding. So we had several years of good cooperation, including at that time, a Japanese professor at the post graduate school, Yutaka Katayama . So we did have a good cooperation going with the Japanese, but they could not get anymore money. So that was the end of that. However, I learned things from them. "
"Bob Mcgee","Interviewer","What are the future challenges in robotics? Where do you think the field is going?"
"Bob Mcgee","Interviewee","Right. Right. that is a very hard question. Robots are here to stay. they will become more pervasive. So it might turn out that the biggest challenge is what Dr. Bekey was talking about today. There does not exist a field called robot ethics. We do not understand very well how to assign responsibility for the mistakes that are bound to occur. So I think the biggest challenges is the interface between humans and robots. Very, very big challenge there. Of course, there are many others. And technologically speaking, I think I see actuators as the most serious challenge. We have nothing approximating, natural human muscle fiber or animal muscle fiber. That is lacking altogether. So that is a huge challenge. I do not see anything on the horizon really, that I know about. Those are the two problems I would single out."
"Bob Mcgee","Interviewer","What do you see as the most promising kinds of applications and the kinds of things We will see robots doing more commonly?"
"Bob Mcgee","Interviewee","I think it is pervasive. Again, I like what George said today. Robots will be everywhere. we are going to have vehicles operating on highways without human drivers. I am sure of it. And that is a very dangerous kind of robot. So liability questions have to be resolved there. Military robots is obviously going to continue. I understand that this year the United States Air Force spent more money on a procurement of unmanned aircraft than it did of manned aircraft for the first time. Those are not robots yet, but they will be increasingly so. So I see explosive growth in military robotics and explosive growth in civilian applications. I really like the idea of robots as assistance for home healthcare, but I think it is very far off. I think that is a really hard problem."
"Bob Mcgee","Interviewer","What do you think are some of the potential social implications of all these different types of robots and these different kinds of ?"
"Bob Mcgee","Interviewee","Huge. Huge. They could make us redundant. They could. If we assign enough responsibility to robots, and if we give them enough independence, which is a very, very dangerous subject, we could become redundant. I think we probably will."
"Bob Mcgee","Interviewer","Do you see that as something, has that been something, this knowledge, been something that you have been able to work into how you develop your work at all?"
"Bob Mcgee","Interviewee","No. I do not think it has anything to do with anything I have done. No."
"Bob Mcgee","Interviewer","Do you think, I mean, today one of the questions that Professor Bekey brought up was this notion of engineering education and how some of these ideas about the societal aspects of it or the ethical aspects of it to be brought into education and design, how would you see that?"
"Bob Mcgee","Interviewee","I think it is a legal problem."
"Bob Mcgee","Interviewer","Okay."
"Bob Mcgee","Interviewee","I do not see engineers doing the job of lawyers and judges. I think, my feeling is, the engineering community has a responsibility to escalate the means by which we communicate with robots so that it approaches natural language. I think That is not hard to do. I think we can do it right now, if we decide it is important. Of course, I am speaking only of text. I am not talking about spoken communication."
"Bob Mcgee","Interviewer","So you mentioned this notion of robot ethics as being something that could be a very important aspect of robotics in the future."
"Bob Mcgee","Interviewee","Right."
"Bob Mcgee","Interviewer","So how would you see it, so in the sense then, the engineers would be interacting more with judges or some other people or "
"Bob Mcgee","Interviewee","Like any other product."
"Bob Mcgee","Interviewer"," they would be in a sense separate? Mm-hm?"
"Bob Mcgee","Interviewee","Like any other product."
"Bob Mcgee","Interviewer","Okay."
"Bob Mcgee","Interviewee","it is lawyers who work with juries and judges to determine liability for injuries or death of human beings as a consequence of the function of machinery. I do not see robots as being much different in that regard, except for the ability of robots to act more pervasively and more autonomously."
"Bob Mcgee","Interviewer","Is there anything that you would like to add before we end that you think we missed or "
"Bob Mcgee","Interviewee","Yeah."
"Bob Mcgee","Interviewee","I think it is vitally important when dealing with potentially lethal robots, whether They are automobiles or military machines or robotics surgery, I think it is very important to have the top level of software written in a way that can be discussed in a courtroom. And I think it is doable today."
"Bob Mcgee","Interviewer","Do you see a lot of work going in that direction?"
"Bob Mcgee","Interviewee","No. I would like to see a lot. "
"Bob Mcgee","Interviewer","Why not? Why do you think it is not a majority?"
"Bob Mcgee","Interviewee","It hasn't become a real issue until just now."
"Bob Mcgee","Interviewer","Okay."
"Bob Mcgee","Interviewee","And as Dr. Bekey pointed out, the drones in Afghanistan are not robots, but they could become robots at any time the Air Force and the government decide to do so. And that causes that to jump right out in our faces. We must face issues of transparency and accountability involving human lives or injury to humans. We have to face it right now, and I think we are not. I think it is too new."
"Bob Mcgee","Interviewer","Well, good luck with your work."
"Bob Mcgee","Interviewee","Thank you."
"Brad Nelson","Interviewer","Start by telling us where you were born, where you grew up and went to school."
"Brad Nelson","Interviewee","Okay, I was born in Southern Illinois, Murphysboro, Illinois, grew up in small towns in Illinois. I went high school in Normal and then to University of Illinois, Champagne, got a mechanical engineering degree. Then I went up to Minnesota to get a Master's degree and I want to Minnesota because I heard they had a good controls group and good controls people up there and I wanted to do controls and I got up to the mechanical engineering department and realized all the good controls people are actually in the electrical engineering department and found somebody by the name of Max Donath {ph?] that was working in robotics, which was about as close as I could get to what I wanted to do, and that was in 1984, and so fall of 1984 was when I started reading literature, trying to understand what this field was about and it was a really exciting time in robotics. Some Seminole papers had just come out. Things like Hybrid Force Control by Craig and Rabert , Impedes Control from Neville Hogan and these kinds of things were starting to come out, Stiffness Control from Salisbury and I remember Artificial Potentials from Oussama Khatib and it was exciting, and every time I read a paper it was a different way of thinking about problems and then I had start to see how the people like Matt Mason were looking at manipulation problems and thinking about things completely differently than a mechanical engineer did, and so that was back, I think the mid-1980s was when we thought robotics was everybody was still a little naive I think about how hard the problems were and while I was in Minneapolis got involved with Honeywell. They were working on a darpa project called Intelligent Task Automation and there were a couple of different forms of that, one was a big vehicle that was driving it. I think it was out at Denver at an autonomous vehicle. But ours is a manipulation problem and we worked on assembling Honeywell microswitches for the, I think some kind of a switch that was used in some military component, but it was really just a robotics problem and I remember it had 17 parts to it, 15 of them were different and I can remember each of those parts because I had worked on the vision problem and trying to find them in a tray and locate them and then the idea was to assemble them into a complete switch automatically and we worked with Adept Technology and Jim Maples and some of those guys. We had an force control Adept that had force-feed back guy. Gosh, I want to say it was we had a JR3. I remember the four sensors. I remember a board that could do 16 megaflops, I think. You know, these things that just seemed like incredible numbers at the time which are nothing now, and we could do, you know, getting to play with just cutting-edge work and then also in that project were people like Stanford Research Institute, Bob Boles, and the Global Part Recognitions System. There were relationships to a lot of these people I had read about and, you know, I think Oussama Khatib was somewhat interested, Tom Bidford was somewhat related and I remember feeling like of isolated at Honeywell because I would come in at, we were doing computer vision on a vac750 and I would come in at 5 o'clock at night when everybody was going home so that I could have the whole machine to myself to do, you know, image processing and things, and then when they came in at 8, I would go home to sleep and then I remember one of Bob's researchers, Jim Hersen , came out and Jim worked all night long. I learned how to hack. I learned that it is okay to work these kind of hours, that other people do this to and, you know, I saw this side of how to solve these problems and how to work on them hard and that was exciting, and so did a few things after that, I guess, and then ended up eventually, let us see, left the country for a while, worked overseas and then came back and worked at Motorola in software engineering. Actually, I was working the telecommunications industry. This is in the early 1990s when, or late 1980s when cell phones were just starting to take off in the U.S. and digital wireless communication people had this idea you could actually send digital data over wireless and it was a great time to be in that kind of to be working in that. But I realized I really liked robotics and I heard one of my friends had gone to this robotics PhD program at Carnage Mellon. They had just started and I was thinking about other schools. I was thinking of Berkley or MIT, but he convinced me to go there and then I ended up leaving what was a really hot field, data telecommunications and think of this in like 1988, 1989, and then going into a field that was actually not too popular at that time, which was robotics. People had kind of woken up to how hard some of these problems were and so went back and ended up in Pittsburg and spent five years there so. "
"Brad Nelson","Interviewer","So that was a whole lot of [inaudible] during your Master's degree."
"Brad Nelson","Interviewee","Yeah. Yeah, so."
"Brad Nelson","Interviewer","So once you started working on these projects, how did you get into contact with so many people, or how did you get involved in the Honeywell project? Was that a grant that your advisor had or were these projects that you were doing as part of your thesis?"
"Brad Nelson","Interviewee","With Honeywell I was, let us see. I think I was, when I got to Minnesota as a masters I was in a fellowship and then I was looking to do some outside work after that finished and make some money and, you know, somebody put me in contact, I think John Crumb who is at Microsoft Research, he had somehow gotten a position there and said oh, They are hiring students. So I went out and immediately started to abandon my research at the university because of the problems we were working on at Honeywell were really exciting and so That is how I got involved in there and that really opened my eyes to I think, you know, some of the real cutting-edge work that was going on on the West Coast but also there were connections to the East Coast as well, you know, coming from the mid-West you can get a little isolated sometimes. So that was a good move to go to Honeywell and I spent a couple years there working so."
"Brad Nelson","Interviewer","Oh, okay. So what did you end up writing your Master's thesis on?"
"Brad Nelson","Interviewee","I think the title, I probably have it over here actually, Optimal Location of Assembly Tasks in a Manipulator Workspace, I think. It was yeah, I remember in 1985 a paper came out at Akira Yoshizawa, the famous manipulability paper that sort of gave a way of analyzing how near singularities, what are some of the problems with the way manipulators were configured and I started looking at read that paper. My advisor, Max Donath, suggested I look at it because we were working on robotic assembly at the time and I realized I needed to simulate robot motion and all that. So then I, what did I do? I wrote my own robot simulator. I remember that. Yeah, I wrote my own robot simulator, really simple graphics in C, and I used the equations that Lou Paul published in, I think it was called the International Journal of Robotics and Automation at the time, on the Puma 560, which was a manipulator we were using and it turned out those equations were wrong and I was too lazy to sit down with a pencil and paper and re-derive them myself to get them right. So I heard about this computer program that would do algebra, symbolic algebra, called Maxima. So instead of sitting down with pencil and paper to derive the kinematic equations for an inverse PUMA, I learned LISP so I could learn Maxima so that I could learn how to derive these equations symbolically on a computer, and then with that it is sort of like you realize oh wow, I can actually calculate determinants of huge matrices automatically. I can take, you know, I can reduce the computation time. Computation was a really big deal back then, to try to reduce that to reduce the calculations. So then I figured out ways I could kind of prune trees to search for optimal locations of these assembly tasks and so That is like of how the Master's thesis came out. I have not thought about that for a long time actually. "
"Brad Nelson","Interviewer","Did you ever talk to Lou Paul or contact him about "
"Brad Nelson","Interviewee","You know I met him once when I was a student helper at a international symposium on robotics research, ISRR. I met him once. I guess I was really intimidated. I did not have the guts to say how come your equations were wrong, you know. I am sure I would not have said that. Yeah so, and I remember after I had coded all this and it was not working somebody said did not you know those equations were wrong, yeah, like everybody knew that. I do not know if That is true or not, but. I am not sure everybody knew."
"Brad Nelson","Interviewer","So who did you work with when you got to Carnegie Mellon?"
"Brad Nelson","Interviewee","Carnegie Mellon, my advisor, PhD advisor was [inaudible] Valsala . he is an electrical engineer. He was a young assistant professor at the time, now he is the dean of engineering there. I started off, again I was working in assembly, looking at assemblability of mechanisms doing CAD-based design for assembly and then I was lucky to get a fellowship from the army and sort of made me a free agent and so there is another grad student there that had been working on visual servoing for a couple of years and looked like a fun problem, got back to trying to do fast vision, computer vision some, and again, this is back in the early-1990s so a lot different than these days in how quickly you could do computations and that was exciting. I think trying to get, you know, camera to do fast tracking of objects and then, you know, bring that into the servo loop of manipulator, and this is again with Puma 56 as we had three of them we used simultaneously we called the tricobot , and then I thought oh, you know, it would be interesting, I had worked with force control a bit when I was at Honeywell. So I thought why do not I look at the how do you do force and vision together and it is still a problem that still interests me. How is it that you decide when to switch sensing modalities and how can you use them in complimentary ways and I still, you know, still think about that, and even though today I am working in the micro/nano world, those kind of things still are on my mind."
"Brad Nelson","Interviewer","What do you think are the hardest problems in that area of relating force and vision?"
"Brad Nelson","Interviewee","Hardest problem, well I think in visual servoing I think right away I recognize the hardest problem in visual servoing was the vision problem. Yeah, we could track objects but it was, you know, it was under artificial conditions but the vision problem is the hardest part to solve. You know, in force control it was contact, going from non-contact to contact states, you know, instabilities and things like that were really hard. That was one of the things that was, I thought was kind of cool was I could show how using vision, I could do really high-speed impacts because the manipulator knew if it was getting ready to hit something. I mean it was so simple but it was sort of like yeah, I mean, That is not the way we do it when we know we are getting near something we are changing our parameters a little. So that was kind of interesting I think, but yeah. So the vision problem and also the hard problem was just having a good enough environmental model. We had to have some kind of a model of the environment and how do you create that, where does that come from, how do you parameterize it and then how do you prepare the system for changing from contact and non-contact states and for dealing with these uncertainties. "
"Brad Nelson","Interviewer","So what were some of the first attempts you made to do that kind of environmental modeling? What were the "
"Brad Nelson","Interviewee","Oh, I think this is back boy, this is back in the days of silicon graphics and we had some machines that, you know, big, huge machines that cost a lot of money that do, you know, little solid models and then there was gosh, I remember like Denabb , was that a company that had a robot simulation model that so I would represent these just as, you know, as boundary representations in there. So I would try to use commercial packages and kind of break into them and use them and use their engines to do some of the computations so yeah. "
"Brad Nelson","Interviewer","What was the trick of the first sort of material robot that you were working with that?"
"Brad Nelson","Interviewee","No, I worked with Adept Robots in Minnesota. We had one of the first five Axis Adepts there. I think well, they used to say the first five Axis. I do not know if it was. But we actually either had an extra degree of freedom on the end effector. They gave us a fifth degree of freedom. That was on the first Honeywell. We also had a Puma at Honeywell where we did this kind of laser-based visual servoing kind of approach there. But those were the, yeah, the first manipulators I worked with, and then when I worked in Khatib's lab at CMU we had the tricobot with three Pumas. We also had the DD arm, the director DD arm. This is the second one. The first one was out at Takko Tinate's lab and Khatib was a student there and working on that, and then we had the second DD arm and I did not work on that too much. I did a lot of real-time, you know, we had a home-brewed real-time operating system called Kimeron, did a lot of hacking of that and a great way to learn everything about, you know, from voltages and bits and bytes up to [inaudible] and manipulator mass matrices and things like that so."
"Brad Nelson","Interviewer","And what was your thesis on?"
"Brad Nelson","Interviewee","Thesis was called something like Port-Based Agents for Assimilating Disparate Sensory Feedback. It was the idea of trying to identify components of this complicated system that used several different robots with force and vision feedback and represent those as these agents that were port-based and then how do you connect those ports together to get this, you know, more intelligent behavior. I mean a big focus of our lab at the time at Carnegie Mellon was just trying to figure out ways to make robots easier to program, because of course the thing we learned a lot in the 1980s was you can build this nice piece of hardware, but programming it was a nightmare and the software and putting it all together was quite was the challenge and so we were always looking at different ways of getting reconfigurable real-time operating systems, doing iconic-based programming, trying to take components of the system and represent them, and you know, this was back when C++ and object-oriented programming was just starting to be appreciated, what it could do, and so you kind of take some of those lessons from that and bring it together, so yeah."
"Brad Nelson","Interviewer","What did you do after you graduated?"
"Brad Nelson","Interviewee","So I got about halfway through my PhD, had two kids. Well, my wife and I had two kids during that time and I realized I was working on manipulators and manipulators were not very popular in the early 1990s and all the work had been done and I am like jeez, what should I do, and towards the end of my thesis I started thinking, you know, what if I took everything I had done with force and vision control and instead of doing it at large scales, what if I did it small scales like under microscopes and I looked at micro positioning and I thought, you know, there could be some interesting applications there and I remember going to Khatib, my advisor, this is probably my fourth year of my thesis, and I said you know, what if we did this, what if we worked on this? I had played with some microscopes and kind of got an idea of what I thought some of the hard problems were and he was not interested. He was more focused on other strategic interests and so I said That is fine. I am going to just finish this off and then I sent out tons of applications for faculty positions. I think 40-some or something and got almost no response, but I was fortunate to get then an offer from the University of Illinois in Chicago, the mechanical department there as an assistant professor, and so when I left CMU after working on these manipulators, big manipulators, I swore I would never work on anything that was not hot, you know, that was not because I had my, you know, That is when it became obvious to me. So I started looking at a few areas and one was medical robotics. I had seen at CMU a great talk by Russ Taylor when he was at IBM doing dog hip implants and things like that with IBM robots and I thought now that looks like a cool area of the future, but That is hard to get into and I looked at that. I looked at continuing with what I was doing just because I knew it, but I was not and you know, you looked at a few different areas but I found an old probe station, an integrated circuit probe station. Basically it is a microscope with some positioners on it and so I got my hands on one of those and started, you know, adding motors and things to it and this was back before I had grad students to do this stuff for me, and you know, had to turn this basically just an integrated circuit manual probe station into sort of an automated system for trying to implement some of the ideas from my PhD thesis but on a small scale, and That is when I started working in micro assembly, and one of the big motivators for that, I have to say was IROS, one of the two big robotics conferences. IROS was in Pittsburg in 1995, the same, almost, you know, within days of when I finished my PhD and was on my way back to Illinois as a professor and two papers were at IROS that I remember specifically. One was out of Toshifa Cuda's group and Fumi Arye was the first author on that, and the other was for Moran Feering at Berkeley and I do not remember the exact titles of those. I have them written down. Both of those papers at IROSS were on the forces that are involved when you manipulate small objects. So as things get very, very small, you know, in robotics at that point if you are doing manipulation you thought of two things. You thought of friction and you thought of gravity and inertia. You know, but basically you got forces due to gravity and you have got forces due to friction and then all of the sudden this thing's getting very small because the volumes are so small, the inertial forces, the gravitational forces become negligible, friction becomes meaningless almost in a sense because you are looking at much smaller scale phenomena and you start thinking about things like electrostatic forces, Vandergoss forces, at least more and more chemical kinds of forces that you are used to learning about in chemistry or physics classes and you realize that our sense of how to handle objects is completely different or completely foreign. So that made it an interesting research. there is some interesting researchers to be explored and That is what Fumi and Toshi and Ron had identified in these papers and did, you know, a nice job of communicating and that was a good time for me to read those papers. I was thinking about new directions. I had been thinking about going this way and I realized maybe there are some fundamental researchers use it that had some legs, something that was going to last a while. It also happened to be in the mid-1990s was kind of the golden years of MEMS, micro-electric mechanical systems. You know, accelerometers and pressure sensors were out there, airbags were in cars and these companies were starting to make money and people had all these ideas for new MEMS devices, flow controllers, these things to do projections of video using little tiny micro-mirrors that moved and crazy ideas out there. But there is a huge learning curve beginning into MEMS. you have got to learn microfab, you have got to have the facilities and so I thought okay. The story I made was what if we could, and other people made it at the same time, what if we could instead of micro fabricating MEMS with the normal processes, what if we could actually assemble small things and so started looking at that and found, you know, yeah, there is a lot of issues to explore there. That was back at the time at the National Science Foundation in the US when Howard Moraff was running the robotics program there and Howard was a great supporter of young professors, young people coming in like me and I remember my first career Word proposal I submitted. I think like a lot of people you submit a proposal that wants to solve every problem in robotics. You think you are, you know, I have got a lab and I am going to do that and I think my proposal did that, it did a lot of things. But I called Howard and asked him, you know, about the review, but of course it got rejected, process and tried to get some feedback from him and he picked out one paragraph he said people were really interested in in my proposal on micro assembly. So then I wrote my next proposal just on micro assembly and I think after that got funded, you know, five, six, seven proposals in a row, never got a rejection and then realized hey, this is a good research area. I can sell it, it is got good topics, it is interesting, I am learning new things and people will give me money so, and about that time then Max Donath, my advisor at Minnesota, called me up and he said I hear things are going well. we have got some openings up here. Would you be interested? Famous last words, it never hurts to send a CV, and so I went up to Minnesota and after three years at Illinois/Chicago and the great thing about Minnesota was and is, it is got a really good micro fabrication facility, first-rate, good education of students for that and then also good characterization facilities, It has an electromicroscopy facilities and these kinds of things you need, and so I really was able to leverage that. It really took my work, the capabilities we could do. We could actually start to make MEMS devices and things like that. So that was 1998, I think I moved up there. It was also the year I met a young kid in China by the name of Yuson , who became I eventually convinced to come to Minnesota and do his PhD with me and he did a lot of interesting work for us in cell manipulation and we worked in manipulating individual biological cells. So we moved from just manipulating and assembling parts to moving into the bio area and other people, you know, started thinking about these lines and you just try to be there and move into these directions and then so in I think 2002 we finally, I got a system to work where we could handle individual cells, we could make measurements and publish I think some of the first work in that area that was really interesting. That also happened to be, and then I happened to spent about four years at Minnesota, I happened to get an email from a place called ETH. I was not quite sure what it actually was, Swiss Federal [inaudible] in Zurich and the email said oh, we have got an opening. there is a professor who is retiring and we have got an institute that you could that needs to be taken over and we think you would be an interesting candidate for that and the job comes with, and they listed, you know, seven staff positions and yearly recurring research, you know, and potentially millions for startup and things like that and you look at that and you start to realize you mean, I do not have to be on a three-year funding cycle anymore, I do not have to think about my next NSF and whether that hits or not and what is going to happen. This will let me think long-term and so famous last words, it never hurts to send a CV, and came out as June, beautiful June. It was June 6th, I remember in probably I came out a beautiful day, mountains were out and interviewed and you fall in love. It was easy to fall in love with this place on a beautiful day and you see the facilities and the people and Zurich's a beautiful city and so I eventually moved here and so I have been here 9 and a half years or 8 and a half years now, so."
"Brad Nelson","Interviewer","So it was 2000?"
"Brad Nelson","Interviewee","I actually moved here, yeah, fall 2002, beginning of 2003 so."
"Brad Nelson","Interviewer","Okay, yeah just to go back a little bit, so prior to this, like, year was 1995 kind of like some papers that you noted, was it your sense there was much interaction between the MEMS community and the robotics community?"
"Brad Nelson","Interviewee","No. People were starting to think about it, you know, there was talk. I know back in the 1980s or actually when I was at CMU there was a group in Japan, MIYOTA, was working on it trying to make a silicon, I think they called it silicon dragonfly, you know, trying to make something that could fly out of MEMS technology and a very, very difficult problem. At that time though if you went to the MEMS community and you talked about assembly, and I mean I talked I went to Motorola when I was in Chicago and tried to convince them about this. I remember a quote from one of the Motorola engineers when I was telling him what I was doing and he said well, if you are doing assembly, you are doing something wrong, you know, That is not the way to do this and so it is like yeah, you know, I understand his point. You know, he is not going to Motorola is not going to build a product That is going to be micro assembled at that point. But there was still that feeling in the MEMS community that, you know, the point is batch fabrication. The point is not to do this serial thing. you have got to look at that. So other people like Karl Bohringer and I know Ken Goldberg and folks were looking at parallel assembly and ways of moving several objects together. This is kind of the beginning of some of the ideas in self-assembly and out of that community. So there was starting to be interest in assembling these small things, but it was not but the main MEMS community. I mean, they were riding high, you know, they were the king of the hill in research in a lot of ways and huge numbers of conferences and a lot of success and, you know, also in industry in seeing their products or seeing a lot of the technologies develop for them coming to fruition commercially so."
"Brad Nelson","Interviewer","And would you say that the micro asssembly sort of research area now has more of a self-genera of robotics or MEMS or sort of a hybrid?"
"Brad Nelson","Interviewee","Well, I kind of classify it now as micro and nanorobotics. I mean They are a somewhat different field but all people tend to work in them at the same, you know, but I think it is a subfield of robotics more than anything but I think we have got more respect in the MEMS community than we used to have, and That is because of people like Fumi Arye and Karl Bohringer who are, you know, first-rate engineers and scientists and they go in there and They are well-regarded and I think, you know, at first, like everything you come in, you do not know what you are doing, you look like an idiot and then you start to understand the issues and you start to speak each other's language and understand why they have their viewpoint and you bring that together, and I think that so you know, we are not I think yeah, we are not a part of the MEMS community although all of us working in it are usually, or a lot of us have close connections to it, but we are still I mean, my home's robotics still. I consider that. These are the main conferences I go to and where my main interests still are so."
"Brad Nelson","Interviewer","So as a subfield, how did it involve into micronano robotics and do they have a centralized conference?"
"Brad Nelson","Interviewee","Well, we still kind of hang onto Vicra. We still have our sessions and workshops there. I mean, That is I was a part of SPIE for a while, the society of phatonic or whatever, whatever. it is some optical something engineers. We were a part of that for a while, I go to some of the MEMS conferences, I go to nano, you know, I am editor of the IEEE Transactions and Nanotechnology. But it kind of evolved, you know, I mean I think that the path we took was similar to a lot of folks where you get in, you start to do assembly. I think we started doing more fabrication and things like that then a lot of other groups, but a lot of folks just focus on precision assembly and precision positioning, which is a hard and important problem for industry and that you get in there and then you start thinking smaller, but one person that was ahead of all of us in this was, I think, R.E. Keisha at the University of Southern California, and R.E., for you know, while I was thinking micro, R.E. is already three orders of magnitude smaller and he is in the nano world and he is talking chemistry and surface effect things, things that at the time I did not know what the heck he was talking about. But he was seeing the potential of some of his programmable assembly ideas in the macro world and putting them into the nano world and working with a atomic force microscope, scanning probe microscopes and automating those and bringing robotics in, which I think was a I mean, I looked at it, I thought about it and I thought well That is way too far of a leap for me, but R.E. was there working and he did a great job and has done a great job and pulling robotics into that and helping a lot of us see the potential, and he also does the, not just the vision, the research vision, but he also has done a lot of work in helping make sure there is funding there so that the research can continue, he served as editor and chief of the Transactions in Nanotechnology and helped bring that journal up to higher standards and so yeah, R.E. was yeah, in the nano world I think was really one of the pioneers of that so. "
"Brad Nelson","Interviewer","What was the first microrobotics systems that you built?"
"Brad Nelson","Interviewee","The first one would have been when I was in Illinois in Chicago. I found somebody had, in a lab there was a, it was called a Wentworth probe station. It had a microscope, probably a mitutoyo microscope on it and some manual positioners and I remember, you know, thinking about micro assembly, how can I get I had a whopping $30,000 startup package, this is 1995. $30,000 was not very much then even, but I did not have a lot of money and I was looking at how to get something going and I heard in one of the labs there was this Wentworth probe station and they said it does not belong to anybody, and in 10-minutes I was down there. I think, you know, in a half an hour I had, heavy thing, I did have a table. We had to actually move the while thing into my lab and I started then getting mechanical drawings on it and we just kind of retrofitted it with motors put on, just D/C serve up motors and low-cost controllers and took this manual probe station from moving wafers and probing them under a microscope and then we, I should say I, got the system to work and then my students, people like Vickerman, [inaudible], my students and one of my first real PhD student and then, you know, I worked with him and taught him, okay, here is how you do visual servoing, this is how we track parts and we, you know, and he is a smart guy. he is at Seagate now and he picked all that up and really pushed things and then you train, you know, you get other students. Yujo was one of my students. He was interested and then I got some money and got an atomic force microscope head and so the days where I, you know, did anything to save a few hundred dollars and I negotiated with the company just to get the key part. I went, I can not believe they sent that to me. Nobody would do that now. They just sent the inner component of the AFM. The whole FM cost a couple hundred thousand and they just sent me the inner component for, like, nothing. I guess I can not believe they did that now that I think back about it, but nobody would do that now. But you know, we started building our own systems from scratch to do micro and nano manipulation and those but those were all manipulation-based systems."
"Brad Nelson","Interviewer","So what was the assembly problem? What were you trying to actually build with it as a tester?"
"Brad Nelson","Interviewee","Well some of the works were just fundamental. We were trying to do things like come up with good models of microscope, good camera models, optical models of microscopes. If you calibrate back in the days of Si, I do not know how people calibrate cameras these days. You do not hear that much about it, but you know, there was the Si approach or IBM had developed a camera calibration routine we all used, but the real problem with the Si approach was that you had to have 3D information. You could not just give it a flat, you know, bunch of dots. They had to have there had to be a depth to them in order to get this conserve to, the word is escaping me, to converge. I said conserve, okay, to get the algorithm to converge and so that algorithm would not work. So then how can we calibrate a microscope, you know, that way and then we got to come up with a new models, so it was a fundamental problem. Another one was, you know, we wanted to do high position positioning and a lot of people had looked at subpixel sampling. So we looked at okay, how much can I get, you know, can I get below a wavelength of Y? How far down can you go? Then with the AFM we started going and looking at the mechanics of manipulation and in other words, what are some of the surface forces involved and how can we quantify those and how can we model them, things like vendor vols or Winsor electrostatics, surface tension if you got it. So a lot of it was very fundamental work and then I would get some industry projects, like I worked with Seagate when I was in Minnesota and they had a little motor, a tiny little motor they wanted to put on the end of the head of a read/write head to nanoposition the read/write head. Well it turned out that motor, the design they gave us needed assembly and needed how this little, tiny magnets that were a couple hundred microns, about a fifth of a millimeter on a edge and about a half a millimeter long, and four of those had to be picked up and assembled. You know, that was a system. I had a telecommunications company that came to me and wanted arrays of microswitches, can we design microactuators and so we looked at a lot of different designs. Some of them we carded them with micro assembly, some of them did not and then so we were kind of driven research-wise, NSF-wise was more fundamental work and then industry-wise we try to find interesting projects to see, that seemed like a good strategy at the time so, you know."
"Brad Nelson","Interviewer","So was there anything that you, when it was assembled you would call that the micromotor. I mean is this a component of "
"Brad Nelson","Interviewee","Yeah, so we used to use the term microrobotic system but when I got to ETH, remember this is in 2000, late 2002. All of the sudden I had many more resources available to me than I had before and, which is why I came here. But when you actually have those resources and you think, What'm I going to do? What can I really do to make an impact? you started to try to think long term. You start to try to think of the things that you thought were interesting. And so I go back to Russ Taylor, for instance, and the robotic-surgery talk that I s aw back in the early 1990s. I was thinking of that. that is a field That is going to go somewhere. So, back at 2002 there is two products that had just come in the market and passed clinical trials, I think, and that were being commercialized or in clinical trials. And one was intuitive surgicals, Da Vinci robot, robots doing surgery while the surgeon's across the room tele-operating them. And the other was the given-imaging camera pill. They swallow the pill and it goes through your body and takes 50,000 images over about eight hours and saves them to a disk you are wearing. And those are exciting. I mean, these technologies are out there, and, again it was like the MEMS in the mid-1990s you could see these fields rising, and it is a really bad time to get into a field when it is rising that way when you realize people have been in this. You think, I do not want to just jump into this right now. I want to try to figure out where it is going to go. I want to try to predict where things are going to be heading. And so we started thinking about where might some of these fields be heading, and it seemed natural. Eventual with intuitive surgery you want to get rid of the robots off to the side. You want to just swallow the robot like you swallow the camera pill. You want to think, If I can make these things smaller, what might they do? And the other thing I realized this is one of my post-docs at the time, guy who worked for me for eight years, Karl Vollmers, he was one of the first people to come here with me. And I had an ETH apartment up the hill here, and he was staying with me for a couple months until he found a place, a little one-bedroom place, and we would sit around and talk about what our idea and we both realized people are much more interested in the things we were building than in the processes we were using to build them. We were making these micro-robotic systems to pick things up and assemble, but people always got much more interested in what it was we were assembling. And the other thing Karl and another one of my Ph.D. students, Sean Guannin worked on We had worked on different magnetic materials for making micro-switches and things like that, and so we had expertise in how to assemble small things. We had expertise in magnetic materials and small things. I was thinking medical robotics is the future in a lot of ways, but I do not want to just do an intuitive clone. I want to do something different. Why do not we see if we can make really small things and cut the tethers? And That is when we first started making true micro-robots, things that did not have tethers that were moving without wires. And that was 2003 we started developing these ideas. Burk Yeshin moved out here, had about six or seven when I came from Minnesota to Zurich, I think about seven or eight people came with me, counting family, my family. I counted 17 people moved from Minnesota to here when I came, and so we started thinking, Where're we going to go with that? Burk Yeshin came out. We started thinking magnetic fields just make a lot of sense, because you can project them over certain distance. Doctors are comfortable putting people in magnetic fields, and we did not know anything about magnetic hardly except materials. I mean, we knew a lot. So Burk built a planer system that took a little millimeter-sized nickel micro-robot that we micro-assembled and used external magnetic coils to drive it through this maze and move it through. And we were like, Maybe we can do something. We do the math and it is like, you are not going to get one of these things to swim through the heart, but if you can get near it, you might be able to get just generate some motion. So you do the physics, model. And so we started getting this vision of small micro-robots in the body, and we thought we were the only person with a vision, and then we found that one. Sylvain Martel also was working at he was at Kohl Polytechnic at the time and he had this idea of using MRIs to guide little particles, and it was good for us to find that out. It lit a fire under us to move quicker. And so, we started going along. I started thinking of how we might use these. I went back. Russ Taylor comes up. Greg Hager is at Hopkins was working with Russ. They were thinking about eye surgery. I also talked to Cam Raveritz , EMU, who was working on a tool for doing eye surgery, and they were telling me about how the forces were not known. Cam was saying we should use some of these manipulation devices we made, some of the force sensors we used to try to measure some of these and quantify them. So we started looking at eye surgery and we go, Maybe this is a good place to start. So, for several years we have been looking at how we can make things that can move through the eye. We call it a micro-robot. it is a hunk of metal with some functionalization on it, and then the whole robotics is really the field, the way we generate the fields on the outside, but the math for that is pure redundancy control of manipulators, stuff. it is stuff That is 25, going on 30 years old now, a lot of the fundamental work, but it is done in a different way. But That is when we started thinking, and That is when we started making micro-robots, and now we just keep going in that direction."
"Brad Nelson","Interviewer","So, the one that went through the magnetic maze was kind of the first one. What are some of the other systems that you built?"
"Brad Nelson","Interviewee","So, we did that and we were understanding our models. We were really just doing physics and trying to understand things, and then Allison Okamura at Hopkins I was visiting there once, and she says, I have got this really great student. I think he would really be great in your lab, Jake Abbott. And so, Jake came out and he spent three years in my group, and my instructions to him when he got here was, You see what Burk did with the planer robot moving through the maze? We want to do that in 3D. Going 2D to 3D's often trivial, right? So, seldom trivial, really, right? And then Jake, he started basically had his own little team here and started thinking how we might do that and came up with, I think, some really interesting technology. We got a patent on it and actually, we have licensed it now to a startup company That is trying to using this technology to build biomedical devices. And."
"Brad Nelson","Interviewer","what is the company?"
"Brad Nelson","Interviewee","The company's ANT Scientific. it is an ETH spinoff, and it is three of my former students are the core people on it. One's the CEO. One's the CTO and the other's the guy who is basically product development. he is trying to figure out applications for this, and so."
"Brad Nelson","Interviewer","When did they start out?"
"Brad Nelson","Interviewee","Last fall."
"Brad Nelson","Interviewer","Very nice."
"Brad Nelson","Interviewee","So They are very new, but the idea now is you get along in your career and you get to be my age, you start thinking, Do I need to publish another paper? I mean, I really do not need another paper but I do want to see the technology in the real world at some point. And That is what you have got to do, either license it to somebody and let them take it or see if you can this is a bit of a leap to use some of this stuff, so we are going to try to do it on our own and partnering with other people there, so."
"Brad Nelson","Interviewer","Have there been other startups that come out of the work."
"Brad Nelson","Interviewee","Yeah. So, there is another one called FemtoTools, and They are successful. They sell product. they have got five employees right now. They are growing, and they basically this goes back to manipulation. This is where we got our start back in the early 1990s, early 2000. This is back to Yu Sun . He got one of our force-sensing device that could make measurements at scales that you could not get anything for Selmet handling to work. And then Felix Beyeler, a Swiss student, came and took his design and really extended it, I mean, kind of hardened it, did new things with it. And then Felix was interested in seeing if he could we knew there is a market for it, because every time I had give a talk, people would always come up and say, Can I get one of these? I really need something like this. And so, back, I think, in 2007, 2008, Felix spun off this company and a few of my other people went with him and spun that off, and That is as I said, that sells product and growing company. And they sell micro-manipulation systems and tools, grippers and force sensors and parts for that. So, it is satisfying to see your research get to a point where somebody's willing to pay money for it in the real world, not just research."
"Brad Nelson","Interviewer","What about your other collaborations with various corporations? I mean, obviously you worked at Honeywell, but other places where your work has been used by industry."
"Brad Nelson","Interviewee","Well, we did a lot of work with Seagate when we were in Minneapolis, and then we developed some devices for the telecommunications company, which they have patented. And this was just before the telecom crash in 2000. So then plans change when industries crash. I mean, we have got other companies we are working with right now, but I think there is two ways to make an impact with your research. One is to get companies to use your technology and get it out there, but the other thing that you realize it is probably the more important one is to bring in really good students, show them some interesting area, and then They are the ones that go out there and they start leaving the company. And a guy like Vikram at Seagate I know some of my folks have gotten different companies. They rise in the company, and Burk's AVB was at AVB and led product-development teams and now has moved into new areas, different areas. And so you realize it is the students, the good ones, They are the ones that are really carrying the torch when they get out there into industry and start implementing these new technologies, I think."
"Brad Nelson","Interviewer","And who are some of your other students? Have any of them wound up in academia, as well as."
"Brad Nelson","Interviewee","Yeah. Several. So Yu Sun is at Toronto. Jake is at the University of Utah. Gi Young is at Carnegie Mellon. A good nanofabrication guy, Arun, who did some beautiful work in carbon nanotube devices for me, he is just moved from Sandy and now he is moving to Virginia Commonwealth University. I should mention Li Shin. Li Shin joined my group, I can not remember, 2003 or so. I was actually advertising for somebody in the area of biology for a post-doc, and Li Shin came to me at a conference. I knew Li Shin from his work in Fakuda's group in Japan. In his Ph.D. thesis he'd done beautiful nano-manipulation work. And he said, I had be interested in not maybe doing biology but working in this other area. And Arun, who was a former student of mine at Minnesota, a Master's student then, also told me he'd like to come back to Switzerland as a Ph.D. and he was interested in similar topic. And then I also had a really good German student, Dominik Bell, who is now CEO of Aeon Scientific, and he joined us. All of a sudden I had this nano group of really first-rate people. Li Shin and Arun and Dominik and then some others joined, and so That is where we really how we did the nano work, got involved in there. Li Shin is at Michigan State. That is how that started. So, Li Shin is a professor there. Boy, I should have a list. I am forgetting people, I am sure, but It will come back to me at some point."
"Brad Nelson","Interviewer","How many Ph.D.s do you think you have supervised?"
"Brad Nelson","Interviewee","God, I do not know. I have not even counted. I do not even know how many people work for me half the time. let us see. I do not know if I have had 20, 25. I guess I could count the number of theses I have on my bookshelf, but I know some of them do not give me their final copies, so it is probably not right."
"Brad Nelson","Interviewer","So, apart from students, have there been some other really important collaborators that you have worked with over the years that've been influential on your work and development?"
"Brad Nelson","Interviewee","Gosh, yeah. let us see. I mean, as a Ph.D. student I was two years I think I am actually older than Nikolaos Papanikolopoulos, but he was ahead of me as a grad student and he was sort of my big brother and he showed me well, he is Greek. He did not show me how to write good code, That is for sure, but he showed me how to do math right, and we did a lot of just LQR, LQG stuff. That was good. I mean, of course, Pradeep and Max Jonath and all these people are good. And in University of Chicago I had professors that treat you well and mentor you and people like Sabray Sen going in to Minnesota, who or I mean at University of Illinois at Chicago and so that has been important, and then, I mean, people that're pretty open with a lot of their work and help us, guide us into areas. The Hopkins people have been good. Russ Taylor and Greg Hager, I mentioned them. And then, I mean, the micro-nano community, I think. We all sort of look at each other and try to take the next step and look at different things. So, in Europe there is a lot of good micro-robotics folks. there is the group in Les Ensembles, Nicolas Chorier and Michael Gauthier, some of those folks there. Up in Germany there is Sergej Fatikow and his micro or nano-manipulation group up there and, of course, Paolo Dario at Pisa. When I first got here, he helped me get into the E.U. cycle and become a part of the European Union funding cycle. So, I think I am forgetting lots and lots of people. You do not get there."
"Brad Nelson","Interviewee","And then we work with a lot of folks in different fields and just being able to interact a little with, for instance, biophysicists, I mean, a guy like Howard Berg at Harvard, who did a lot of bacteria work. I spent some time with him, and just listening to a guy like that, who was at the beginning of understanding bacterial motors. A 20-minute talk from him, you learn more in 20 minutes than you learn a week at a workshop. I mean, initially in robotics, I mean, I was inspired by, I mean, to me, people like I mean, there is a great paper, Erdmann there is a fine motion-planning paper, Mike Erdmann, and, I think, Matt Mason and Russ Taylor, I think, were on that. These kinds of things, these kinds of people and seeing this work that just blows you away. And when you are just a mechanical engineer and you see these different ways of approaching problems when you are young is really intimidating. I remember when I was at Carnegie Mellon, the first two Ph.D. theses I saw were Ken Goldberg's thesis and Shree Nayar. Ken's at Berkeley. Shree Nayar's at Columbia. I remember my first semester going to those and just thinking, My God, this is what they expect me to do? This is unbelievable, to see the quality of work and these guys are so well-spoken. That is why you go to these places and it really raises your level, right, when you see people like that, and it makes you want to try to strive for something like that, a guy like Takeo Kanade at CMU running the Vision Autonosystems Center. he is my academic grandfather. And seeing the work ethic but the creativity that he has, and these are the kinds of things that press you."
"Brad Nelson","Interviewer","So, when you arrived at Illinois and I could ask the same question about Minnesota. So how were you received as sort of a roboticist within what is it, the mechanical-engineering department?"
"Brad Nelson","Interviewee","Yeah."
"Brad Nelson","Interviewer","Were there other people working in that area, or were you were they trying to get into robotics?"
"Brad Nelson","Interviewee","So I arrived at Illinois-Chicago in 1995, assistant professor. In a lot of ways, robotics was a bad word back then, and I think for good reason. First of all, the field had overpromised in the 1980s what it could deliver. I also think there were a lot of researchers, academics, who did not know what to do. They did not have a good view of where is controls going? Where was manufacturing? And so they said they were doing robotics and they build little things and there was not a lot of there just was not a lot of depth into thinking about what they were doing. And you look at these shlockey little things and if you are a thermodynamicist working with statistical mechanical doing some pretty detailed theory, and you look at this stuff and you kind of raise your eyebrows and like, Who are these jokers? And it can create bad reputation for the field. So you come in there. I remember during my interview at Illinois-Chicago I went into Selcha Guccieri was the department head at the time, and I went in to his office to talk to him, and this is one of my first real interviews as an academic and probably my only real interview at that time, actually. And he is looking at my CV. He says, Ph.D. in robotics? So is this a real degree? I just about had a heart attack. I am like, Yeah, it is a real degree. And I still feel there are people out there who still see it that way. I think in this department here There are still people that think, You guys are just building junk. there is nothing to it. you are just building stuff. there is no depth to it. And the same people have not ever tried to build something, so they do not really understand the difficulties, I think, usually. But That is one of the reasons you do it is because it is so wide open, I think, so there is so much to do."
"Brad Nelson","Interviewer","And in terms of funding over your career, where have you sought funding and where have you received funding?"
"Brad Nelson","Interviewee","Well, in the States, I mean, the National Science Foundation was very good to me. And I got the Young Investigator Award. I was on a couple DARPA grants and I had industry money coming. I had some good industry money. I never had a problem in the States with funds other than my first year, like everybody, but then I left before I came here before a lot of the well, I came here in 2002, and, let us see, when was there was a new president around that time, I think, and things kind of changed then. I think priorities of the country changed. And so, now, here, I have basic funding, so I have a group and I can keep people around for years. I can keep memory in the system. I keep chemists in the group. I keep a guy who is an electrical engineer who is been here 30 years and he designs electronic boards for me and it is a key part of our success is being able to exactly get the kind of electronics we need without having to fit a round peg in a square hole. Then I have my systems engineers. I have my fundamental rocks , but I am able to keep that here, so I have got that basic funding. But then here in Europe and in Switzerland, I mean, there is also the Swiss National Science Foundation. I am a research counselor for that, so I also help determine how that money gets distributed a little. I have some say in it, not a lot. European Union funds, things. Switzerland has a program that helps That is more near-term product, so it is a federally funded government program that you do not want to do basic research on it but it kind of helps develop a product. And so, with some of the startups, we are able to leverage that money."
"Brad Nelson","Interviewer","How does that work with Switzerland not being part of the E.U. but still being able to get E.U. funding?"
"Brad Nelson","Interviewee","So, it is changed since I have been here. I mean, it used to be if you got funded on an E.U. proposal, then Switzerland had an agreement that they would just put the money into the E.U. proposal and it would come back to you. But since that time, it is changed and now Switzerland actually makes a contribution to the E.U., and then just based on the valuation of the proposals, some of that money comes back. So it is not one to one like it was. So, as I say, That is the way Switzerland behaves here. They are good at boy, this is let us see. They participate in the E.U. when it works out for well for them, I should say, but they become a part of the community, and I think That is the real benefit I have seen of being a part of the European Union funding cycle is not necessarily I mean, you do interesting projects, but really it gives me a great chance to meet and work with people all over Europe, I mean, people like Paolo Dario in Italy or Sergej up in Germany or the folks in France, Antoine Ferrier , the folks in Bais Enseign , people all over, Bulgarians, Finns. So, I think That is the one thing that this has done is it is really helped at least my perspective. It seems to bring the science in Europe closer together, so That is done that. We get some industry funds here. I am not as hungry for that as I was in the U.S. In the U.S. I would basically help develop products and give patients if I could just to get money, but here it is like we can be pickier and choosier here. We can choose our problems a little more, our interests and what we think is best. So it is a bit of a different system here."
"Brad Nelson","Interviewer","So, what do you see as kind of the future of micro-robot, nano-robotics? What are the big, sort of outstanding problems and research directions?"
"Brad Nelson","Interviewee","Well, I think in the immediate term what I am looking at are, first of all, applications. How're we going to use these? What can they really do? I think there is really interesting evidence that targeted delivery in various parts of the body can have dramatic impacts on recovery from diseases. We see that in the brain, and we are seeing that in the eye now, in the retina, and I am sure as we start to rethink the way we might get drugs there, I think that it is going to be really interesting to figure out, Okay, how do we get things on these robots? How do we get them there? That is one of the things we are working on. How do you make these things move? One of the big open issues is the imaging problem. How are you going to see these things and find them in the body? Can you instantiate behaviors on them in some way so they can behave much like a bacteria does, where They are basically following some kind of a gradient, some chemical gradient or light gradient or pH or something like that. I think That is where I am looking, and if I were starting my career over again building a lab and thinking about interesting problems, I would love to work on figuring out all these little molecular mechanisms that're I mean, They are little tiny machines. They are little O-rings that two kinds of proteins that just naturally form these beautiful O-rings, for instance. On an E. coli membrane there are sensors. There are communication pathways that're very chemical but mechanical, in a sense. I think understanding these, I think, robotics has a lot to bring, because there is a lot of modeling. there is a lot of kinematics involved. there is a lot of different forces and many, many degrees of freedom, so I think the motion-planning community I mean, these people are working in these areas. I think there is really exciting areas out there to go at these scales. Simultaneously while we are doing that, I mean, I am an engineer. I want to build something useful. I mean, I am happy to explore things and That is exciting. That is what gets me up in the morning, but I also want to make sure what I am doing has an impact, and so I think on the other side we now think and understand work closer with the doctors, the biomedical people who understand the issues, the problems, and then think, What are the tools that we can bring to bear on these problems? And so finding the applications and then functionalizing, I think, are interesting. And, like I said, imaging is a key problem that I have not had the guts to jump into enough yet as much as I need to. That is one of the reasons to work on the eye, because we can just look through a microscope and see it instead of worrying about that."
"Brad Nelson","Interviewer","A lot of the biorobotics work that has been done is sort of interfacing neurons with robotic systems, electronic systems, but there hasn't been as much of the sort of mechanical interaction between the biological side and the robotic side, or would you say that."
"Brad Nelson","Interviewee","Well, I mean, we have worked with biologists. we have studied drosophila, how fruit flies fly, and when you do that, basically we build the tools for the neurobiologist to make measurements. it is the lift force of the fruit fly. what is its bandwidth or something like that? But as you work with them and you work with things like C. elegans or you work with zebra fish or E. coli, you can not help but get ideas on how to build new kinds of micro-robotic mechanisms or use some of these physical principles that why does E. coli have a rotary motor? Why does it have this corkscrew flagella on it? Well, it turns out from a fluid-dynamics perspective it is a beautiful design. I never would have dreamed of it. But then it turns out Jeffrey Taylor did it back in 1952. I would not have thought of it, though. Anyway, I am rambling about the previous work in this area, but I think that there is interesting work in Germany in the '30s out of this thing. But why are these organisms how did they evolve to use these in this way in this little niche, these little physical niche, these mechanisms that I as a mechanical-engineering designer would not sit down and come up with on my own. So you look at those. But I think as we go smaller and we start to look at these molecular mechanisms, all of a sudden you realize we have to look at nature. I just really think that the problem is too there is a computational issue. there is a search issue that we are never going to overcome, where we are going to be able to design mechanisms that are half as capable as these proteins that come together to form these structures. I mean, there is the DNA origami people, people that're looking at using DNA, the semen work that started 20 years ago, and there is an interesting community there. But That is just the tip of the iceberg of what is going on at these scales, and there is all these things if we just look at nature and look at if we get good cryo-transmission electron microscope images and better ones, then we can start to really visualize these mechanisms and things. I think, boy, That is fascinating to me, and I think that would be a great area to head in."
"Brad Nelson","Interviewer","How far off do you think it is before we can assemble biological systems of our own design?"
"Brad Nelson","Interviewee","Well, I mean, if you talk to geneticists, I mean, there are things they can do now. I mean, I do not know. When I talked to them I was mentioning this O-ring. You take Fly N and Fly M, and there are a couple of proteins. And they just come together and fit in a certain way and they form a ring. As an engineer, I am curious what are the process parameters. How robust is that? When will that not happen? What concentrations do I need? What temperatures will that happen? Is that a tool I can build something else off of? But I can build that, I think, now. Kelly Huset at Utah tells me he can build flagella. He can just build a flagella, get a whole bunch of them. Then, I mean, you look at the synthetic biology people, I mean, they think they can do all these things. I think it is a great field. Like everything That is new, I think everybody underestimates the complexity of it, just like we did robotics in the 1980s. Probably we are still underestimating its complexity, but I think the complexity of these problems is really difficult to get a handle on when you start. We learned that for decades, many, many times in many fields."
"Brad Nelson","Interviewer","And what is your advice for young people who would be interested in pursuing a career in robotics or micro-robotics? What should they do and how should they go about it?"
"Brad Nelson","Interviewee","Well, I think if you want to work in robotics, I mean, the first thing is you got to have a passion. You got to be willing to come in to work at five in the evening and go home at eight in the morning, if That is what it takes. But you also have to make sure you are working with the best people you can work with, because my experience is everybody else is smarter than you are, and you better go out and grab their knowledge and try to learn the lessons from them, right. And what is it? Anyway, you just need to work with the best people, and then you build these networks and, I mean, it is a fun community to be a part of, because especially if you have been in it as long as I have now, over 26 years or so, you see the field. You see areas grow and wane and then you see things come back. You know the groups that you can trust and you think their work is if they can not solve it, you know you are not going to be able to, or if you think it is interesting, there might be something really there. But I think working with just that interaction with the top people in the field brings you up, I think. I mean, there is advice if you really want to make an impact in the field, go to the scales. Go to the one end, the very, very far end, or we went to the very small end, but you can not go much smaller than we are going now. We could talk quantum robotics and I know T.J. Tarn talks that, but I have an idea of what it might be, but I am not willing to say it, but it has nothing to do with small. It has something to do with the philosophy of the field. But I do not know if there is extremes of the field to go in right now, but I think there is I mean, medical robotics is exciting. I mean, when I first saw Russ Taylor give the talk in 1990, I think it was, or 1991, I could tell it was going to be exciting, and I think it is more exciting than ever. I think there is a ton to do at molecular levels. we are just starting to scratch the surface, and I think We will do interesting things. But then you see military applications and you see that is pushing the technology in incredible ways. People talk about service robotics, and I still think that is a completely open issue. I do not understand. I am not sure how these things are going to be accepted. Everybody's got their own view. I mean, the Japanese have their view of it. Americans are going to have their view and the Europeans are working in these areas, too. About I think there is a lot of interesting areas, but as long as you go into one that and work with the best people and you are passionate about what you do, good things happen eventually."
"Brad Nelson","Interviewer","Great. Is there anything else you would like to add, all those things we missed?"
"Brad Nelson","Interviewee","Gosh. I do not know. No. I just look back. I guess talking about this, it is interesting. I mean, in 1984, falling into robotics accidentally, it is amazing how it is a passion. Anything that has anything to do with robotics I still read, even though I work in micro-nano. it is a fascinating field, and it'd still be interesting to see where it is going to go, because I am not willing to make a prediction, but it is clearly here for a long time, forever, as far as I can see, as long as we are here and somebody's going to be trying to make smarter and smarter machines, things that're more intelligent. And so, I was lucky to sort of accidentally fall into it and happy. I am happy to be a part of it for such a long time."
"Brad Nelson","Interviewer","Were you influenced by any sort of robotic sort of literature or movies as a kid?"
"Brad Nelson","Interviewee","My mom has a picture of me in third grade. For Halloween I was a robot. No. I think as a kid I was influenced by the Apollo missions. I was seven years old when they landed on the moon, and I did not want to be an astronaut but I wanted to know how to build a rocket. I wanted to know how to build the Eagle and the modules and the lunar modules and what those were. And I think more than anything that got me excited about engineering was the space program in the 1960s and 1970s and landing on the moon in July. Is it July 20, 1969, I guess, right? Was it?"
"Brad Nelson","Interviewer","July. Something July."
"Brad Nelson","Interviewee","I think it is July 20, 1969, and 7 years old. that is a good thing for a that was back before all these toys and everything. You had to really want to follow these things if you were interested in it."
"Brad Nelson","Interviewer","Good."
"Brad Nelson","Interviewee","Thank you."
"Brian Carlisle","Interviewer","Okay, so why do not we just start by having you introduce yourself and tell us where you were born and where you grew up."
"Brian Carlisle","Interviewee","Hi. I am Brian Carlisle. I was born in San Francisco. I grew up in both San Francisco and Marin County and then later lived down in the Peninsula. "
"Brian Carlisle","Interviewer","And where did you do your undergraduate studies?"
"Brian Carlisle","Interviewee","I went to both undergraduate and graduate work at Stanford University. So I studied mechanical engineering there at Stanford. And a professor was a gentleman named Bernie Roth, who was very well known in the robotics community and who was also the advisor and professor for a number of other colleagues that I subsequently worked with, including Bruce Shimano, whom I believe you have also interviewed. "
"Brian Carlisle","Interviewer","How did you first become interested in robotics?"
"Brian Carlisle","Interviewee","I was always kind of interested in mechanical things. My grandfather was a pattern maker who made patterns for big diesel engines. So what he did was make big wooden patterns for these giant engines that would pull freight trains around. And I visited him several times in Ohio. And he took me one time to his factory where he worked. And I was sort of fascinated by the whole process of making things, and creating something that was big and strong and powerful and mechanical. So that got me interested in mechanical things at a very early age. And then later, as I was a teenager, I got interested in model railroading. And I got a big model railroading thing going for a while when I was 16, 17, 18, and did that. And then finally when I went to college, I decided I wanted to go into engineering."
"Brian Carlisle","Interviewer","And when did you decide you really wanted to focus on robotics?"
"Brian Carlisle","Interviewee","Robotics probably about my senior year, I would guess. I started generally in mechanical engineering. I met some folks through Bernie Roth, my advisor. My senior year a gentleman named Vic Scheinman, who was also at Stanford, and Bruce Shimano. And Vic was working on some robots there at Stanford, which We will talk about here in a little bit. And so I got together with Victor and with Bruce kind of my senior year, Master's year. And then when I graduated with my Master's degree, I went to work with Vic and Bruce in a very, very small company."
"Brian Carlisle","Interviewer","Did you do a Ph.D. also?"
"Brian Carlisle","Interviewee","No. Just I did a Master's. Actually, I did most of my undergraduate work in mechanical engineering and design, and mechanical engineering. And then most of my Master's work in electrical engineering. And I was particularly interested in servo mechanisms. And at that time, microprocessors were just coming out. I graduated in 1975 with my Master's. And microprocessors were coming out in the early, mid-1970s. And so servo control was transitioning from essentially an analog process to a digital process. And so I took a number of courses in microprocessor-based control and sort of servo engineering and servo mechanisms. And all that was, you know, kind of led right into the robotics thing. "
"Brian Carlisle","Interviewer","What kind of microprocessors were they using for that?"
"Brian Carlisle","Interviewee","The very early ones that first came out for microprocessor motion control were things like the, what was it? It was the 8088, it was not the 8088. It was 6802 I think. Or 6502 was the number. It was a little small eight-bit slow 10 megahertz processor. But the first Intel architectures were coming out kind of in the mid-1970s. And also DEC, who is no longer with us, Digital Equipment Corporation, came out with a minicomputer, which they sort of turned into a microcomputer, and that was called the LSI-11. And they had taken something that had been a 32-bit architecture and kind of squeezed it down into something that would fit in kind of a breadbox. And that was kind of the first more general purpose, high level microcomputer/minicomputer kind of architecture. And so we used that early on in the mid-1970s to actually do the computations to control the robots. And we used things like the very small 6502 microprocessors to control the individual motors."
"Brian Carlisle","Interviewer","How were you programming them?"
"Brian Carlisle","Interviewee","The microprocessors or the robots?"
"Brian Carlisle","Interviewer","Both."
"Brian Carlisle","Interviewee","Well, robots have several layers of control in them. there is a layer of control which is motion control, which is basically controlling the motors. And then since you have some number of motors in a robot, ranging typically from three motors to six or seven motors, you need to coordinate all of those motors together to make the robot move. And you do that typically by having a mathematical model of the robot called a kinematic model. And you can tell the robot at a higher level computer what kind of motions you want to make, and typically straight-line motions in Cartesian space. And then the computer figures out all of the individual commands for the individual motors. So you have at the sort of supervisory control level a language which is a robot programming language, similar to many computer languages, with its standard control structures, do loops and if loops and while loops and case structures and so forth. But then in addition to that, you have a whole library of motion control commands. Open the gripper or move in a straight line, or in some cases talk to a vision system and get information from some kind of a sensor and then make some decisions about that. So my partner that I have worked with whom you interviewed, Bruce Shimano, really was kind of the software guy, and he was the guy that was expert in the kinematics and the language and the mathematics to move the robots. And I was more the hardware guy, the mechanical guy and electrical guy in terms of the mechanisms themselves. "
"Brian Carlisle","Interviewer","So what were some of the big challenges for the electrical and mechanical design of the first systems you worked on?"
"Brian Carlisle","Interviewee","Well early on, certainly in the early 1970s, the earliest robots were hydraulic-powered machines. They were very big and they were very powerful, but they really did not have much of a control system in them. The earliest controllers were rotating drums in which analog information was stored on a rotating drum. It was like a player piano. The drum would rotate around and it would send out some analog information to some servos and the robot would sort of lurch around and open and close a gripper. And so that was not a real sophisticated controller, but nonetheless, some early applications in the 1960s, were done that way. The computer control of robots was really introduced in the mid-1970s, and Stanford was one of the principal locations where that was done. MIT was also working in that area at the time and Carnegie Mellon a little bit. One of the big challenges was first of all, how do you make all this complicated mathematic execute quickly enough in the computers that were available at the time? Secondly, how do you replace these hydraulic servos with electric servos or electric motors that were strong enough to move some of these big mechanisms around? So there was both a software design and then kind of a mechanical design challenge in making the early electric robots. "
"Brian Carlisle","Interviewer","Where there any memorable breakthroughs in that?"
"Brian Carlisle","Interviewee","Well, I think probably the biggest software breakthrough was a thesis done by Don Piper in 1968. He was another one of Bernie Roth's students. And Don's thesis was essentially how you solve a six-axis kinematic the inverse solution for a six-axis kinematic transformation. That is, how you invert the rather large and complicated matrix that results when you are trying to figure out how to move six degrees of freedom in a robot arm to get the tip to move in straight lines. So Don Piper sort of figured that out, and that was kind of the basis for computer control of robotics. That was an important breakthrough, and that came from Stanford also, in Bernie's group."
"Brian Carlisle","Interviewer","The first system you worked on was the Vicarm?"
"Brian Carlisle","Interviewee","Yeah. We have a bit of a history slide here. We have sort of in the 1969 timeframe something called the Stanford Arm, which was a Cartesian sort of a polar coordinate robot that rotated and extended and had a wrist and so forth. And that was developed by Vic Scheinman at Stanford and a couple of other students there. Bruce Shimano was involved in doing some of the controls for that. The control system for that robot was a PDP-10 computer. It was the size of a Volkswagen, and a very big, fairly expensive computer at the time. It was used just really primarily in research at Stanford for a couple of years. Then in 1975, when I graduated from Stanford, I joined Victor and Bruce joined Victor, and three of us had this small company called Vicarm or Vic's Arm. And we sold one of these robots to the General Motors research lab. I remember delivering that on my birthday in a snowstorm, my birthday happens to be in February, to Troy, Michigan. And dragging this robot to the loading dock there at General Motors through the snow. That was entertaining. And then going in and installing it with a couple of fellows who are also known in the robotics community, a gentleman named Lothar Russol and another fellow named Mitch Ward. And so we delivered that robot to them with a at that time, we had packaged the language that Bruce had developed at Stanford into something that would run on one of these LSI-11 computers. And so we delivered the robot and a controller. Actually I take that back. I think that was early enough that we did not have the language in the portable computer yet. We just delivered the robot, and the repackaging came a bit later. So that was a direct sort of transfer of technology from the university to a big interested commercial prospect. General Motors had been using robots for some time, but they were these large, hydraulic, very simple robots. And GM was interested in the idea of a robot that was more human scale and that could do small part assembly and material handling. So GM did some research then for a little while on that early Vicarm robot. And then Vicarm kind of carried on doing a bit more work and starting to develop the packaging of the controls into the LSI-11 computer environment. And then in early, maybe late 1976 or so, GM came out with an RFQ for something that they called the PUMA robot, which was a GM acronym for programmable universal machine for assembly. And that whole concept was in part based on this Vicarm robot that we had delivered. And so there were a number of companies that bid on that, including some very large companies like ABB and Cincinnati Milacron, and Bendix and Honeywell and so forth. And then there was Unimation, and then there was Vicarm. Unimation was sort of the existing commercially-viable robot company at that time. In 1977, they were doing maybe $25 million a year selling these large hydraulic robots, primarily to the automotive industry. Vicarm was a tiny company and had no resources to successfully bid on a proposal from General Motors. We could not have credibly done that. So we sold Vicarm to Unimation and then bid on the PUMA contract. And we won that contract because we really had, relative even to these very large companies, we had technology that worked and we could demonstrate that. So we went on then over the next year and a half to develop kind of a commercial product, which was called the PUMA. And this was the very first prototype that was delivered to the Smithsonian, by General Motors actually, in 2003. But we delivered that first prototype about a year later, sometime in I would guess early 1978, somewhere in there. And GM really liked it, and then we did a more packaged version of it with castings and kind of the more industrial version rather than just a prototype. And that grew very quickly into quite a good business for Unimation. It grew into about a $40 million business in the next three or four years and more than doubled the size of Unimation. And there were some thousands of these PUMA robots that were built and sold all over the world. And there are still a few of them hanging around university research labs that people still tinker with. And the PUMA came, so we developed that in various sizes. There was kind of a small version that we did, which you can see I do not know if you can see it in the camera, but over here in the background. And that small version was done in the early 1980s, and there were some bigger versions, and so forth. So that was kind of a technology transfer story, really, from university to a very small company, then to sort of a medium-size company and out into industry."
"Brian Carlisle","Interviewer","What were some of the big innovations that were realized in the PUMA? How was it different than the preceding arms?"
"Brian Carlisle","Interviewee","The preceding arms were essentially all hydraulic. Unimation had made these very large, heavy hydraulic arms with these, again, very simple controllers, almost rotating-drum type of controllers. Other companies who were in the business, Bendix, had some hydraulic robots, Cincinnati Milacron had some hydraulic robots. And again, all of those with very simple types of controllers. There were some other pneumatic robots out there that were driven by air cylinders, essentially. But there was no electric robot, there was no servo-controlled robot, and there was no language, and there was no robot that had the kinematic solution, running in a controller where it could literally move in straight lines and talk to sensors and communicate with vision systems and do repetitive structures and do loops and things and pick parts off of pallets without having every single program, every single motion explicitly taught. So the PUMA was different in both regards, both in the control system, being the first computer-based control system that was available. And then secondly, in being the first small, light to medium-payload electric robot that was available. And about that same time, another company, ABB in Sweden, came out with a small electric robot that they targeted primarily at arc welding. So just about that time, the mid-1970s, the 1976, 1977 timeframe, there were these two products that came into the market. There was the PUMA from Unimation and then there was this small electric robot, I think it was called the IRB-6, from ABB."
"Brian Carlisle","Interviewer","And after that, a lot of companies then moved into electronic robotics?"
"Brian Carlisle","Interviewee","Yeah. And so the PUMA was somewhat of a watershed product in the sense that it became clear then A, that there was a market for small electric robots with General Motors buying these things, buying 40 million a year of these things. And then B, that the technology was mature enough to make small electric robots. So then everybody sort of piled on board. You had many Japanese companies kind of expand into the robot business, doing lots of electric robots, various European companies. A few years later, I think by 1983 or so, when Time Magazine had robots on the cover of Time Magazine, just in the US there were 34 US companies that I counted up at the time that were in the robot business. There were probably two or three times that in Japan in the robot business. And there were a good dozen or so in Europe. So it was believed in the early 1980s that robotics would be a really explosive growth business, that robots would replace human labor in things that were heavy, big, and dangerous, like spot welding, which in fact they largely have done, in hazardous environments, underwater sorts of things, which has also come about. But it was also felt that robots would do a lot of work in small part assembly. And that has been, I would say less ubiquitous than some of these other areas, because people can still easily do small part assembly until you get to the point where you are talking about very high precision. When you get down to thousandths of an inch or 10, 20, 30, 40 microns kinds of precisions, then it becomes very difficult for people to do it and then you find that robots or other automated equipment using various kinds of feedback is doing that. But there was this sense in the early 1980s that robots were going to be everywhere and that humanoids were just a few years away. And so there was kind of this wild boom in companies investing in robotics. And that lasted for about five years and then kind of tapered off."
"Brian Carlisle","Interviewer","Why do you think it tapered off?"
"Brian Carlisle","Interviewee","It tapered off for several reasons. One, a lot of the robots are not nearly, even today, as independent and sophisticated as a person is. And so many applications that were envisioned for a robot you just could not do with the technology. You could not send a robot in to clean the bathroom or put the dishes away or wash the windows or do many of these kinds of things that were kind of imagined in the early days. So people sort of took the science fiction view of robots and figured it was all going to happen in the next five or ten years, and the technology has taken much longer to develop. So I think That is kind of the bottom line. There are some things that robots are quite good at doing if They are very repetitive in a very structured environment, and you order the parts and the robot can go pick up the parts and that. But working in unstructured environments is still very challenging, even today. "
"Brian Carlisle","Interviewer","What were some of the big companies that were investing in robotics then?"
"Brian Carlisle","Interviewee","You had many of the large companies in the United States. You had General Electric, which had a big robotics program. Westinghouse, which then not to be outdone by General Electric, purchased Unimation in about the 1983 timeframe. And then you had IBM had a big robotics program. You had Bendix, you had Honeywell had a robotics program. So quite a number of large companies had programs, and then there were a number of smaller companies as well, sort of startup kinds of companies."
"Brian Carlisle","Interviewer","What led you to your next business venture?"
"Brian Carlisle","Interviewee","We had sold Vicarm out to Unimation. And the way that kind of worked out was that we were out here in California, being California kids, and Unimation was back in Connecticut. And so our working relationship with Unimation evolved into we became sort of an R and D group, a research lab, and they had the manufacturing and production facilities back there. And so we would develop new products and both controls and robots, and we had mobile robots rolling around and doing infrared navigation and a whole variety of things. And Unimation would commercialize those products back there. And that worked out quite well for about five or six years. And then Westinghouse, as I mentioned, acquired Unimation. And Westinghouse had a big robot research group in Pittsburgh. They were a number of years behind where we were in both technology and in software and in terms of the experience and some of the capabilities of the team. But there was quite a period of kind of integration planning that went on. At the same time, Westinghouse reorganized. Just after this acquisition, they reorganized from three business units or four business units down into some smaller number, two or three business units. And they eliminated the business unit that had planned and executed the acquisition of Unimation. So all the managers who had done that were all let go or reassigned and Unimation was punted into this completely new group that had no clue as to why they suddenly had inherited this business. That new group, in their wisdom, went out and hired Mackenzie a consulting company, to tell them what they ought to do with this acquisition that they'd just spent $107 million on. And so we then had six months of young sort of consultants from Mackenzie who did not know anything about robots coming out and asking us in California, Well what should we tell Westinghouse they ought to do with this business? And that looked like it really was not going to have a very positive outcome. And so at the same time in this period around 1983, there was as I mentioned a great deal of brouhaha and euphoria about robotics being on the cover of Time and so forth. And so we were being regularly approached by venture capital investors, and I knew people in the venture capital community. And they said, Gee, why do not you guys go start your own robot company? So after watching Westinghouse thrash around for some six months or so with no clear plan, and then finally they hit upon the nice idea that they would offer us all the opportunity to relocate to Pittsburgh, which did not go over terribly well with this bunch of people from Silicon Valley, we said, No thank you. And Bruce and I went out and we raised some millions of dollars in venture capital to start Adept Technology. So that was in 1983. And at that time, we looked at the market and we said while it is not a huge market, there still is an opportunity in this area of small part material handling and assembly. And in particular, it would be nice if the robots were more reliable than the robots had been in the past, because they need to run very fast and for a long period of time. So I had been working with another company on a new motor design, a direct-drive motor, similar to a giant stepper motor, it was called a variable reluctance motor. And it was low cost but very high torque. But it was very challenging to control this thing to make it run smoothly and quickly. So We had figured out a little bit of that while we were at Unimation, and I had given Westinghouse the opportunity to invest in it and develop it and Westinghouse said, No, we do not think this is very useful. So they walked away from it. So we took that core technology and we cut this deal with Westinghouse. And we said, Look, We will give you 15 percent of this new company. You let us take this technology base that we have. We will not take any of the existing products, Westinghouse will retain the PUMA and all the existing products, but We will go do something new and We will get it funded. But we want to take the people, we want to have a license to certain bits of technology and particularly this motor and some other stuff, and We will go off and do our own thing. And if you guys are interested in it, maybe you can sell it or distribute it at some point. So we funded this thing with venture capital and went out and hired a few more people. But we started Adept with 27 engineers, 27 people, most of whom were engineers, and a facility and some ideas. And we went out to develop a direct-drive assembly robot, which we did in about 14 months and introduced it about a year, year and a half later. And it was a really popular product. Our first year of sales we went from zero to $14 million in revenue, which was much faster even than we had grown the PUMA product line with Unimation. And the Adept 1, as it was called, was bought by companies all over the world. It was very reliable. Some of the machines that we developed and delivered in 1984 are still running in factories today, many years later. And it was very well received and very well recognized. And so Adept over the next few years grew to sales of over $100 million. And we developed other products. We continued to develop. We believed then and as we believe now that much of the key differentiating technology for robots is the sophistication, power, and ease of use of the control system, the language in the controller. We invested quite a bit of money in integrating machine vision with motion control. And so Adept was one of the very early in fact, We had done that even at Unimation. This early robot here back in the Unimation days was actually a vision-guided demonstration. This had a camera and it was as six-axis robot with machine vision back in 1981, which was years before any of the other robot companies were really doing anything with integrating machine vision. And so Adept, when we introduced the Adept 1, we introduced it along with a machine vision system at the same time. And Adept over the years and even today probably sells half its robots with machine vision. And we developed a number of technologies, some things called flexible part feeders which would allow you to just take a bag of jumbled parts and drop them kind of this vibrating conveyor which would spread them out under a camera, and then the robot could pick them up once they were separated. And that made it much easier to do small part assembly, because one of the big challenges was how do you get the parts out of this bag of parts? So we did work in robotics, we did work in vision, we did work in part feeding, we did work in making all of that easier to visualize and to program. In 1996, I bought a company called SILMA. And SILMA was another Stanford spinoff. One of the founders was a gentleman named John Craig, who was another one of Bernie Roth's students. And they had concentrated on developing offline three-dimensional simulation and robot programming technology. So they could program spot welding machines and they could program coordinate measuring machines and they could program assembly robots. And you could develop all the software in the soft line environment and you could visualize it and move CAD models around and debug it and get the geometry sorted out and then download that program to your spot welding line or whatever you had. Well, I had believed for some time, and still believe that as we go forward in robotics, we need to integrate the ability to model and reason about geometry with the robot control system. And so I acquired SILMA so that we would start to get that technology within Adept. And SILMA was about a five or $6 million business then at the time. And we started then to integrate some of the SILMA technology with some of the Adept robotics technology. And so we could do I do not know if it is on here. Let me see if I have the next slide here. Yeah. So we could do things like this, where you could simulate an entire production line and you could simulate the robots at each of their stations and you could predict how quickly they could do a particular task. And then you could do line balancing along the line so that if workstation 1 took five seconds and workstation 2 took three seconds, you could move some things around and try to balance the cycle time for each of the workstations so that you would improve your throughput. And typically when you did that with the simulation tools you would improve the throughput of the entire assembly line by 30 percent or more. And when you are spending maybe half a million dollars or a million dollars on an assembly line, getting 30 percent more productivity out of it was a big deal. We also developed technology to reason about the geometric stability of parts. If you dumped a bunch of parts onto a flat surface, what percentage of the time would they lie in these various stable states? And based on that, you could predict what the throughput of these flexible part feeders would be, how many parts per minute you could feed. And so we had some very sophisticated mathematics and reasoning that we were starting to build into the systems in the late 1990s and sort of early 2000 timeframe. And it was my intent to integrate the offline geometric modeling and reasoning capability with the online control systems. Because what you ultimately would like to have is you would like to be able to have a robot roll into a room and use its vision scanners and laser range scanners to make up a model of the room and know whether it can reach under the table or over the table but it can not go through the table. And so if it does not have a model already, you would like to be able to create a model. you would like to be able to reason about that model. you would like to be able to update that model with sensory information. And That is kind of what people do and what higher level reasoning entities do. So that was kind of the rationale. And we never completed the integration of SILMA. We did a lot of work there, but the products were still sort of a separate simulation and separate motion control system by the time we left and started Precise. But that was the vision."
"Brian Carlisle","Interviewer","Who was working on the vision systems during that time?"
"Brian Carlisle","Interviewee","Well, if we go back to kind of the original Unimation days, there was vision work that had started at Stanford also. It had migrated over to SRI, Stanford Research Institute. There was a gentleman over there named Bob Bowles who was well known in the vision community. He had done a lot of work, along with a couple of other people over there sort of commercializing some of the research that had been done at Stanford. And then we licensed some of the SRI technology at Unimation in the late, well, probably would have been in the early 1980s, about the 1980 timeframe. And we hired a Ph.D. named Scott Roth from Cal Tech. And Scott worked with Bruce Shimano and essentially did our commercial version of that vision technology. And we developed patents for various things. And so he was kind of the leader both early on at Unimation and then subsequently at Adept in developing a lot of the early vision technology for us. "
"Brian Carlisle","Interviewer","What was it like working with Bruce and starting up that company, and Vic?"
"Brian Carlisle","Interviewee","Well the three of us are all very different personalities. Have you met Vic Scheinman?"
"Brian Carlisle","Interviewer","Tomorrow."
"Brian Carlisle","Interviewee","Tomorrow. Well, you will get Vic's take on it all. Vic's a very high energy guy with lots of ideas and a rather short attention span. And so he was great at generating ideas. he is very bright and he is very capable. But in terms of the back end of things, of really turning something into a commercial product, he kind of loses interest fairly quickly. And in some sense, That is why he hired me originally in the early days of Vicarm was to kind of make things into real products and supportable products and that. Bruce is a very, very bright guy. he is very methodical, he is very thorough. he is extremely detail oriented and never forgets anything. And his real love is software and mathematics and so he is a real programmer. And I am sort of somewhere in between. I have lots of ideas, but I can also kind of work details and get through the process and get to the back end. And so I would say our relationship with Victor was when it was Vicarm it was Vic's company and he was coming up with a lot of ideas and Bruce and I were doing some of the execution. When it was our company, and I actually took over Vic Scheinman was the original concept guy on the PUMA robot because Unimation had bought Vicarm and the PUMA was a derivative of some of Victor's work. After a couple of years though at Unimation, even Unimation was kind of too big a company for Victor. So Victor quit and went off to do something else, working with another company called Automatix, where he went and did some other new things. And so I was running kind of then the research group there for Unimation. And then when Bruce and I started our own company, obviously all the ideas were essentially our ideas at that time. Bruce and I have a very good working relationship. we have worked together for, I do not know, more than 30 years. And I have lots of ideas. Bruce is very calm and he is sort of a low-pass filter. So if I can convince Bruce that one of my ideas is a reasonable idea, then usually it has some So we work quite well. We kind of complement each other personality-wise. He has always preferred to live in Southern California. He was born down there, his family is down there. And They are Japanese-American, they were very close to their families, they like to spend weekends together with families and that. And I have always hated Southern California and I have always preferred to live in Northern California. I can not imagine why anybody would ever want to live in Southern California. So I have liked the mountains and skiing, and so I have lived in the Bay Area. Now I am up here in the Auburn, sort of near Lake Tahoe, Squaw Valley Area. But having said that, we have worked together quite well for many, many years and continue to have a very close relationship. "
"Brian Carlisle","Interviewer","How were you able to coordinate over that distance?"
"Brian Carlisle","Interviewee","Well, starting in the mid-1970s, that was also kind of the birth of the ARPANET, which sort of morphed into the Internet. And so we have always just done lots of telecommunications and emails and phone calls and web conferences and all of that. And also, logistically, the work that we were doing was fairly well segmented. Bruce was doing programming and running a software group down in LA. And when I was running Unimation or subsequently running Adept or now running Precise, I was running more the hardware stuff. But the software stuff, you can kind of split off. So the software guys were kind of locked in an office and every week or two We had slide a pizza under the door kind of thing. We tried to isolate them from distractions, from customers dropping in, from sales guys saying, Can you do this? Can you do that? And as a result, they were able to be very, very productive and they had a quiet sort of fairly intense working environment. But Bruce enjoyed that and That is the way he liked to work. And the people that he hired to work with him also were those types of people. And so they have always worked very independently and it is worked quite well. Now there are periods when you are doing a robot where you have to do integration, where you have to bring software and hardware and mechanical stuff together. And when you do that, then people have to travel and we all get together in one place and try to make the robot work. But a lot of the development can be done independently."
"Brian Carlisle","Interviewer","Where were the production facilities? Where did you actually build the robots?"
"Brian Carlisle","Interviewee","Well, in the Unimation days, they were in Connecticut. In the Adept days, they were in originally San Jose and then later Livermore, but in the Bay Area. We had about 100,000 square foot facility there in San Jose. And then we expanded even beyond that in sort of the 2000 timeframe. And then subsequently, Adept was contracted about the time we left, that was part of the reason we did leave, which We will get to. So it is probably about half that size now, maybe 40 or 50,000 square feet, something like that. What we are doing with this company is we are now doing production at a company that is a friend of mine down in Los Angeles again, so the production is actually done down near Anaheim. Were you at Chad? Did you interview Bruce at Chad?"
"Brian Carlisle","Interviewer","Yeah, I was at Chad."
"Brian Carlisle","Interviewee","So you saw Chad, yeah. Chad's where we are doing our manufacturing right now."
"Brian Carlisle","Interviewer","Can you talk a little bit about Precise Automation and how it came together?"
"Brian Carlisle","Interviewee","Yeah. So We had grown Adept by sort of the late 1990s to about $100 million or so in revenue. We had $25 million in cash, we were profitable. So the company was pretty successful and we had gone public in 1996. And so we were sitting around at the board level talking about well, we have grown up to this point, how do we grow this thing to the next 100 to $200 million? And so we started or contracted or assigned three marketing people to look at three new markets. One was a semiconductor robot market, the second was the photonics, fiber optics market. And the third was the life sciences and kind of genomics market. Each of those markets was developing for robotics. And so we spent about a year or so doing these market studies in each of those new markets. And at the end of the day, we decided that we could not do three new markets. They all looked interesting, but now we selected semiconductor and we selected photonics as two that were close to home. Semiconductor, we were in the middle of Silicon Valley and so we had lots of semiconductor companies there. And photonics was exploding. At that time, JDS Uniphase, which also was a big presence in Silicon Valley, thousands of employees, had grown from 2,000 employees to 24,000 employees in just a few years. And everybody was wiring fiber all over the place and putting these fiber optic transceivers which convert electrical signals to optical signals under water and all kinds of places. And so it appeared that semiconductor and photonics would both be very interesting growth markets for us. And we went out and we did a couple of acquisitions to help us address those markets. And semiconductor, between sort of 1999 and then sort of 2000, we grew a business from basically zero to $20 million. So we had a quite a nice business that developed there. In photonics, we got a very big program with JDS Uniphase, and we were doing $2 million work sales for them and they told us they were going to need hundreds of these things and that we really had to expand our manufacturing facility to be able to meet their needs, and how were possibly going to ramp up and scale up and so forth. And we had taken their first-pass yields on these little fiber optic transceivers, which required that you align an optical fiber with a laser diode to a tolerance of a few microns and then fasten them in place. And We had figured out how to do that. Their first-pass yields had been about 30 percent for this product and they were selling it for thousands of dollars, in some cases $10,000 and throwing 70 percent of them away. And so we were able to take their first-pass yields up to 97, 98 percent with automation. So they were delighted about that and were just going crazy with this forecast. They even invested $25 million in Adept to support that whole development program. So in sort of the 1999, early 2000 timeframe, it looked like Adept was probably going to grow from 100 million to 200 million in the next five or ten years. So we went over and we leased a big new facility over in Livermore. We roughly doubled our space from about 100,000 square feet to about 200,000 square feet. And we did some acquisitions and we were scaling up. And then in 2000, sort of the whole economy, at least the electronics economy, marched off a cliff. We had this whole Y2K thing, and so everybody who needed to buy a computer bought a computer in 1999 and they did not need to buy any more computers in 2000. And so the computer market tanked. The semiconductor market as a consequence tanked. The disk drive market as a consequence tanked. The photonics market, as soon as the long-haul fiber was built out, that had been way over built and way over extended, and all the telecom communications companies tanked, so you had companies like Northern Telecom that almost went bankrupt, Lucent, that was sort of sold off, Alcatel, which had huge problems. I mean, these big worldwide 50, 60, $70 billion companies just cratered. And JDS Uniphase went from 24,000 employees back down to about 2,000 employees over the next three or four years. So they absolutely stopped building any new product and cut off their business. So at Adept we saw our orders, our revenue, drop from 120 million down to something like less than half that, about 50 million, in a period of about 18 months. And we had just gone out and leased, signed a ten-year lease on this great big new facility, expensive facility, and the whole business vanished on us. So that was extremely painful. We essentially spent the three years between 2000 and 2003 downsizing the company. And we had multiple layoffs and we had to close sales offices all over the world. it is very difficult to lay people off in Europe, in France and Germany. It takes a year or more to let somebody go. And obviously, it is very difficult emotionally to take all these people that you have hired and they have grown with you and you have known for, in some cases, 20 years or more and tell them that they just can not work with you anymore. So as well as, of course, we were a public company. So we had tremendous pressure from investors and the board of directors. We were losing a lot of money and so forth. So we spent three years sort of going through huge write downs and layoffs and downsizing the company, which we finally sort of accomplished by the middle of 2003. And we never ran out of money, which was good. But our cash was getting low. So at the end, sort the middle of 2003, we went out to raise some additional working capital for the company. And at that time, we had a reasonable story to tell. We had stopped burning cash, the orders were starting to improve a bit again. So the company was stable and not hemorrhaging. And so I went out and raised $10 million with a venture fund called Special Situations Fund in New York. So they put a person on the board and they said, Gee, we are going to put our money in, but we really want to have somebody else come in and run this company because it is been so bad for the last three years that somebody else must be able to do better. So the board hired a new CEO who came in. And about three weeks after he arrived, he decided, Well, I really have no interest in trying to work with a couple of founders here. So he just fired Bruce Shimano and I, just walked in one morning and fired us with no warning. And actually well, we will not go much further there. So Bruce and I were out. And this new fellow had his opportunity to run the company. He was fired five years later. But he did last four or five years, but finally the board got tired of him. So our only sort of solace, I suppose, is that he certainly did not do any better than we had done over the previous 15 or 20 years. "
"Brian Carlisle","Interviewer","Who was he? What was his background?"
"Brian Carlisle","Interviewee","He had worked in the automation industry but in a very different industry, in the paper industry. So he'd done paper mill automation. And he did not really understand robotics, he did not understand the market, he did not understand the technology. And he did not understand the rationale and history for why we had the products we had. And he was not a big listener. He was one of these fellows who was going to come in and do it his way. And so a lot of the very, very senior people left within six months to a year after he arrived. He really kind of decimated the company. But That is kind of what happens, or not always happens, but sometimes happens. Boards, when the business is bad have an obligation to the shareholders to go do something. And the one thing they can go do is they can go change the CEO. And so That is what the board did. And certainly it can be argued whether it was the right decision or not, but nonetheless, That is what they decided to go do. So Bruce and I then went out and started a new company, this company that we are currently running, called Precise Automation. And we decided this time that we were not going to give up voting control of the company to an outside board of directors. So we raised quite a bit less money this time around. I funded part of it and we have some outside investors and we have a couple of corporate investors. And so we have grown this company more slowly. But we have also done what we hope will be kind of the next generation of control systems and robotic technology. And that now is starting to get out into the marketplace. So this company is now starting to grow. We will grow 100 percent this year and probably 100 percent next year. we are still small. we are sort of at the $4 million revenue range right now. But we should be doing six or eight next year, and We will get up into the bigger numbers at some point. But this time, we will do it in a manner that does not require us to give up control of the business. I still believe that robotics will continue to be that the technology will continue to address many different areas. That it will get out of the factory, as it is starting to do, into service areas. There are already some nice models for surgical robots, which it can be argued whether They are robots or master-slave tele-manipulators, but certainly a couple, at least one company, has done very well in that area. There are good examples of some military, hazardous environment sorts of things, robots going into caves and looking for mines. And there are some toys and things like that now that are starting to come out with some of the technology, kind of low-end technology. And if you think about it in sort of its most general sense, people have lots of definitions for robots, but my definition is essentially an autonomous thinking machine that can sense and interact on its environment, interact with its environment. Computers have essentially been these disembodied boxes that we kept in a closet for the last 30, 40 years. And a robot is in some sense a computer that has some sensing, whether it is vision or a sense of touch, and the ability to act on the environment, whether it is just rolling around with wheels or flying a plane or running a cruise missile or doing surgery, That is sort of a very broad definition. And the types of technology that we have developed and will continue to develop can serve, if you take that broad definition, many, many different applications. And so I think as this company gets a bit more mature, we will have a lot of opportunities to spin this technology into several different directions."
"Brian Carlisle","Interviewer","Do you think that the fact that robots are embodied also in a sense limits their ability to be general purpose like computers are?"
"Brian Carlisle","Interviewee","Yeah. I mean, in some sense. Obviously a human is an extremely flexible mechanism. But even humans pick up tools to do a lot of things. So we adapt the human body, whether we jump in an automobile or pick up a screwdriver, by adding various tools and so forth. And certainly, you are not going to have a general purpose robot That is going to be more flexible or even as flexible as a human any time soon. But you will have robotic technology that can be packaged into, whether it is a sentry That is rolling around or a drone That is flying around, the sensing technology, whether it is machine vision or terrain mapping or actuation, coordinating multiple actuators to move in a coordinate system, that core technology base can be packaged in different kinds of mechanical packages to address a lot of different applications."
"Brian Carlisle","Interviewer","And what are the main applications you focus on at Precise?"
"Brian Carlisle","Interviewee","Well, at Precise, we decided we needed to build a business that was not terribly risky in the sense that we did not want to spend 10 years doing R and D and have to raise tens of millions of dollars to go something dramatically new. And so we started by sort of packaging the technology and we are focusing on a couple of markets, one of which is life sciences. So we are doing robots for life science applications. That is a market that requires some sensing, it requires a lot of material handling, it requires motion control. There are both some dedicated machines where we are selling controllers into that market and then we are also making some various mechanisms that go into that market. And it is also one That is growing quite quickly. With the focus on healthcare in the United States, we are doing more and more personalized medicine. There are companies out there trying to figure out how They are going to run a million drugs past your particular cancer and see which one actually does something That is effective, as opposed to hitting you with these broad chemo blasts that destroy your entire body. there is a lot of genomic work going on. So there is a lot of R and D work going on in life sciences, and then there is also a lot of processing of just samples, biological samples, whether They are blood or urine or whatever. And all That is got to be handled and processed and so forth. it is a market, it is going to be a growing market, there will be derivatives and spinoffs of that market. And it is not going to go to China, it is not going to go to Singapore or go overseas, it is going to stay here in the United States. So That is really where we are spending a fair bit of our time. we are doing a little bit of work with the semiconductor industry where we are selling controls to people that are building semiconductor robots. A lot of that is in Korea right now, a lot of that is in Asia because most of that market is overseas now. And we are doing a little bit of work in disk drive and most of those products are going to Singapore, are again going overseas. But I would say over half our business right now is in this life sciences area."
"Brian Carlisle","Interviewer","That was the one that you ended up not doing out of the three."
"Brian Carlisle","Interviewee","Yes, That is right. Yeah, it looked good 10 years ago and it still looks good. But we did not know anything about it then. And I can not say we know a great deal about it now, but we know more about it now than we did then. And it is also matured a bit and developed a bit over that period of time."
"Brian Carlisle","Interviewer","You obviously have had a lot of very successful technologies that you developed. Were there any paths that you took that were unsuccessful and that you thought would be interesting but just did not work out for certain reasons?"
"Brian Carlisle","Interviewee","Well, yeah. I mean, you do not always hit home runs. And you hopefully learn as you go along. We had one product at Adept which was a real boat anchor, it was called the Adept 2. But we decided we were going to take these big direct-drive motors and make a very small robot with this that would go really, really fast because it would have these giant motors on it. But it turned out that it was just too big and too expensive and too heavy and we should have built something much smaller. So we probably spent a year developing that thing and it never went anywhere. And that was also a case of not doing a very good job of listening to our customers and our market. Earlier, at Unimation, we had high hopes for mobile robots. And we developed a platform that had these omni-directional wheels on it back in, I do not know, probably 1980, 1981 timeframe. So it has these three wheels and it could move in any direction. And we put a robot on top of that, and it had portable battery power and it could go recharge itself. And we had infrared sensors on it and it could navigate around, and it could move around a factory. And the idea was that it could go service intermittently process stations that needed to be loaded and unloaded every few minutes, but then that you could move the robot around. And we thought that would be quite interesting for the semiconductor industry. And we had talks with TI and other semiconductor companies about it. And they said, Yeah, gee, that is interesting. But it was not interesting enough that they really wanted to buy it. And so we put probably a few years of research into that and made some nice videos about it. But it was probably 30 years too early. There just was not a real viable commercial market for it yet. And today, there are lots of automated vehicles moving both overhead and to some extent on the floor of semiconductor factories. But as the semiconductor ultimately evolved, most of the transportation is done on overhead rails to keep from cluttering up the floors. And a lot of the floors also are these clean room floors, and it is hard to put heavy loads on them sometimes. "
"Brian Carlisle","Interviewer","So you mentioned that with Adept 2 that you were not listening to your market."
"Brian Carlisle","Interviewee","Right."
"Brian Carlisle","Interviewer","How do you usually integrate the voice of the market into your work?"
"Brian Carlisle","Interviewee","Well, it is always kind of a fine line. Because if you just ask the market what they want, they will tell you sort of what they wanted yesterday. And if nobody is making that, that is an opportunity, you can go do it. But usually, you try to shoot a few years ahead because it is going to take you a few years ahead to do something. And then secondly, you would like to, when you introduce something, have something that not 10 other guys are doing exactly the same thing. So most of these activities involve some balance between trying to forecast what is going to be a successful product in a couple of years and doing enough homework that it actually is when you get it out there. We knew for the Adept 2 that for small part assembly that people wanted to go real fast. And they wanted to get higher throughput and do sub-one-second cycle times and things like that. We thought that they would not mind a great big old footprint that was at that time about 14 inches in diameter for moving around these little tiny parts. But that we sort of blew it on. And some people, if you listen to what people like Steve Jobs will say, they say, Well, I envision the future and we go create the future. And if you are really, really good and if you time things correctly, you can do that. But even companies like Apple, they had the Newton, which was, if you remember, was probably 25 years ahead of its time and it was a horrible flop, but seemed like a good idea at the time. And so have to wait for the market to come around. I have believed for many years in using machine vision to do what we call flexible part feeding. And I flogged that for probably 15 years at Adept and it is starting finally now to gain more and broader we are doing at Precise. But there are some companies out there, and vision-based part feeders are becoming common now, much more accepted. So sometimes market to come around. "
"Bruce Shimano","Interviewer","So, we can just start by having you tell us your name, where you were born, and where you grew up."
"Bruce Shimano","Interviewee","Yeah, I am Bruce Shimano. I was born in Los Angeles, California, grew up there. And I attended Stanford University for both my undergraduate and graduate degrees. "
"Bruce Shimano","Interviewer","Okay. What did you study as an undergraduate?"
"Bruce Shimano","Interviewee","I was in the Mechanical Engineering Department as an undergraduate. I was lucky enough that very shortly after getting to Stanford, probably in my sophomore year, I switched to Engineering, and was in Mechanical Engineering. Was randomly assigned to Bernard Roth, as my professor. And he, in fact, was then my advisor, through three years of undergraduate work; and then, my Master's work, and my Ph.D."
"Bruce Shimano","Interviewer","What did you work on initially, for your Master's degree?"
"Bruce Shimano","Interviewee","I did work in computer graphics. And, so I was at Stanford for five years, getting my Bachelor's and my Master's, concurrently. And then, I went away for two years. And after that, I called up Bernie Roth, my advisor, again, and asked him what the options were. And he said, Well, you can come back here, and work on your Ph.D. in Mechanical Engineering. And That is what I did. And he said that he would get me a summer job at the Stanford Artificial Intelligence Center. And he knew people there, and he then got me assigned, got me a job as a research assistant at SAIL, and I was lucky enough to have as my boss there Richard . And so, I went into the Robotics Group. So, I started in robotics, then, when I started my Ph.D."
"Bruce Shimano","Interviewer","So, your undergraduate and Master's were in Mechanical Engineering?"
"Bruce Shimano","Interviewee","Both my Bachelor's, Master's, Ph.D. were all in the Mechanical Engineering Department. At that time, there was no such thing as a Robotics degree. People were either in computers a lot of them were in Computer Science. Some people were in Mechanical Engineering, because of Bernie Roth. A few people, perhaps, in Aero and Astro, because of the controls aspect; but, primarily it was since there was no official curriculum, at that point in fact, there were no Robotics textbooks at that point. So, all the work was really done just as a research assistant at the Stanford Artificial Intelligence Lab. And they had a group which was called the Stanford Hand-Eye Group. And, at that time, it was working on the development of the initial electric robots, and programming languages, and controls and such."
"Bruce Shimano","Interviewer","So, what year did you join SAIL?"
"Bruce Shimano","Interviewee","I was at SAIL from 1974 to 1978 or 199, so about four or five years."
"Bruce Shimano","Interviewer","And, prior to that, did you have an interest in robotics, or was it really the opportunity to work in the robotics lab that started you off?"
"Bruce Shimano","Interviewee","I was always interested in Programming and Computer Science; but I was also interested in Mechanical Engineering. And, actually, at that time, Stanford did not have an undergraduate degree in Computer Science, either. So, as an undergraduate, really, the choices were I went to Stanford in 1967: was there from 1967 to 1972, to get my Master's and Bachelor's. So, at that time, your choices were to, as an undergraduate, were to be in Engineering: either Mechanical, Electrical, or one of the natural sciences Physics, or you could be in Math. But, if you wanted to be and, a lot of the people in Computer Science, I think, had some relationship to the Math Department, as well. But, there was no undergraduate Computer Science degree, there was no undergraduate Computer Science Department, and there was no robotics, whatsoever. So, as an undergraduate, then, I was in Mechanical Engineering, which I enjoyed; although, I have never really been a hardcore mechanical engineer. So, as an undergraduate, I enjoyed the engineering, and I was just lucky enough that I was assigned to Bernard Roth, who happened to be the person in Mechanical Engineering who did the most work in Computer Science and Programming, analytical types of things. Although, his primary background is a kinematician, he was also the person in the Mechanical Engineering Department who had the most relationship with computers. And, so, I did a Computer Graphics Master's with him as my advisor, because there was a Computer Graphics group, also."
"Bruce Shimano","Interviewer","Who else was in the Robotics Group that you worked with when you first came there?"
"Bruce Shimano","Interviewee","In 1974, when I went back to Stanford, then, to go to the Artificial Intelligence Lab, there were a number of people in the Hand-Eye Group Richard was my advisor, and my boss and I worked with Lou for many years. And, Lou was a great guy, and he really did a lot of the foundational programming, robot-programming language work. Bernie Roth, who was my advisor: he advised generations of robotics people. Don Piper was one of his students, and Don Piper wrote a sort of a breakthrough Ph.D., which applied kinematics and kinematics series to robots. Don Piper, working for Bernie Roth, is really the guy who established homogeneous transformations, and , and all that sort of stuff. That was all out of Bernie Roth and Don Piper's work. Don Piper left before I got there, but he sort of set a lot of the mathematical foundations for robotics. did a lot of the controls and language work, and I did work with Lou. Victor Scheinman, who was my officemate is the fellow who designed all the mechanical systems and some of the control systems for Stanford, and for MIT. And, so Victor's really the guy who laid all the groundwork for small, electric robots there. There were, at that time, industrial companies like Cincinnati Milacron, who were doing these very large, electric robots for spot-welding. But, Victor's really the guy who developed the small electric robots that would then become the assembly robots in the future. So, Victor Scheinman was my officemate. Tom was more of a vision guy, and he led a portion of the Hand-Eye Group. And Ray was another officemate of mine. But Ray was mainly interested in kind of language, and not robotics, per se, so he went on to other things. let us see; I am trying to think of who else. Bob did a lot of groundbreaking vision work for robotics, and Bob went on to SRI. I assume he is still at SRI; I have not talked to Bob for a while. But Bob did a lot of the great initial work in computer vision, as it applies to robotics. He developed a lot of the initial connectivity algorithms. So, Bob was at Stanford when I started there. And there were a number of people who went on to work at the IBM group, in Watson; and then, later on, were spun off as part of IBM's effort to to industrial robots."
"Bruce Shimano","Interviewer","When was that?"
"Bruce Shimano","Interviewee","IBM got started in robotics probably around 1980, or so. And, in 1980, there was a sort of boom rush of companies getting into robotics. At the time that Brian Carlisle and I started Adept Technology, after I got my Ph.D., and after I worked for Unimation, we started Adept Technology. When Adept Technology was founded in 1983, I believe that there were some 40 to 60 US robot companies. A number of them were in the heavy part of the industry, looking at sort of spot-welding applications, which was the application of the day, and is still the largest automotive application. So, at that time, you had companies like Unimation, which was the first robotics company; Cincinnati Milacron; so, there were companies of that sort that really specialized in the larger robots that were doing spot-welding applications. In the early 1980s, there were a number of companies then that entered into the smaller robotics: the assembly markets, and such. IBM was one of them. Westinghouse kind of dabbled in everything; GE. So, there were the large companies, and then there were a lot of start-up companies: Automatix, which Victor Scheinman founded, with a number of other people, like Phil Villers. There were small companies, like American Robotics, Intellidex. So, there was just a wrath of everybody and his uncle in the United States, in the early 1980s, decided to get into robotics, IBM being one of them."
"Bruce Shimano","Interviewer","Do you think there was a reason for the interest at that time, something specific?"
"Bruce Shimano","Interviewee","Yeah, I think that Unimation, who was the first industrial robot company: they struggled for years and years to find a good application, and to make money. In the 1970s, finally, there was good acceptance of the large robots for spot-welding. And, today, all spot-welding is done robotically. But, prior to that, people went out there with these big spot-welding guns, and they welded cars together. But, after working for probably 10 or 15 years, Unimation finally had a beach head in automotive and spot-welding, and it is one of those things that you go from having no one believe you, 'til, years later on, it is just the accepted way to do it. So, in the 1970s, robotics became the accepted way to spot-weld cars. And, you know, automotive was a huge business, still is. And suddenly, there were all these robots being used for spot-welding. So, people then accepted that, gee, these so-called industrial robots: they could really do something. At that time, the things that they did were very simple; they were all teach-and-repeat. You just taught them a fixed pattern, and they did it. In fact, the early industrial robots, like the Unimate, did not even have computers in them. They had what was called plated-wire memory, and it was just this, literally, hard-core memory that just played back this repetition of points, and had all this logic; no computers to speak of. That then just took these positions in memory, and just regurgitated them in a fixed pattern. So, you could, for a spot-welding application, you might teach 50 positions, and the robot would just go: position one, position two; never change anything. It would just go boom, boom, boom, boom. And there would be signals coming in that would tell it, you know, next car was there. And it would just start, and it would just go boom, boom, boom; and it would fire off the spot-welding gun. And the spot-welding gun: what it did is it had fingers that clamped metal together, and it could squeeze the metal. And once the metal was compressed, then it put an electric current through that. And then, that welded the two pieces of metal. So, the car bodies were all done that way. So, there was, in the 1970s, finally, an acceptance that these things, which, at that time, were called industrial robots, but which were really dumb, actually could do something. And, in fact, they could do something better than a person could, because they were very repeatable. The cars in a car, you would have hundreds of spot-welds; I do not think it was thousands, but you would have hundreds of spot-welds. Around every door, you would have sheet metal, and you would have to spot-weld that thing maybe 20 or 30 times. So, all the various car pieces you were spot-welding together. And robots were very good at that. So, after that time, then, in the late 1970s, we started to look at assembly. And suddenly, people thought, Oh, these robots are pretty good. And there were some other applications: there was spray-painting, which was popular then, too. But spray-painting was kind of an extension of spot-welding. It was, again, dumb robots that were just kind of doing this very fixed pattern. So, there were spray-painting companies, and there are arc-welding companies. And, in the late 1970s, then, there was a lot of interest in assembly and small-parts assembly. And, so That is when a lot of companies got involved. To do a spot-welding robot, they were very expensive robots for the time. They were very big, and you needed a fairly big manufacturing operation to go do that. Once you started talking about electric robots and small robots, then it was a lot easier to break into the market. And there were, at that time, then, the Japanese started coming on board. And the Japanese were prepared to license things. So, for instance, IBM did have their I think they might have had one mechanical robot of their own. But, primarily, IBM was in the business to sell computers. So, they bought Japanese mechanical systems. And they married them with IBM robots. So, IBM just thought of this as a good application to sell computers. And they thought they had all this computer technology. But there were lots of other companies, too. And everyone just felt that robotics was going to be a big deal, and had these companies like Westinghouse and GE that had always been dabbling in automation. They thought that this was the next big beach head. So, there was this huge boom of companies that got into the market. It was probably helped somewhat by Automatix, the company that Victor Scheinman started. Victor actually started Vicron, that I worked at. So, Victor, Brian Carlisle, and myself were a part of a company for a few years. Then Victor left that, and went off and started Automatix. And I think Automatix probably helped the business, because they were never a huge financial success, in terms of profitability; but they were a real Wall Street darling, and so they were able to go out and get a lot of money very quickly. And they had a ridiculously high valuation. And they had a lot of business savvy. And people saw that, and they went, Whoa. Wall Street's interested in this. We can go get a lot of Wall Street money, too. So, there were just a lot of things that happened at that time."
"Bruce Shimano","Interviewer","And these companies that you were working with were looking at the same applications in automotive assembly, and painting and welding?"
"Bruce Shimano","Interviewee","Yeah. At that time, during the late 1960s well, in the 1960s, there were a few universities that were involved in robotics in the US. There were a lot of international places, as well. But when you talked about robotics in the 1960s, it was really a couple of companies: there was Unimation, who would been there since the late 1950s; Cincinnati Milacron, who was getting involved in stuff like I believe that ABB might have been there, although I am not sure. So, there were maybe a couple in Europe, perhaps. And then, in Japan, really, Japanese robots got started when Unimation licensed some of their technology to some of the companies in Japan. So, there were only a handful of companies in the 1960s, and really struggling. But there was a lot of robotics instruction going on in the universities. So, there were robotics conferences. And in the 1970s, there were lots of conferences. So, in the early 1970s, there were not very many more companies; but there was a lot of university research, and there was a fair amount of government grants at that time. ARPA was giving grants for robotics research, and various other places were giving robotics research grants, looking into both vision and the mechanical side, and the programming side. So, there was a lot of research interest at that time. In the US, it was primarily MIT, Carnegie Mellon, and Stanford. That was, I think, in the early 1970s, the primary hubs of where you have quite a few people. There were other places, as well. A little bit later on, Caltech and JPL had some people come out, and such. But, in the early 1970s, it was primarily that. But there were universities overseas, as well; there were people who dabbled in robotics in Europe much earlier than that, and some in Japan, as well. And it was in the late 1970s that there was this blossoming of industrial interest."
"Bruce Shimano","Interviewer","So, what was the first project you worked on when you got to SAIL? Do you remember that?"
"Bruce Shimano","Interviewee","Yeah. I worked on a language. Stanford was developing a language originally called HAL; but then, of course, there was a problem with 2001. So, we had to drop that, and there was this big fight about what the language should be called. So, finally, we just dropped the H, and it became AL, just because we could not figure out any better name. And Stanford has the Artificial Intelligence Lab has a long history of acronyms with no meaning, because at the Artificial Intelligence Lab, the programming language which was used there was SAIL. And people thought it was the Stanford Artificial Intelligence Language, but it never really was. And other documents referred to SAIL, and said that SAIL was really an acronym for a Suitable Acronym Invented Later. So, Stanford did not put much credence into what the acronym meant. So, I was assigned to work on AL. And AL was going to be the first high-powered industrial programming language. And I worked there for Lou Paul, who had done the predecessor language, which was called WAVE, W-A-V-E. and WAVE was a very simple system, but it really was a groundbreaking system in that it was all digital, it had trajectory generation, it had kinematics. It had a lot of good stuff in it. So, Lou Paul did WAVE, pretty much by himself, and that was his Ph.D. thesis. So, in the early 1960s, there was sort of the mathematical basis that was laid down by Piper and other people. There was some control work that was done at Stanford, then Lou Paul came along and did WAVE, and pulled it all together into a programming system. And then, when I got there in 1974, my job was to work on AL, which was to have all the feature of WAVE, in terms of robot control; but which was supposed to have a full-featured language on top, that you could program in and such. And AL was a very ambitious program, project for the time. And it integrated vision, it had robotic control, it could handle multiple robots. It had a very structured language in it, and it was a very formal language. And we had a group of probably, I think, six to eight of us, working on various aspects. And, at that time, the computers that drove all this stuff were all from Digital Equipment. And they were all PDP-10s, and such. And, so we would have a little we had a little table about the size of a regular office table that had a robot on it; and then, behind that, you had just this gigantic, air-conditioned room full of computers. And, at that time, the computers were sort of racks and racks and racks of stuff that you used. During the time that I was at Stanford, Digital Equipment came out with their PDP-11 series, which was a computer that could actually fit in one rack. So, we developed our language for that. And then, it was after that that the PC's, and everything else came along. So, computers at that time were actually much bigger than the robots were. So, my job was to work on the language. Victor Scheinman developed the mechanism and some of the controls. So, I was really following in the footsteps of Richard . "
"Bruce Shimano","Interviewer","So, what were the first robot applications that the software was used for?"
"Bruce Shimano","Interviewee","Oh, it was all simple assembly applications. But, also, at Stanford, we tended to emphasize vision-based applications. The group was actually called the Hand-Eye Group, within the Stanford Artificial Intelligence Lab. So, we had heavy emphasis on vision, right from the beginning. So, we were working on camera-to-robot calibrations, and things of that sort. So, we did applications like stacking little blocks, little children's wooden blocks. We would try to stack those up, using vision. you would throw the blocks down in front of the camera, or cameras, and you would identify the blocks. Then you would pick up the blocks, and try to stack 'em. That is kind of the degree of sophistication that we had at that time. Nowadays, you could do that no trouble. You could go out and you could get a system, and you would be able to do that in a short period of time. But at that time, that was a big deal. We were also working on control algorithms, trying to get the robots to actually perform better because it was nowadays, robots' controls are pretty well known. you are able to get very good, smooth control of things. At that time, everything was much more crude. And, so really, our projects were very simple projects that we were trying to do: block-stacking, doing peg-in-the-hole kinds of insertions, and really just trying to pull together a complete system. Because at that time, there were no computer-based robots out in industry. Later on, since Milacron would introduce one. But, as I mentioned, in the 1960s, all the industrial robots, they were a lot of them were hydraulic, not electric; and, all of them had very, very simple controls. So, our job was really to have robots that you could program, in a conventional, computer-programming sense; and, figuring out how to integrate that with the vision, getting them all to talk, and such. So, the applications were not so important as trying to figure out how to get everything to talk together. "
"Bruce Shimano","Interviewer","So, after you finished at Stanford, where did you go after that?"
"Bruce Shimano","Interviewee","Victor Scheinman, who did the MIT robot, the Stanford robot the mechanical design, the electrical design he was my officemate, and he had a deal with Stanford, where he would support the mechanical systems. But also, he was off, manufacturing, in sort of a garage, mechanical systems that he would then sell to research labs. Because, in the early 1970s, there were a number of research people who started getting interested in getting into robotics, but you could not take an industrial robot because they were these gigantic things. They were hydraulic, they did not have computers in them, they did not have interfaces with computers. So, Victor did a great job at developing an electric robot, tabletop electric robot, a lightweight, in a couple of different configurations. And he then sold it. He went, on sabbatical, to MIT, to go do the MIT, the Scheinman MIT arm. So, he developed a number of these mechanisms. And there were both universities, and also research facilities at companies that wanted to start to do some robotics research, but they did not want to spend the time to go develop their mechanical systems, which was a big task. So, Victor started a company called Vicron. So, Victor was simultaneously working at Stanford, at the Lab, and part-time; and also, part-time, still working on his degree, although not very much; and then, working on his company, Vicron. And, initially, Vicron was just selling mechanical robots, and other people had to figure out how to interface them. And then, he decided, well, he'd sell kind of an interfacing package for them. And, to some companies, to some research people, he even sold kits of parts, and they would put it together, themselves. And he sold such things to, like, GM they had a robotics research group. So, Victor sold a couple of his robots to GM, to GM's research center. And this was probably in 1976, I would guess, 1976, probably 1976, 1977. So, Vicron sold a couple of them to GM. And the GM guys and the lead people there were Mitch Ward and Luther Russell . Mitch came, and he told Victor, well, he was gonna buy a couple of robots, a couple of these mechanical robots, and he'd like to get the controls, also. But, the problem he had was that if there was no software with this thing, then he would take this back to his management and his management looked at this thing sitting on the desk. And for months they'd be saying, Well, when's it going to move? So, Mitch told Victor, You know, it'd really be helpful if you at least provided us with some test software so that when we got it, we could just plug it in and if we could just move it around a little bit, it would really take the heat off of us. And, you know, the management people would be much happier and then We had leave them alone and then he can do what he wanted to. So, Victor came to me and he said, gee, he really needed some test software to just move this thing around. It does not have to be very elegant, but, you know, he'd pay me some money and since Victor had this deal with the lab, then we talked to the lab and they did not mind me doing this on their computers. And so, then I worked part time while I was getting my Ph.D. for Victor. And so, I did this little test program to supply to General Motors. And, it got, you know, bigger and bigger and bigger and so finally, you know, General Motors said, Well, what is this software? And, you know, Victor said, Well, we got to give it a name. And so, Victor called that VAL because there was Hal at Stanford, which had became Al, which was A-L and so Victor just put a V in front of it, just like his company was Vicarm, which, you know, people did not know whether that was Vic's arm or what. So, Victor put a V in front it, in front of A-L and he says, Well, this is VAL. And so, we wrote a little manual. You know, it was like a four or five page manual. And so, we gave it to GM. Then, eventually, more people wanted that and, you know, I kept on working for Victor. And so, I was doing more and more part time programming for Victor and then eventually building the robots got to be too much for Victor. And so, Victor asked Bernie Roth, my advisor and Victor's advisor, was there anyone that he knew that he could get to help him out. And so, Bernie introduced Victor to Brian Carlisle and he hired Brian Carlisle then as his first full time employee. And so, Brian then started working on the robots and, you know, doing the mechanical design and the electrical design and Brian was actually better at electrical design, you know, had a better background than Victor. Victor is also the primo mechanical guy and a dabbler in electronics. Brian was a good at mechanics, but even stronger than Victor in electronics and I did the software; so it was the three of us. And so, That is what I did and so when I got my Ph.D. then Victor said, Well, you should keep on working for us. I said, well, I wanted to move to Los Angeles because That is where my family was and Victor and Brian said, Well, That is fine with us. We do not see you anyway. you are always at Stanford. You just modem over the software. So, if you want to live in Los Angeles That is fine. And just before I graduated, probably the year before I graduated, Victor sold Vicarm to Unimation and Unimation because the West Coast research division of Unimation. So, Victor and Brian worked for Unimation and when I quit, when I finished my Ph.D. then I worked for Unimation as well. In about 1979 or so, the group at General Motors who had purchased a couple of the Vicarm robots, General Motors decided that they really wanted to look at robotics for assembly, which no one, you know, had really done on a big scale. There were people like us at Stanford who were doing these little tinker toy kinds of assembly, but there was no one who had an electric robot who was actually in a factory doing assembly. So, General Motors put out a request for bid for an electric robot that they wanted to use in assembly and that robot was called the PUMA for Programmable Universal something or other. But, they had done a study; GM had done a study and they had arrived at the conclusion that the majority of parts that go into a car after you get it all welded together and everything, they were all small parts and they were, you know, five pounds or less and because They are all assembled by people now, they were all, you know, lightweight and were things that people could get to within an arm reach. And so, they spec'ed out this PUMA robot as something that could assemble parts five pounds or less and were within sort of an arm's reach. And since General Motors' research lab had purchased one of our robots, one of our Vicarm robots then they obviously had a lot of input into this and so a lot of the spec for kind of the things they wanted were, you know, pretty much what we had developed at Stanford at Vicarm. So, there was this RFQ and lots of people competed for this RFQ. This was a big deal and part of the reason Unimation purchased us was to go after this RFQ, and we won the RFQ. I mean there was, you know, Bendix and Unimation and Cincinnati Milacron; you know, lots of people bid on this thing. All the industrial companies at that time bid on it and we won and we won, you know, in part because they had been using our things for years. So, we got the project to build the PUMA robot, the first industrial all electric computer-driven assembly robot and over the next couple of years That is what we did. We developed the PUMA robot and we delivered the PUMA robot to General Motors. And the PUMA robot and its successors, you know, eventually got to be a big portion of Unimation's business. It grew to be about $30 million or $40 million business for them, you know, in a few years. So, it was a very successful project and General Motors was very happy with it and it really ushered in the computer, you know, true computer-driven assembly robot. There were industrial robots a long time. They were primarily hydraulic. There were electric robots that were introduced for spot welding. That eventually took over all spot welding. Nowadays, there are no hydraulic robots. They are all done by electric ones because the hydraulics, they always seeped a certain amount of fluid everywhere, so they were kind of messy. So, there were other people who developed electric robots. So, we were not really the first industrial electric robot, but we were the first industrial electric assembly robot. And then after that, you know, everyone tried to get into the game. "
"Bruce Shimano","Interviewer","Was it mostly just the development done by the three of you, or who else was on this "
"Bruce Shimano","Interviewee","So, it started out with the three of us and then Victor hired a machinist. By the time that we started on the PUMA project, I think our group was maybe ten people or so. So, That is Chuck Spaulding who is still at Dev Technology; Don Allan who is with us at Precise Automation. He did some of the mechanical design. Then we had a couple of other people who were more electronics people. So, I think that Victor, Brian, Chuck Spaulding and I, you know, we were really the robotics people. Dave Pap Rocki who is still at Adept, he was there too and then there were just, you know, a handful of other people who maybe specialized in amplifiers or digital boards and things of that sort. "
"Bruce Shimano","Interviewer","So, from the time you won the bid from GM until you delivered the prototype, how long did you spend developing?"
"Bruce Shimano","Interviewee","I think it was about 18 months until we delivered the first prototype and then it was probably another year before we went into production and then probably a couple of years after that before things got smoothed out. In fact, when you interview Brian Carlisle, he can probably tell you about that because we developed this, you know, PUMA robot with and the control was about, you know, that big. So, we developed this computer-based controller. It had a programming language and had a CRT that you had to type at. It had a little manual control pendant and we did that all in the West Coast and Unimation was in Connecticut, in Danbury. That was the headquarters. So, after we had the prototypes then, you know, we were really a small group. We were not going to be a production group. So, after the prototypes, we had to take this back to Danbury and have Danbury start to manufacture it and Brian did that, Brian Carlisle did. When Brian went back to Danbury, and this was in 1979-1980 or so; when he went to Danbury, they did not even have an oscilloscope and they put him in one of the they had no space for him, so they put him in one of the test bays for the hydraulic robots because these hydraulic robots, they were pretty big. And so, the test bay for a hydraulic robot is about a single car garage kind of size. So, they put Brian in this test bay, set him up and he said, Well, you know, I need a scope. They said, Well, we do not have a scope. So, he had to go out and buy a scope. And at that time, they did not have a computer, you know, in the company and they were about to get their first computer. So, you know, everything was still ledgers and paper and pencil. And so, they did not even have a computer in the building. And so, you know, That is what Brian dropped into and then we had to transfer our technology to them, you know, people who had never seen a scope and who never touched a computer. So, that was and Unimation was, you know, one of the better companies and so that was a real rude awakening and it took a lot of time for Unimation to come up to speed and understand that. They went out and they hired some good people to take all this stuff over from us and, you know, they did a good job, but it was a real cultural shift for them. There was a lot naysayers and people who did not support us back in the corporate headquarters because there were people there who, frankly, did not even think that electric robots were a good idea. They said hydraulic robots are really the way to go, and there are you know, there is some reason for them to think that because hydraulic robots are very efficient in terms of energy. So, They are very efficient, but no matter what you did to them, you just could not get them to stop leaking oil, hydraulic fluid. And their servos were very hard to control and such and they were expensive too because they had these very expensive valves. Hydraulics at that time were mostly things that people had these sort of bang-bang controls that you just opened up a hydraulic valve and the hydraulic fluid rushed in and, you know, some big plow or something would do something. To really do robotics with hydraulics, you had to have these very expensive aerospace valves to control them. So, it was expensive to do it, but there were still people at Unimation who thought that hydraulics were the way to go and they resisted electrics for the longest time. And if it had not been for GM insisting on an electric robot, you know, Unimation would have gone down with hydraulics, you know, forever. So, it was a big shift."
"Bruce Shimano","Interviewer","That is fantastic. I can not think of the next question; too many questions to ask."
"Bruce Shimano","Interviewee","Well, I can tell you about the 1980s. How about the 1980s?"
"Bruce Shimano","Interviewer","How about the 1980s and what would have been the first year that GM was actually using a PUMA to manufacture cars?"
"Bruce Shimano","Interviewee","You know, I do not know for sure, but I would guess they probably started using them around you know, prototype probably about 1980, 1981 at the latest and so That is when they started, you know, putting them into the factories. And then, of course, we did a small five kilogram one and then there was sort of a larger one and a larger one that came along and Unimation did those. After we got the well, actually, sort of concurrent with doing the PUMA, we were still all, you know, very much fanatics about machine vision with our background at Stanford. And so, even though GM was not interested to begin with, you know, we did the first vision integration with industrial robots, showing an industrial robot working with vision. Now, I think that was at we did our first demo of that at Robots 9 or something like that in Washington. I believe that was around 1978 or 1979 we did the first one."
"Bruce Shimano","Interviewer","That was at an annual robotics conference?"
"Bruce Shimano","Interviewee","Yeah, yeah."
"Bruce Shimano","Interviewer","And who sponsored that, or how was that organized?"
"Bruce Shimano","Interviewee","It was RA and also there was the International Robotics Group. So, that was a big industrial robot show. And so, you know, we were always, you know, very enthusiastic about computer vision. And so, we did, you know, the first integration of the computer vision systems that were coming along at that time. There were people out of SRI did the first sort of practical vision that you could use with the robot. They did blob analysis and connectivity. Before that, you know, people were just sort of flaying around, trying to figure out how to identify objects and SRI came up with blob analysis and connectivity and they said, Look, if you just do a binary image and if you find the edges, the bounding edges and if you then characterize that blob by the center area and then its moments of inertia then that tells you a lot. And so as long as the parts are not touching and so long as They are well lit, you could actually go out and pick up these parts. So, SRI developed connectivity, which was, you know, a great thing; not the end all/be all, but a huge step forward. Out of SRI came a company called Machine Intelligence. They were started by Charlie Rosen and some other people. And so, Machine Intelligence was going to take the they got a license from SRI to productize this. And so, we took one of the Machine Intelligence systems and we interfaced that to one of our robots and we showed that Robots 9. There were vision systems before that, but the vision systems were all simple inspection systems. They would look for a dark patch or a light patch, or they would count pixels or they would look for an edge and things of that sort, which is fine for inspection. So, there were vision inspection systems, you know, during the 1970s and maybe before, but what SRI did is they came out with the first object recognition system that could tell you, here is where this object is, you know, that you would do simple teaching and you would say, I have got this round, you know, cap I want to pick up and then it would go and tell you, here is the cap. here is the cap. here is the cap and we go, Boom, boom, boom, you can go pick them up."
"Bruce Shimano","Interviewer","What was that program called?"
"Bruce Shimano","Interviewee","I do not know what their program was called, but their technology was called blob analysis and now people call it connectivity. And the company was Machine Intelligence and Machine Intelligence, after they got started then Phil Villers and Victor so, Victor was with us until, I think, 1980 or so, maybe 1981 and then he went back to Stanford for a short time. And then, he had a long-time friend named Phil Villers. So, Phil Villers had quite a bit of money. He had a cab company, but he left that and so, Phil Villers was looking around for something. And so, Phil talked to Victor and they pulled together the company that they eventually founded, which was called Automatix. And Automatix, as I said, you know, did a great service to the robotics industry by, you know, really attracting financial people into the business. Automatix took the same SRI technology and that was one of their first products as well. "
"Bruce Shimano","Interviewer","So, how did robotics unfold in the 1980s after that?"
"Bruce Shimano","Interviewee","So, what happened was that for Brian so, Brian, Victor and I did the PUMA. We delivered the PUMA, but after that, Victor went back to Stanford and so Brian took over management of the group. You know, we slowly grew and so there were probably about 20 of us or 25 of us at Unimation's West Coast group and we were still doing development. Unimation was owned by another company and that company Unimation was starting to do better and I think they might have hit $70 million in revenue. I do not know if they ever hit $100 million in revenue, but Unimation was growing, was doing better. Robotics was very popular. Conduct who owned Unimation got into financial trouble and Conduct, in addition to selling off their corporate headquarters, they sold off Unimation. And so, Unimation was sold to Westinghouse. And so, as part of this, you know, big spree of robotics in the early 1980s, with everyone getting into the business Westinghouse already had a robotics group, but they looked at Unimation and they said, Well, if we bought Unimation then We had really get a lead up on everybody. And so, Unimation was sold to Westinghouse in I think it closed in December of 1982. And Westinghouse, the Westinghouse people were very good people and they were nice guys to work with, but this whole robotics thing was a total disaster and the group that originally justified buying Unimation, well, they were purged before the sale closed and a new team was put in place right after the sale. And then, that team was purged because Westinghouse was really struggling with some other businesses, and so, they were reorganizing like crazy. So, between the time that they decided to buy Unimation and, you know, the deal closed and a few months after that, there was like the third management group that was put in charge of Unimation. They were good guys, but they had no idea why Westinghouse purchased Unimation and, you know, what the business was all about and they had no background in robotics. They then toured, the new management then toured the various things that they had bought and they came out to the West Coast and the fellow there was a very nice guy. He was the vice president of research and development at Westinghouse. He was in charge of the 3,000-person Westinghouse lab in Pittsburgh and he knew nothing about robotics. And he came out and he said, I do not know what we are going to do with Unimation, so I have no idea what to do with the 25 of you guys. And he says, You know, maybe you guys ought to all move out to Pittsburgh and, you know, join this 3,000-person research lab and he invited us out. And we went out there and, you know, they had smart guys, but, you know, we started as a three-man company and then we got to be ten people, and then we were sucked up by Unimation which was a few hundred people and we thought that was pretty big and then suddenly we are in Westinghouse That is got 3,000 employees or something of that sort and They are inviting us to, you know, join their 3,000-person lab. The Stanford Artificial Intelligence lab was probably 50 people or something like that. And so, we went there and they were really nice guys and they said, Well, you know, Westinghouse knows who we are and if you would like to be with us, fine. If you do not, you know, you do not. And so, we went to Joe Engelberger, who was, you know, the father of robotics and the head of Unimation and our boss during the time we were at Unimation and we said, Joe, you know, this just is not for us and, you know, we are going to leave, Brian and I. we are going to leave. Joe said, Well, do not leave. You know, what are these other 23 people going to do out there without the two of you guys since you, you know, run the place? He said, Let me talk to people at Westinghouse. So, he talked to Westinghouse and one time when Brian and I were out there, because now what happens is Westinghouse, since they really had no clue what to do with Unimation then they did what a lot of big companies did. They hired MacKenzie to come in and do a market study for them and tell them what to do with this thing they just bought. So, MacKenzie was running these market studies and as part of the market study, they put together these little focus groups. And so, Brian and I had to attend meetings in Pittsburgh in this focus group to help Westinghouse decide what they were going to do. After one focus group, the vice president of research invited us to his office on the, you know, 23rd floor of the Westinghouse building and he said, Well, I hear you guys want to leave and we said, Yeah, you know, it is not for us. And he says, I understand that entirely. And he says, Coincidentally, Westinghouse has just done a study and we have decided that because big companies, in that day, did not have the option of going belly up, that they owed it to people; you know, it is kind of a different mentality than the last couple of years That is happened in the U.S., but he said, You know, Westinghouse does not have the luxury of going bell up. We got a lot of people here and we have a lot of shareholders and that means that we can not take risk, but we want to innovate. And so, we decided the only way we can innovate is that we have got invest in small things. And so, he said that this ruling just came out, that Westinghouse said they were going to go invest in startups and he said that they were thinking about buying into things. They never thought of spinning us off, but he said, Why do not you two guys, rather than just going, why do not you take the West Coast with you and take these 25 people with you, and he said, You can take the technology you have developed. You can take the people you have developed and all we want is we want just a minority ownership in it so that we can keep track of you guys and at some point, you know, we may decide that if you guys are interested, you know, we might buy you back, but it would be our way to invest in innovation. And he said, You know, you have to go get money yourself, which was no problem because there were lots of people that we knew, and he said, But you can take the people, you can take the facilities and the only restriction is you can not go do a knock-off PUMA because you did the PUMA for us and That is ours. But so long as you do not do a PUMA, you can do whatever you want. You can do whatever you want with the technology. We do not care. We were stunned because here it was, we thought it was going to be a contentious battle and we thought they were going to argue with us and they just tell us to take the thing. In fact, Brian and I left the office, we drove to the airport to catch a plane, and halfway to the airport, we just could not believe it. So, we stopped at a phone booth and we called his second in command who was at the meeting. We said, Did he just tell us that we could take that and we have the technology and we can do what we want and we got the people? And the guy says, Yeah. He does not believe it either, but That is what he said and That is how we started that technology. So, we got venture capital money and Westinghouse stayed on our board for, you know, probably 15 years until we went public. Westinghouse participated in the various rounds of financing, you know, keeping their pro rata share to keep their ownership the same. They had a board member and they would send people out. And so, we had a good relationship with them, but That is how we started Adept. And so, we started Adept in 1983 when there were 50 other U.S. companies in robotics and clearly, we were going to be in assembly robots and although we were 6-axis kinds of people, we could not go do another PUMA. And so, we looked around and we said, well, we have been doing work in direct drive technology and we really thought that there was good work, you know, research being done in direct drive. So, we thought direct drive was the way to go and there was a lot of interest at that time in SCARA robots because SCARAs were just becoming popular. The PUMA was a 5-axis or 6-axis robot. In fact, a couple of years after that, the Japanese had invested the SCARA and the SCARA seemed to be a really good assembly architecture. We said, gee, we have got this direct drive motor technology that we have been working on and the Japanese have introduced this SCARA configuration, which seems a very good configuration because it is cheaper, because it is only 4-axes and the thing that the Japanese discovered was that a lot of assembly is vertical assembly. So, it is parts that go vertically into other parts. And so, the PUMA was modeled after a person and so General Motors wanted this articulated robot with six-degrees of freedom, that could reach around and do all these things, which a PUMA could do. But, it turns out that for assembly, most assembly is vertical assembly and you only need four-degrees of freedom. Furthermore, you know, having the compliance of the SCARA going horizontally, you know, people thought that would be a good idea, although that never really turned out to be very much. The key idea was that assembly is really a vertical operation. And so, we said, you know, the Japanese researchers, they have hit on something here. And so, we went out and we did the Adept 1, which is a direct drive SCARA robot and That is what we introduced. SCARA robots were Adept Technology's claim to fame. And so, we competed with all these other 40 U.S. robot companies and some of them were using articulated configurations that were a lot more expensive. Some of them were using Japanese robots. Some of them did some of these cheap knock-offs and we were lucky. We just had, you know, a great team with us in terms of the sales and marketing people and the manufacturing team and the engineering team. There was really no one who had a better engineering team than we did. And so, we put together the Adept 1 and that was really, you know, the key product for Adept for probably 15 years. "
"Bruce Shimano","Interviewer","That was Lupul ?"
"Bruce Shimano","Interviewee","Lupul. Richard Lupul."
"Bruce Shimano","Interviewer","Oh, Richard."
"Bruce Shimano","Interviewee","All of us knew him as Lupul, but, in fact, Richard is his first name."
"Bruce Shimano","Interviewer","Okay."
"Bruce Shimano","Interviewee","But you definitely need to speak to Victor Scheinman, because Victor's the guy who invented all the mechanical systems that everything else sprang from. And I think you should talk to Bernie Roth too, because Bernie is the guy who, he is really the person who got everyone interested in robotics at Stanford and was everyone's advisor. He was Piper's advisor, Mike Kahn's advisor. He was Richard Lupul's advisor. He was Victor's advisor, Brian's advisor, my advisor. He was everybody's advisor at Stanford."
"Bruce Shimano","Interviewer","And he is still in the Stanford?"
"Bruce Shimano","Interviewee","he is still at Stanford in mechanical engineering."
"Bruce Shimano","Interviewer","I will have to check our schedule."
"Bruce Shimano","Interviewee","Yeah."
"Bruce Shimano","Interviewer","Doing 20 of these in the next two weeks."
"Bruce Shimano","Interviewee","Yeah. If you want to, tell the question of if you want the early years or the sort of later years. And if you want the early years, you should speak to Victor and Bernie and possibly Lou ."
"Bruce Shimano","Interviewer","Yeah. Okay. So the Adept 1. So what year did you finish that and it was ?"
"Bruce Shimano","Interviewee","So we founded Adept in 1983 and we demonstrated the Adept 1, I believe it was June of 1985. And we went to production shortly thereafter. And the interesting thing about the Adept 1 is that when we started Adept people still questioned whether vision was at all useful with robots. So it'd taken people 1960s to really think that these things which were called indetro robots were useful at all. And then in the 1970s there was an acceptance that you could use industrial robots for blind spot welding, for spray painting and things of that sort. And then in the 1980s, people began to accept that you could use electric robots for assembly. But when we started Adept, still people did not think that computer vision was very useful. And there were not any good vision applications."
"Bruce Shimano","Interviewer","What kind of cameras were they using? What kind of video signal were they?"
"Bruce Shimano","Interviewee","Cameras at that time in the well, way back in the 1970s there was these cameras that were Koho cameras that were these boxes about like this. In the late 1970s then the cameras were kind of these cylinders about this big. And their prices were better, but they were, the resolutions, were probably 100 by 100 pixels or something of that sort. Nothing. And then actually, gradually, they got to be 200 by 200 pixels and things of that sort. So there was a lot of advancements in cameras during that time. So digital cameras really came a long way in the late 1970s, early 1980s. But there still were not any good robot vision applications. And almost all robots were black. Were just blind pick and plays. And as I mentioned, we demonstrated a vision application in the late 1970s, but still was simple. So as I mentioned, there were a couple companies that came along out of the SRI technology. Machine Intelligence, who tried to sell it, but really they were still selling more inspectual things. They never really got a good foothold in the robotics. And then Automatics, they were going to push vision big time. And they sold some vision, but really not very much. They initially came out with a vision system, but most of their stuff was just blind work too. And we had sold a few vision systems here or there, but we were convinced that vision was a good thing. And it is interesting that the very first Adept 1 that we sold, Adept 1, number 1, that had a vision system on it. And we did not know why. And probably six months or a year after, we were still asking, Why are these people buying these things? And through a good part of the 1980s, robot companies everywhere did not sell vision. We sold vision from the beginning of Adept. But there were a lot of companies that never offered vision through the 1980s, robot companies. So we were still looking around for an application. People were still buying vision. We did not know why they were buying vision. Adept from the very first year, we sold 25 percent of our robots with vision and did not know why. We had a very smart marketing lady by the name of Elaine Wood at Adept. And so we asked Elaine, Go figure out why people are buying vision, and try to figure out how we could use vision, because we think it is a great thing. But we got to figure out what we can do with this. And of course, there were companies like Cognex who were selling vision for inspection. There were specialized companies in the semiconductor industry that were starting to look at vision. But so Elaine went around and she said, The great thing we are starting to, at that time, probably in 1986, 1987, we started to look at assembling of printed circuit boards. Because there were a lot of these really expensive chip shooters. And these chip shooters, they were these hard animation things where you put on reels of components and they would just go boom, boom, boom, and they would stuff these things down. Through-hole components at that time, very little surface map. And so there were these very expensive hard animation machines that people made for through-hole insertion, that did the lead prep and stuffed these things down and such. But Elaine said there is a lot of components that fit into the odd component category, and by that it is not resistors and capacitors that you can stuff down. There are these, they might be an oscillator or a power supply or something you got to put down. There might be one or two of these things on a board and They are really big and They are done by hand now. And Elaine said, would not it be great if we could use a robot to put down these odd components and vision would be tremendous, because you have to look at these fiducial marks on these boards and these fiducial marks or these landmarks will tell you where to put the chips down. And these boards kind of move around a little bit and They are all through-hole components, and so you got to get these leads through these holes. And if you try to do it blindly, That is just never going to work. And so she said we ought to develop an application to go find these fiducials and then adjust the robot position, put these things down, odd components down. And we did that and that was the first application that we did where we really knew what we were doing and we really knew what the benefit vision was. And nowadays, all these chip shooters, they all use vision too. But at that time, they did not. And people use vision for mask alignment and things of that sort, but they did not really use it for putting down chips."
"Bruce Shimano","Interviewer","So what year did you finish that?"
"Bruce Shimano","Interviewee","That was probably I think 1986 or 1987, that sort of time frame. And so that was really when we knew why we were selling vision. We were promoting vision since the late 1970s. The very first robot went out with vision, but finally two or three years later, we finally knew why we were selling vision and what it was good for and applications that we can go out and tell people, Hey, if you are going to go do this, you really want to use vision, because here is what it is going to go do for you."
"Bruce Shimano","Interviewer","Yeah."
"Bruce Shimano","Interviewee","So the 1980s were a sort of consolidation time. That is when a lot of U.S. companies went by the boards. And so we went from 50 industrial companies down to a handful and by the 1990s, Adept was the only U.S. robot company left."
"Bruce Shimano","Interviewer","Wow. What was the last ?"
"Bruce Shimano","Interviewee","Well, there is General Motors started it about the same time. They, General Motors, decided that in 1983, about the same time we were starting, about 1983, 1984, that they were not getting what they needed from the robot venders and they were going to start their own robot company, which was General Motors FANUC. And so it was a partnership between General Motors and FANUC. And FANUC would be doing the manufacturing. General Motors would do the controls and be the marketing arm. General Motors FANUC was, I am forgetting, but I think in the late 1980s FANUC bought out General Motor and so today They are just FANUC. let us see. Who else was gee, I can not even tell you who the last ones were. There was just a bloodbath of them going out of business, and That is when the Japanese were coming on strong. And the Japanese, as I mentioned, they originally got their technology by licensing from Unimation."
"Bruce Shimano","Interviewer","So what were the big Japanese companies at that time?"
"Bruce Shimano","Interviewee","Well, FANUC was big. SECO instruments, in terms of assembly. Sony was in there and still is in there."
"Bruce Shimano","Interviewee","I am forgetting some of the other big ones. it is just escaping my attention at this point. And of course at that time, then you had ABB was really doing well. Kuka, you know, both really a focus on automotive. So, there were a number of European companies. "
"Bruce Shimano","Interviewer","So, when did Kuka start? "
"Bruce Shimano","Interviewee","I could not tell you. Yeah. "
"Bruce Shimano","Interviewer","Okay. So, then Adept was the last U.S. company standing in the early 1990s? "
"Bruce Shimano","Interviewee","Right. "
"Bruce Shimano","Interviewer","And what happened since then? "
"Bruce Shimano","Interviewee","Brian and I ran Adept. And we were the two founders of Adept. He was the CEO, and I was on the board of directors, the vice president of research and development and ran engineering from time to time. But he and I ran Adept, and we finally were able to take it public in 1996. So, 13 years after we started it, I think we started making modest profits probably in the late 1980s. And so, during the early 1990s we were making modest profits. Our profitability got a little bit better the mid 1990s, and so we took the company public in 1996. In the late 1990s, you know, once we were a public company, then there was more pressure than ever to make profits. And the board really wanted to see us expand the company quite a bit and to take some risks. And so, we made a number of investments, strategic investments in semiconductor, and then also we started to make some head way in semiconductor, in the packaging markets, which we did pretty well at. But they wanted something a little, you know, that was really going to explode. And so, in the early 2000s, we invested in photonics in a big way. And after the Internet bust, then in the early 2000s, people said, Well, you know, the Internets, all these startups are sort of going bust. Because clearly the Internet's going to work, but in order for the Internet to do better, you know, people need more bandwidth. And so, it was thought that the next big push was really to get bandwidth in everybody's house. And the way to do that was through fiberoptics. And so, photonics was the development of fiberoptics, that you can lay this cable everywhere and get band width. And so, in the early 2000, this was this huge rush to photonics, and everyone was going into photonics. In fact, Corning, you know, had been in optics for a long time. Corning had Corningware; Corning had Corning missiles and things of that sort. And you know, Corning in the early 2000s, they sold off Corning ware, and they sold off the missile division, and they were going to specialize just in photonics and fiberoptics, to lay cable. And then there were lots of other companies, like J.D.S. Uniphase and such. And so, you know, photonics just took off. And we said this is some place that we could play. Because we had actually been working with Corning on doing optical assembly for a long time. So, we made a big play in photonics. And photonics was this rush, you know, just like the Internet and everything else was. I mean, it just exploded. There were conferences and, you know, money everywhere. And then it just cratered. And unfortunately, That is where we made our bet. And then, of course, towards just about the time photonics was cratering, then 9/11 happened. And so, what happened then was that, you know, the combination of 9/11 and just the cratering of photonics, we had to really shrink Adept. We grew Adept. I think we peaked out over a hundred million dollars in revenue. But suddenly, you know, with 9/11 and photonics cratering, we had to shrink the company by you know, get rid of two thirds of the company. And that was very painful. So, we shrunk the company down from a hundred million dollar revenue down to about 30 or 40 million dollar revenue. And unfortunately, you know, with it all the people. Some of them, you know, had been with us a long time, all of them friends. And so, we made it through there just by the skin of our teeth. And so, you know, we were still alive. We made it through to another crunch, but we needed more cash. And so we went out and we got more cash. And the board said, well, they want to change management, that we had been running the company for 20 years, from 1983 to 2003. And they said that that was long enough, that, you know, most companies change management all the time. And for us to be in charge for 20 years they thought was way overdue that they got new management in a public company. And so, as part of getting the money in, we got shoved out, which was okay, because it was a very unpleasant time for us. It was really sad to part with a lot of the friends that we had, but it was a very contentious situation at that time with the board of directors. And Enron had happened, and basically it is not very fun to run a public company in any vein. And Adept, even though we had a good industry and then though it was a fun industry, being a public company is just no fun. So, That is when we left, in 2003, and we started Precise Automation, Brian and I. "
"Bruce Shimano","Interviewer","Okay. So, and what is the focus for Precise Automation? "
"Bruce Shimano","Interviewee","Our focus is different, that when we started Adept, we knew we were going to be a big company. And so, right off the bat, we got tons of venture capital funding. And we put in a whole manufacturing operation and we grew like crazy in the early years. And so, our goal was to be, you know, a big company. With Precise Automation, our goal is to be a small company that really focuses on technology, and instead of investing in a big sales channel and a big manufacturing organization, our view is that, you know, those days are kind of done. And so, we have a very small sales force, just a couple of people, and we have no operations to speak of, and we have partners who do all the operations for us. And so, in fact, we are at Chad today, and Chad does all the robot manufacturing for Precise Automation. So, Brian and I are still, you know, robotics, industrial robots is our business. And controls and robots is our business, but we now feel that it is better to have the flexibility to have other organizations within the United States, you know, do the manufacturing. So, we still have, you know, all our products manufactured in the U.S., but we just do not do it ourselves. And we focus really on the technology. And also, at Adept, we have shied away from automotive, but we did a lot of electronics. And at Precise, we are really focused on other marketplaces, lab automation, we do a great deal in will be automation, and our robots are now designed for that. We do some work in semiconductors still. We do a little bit of packaging and such. So, you know, we believe that there are just different marketplaces now and different ways to do business. And so, you know, obviously automotive is still a big portion of the industrial robot business, but it is a commodity business, and it is pretty brutal. And it is just, you know, these large automotive companies just are beating the robotics people to a pulp in terms of making ends meet. But, you know, there are a lot of robots that are still sold there. Semiconductor is an interesting opportunity. There are actually more robots sold in the semiconductor, I think, than there are to automotive nowadays, but it is a very small market in terms of the number of players and the number of users. So, we supply controls in the semiconductor. We think lab automation, pharmaceuticals, is a really interesting area, though, because people in that business are getting to the point now that They are handling more and more product. We have one company that we deal with, and their business is to handle the blood samples that, you know, you go and, nowadays, everyone when they get a physical or you go to, you can go your doctor, you get blood workup. And so, there are thousands of tubes of blood that have to be sampled, tested every single day. Well, more and more, you know, the day was when you would go to your local doctor and they would do their own blood work. Well, people do not do their blood work anymore. They send them out. And so, now there are these companies, and their whole job is to do blood work. And they will get in 70 thousand vials at night, and by the next morning, they have had to split those out into all these tests and return the results to the doctors. And so, there are these huge blood processing places. And it is all done by hand. You know, 70 thousand tubes come in and people, you know, pour it out and, you know, split it out into various tests, then load that stuff in. And I have not toured one of those plants, but, you know, these customer of ours have toured it, and they say if you would see these plants, you would never believe test results again in your life. Because the number of mistakes that are made in all that handling, they said, is just frightening. And so now those companies want to automate that. they have had these little plastic tubes, and they want to, you know, have robots power out those tubes into these samples. Then they want to load these samples into these testers, but they need to handle 70 thousand in a night. And so, there are these huge automation systems that They are putting in for that. There are other people who are doing, you know, all sorts of pharmaceutical tests and such. And you know, pharmacy is just a huge business now. And all this pharmacy, it is all a matter of testing. You know, these people, and They are developing new drugs, it is all testing. They split them up, they, you know, try various things, and it is a tremendous amount of testing. And all that testing used to be done by hand, but now more and more They are automating that. So, you know, we believe that lab automation is really a very good industry. "
"Bruce Shimano","Interviewer","Are you involved at all in the genetic sequencing machine? "
"Bruce Shimano","Interviewee","Yeah. They do that as, you know, they do that as well. So, yes, That is part of that industry. So, you know, there are a lot of these areas that, you know, there are the areas that people think of, like electronics, which robots are used in quite a bit. there is automotive that robots are used in. Spot welding, there is even arc welding that people use robots in. But, there are all these industries that are kind of under the radar that use thousands of robots that you do not think about. Semiconductor's a good case, you know. People never even paid attention to semiconductor, and yet there are thousands of robots sold every year into semiconductor by just a few companies. "
"Bruce Shimano","Interviewer","So, what are the big companies now for industrial automation in semiconductors? "
"Bruce Shimano","Interviewee","Well, in semiconductor, it is mostly the Japanese. you have got, you know, I believe that Yoshikawa made a big push, and so Yoshikawa's got a lot of semiconductor business. They might be the biggest semiconductor robot of the conventional robot people. The company that specializes just in semiconductor, though, is Brooks. And so, Brooks is not thought of as a robotics company, but in fact, That is what they are. They are a robotics company, but they specialize just in semiconductor. And I think probably Brooks and Yoshikawa I would guess would be the two biggest suppliers of semiconductor robots. And then there are lots of other smaller players. "
"Bruce Shimano","Interviewer","And what about in laboratory automation? "
"Bruce Shimano","Interviewee","Yeah. That is just an emerging area now. And so, there are some small ones. Actually, there is one company that does Cartesian robots. All they do are Cartesian robots, and all they do is for a small segment of lab automation. They do this Cartesian robot which is just to and I am forgetting what their particular application is but they sell about a thousand robots a year, which, you know, is probably more robots than a lot of robot companies sell. And no one knows about them. You know, and they make this one Cartesian system that they sell a thousand robots a year, and that is all they do. And They are a Swiss company, and they just make, you know, this little robot and accessories. And they do probably, you know, some tens of millions of dollars in revenue. But They are not, you know, They are not part of any robotics organization. They do not show up at robotics shows. They just attend these lab automation shows. "
"Bruce Shimano","Interviewer","What about packaging? "
"Bruce Shimano","Interviewee","Packaging, you know, I think that ABB does a lot of packaging. Adept does a fair amount of packaging. I do not think that FANUC or Yoshikawa has ever broken very much into packaging. they have tried. And then, of course, you know, there are specialized robots. For instance, there is the Delta robot, which SIG makes. And, you know, the Delta robots, there is been a real up surge in Delta robots because all the patents ran out a year and a half ago. And so, Demaurex held the original patents for the Delta robots. And they sold a license for the larger Delta to ABB, and they sold the patent to the medium size robots to SIG. And so That is why the Delta robot has only been used by only been sold by Demaurex, ABB and SIG for the last 15 years. But the patents have all run out. And so, That is why in the last year and a half, you have seen Delta robots spring up everywhere. "
"Bruce Shimano","Interviewer","what is a Delta robot? "
"Bruce Shimano","Interviewee","Delta robot is it is a parallel robot. It looks like if you take your camera tripod, flip it upside down, that is a Delta robot. And so, instead of a serial robot where you have one link after another link and then the end is moved by this serial chain, the Delta robot's a parallel robot that has these three legs. And by driving these legs up and down, you can move this platform around, and then that platform, it is a very clever design because by the arrangement of these links, the platform always stays horizontal. So, it is a very clever design. It has the attribute that all the motors are stationary. Because in any robot, a lot of the weight is the motor, and where you put the motors. And so, you have a choice. You can either put the motors close, in which case you have got all this weight out there that you are trying to move, or you can remote the motors, in which case you have got some sort of drive train, which is causing you a lot of money. Well, the Delta robot is this parallel system. "
"Bruce Shimano","Interviewer","Okay. Let me think if there is other questions. So, anything else you want to say about the 1980s or 1990s that we did not cover? "
"Bruce Shimano","Interviewee","No. You know, I think if you talk to the Japanese and some of the other people, you will get more of a sense for people who are trying to break into the service industries and such. And we just have not, you know, That is just not been our forte. But That is, service robots have been, you know, important things since the mid 1980s, but they just have not gone anywhere. "
"Bruce Shimano","Interviewer","What about consumer robots? "
"Bruce Shimano","Interviewee","No. They are mostly toys. The things that there have been is that there have been various educational robots that people have made from time to time, but there really hasn't been a very popular educational robot That is lasted, you know, more than a few years. So, there have been a number of people who have tried education robots, but, you know, none of them have made it. Yeah, I think that is about it. Also, when you talk to you know, there is a big distinction between robotics and what we do. I think that people have correctly characterized that we are really in intelligent automation. And they would differentiate that from robotics, which, you know, is going towards more autonomy kinds of things. I mean, our goal is not to have thinking machines. Our goal is to have things that are cost effective and that are easy to teach what to do. So, I think that there is still just a, you know, a huge gap between autonomy and thinking machines and what we sell. "
"Bruce Shimano","Interviewer","A lot of the technologies you have developed could be used for all sorts of applications. "
"Bruce Shimano","Interviewee","Right. "
"Bruce Shimano","Interviewer","So, what do you think the biggest innovations that you personally came up with in your career are, or the people you worked with? "
"Bruce Shimano","Interviewee","Well, I think we were a good promoter of vision for robotics for a long time. You know, I suppose things would have been different if we would have been a flop at general motors, you know. If someone else had gotten the bid there and had really screwed that up, that probably, you know, would not have changed things forever, but it probably would have slowed things down considerably. Because the Puma really was a landmark machine, and it was a very successful machine both from a product point of view and a, you know, commercial success. And in fact, the last time that I saw Jawa Ingleberger and Victor was when, you know, one of the first Pumas was inducted into the Smithsonian. So, I think the Puma was really a big deal. You know, and that was a bunch of us who worked on that, and that, I think, was very important to get fuel electric assembly robots, you know, accepted. And if we had blown that, probably it would have delayed, you know, their acceptance by some number of years. Yeah, we have done okay in the software. I think, you know, we have continued to advance the software, but from a very pragmatic point of view. You know, I am not sure that at its core, I do not think that there are things that we do today that are all that different from the L language we wrote back in the 1970s. But it is just that it is so much more accessible now. "
"Bruce Shimano","Interviewer","Okay. Thanks. "
"Bruce Shimano","Interviewee","Okay. "
"Bruce Shimano","Interviewer","Appreciate it. "
"Bruno Siciliano","Interviewer","Where you grew up and went to school? "
"Bruno Siciliano","Interviewee","Yes. Okay, so should I start anytime?"
"Bruno Siciliano","Interviewer","Yes."
"Bruno Siciliano","Interviewee","Okay, I was born in Naples, which is the third largest city in Italy, this was 50 and some years ago, October 27, of 1959. And I just recall a funny thing that the ICRA 2009, which is our flagship conference in took place in Kobe, it was we found out there is a group of us, who were born in 1959, so there is a number of roboticists who are, except me, known in the community just remember some names, Roland Siegwart from ETH Zurich, Peter Corke from Australia, is another 1959er and Antonio Bicchi from University of Pisa is another one, and so Roland prepared some kind of nice piece to wear with the logo of the Robotic Society of IEEE and 1959er, so this looked like a good year for robotics. And as a matter of fact, 1959 was also the year when the first industrial robot designed by George Devol, was made, was manufactured by Unimation, which is the company, one of the pioneer industrial robot manufacturers in US, so there must be some conjecture about around that year, that it was quite funny to discover years after. I did my studies here in Naples, I studied the so-called scientific high school at the Lyceum and then I enrolled into EE Electronic Engineering program here at the University of Naples, Federico Secondo where we are meeting, where I am speaking this afternoon, and I did my at that time, our university system, we only had one degree, which was a five year degree, which is the equivalent to the Anglo-Saxon Masters. And I completed my studies actually in four and a half year, and then I was ready to just to leave and probably to move to northern Italy to work for one of the big companies like IBM, Italtel, all the companies in IT having a degree in electronic engineering. And then I had a sort of inspiration, because I got a proposal by a professor, a professor I graduated with, to start the PhD, which is called a Research Doctorate. A Dottorato Research in Italy. This was something new into the university system. Before 1982, we had no PhD, so the highest degree was a Master and the interesting thing was, there was another professor in this department, was being my mentor to robotics, Professor Lorenzo Sciavicco. and at that time, he was just starting doing research in robotics. And myself, having been fascinated by a lot of teenager time readings on the books of Isaac Asimov, about you know, science fiction and robotics, I said robotics, to me, looked so diverse from the classical engineering, and I decided to join the program, because I was fascinated by the new field. At that time, Robotics was still in its infancy in terms of research. Robots were already popular in manufacturing plants, but it was a new field for research. And so I did, I started doing my studies in robotics. And my dream was also to go and do some studies and research in US. And at that meeting, which was the Romanci Conference, which was a sort of mind storm in the history of robotics conferences worldwide, I had the opportunity to meet many distinguished scientists in our field, starting from Professor Bernard Roth, Bernie Roth at Stanford. And then I met also one of the most one of the brightest minds that we have in robotics worldwide, and I am speaking about the coordinator of this project, Professor Oussama Khatib, Oussama, my probably, I think is my best friend, and since our first encounter, we became very, very close, very friends, very much friends to each other. And I had the opportunity then to go and spend one year at Georgia Tech in Atlanta, and I worked with Wayne Book, who was one of the distinguished scientists attending this meeting. And this really changed my life, because it opened up my mind, and I also, during the year there, I had the opportunity to travel in US, and visit other labs, and but more importantly, I started building my network of contacts, which has helped a lot, you know, during my professional growth. So I finished my PhD, and then it was time to make a decision. And I was very tempted to move to the US. I was offered a position as an assistant professor by Georgia Tech, and it was hard for me to say to drop this opportunity because, at that time, I was nothing here, because I had finished my PhD, my grant had finished, and that time, there were no post doc positions available into our university system, and I have to say that I was starving, and the only reason why I could stand it, because I was like a Mama boy, because I was living with my parents, and so I had no major expenses, so I could afford the luxury of doing research as a hobby, without money, without needing money. And so I waited. I was close to a position at Stanford, later in 1989, but there was time was right for a position here as an assistant professor in 1989, and I just ran for the position and I got it, and two years later, I became an associate professor, and eight years later I became full professor and after three years, I was hired at the University of Salerno as professor of automatic control, in 2003, I came back to my alma mater, to the University of Naples, Frederick II, Federico Secondo and here I am, and I direct the PRISMA Lab which is the lab doing work on robotics for industry and services, mechatronics and automation. In the meantime, I had cultivated all my international contacts, and I became quite actively involved into the Robotics Automation Society of IEEE. I have served the Society in many ways, I have been on the editorial board of Transactions, and in 1991, and then I became a NATCO member, a member of the Admissory Committee, in 1996, and in 1999, I was appointed to replace someone as Vice President for Publications. And then I was elected as Representative for Technical Activities and the apex, I think was in October 2005, when I was elected to President Elect of the Robot and Automation Society of IEEE, and this was almost like a dream come true, because I had just gone through all the steps of the society from a simple member to senior member, I had been elected to fellow, in 2000, and so this was like, kind of, I should say the culmination of my professional service to the society. And so I was President in 2008 and 2009, and I am now, despite my, I assume, younger age, kind of retired, because I am now my function is a Junior Past President so I continue to serve the Society with the nominations. At the next two years, I will become Senior Past President which means that I will be in charge of the awards, all the awards that our Society gives to to the excellence in our field, both in conferences and publications and of course in the professional achievements. So this is, in a few words, my story around robotics. And I am just thinking about, I do not have the book with me today, in my office, but there was a quite interesting book that came out in Italian, I do not have a copy here in my office, because I just got it home last week. And this book is called Literally it is like Galileo's nephews. It was written by a science journalist who is quite well known in Italy, and I was flattered to be invited as one of his, ideally, seven nephews of Galileo, and he chose me for engineering, so and there are famous scientists, Italian scientists, one of them for all these Giacomo Rizzolatti, who is a famous neuroscientist in University of Parma, and I was simply flattered that I was invited. And I was reading this book with my kids last weekend, because just I got it, and I was almost moving to tears because this journalist came to interview me and I told him about all my life and the result was a nice blend between my personal life, almost like kind of biography of the first 50 years of my life, and at the same time, you know, the 25 years of my professional growth merged with the growth of robotics in the field. So it was I like the result very much and I mean, it is a nice moment that I could share with my family. And of course I gave the copy to my mother, which, I mean, as you may mention, you know, she was kind of proud of her kids, you know. So this is in a few words, like, my growth as a professional, which I have only been I have really been fascinated by robotics. Robotics has been playing a big part in my life, and I think I am lucky and privileged that for the fact that I have, besides a number of colleagues and professionals in this field, I mean, this community is like is a big family and with many of the distinguished scientists and colleagues, you know, there is a strong friendship which really gives that extra passion and devotion to this field, so it is "
"Bruno Siciliano","Interviewer","So part of your PhD work, were you working at electrical engineering or mechanical engineering or were they sort of mixed together? "
"Bruno Siciliano","Interviewee","This was electronic. The PhD was tied to, I think electronic engineering like my masters, but clearly, working in the field like robotics, I discovered that my background was solid in terms of the mathematics and physics, which typically one studies in doubly, but I was lacking in mechanical engineering and so I always liked to take challenges in my life, I like to just be on the edge, and when it was the time, when it was time to go to the US during my third year of my PhD, the challenge was to go to a mechanical engineering school, and I knew very little mechanics, because simply I had not taken enough courses in mechanics and so when I was working under direction of Wayne Book in the School of Mechanical Engineering at Georgia Tech, was also a growth for me, because I learned a lot about mechanics, and after all the years, I discovered that it was not even enough, because robotics was evolving in the meantime and I had to learn about sensor technology and recently I had to learn a lot about cognitive systems, and AI because robotics is becoming more and more a kind of complex and intelligence systems, and I think that nowadays, robotics has reached a level of maturity that the core methodologies and technologies are well developed. Now to further evolve, we need a lot of interaction with fields that until a few years ago, were probably considered to be really away, apart from robotics, but I think now, I mean, it is the time to reach those crossroads between robotics and all the other fields, and I think further progress will be by, I mean, our attitude should be one of openness and really enlarging our field of interest toward disciplines which, once were considered to be separated from robotics. So this sort of cross fertilization among different fields is happening, and I think robotics is playing a very active role into this process. "
"Bruno Siciliano","Interviewer","So the year you were at Georgia Tech, so what year was that, and what project did you work on? "
"Bruno Siciliano","Interviewee","I was actually granted by the at that time, they had a center which was called Center For Integrated Manufacturing Systems, CIMS, and the emphasis there was on automation, but my actual interest was to work on a new type of robotic system, of robotic manipulator that were becoming very popular. Those were flexible, flexible in the sense of distributed flexibility on the links. So compared to the classical rigid and bulky industrial type of robots, this was a sort of innovation, because flexible manipulators, Dr. Book had been working on flexible manipulators with NASA, with a project with a long boom, the long remote manipulator system used in the Space Shuttle Program, where the flexibility was induced by the length of the arms. Because this big arm, this big boom was supporting a platform where the astronaut would sit, but then flexibility was also used on purpose in the design to make lighter arms, and at that time, it was not clear at all, the enormous potential of this kind of design solution for the future application of robotics. At that time, flexibility was only meant to reduce the load of the structures, of the structure versus the payload, because typically a NASA robot can lift to lift a payload of ten kilos, must weigh 200 kilos. And the reason being that it must be accurate. So for precision, for accuracy, you need a very rigid and heavy structure. But thanks to the progress in the latest years on materials science and technology, we have been able to design lighter and lighter arms by using composite materials, carbon fibers and all the like. But recently these lightweight arms have become more and more challenging because the field has evolved and most of the research nowadays is on the so-called problem of human-robot interaction. So if you want a robot to share the space, the workspace with humans, you must go into safety, and safety does not come for free. If you have a heavy and bulky rigid arm, because a rigid arm can hit someone and can hurt and can even kill someone, so the trend into the field is to design so-called compliant arms, so arms that will be lighter in terms of the absolute weight, but also arms which, if accidentally in contact with a human, would cause less damage. And so nowadays, like, the mechanical designers are realizing light arms, there is one arm that was designed at the DLR, at the Institute of Robotics and Mechatronics, Professor Eutinger, DLR, was a kind of revolutionary arm, because it only weighed 14 kilos to lift up a payload of 13 kilos. we have been using this arm into one of our UPM project. This was the France project where the issue, the attention was on the physical human-robot interaction, dependability and safety. But design is not enough. You also have you also have to rely on sensors and on intelligence, on control. So basically design lighter material are a sort of passive safety measure, but you also have you also need some active measure and you gain active safety by designing control algorithms which are very fast, and in the case of an accidental contact with a human, are also able to retract the arm and not to cause any damage, any hurt into the human. So that the robots of the future will naturally be compliant both passively and actively, thanks to sensor and control and intelligence."
"Bruno Siciliano","Interviewer","So what was the first robotics project you worked on, I assume before Georgia Tech."
"Bruno Siciliano","Interviewee","Ah, this actually this was, during it was a project at Georgia Tech, because most of the research I had been doing during my first two years of my PhD, were like, I would say on basic robotics. Also with a background in control, I was working on robust inductive control but mostly at a theoretical and a simulation level, because at that time, I had no lab, I had no experimental setup, so I was working on a theory, so to speak, because, with a strong background in mathematics and control. So my first exposure to hardware, and I was very worried when I went to Georgia Tech, because I was not I have never been a good experimenter. As an engineer, I have when I started doing my studies in engineering, I had no passion whatsoever for the hardware. I was more attracted by the scientific aspects behind electronic and the novelty of the field. So when I went to Georgia Tech, I had to get my hands on some experimental setup, and the first project was called RALF. RALF stood for Robotics Arm Large and Flexible. And this was a project being developed at Georgia Tech by Wayne Book, and I got to work in that project. And since then, I was involved into other projects in Italy. We worked also on some space robotics project, mainly with the European Space Agency and the Italian Space Agency, and this was a natural follow up because of my expertise on lightweight flexible arm, because flexible arms were being used to use the payload of the space missions. So and then I started working on or I think the first big project was, as I said, France, in which I mean the France is about physical and robot interaction. This was the first big funding that we got from the European Commission. And since then others have followed. I am currently the coordinator of DEXMART, DEXMART is a large scale integrated project sponsored by the European Commission and it is about dual arm, dual hand, so these are called bimanual manipulation, so robots with two arms and two hands. And this project is about at the end. It will finish January of 2012, and so this is another project. And more recently, I have got interested into aerial robots, flying robots, and I currently have one project which is called iRobots, and there is another one starting in November which is a sort of innovation in the field because it will be multiple cooperating robots flying and manipulating some object and this is like a kind of innovation in the field, because flying robots have been used for several years, but only for patterning, for inspecting fields, coasts, you know, grounds unreachable areas, but the novelty of this project is that they will fly and manipulate, so it is combining the concept of robotic manipulation and take this into the air with a lot of easy problems difficult problems, I mean, easy to understand in terms of communication and operation of these robots and also from a control viewpoint. I have a control background of controlling them and controlling the manipulation while they are flying. And this is posing a lot of challenging issues which this is attracting a lot of students, because it is kind of challenge. We have some flying robots in the lab, and the students, they have started to have some fun since a few months. And I think it is one field where we will see considerable progress, and also there is there are a number of applications where any robots might be advantageous compared to the classical ground mobile robots, because of the immediate accessibility of flying robot, but of course the regulation in the field are quite strict and severe. I was told by some Japanese colleagues that they were not allowed to operate flying robots in the Fukushima plant because of strict regulation barriers, and they were only able to operate some mobile robots to inspect the plant and to check the level of radioactivity after the disaster, the contamination. But there are a number of applications where I think air robots would play an important role."
"Bruno Siciliano","Interviewer","So when you came back from Georgia Tech, to you came back to Naples, what year was that? "
"Bruno Siciliano","Interviewee","This was 1986, and for some bureaucratic reasons, I had to wait until 1987 to defend my PhD thesis, because this was a new program, as I was saying earlier, into the university system, and so the graduation was delayed, you know, with no explanation, by a few months and then I was officially without a position I mean, nominally I was considered as a post doc. I remember one episode which is narrated into this book that I mentioned. This was very funny. One night I was working until late as usual, because I was not many of the time, and laptops, portable computers, I mean, laptops were not yet popular, so I was working on a desktop in my office and to work, I had to be in my office until after hours, and the security guard would come every night, past eight to close the building, and he would always find me working, and I, because with my white hair that I had since a young age, he would call me, Professor. I was nothing, because this was after my PhD, and I had no official position into this building, the building where we are talking this afternoon. This was a room opposite to the hallway from here. And that night there was a colleague, a real professor, working after hours, and the guard came to me and said, Do you know this guy? Yes, of course, he is Professor DiMaria, I know him, I know him well. And so he went to this guy and said, I do not know you, but Professor Siciliano say that exception, you are allowed to stay because he knows you. He was furious, he went mad. I mean, he was yelling at the guard, it is like he is nothing, he has no right to be in this building, he is a clandestino, he is a clandestine. This was quite funny, well funny the day after I had a hard time with the department head, because I had to clarify, to clear up my permissions, because I had gained a permission because on my fame of working after hours with this security guard. But this was a time which was not easy, because I had refused offers to go to the US, and also I got an offer to go to Tohoku University in Sendai, which I refused. In a way, I have to say that I have always liked I like traveling a lot, and I have many colleagues and friends all over the world. And I love traveling and I love seeing them and I am often on travel. But I feel attached to my roots, more than I thought initially when I wanted to leave the city and go to work for one of the companies in northern Italy. I think I am attached to my roots, to the city of Napoli, and also to my university. I feel this, and now at this stage I feel even stronger. So I when I had it was good for me, it was important to have the opportunity to leave, because then you have a freedom of choice, and you know, when I was considering position in US universities, American universities, I was very tempted. But then I decided that I have had many, many friends and colleagues from my university time, who moved to the US, like brains who have emigrated, and they admitted they had made up a academic career, and you know, colleagues a professor at UCLA, at Berkeley and in other fields, but I decided that I wanted to do this in Naples, and I think it was kind of big bet and a big challenge and despite all the fickleties of working in this city, which is not an easy place where to live, because of bureaucratic drawbacks into the Italian system, and also because of different concepts. In a way I am considered like a kind of a visionary in the sense that I am a workaholic person and I work and I like to reach higher and higher standards, and sometimes people come to me, like, what for, you know, like, because the system is not really encouraging you, motivating you to do this, because professors in Italy are state employees so my salary is the same as the salary of any professor of my age and my seniority, so you know, I have done all this, if you wish, for the glory, for the beauty of doing research at I think at the worldwide level, and so this costs me something, but if I have to make a balance now, which is half of my life, I can say so. I am happy that I stayed in Naples that all that I have reached, I have done with in my hometown. I think there is an added value to this, and this will be also a heritage, I think for my kids to attend this. And, I do not know, on one hand I wish that they would leave, or I am trying to inject a sort of international attitude into their well they are still young, but on the other hand, I think it is good, you know, I they grew up here with all the good and bad, and the values that we have in our country and our society, and I think in our in my hometown, which is suffering from a lot of problem. Naples is often in media for problems with the garbage, with crime and That is the typical stereotype, but despite all this, I think it is I think it is a great place and also in terms of the I have to say the humanity of the people, is quite unique compared to many other places around the world. And I think the added value for me of having stayed here, and having achieved whatever I have done in my hometown with my alma mater, with my university, I am kind of a little proud of this, and I think that in the end, it was difficult for me when I was younger, to resist the temptation of leaving, but at this point in my life, I am happy that I stayed here."
"Bruno Siciliano","Interviewer","So tell me a bit about how robotics has evolved in Naples. So you have one of, probably the first PhDs in robotics. What were the first labs that opened, and what kind of machines did they have, and what did they "
"Bruno Siciliano","Interviewee","Yes. This the lab that I am going to direct is called the PRISMA Lab. This, if I remember correctly, was started in, I think in 1992, 1993. At that time, we were lucky that we had big funding of in basic research from CNR. CNR is National Research Council and from 1990 to 1994, there was a huge project in Italy which was called and thanks to this project, there was also a lot of funding on the labs, on the infrastructures. And we were lucky that thanks to the big funding from the CNR, we got the PRISMA Lab opened. At that time, and this was a time of making decisions, because my mentor to robotics, Professor Sciavicco, was the head of the group at that time. I was already an associate professor. I had big discussions, not really argument, discussions with him, what kind of lab should we start, because on one hand, I had been fascinated by the advanced robotics lab that I had seen around the world, where it would see no longer industrial robots, but prototypes, innovative robots, be them like advanced robot arms, mobile robots, a lot of work on sensors, and intelligence already, and to me, it was, whereas being a kind of a solid well rounded engineer himself, Professor Sciavicco, he wanted to follow a sort of bottom up approach, so he wanted to start on the safe side with industrial robots because he was convinced of the need of doing some research very close to the technology. And to do some research which could be transferred to the industry without going too far beyond. So there was a big discussion. In the end, he convinced me, because he was worried about starting something too futuristic. Having been no robotics, no lab in Naples before us. So and then we started with this sort of bottom up approach, and I am happy to see now that I think this was a good choice, because I think it was the way to get to gain experience, and also to gain credibility with all the companies in Italy, starting from the big robot manufacturer which is Comau Company, you saw the Comal labs in the lab the Comau robots in the lab, and so and also it was very important to attract the students, because of course, you know, I always wish that in my class there is the future brightest mind researcher, but the other 24 students in my ideal class, they have to become professional, they have to becomes engineers, and they have to work for the companies. So to them, you must transfer something which is which they can spend in their working environments. So I think in a way, we continued our education program and we easily inserted robotics as a course and so we started the robotics course actually in 1990, the academic year in 1990 yes, 1990, 1991, was the first course I gave in robotics, and we had lecture notes, and I remember the first year was really fascinating because this was a new course for us, and the four of us, my mentor myself, and the two younger guys who are now full professors at University of Casino, Professor Stefano Cabrini, and at University of Salerno, Professor Pasquale Chiacchio. At that time, I was an associate professor so they were assistant professors, and during the course, no matter who was giving the class, the four of us would attend all the classes with one goal, try to just improve the contents. And we were very, very critical towards one another, because every class we would after class we would revise the class contents, and I was changing the lecture notes, and then after two years, I had become I became an associate professor, so this became my course, and then I started working on the lecture notes that I wanted to turn into a textbook. And the funny story was that I was looking for a publisher, and we had these lecture notes in Italian, of course, but I have always thought big in my life. I like challenging, and also having made some experience also of TA in US, at Georgia Tech, I had become accustomed acquainted with the university system and then I said, I had the mission to write a textbook both in Italian and in English. So I contacted one publisher in Italy, which was McGraw Hill, which was a subsidiary of the McGraw Hill Companies in US, in New York, and I say, I want to write a textbook in Italian and English, and the editor was almost laughing at me, just, you know, you can not write a textbook in English, because first of all, English is not an easy language to write, and you are not it is not your mother tongue. I said, yeah, but my level of English is good enough and I know how to write good technical English, and also I know the courses, the robotics courses taught abroad. And then he was hesitating, I said, okay, let me speak with the editor, and he spoke with the editor of McGraw Hill at the Frankfurt Book Fair, nothing was happening and then I think I contacted people in the UK, and then I got fed of this wait, and then I say, you know what, I will send my proposal directly to McGraw Hill in New York. So the proposal was sent at that time, e-mails were not yet popular, so it was the sometimes some package, some envelope would come in the mail and you could recognize, this is coming from McGraw Hill, so one day I got an envelope from McGraw Hill Incorporated in New York, and this was the answer to my proposal and the answer was positive. So the proposal had been reviewed, and it was accepted. So they proposed me a contract, and so I signed a contract to write a textbook in English with McGraw Hill in New York. Then I went back to the guy in Milano at McGraw Hill Italia, and I say, I have a contract with your company. They want to translate the book into Italian. And I got the satisfaction of being paid for the translation from English into Italian of my textbook. But this was the kind of honorable thing for me, because they had been kind of reluctant, so this was the story behind the textbook. And then throughout the year, the textbook evolved to the second edition, and then McGraw Hill decided to cut off all the advanced titles, because I think they were purchased by some other companies and so then I had to look for a new publisher. And so the second and the third edition of my textbook, which, by the way, is behind here, it came out two years ago with my mentor, Professor Sciavicco and also two of the young guys at the time, Luigi Milani, who was my first PhD student, he is now an associate professor in my group, and Giuseppe Oriolo who was an associate professor working with Professor De Luca at University of Roma La Sapienza and when I think about the time when I was considering taking jobs and university positions in US, then I think at the end of the day, I can say that it is nice that this came out, because this is also a textbook which is a reference textbook in many, in many universities in US. And I think, you know, it is nice that it is been authored by a young person at the time who was seeking for a position in US, but now at University of Naples. So I think it is a way that just the loop has been closed in terms of all the if I think about the lecture notes that evolved into this textbook and all the story behind, I can say it is I am quite happy that, you know, this project evolved, and I am really flattered by the fact that my colleagues in US and Asia adopt this as a textbook for their courses. "
"Bruno Siciliano","Interviewer","And prior to that, what were the other textbooks that were available in Italian in robotics?"
"Bruno Siciliano","Interviewee","In Italian, none. In Italian, none. There was only a translation. There was a very good book by Fu, Gonzalez and Lee. Lee is, George Lee is a professor at Purdue University, he is almost at the end of his career, he is almost retired, and well he is a dear friend, and this was the only textbook which was available in Italian as a translation, but I have to say that the translation was quite awkward, because apparently it is been translated it had been translated, I mean, the part on sensors, and, let us say, intelligence was fine, but the part on mechanics and control was less fine, because the terminology was a little bizarre, because apparently it had been translated by someone who was a professor in computer science and he was less familiar with all the technical terms and the lingo of mechanics and control and mechatronics. So this was and I just come to know last week, that this Springer signed a contract with a publishing company in China so this is going now to be translated in the Chinese language, and I think they have an initial agreement for 2,000 copies. I think it is by Quian University Press, I can not remember the details, but this will be also in Chinese."
"Bruno Siciliano","Interviewer","And prior to that, I know one of the big textbooks was Lou Paul "
"Bruno Siciliano","Interviewee","Lou Paul, Lou Paul is the bible. Actually, Lou Paul, I remember, when I started my PhD, I was studying on it is one of the books. it is up there, the green one up there, behind the little robots. That is Lou Paul textbook, which was like the reference. This was a kind of precursor, because it came out in the early 1980s, so when I started my PhD in 1983, this was like this was the reference book and I remember the day in 1995, I was at a symposium in Herrsching, near Munich, and the symposium was being hosted by Garth Hertzinger, actually, DLR, this is the International Symposium of Robotics Research, which is like a top quality meeting. This is very, very and it was the first time I had been it is only by invitation and was the first time I was invited, and I remember the time in which I was at one of the sessions, and actually I was sitting next to Lou Paul. Lou Paul has not been attending robotic conference since the late 1990s, but I had met him. Actually I had visited him once after my stay at Georgia Tech, which was all the network contacts, so I visit him at his club at U Penn. and so I was meeting him again, and I was in a session, and a guy came with a little package from DHL and it was McGraw Hill, and they were delivering the first copy of I had goose bumps to remember this, episode, the first copy of the new textbook written by myself and Professor Sciavicco. And I opened the package, and there could not be a better time to open this package, sitting next to Lou Paul. This was quite a coincidence and then I decided to give that copy to him, because I mean, there is no better person. And then he came back later with some comments and he liked of course, you know, the textbook had been much influenced by at that time, there were already other textbooks available, because this was actually almost 15 years later after his first textbook. There were good books by Mark Spong and Vidyasagar. Mark Spong was a professor at the University of Illinois at Urbana Champaign, is Dean now at the University of Texas in Dallas, Dean of Engineering, and the new book is also with Seth Hutchinson who is also very well known in the community, as the current Editor in Chief of the Transactions in Robotics and a dear friend of ours, with Alessandro and others. And there was also a book by Hassan and Zlotin from MIT, and there were quite there was also a book by Hoshikawa from Kyoto University, a book from MIT Press. So of course my own textbook had been had benefited from all these other textbooks. I tried to give a sort of one thing, and of course there was the other, I forgot to mention, but I think it was the most widely adopted book, was John Craig, Stanford University. John Craig was a student of Bernie Roth at Stanford and his book was has always been one of the most widely adopted textbooks in the field. John is no longer in the research community. he is been working for adapting for SILMA which is a company in the Silicon Valley and I have seen him once in a while, you know, when he shows up to ISRR and all people come to IRIS because it is in San Francisco, so I mean, being a friend of Oussama, maybe I will see him again. So of course my own textbook had benefited from those textbooks in many ways. Of course, you know, being published later, it was also for instance, we had a toolbox, a MATLAB toolbox that came with the textbook. This was a nice addition for the fact that, you know, just MATLAB had become sort of the reference software in the field, and so I mean and so this was 1995, and now we are, like, 16 years later, and so this is the third edition of the textbook. And of course, in the meantime, those books, those successful books like Craig, and Spong, Vidyasagar and Hutchinson, are also in the third edition, and I think maybe these three books are have, like, the largest share of adoption worldwide, and I mean, I like the other two very much, because it is but it is robotics is not it is growing, but I mean, you do not write a textbook because you want to become rich, you want to write about, I do not know, internet or physics or basic subjects, but it is fun. I think the importance of a textbook in especially in the field is very important, and lucky enough in the community, we had this huge project, which is the Handbook of Robotics that I coordinated with Oussama Khatib, and That is more like for, I mean, just it is good for the people starting doing research, so it is more like "
"Bruno Siciliano","Interviewer","How did that project come together? "
"Bruno Siciliano","Interviewee","Oh, the story was started in 2002. At that time, we had a good contact with Springer. At that time the whole story started in Europe, because in Europe we had a Network of Excellence, funded by the European Commission. This was called EURON. EURON stood for European Robotic Research Network, and one deliverable of that project was a new series of books in robotics. At that time, I established a contact with Springer, because my textbook had just been moved from McGraw Hill to Springer, so I had a good liaison, a good contact with Springer, and then, together with a colleague from the University of Amsterdam, we were invited by Springer in Heidelberg. We went there, and that time, there were some robotics books published by Springer, but they were scattered in different series, like lecture notes in control information sciences, lecture notes in computer science, but there was no dedicated series to robotics So we sat together and we agreed to launch a new series of robotics books. And this is these are the books that you see behind me, the red and blue books. The series is STAR Series, STAR stands for Springer Tracts in Advanced Robotics and so the STAR series started in between the end of I think it was the end of 2000, the beginning of 2001, but even though it was European project, I wanted I had the ambition to make it international. And then I invited Oussama Khatib, because we always wanted to do something together. Okay, let us do the editorship of the series. So the editors are Oussama Khatib, Franz Groen and myself. And so we launched the STAR series. And the STAR rapidly became as the best selling series at Springer, so there was a really sound start with really good volumes. And a year later I got an e-mail from Thomas Litzinger, who is the Engineering Editor with Springer, and they had just launched the new series of handbooks. And he said, are you interested in writing a handbook on robotics? And I said, oh, That is huge, a handbook is like an encyclopedia, That is no, That is and then I but I was kind of intrigued by the idea, it is like this will be like reference in robotics. And then I just, let me think about, and then I decided, I will call Oussama. So I called Oussama. I remember I was taking the original phone call, I was about to board a plane, as often, especially since the year 2000, and I call him from the airport, and I told him, should we do it? I just I wanted to talk to him before. I could have forwarded the e-mail, but I think it was something that I wanted to tell him in person. So I called him and I say, should we do it? And then our initial answer was positive, and we met in Washington, D.C. actually in Crystal City, because ICRA 2002 was there, so we met with Oussama and the Engineering Editor, so we went to lunch to a nice Italian restaurant, and this was the, you know, like the first stone of the handbook, and we decided to start working on this. And so, and these were six intensive years of work from 2002 to 2008. In my e-mail folder for the handbook, at the end of the project, I was counting something like, I think, 11, 12,000 e-mails stored, which, I mean the first three years was kind of slow, but I mean, I think this was an incredible load also of coordinating all the authors, but I think it was kind of recognition for the whole community, because I think altogether, we wrote a kind of milestone, and it is a kind of piece of 50 years of history of robotics and also our plan is to update the handbook and to work on the second edition to appear in 2013 with multimedia attachment. So the handbook was also, for me it was a way to it was an opportunity for a further growth, because there were some fields in which I was not so familiar and so the effort of coordinating all this group of editors and authors and also in terms of the international contacts, it was quite a challenge to get authors from different institutions, from different countries and often the case, from different schools of thought to work together, and because in many cases, it was the first time they were coauthoring something together, so it was a real challenge. And I think, in the and also there was a kind of peer review of all the chapters, and in the end, I think this was a nice service, that I think we provided to the scientific community, especially to those new to robotics, that they want to start in robotics. So even though, of course I attach it to my textbook and those research project, I think the handbook has been, and probably it will be, it will stay the biggest professional project I have I pursued in my career, I think. And it is nice that, you know, I had the privilege of sharing this with Oussama, because as I said, you know, we are colleagues, but also we are really, like brothers, close friends to each other, and I think there would be no better opportunity to do something together, other than then handbook. So I am happy that this has happened in my life, because it is an enrichment in all possible ways, you know, professionally and humanly and in terms of the friendship and in terms of, yeah, the really the opportunity of seeing all this gathered into this thick volume, which is behind, it is lying on the table, it is like a very thick tool. And I think I am kind of worried because, of course, a second edition will have some extension but I think we are already beyond the physical bound of having all this into one volume, so I do not know how it will work. But maybe, I do not know if we can go only electronically, because of course the way to go is like electronic publishing and in fact this has been I was getting the figures from the publisher last month, and apparently this has been the book with the largest number of downloads electronically from the Springer website, because the people find it useful to download one or more individual chapters, because they are written in a kind of self contained way, so like whoever's work is willing to start, I do not know, research in medical robotics, come here and the best chapter written by Russ Taylor at JHU Johns Hopkins University and Paolo Dario at the school of Sant'Anna, they are like two of the coauthors of this, so in a way, the authors were clearly selected, possibly to the best people, and we were very surprised that everybody agreed with it is a lot of work, of course, but I think once we got a critical mass kernel of the top scientists, it was easy to recruit the others who were missing, because in a way, they felt they want to be part of the venture, and it is all in here, so it is good. "
"Bruno Siciliano","Interviewer","Great, great. Just to go back to the textbook a little bit, subsequent, have there been other Italian language textbooks, or is most of the robotics in Italy being taught in English, or Italian?"
"Bruno Siciliano","Interviewee","Right now, I am teaching two courses. One is called Control of the Robot, Robot control, it is in Italian, and the other course is, it is titled, Advanced Robotics and since three years I have been teaching it in English. What happens is, so the first course is compulsory, for all the students, in automation engineering, the second course is elective, so only the students who are really willing to do a thesis in robotics, they choose advanced robotics. But what happens is that most students decide the book is available both in English and in Italian, but most students decide to buy the book in English because it is also a good opportunity for them to know the technical language in the field, because one way or the other, They are going to work by using English in their professional career. I have to say though, that Italian, like German and French and Spanish is a kind of major language, in the sense that most textbooks are either translated or available directly in the mother language, whereas in countries like The Netherlands, or Denmark or Sweden, it is often the case that even at the masters level, the books are all in English, and even the courses are taught in English. So I had having decided to write a textbook I could not refrain from writing also in Italian, but in my mind, I always wrote first with an English cut. You know, I had in mind to write a book for the international, and also for the if you wish for the Anglo-Saxon university system, because the Italian language is also different and it is much more flourished, and the sentences are longer and the style of writing is completely different, so even when I was I mean, the Italian version of the textbook is quite unique if you compare, even with the technical books in Italian, because it is intentionally crisp and short, with short sentences, because it was actually conceived as a translation from the English language, and I think the students, they like it this way, because Italian is a language I have always live into myself, also being a Neapolitan with a sort of open character and friendly and social, so I used to say, especially to my friends in Germany, that when I work, I am very German, off work I am very Neapolitan. So I am living this kind of dichotomy into my soul, into my innest brain and feelings, because I am very German, very well organized when I work, but clearly, you know, just being born in this city, and having grown up in this city, living in this city, I very much have a kind of open spontaneous and haptic personality, so I live this kind of blend, which in a way could be reflected about the technicality of a language like English, which is almost like a computer language in many ways, and actually, I have to say, I have to confess, that for me, it is easier to give a talk in English than in Italian. I mean, just my colleagues, my friends have been telling me that when they come to a conference or a talk, or even the class, a lecture, it is easier for me to in English, because it is kind of technical language, whereas in Italian, I think I I think I am consciously concerned about using the most beautiful Italian and the richest and the most flourished, because you can talk Italian at very at the different levels, and to talk in a kind of elegant and flourish and appealing Italian, it is not it is by no way easy. And so it is even more difficult for a technical field like robotics, so I am teaching both in Italian and English, and I forgot to mention that we also have a masters here, starting this academic year, so the first masters has taken place. it is actually, the word masters is different from master of science abroad, because a masters here, is a sort of a specializing one year course after the lauria, which is equivalent of the master of science. So in order to access our masters, you must already have a master of science of the equivalent of a lauria, so this new master of this new masters in robotics intelligence systems, all the courses are in English, the courses, the labs and the seminars, because we also have students coming from abroad. So the whole program is in English, and all the interaction by e-mail with colleagues, and we have a scientific board, is in English, because you know, it is meant to be a sort of international masters for the foreign students, and we have a few foreign students that are studying and are doing this masters here in Naples. So at the end of the day, of course if I go to a sometimes I have given public talks to schools, because robotics is also important to take it to the schools and to the younger generations. Two years ago there was a huge science event here in Naples. This is an annual event which is called, Futuro Remoto, literally translating, Remote Future. So it is usually a way to approach people to science and future, and the 2009 edition was devoted to robotics, to robots. We had ASIMO, we had the show with the ASIMO humanoid robot and so Oussama came to Napoli for the grand opening, and we had the opening with a crowded hall of more than 3,000 people and a lot of kids from the schools, and we gave this talk. I talk in Italian and Oussama, of course, talk in English and I was translating for the audience. But other than literally translating, I was summarizing piece by piece what he was saying, otherwise it would become boring, you know, like the literal translation. Also because he had a lot of pictures and videos, so it did not really need also because it was a kind of dissemination talk, not a technical talk by any way, and then I remember, of course, people knew that there would be the ASIMO show, but I was instructed by the ASIMO team during my talk to simulate I had I had cough. I just stopped talking, I had a dry throat, and I was coughing and then I was asking one of the girls, one of the hostesses, like, to bring me a glass of water. And from the backstage, ASIMO came out and served me a glass of water. And even if I had tried this in the backstage, I was I got goose bumps, because with this kind of live 3,000 people and ASIMO was slowly walking to me, just bringing me a tray with a glass of water, and it was compliant enough, I pick up my glass of water, and I drank it, and I remember, like, it was my mother sitting on the front row, and she saw this robot and she told my kids, I think there is a child inside the suit, because ASIMO looks like an astronaut. I think this is not a machine, there is a child, there is a person, a human being inside the cover, because ASIMO is quite natural. But this is a sort of kind of mind storm, because in the manufacturing, and in fact, I think some of the yeah, some of the big the biggest European robot the biggest robot manufacturers worldwide, are from Europe and Japan. Surprisingly enough there is no big robot manufacturer in US, despite the fact that robots, as I was saying earlier, were introduced first in US. For some reason the industrial robotics industry was not nurtured in US, and it was soon the case that the attention was more toward, let us say, service robotics and not the traditional industrial applications. I mean, nowadays, I mean, like, two thirds of the world market is still in industrial robotics, although there are studies in the sector that foresee that in 20 years from now, two thirds of the market will be in service robotics. Service not only for advanced new industrial applications, other than the typical automotive, because most of the market is in the car industry, both for the assembly and for the motor parts, and more recently, for the automotive, all the intelligent system, like parking facility, you know, it is the concept of drive by wire, you know, smart cars and smart roads, autonomous vehicles or semi-autonomous vehicles, and things like this. So going back to Europe, we had this strong robotics and automation tradition. But in a way, I felt that in the late 1980s and early 1990s, we were a little, I think kind of lagging behind the most advanced research in US on field robots and studying around that time in Japan on service robots, because the Japanese started investing in the middle 1990s in their humanoids project or approaches where they were developing biologically inspired robots, like, let us say, zoomorphic like the robot dog or the robot seal, Paro, because I think it is a kind of cultural, and also historical and even religious issue behind, because the Japanese have always been convinced that a machine, to be accepted by humans, must have the same shape and appearance of humans, so That is why they have insisted so much in developing a biologically inspired machines. When Sony made AIBO, the robot dog, available, they had orders on internet in Japan, and they sold 2,500 pieces in a few hours. It took six months in the rest of the world to sell the same number, the same amount of pieces. Because I do not think that, in the western culture, we are prepared to interact with a machine that has the appearance, that has the anthropomorphic or kind of zoomorphic appearance. I think our relationship with the machine is different and we like machine to be a machine and to be clearly distinguished from the humans. So this is one issue and I think Europe had not found yet its way toward advanced robotics. There were some applications of field and service robotics, but in a way they were not mature enough. Things started changing in the middle 1990s, also, I have to say, thanks to the financial support of the European Community, because robotics became one of the topical areas for funding and we had the opportunity of carrying out research at the European level, and to cooperate with partners from other countries, because before, there had been some success stories, only on a local basis. For instance, there was a huge project being created after BLR, that took to the development of the lightweight arm that was manufactured by KUKA later, but this is a local success story between BLR and KUKA, which is kind of local reality, and so was the case for ADB in Sweden, with Lund University and also so was the case for us in Italy, working in consulting and working in close cooperation with Comau, we designed the complete control system for the third and fourth generation controllers for Comau and so there was kind of local realities. But I think we were lacking a kind of inter inter-lab cooperation, and this was possible, thanks to the support of the European Commission. At the same time, there were some scholars, some researchers who had gained PhD, mainly in American universities and they came back to Europe, and so there was a kind of, I think we were in need of a sort of generation turnover, change of generation, and those bright minds with PhDs in US universities, they came back and they started new labs around in Europe. "
"Bruno Siciliano","Interviewer","And who are some of those names that come to mind?"
"Bruno Siciliano","Interviewee","Well, there are well, there are several. As I mentioned earlier, one of the 1959ers is Roland Ziggurat, with currently Vice President for Research and Technology at ETH in Zurich, is "
"Chuck Thorpe","Interviewee"," and so tell me, you are familiar with Newell and Simon still active and McCarthy and Minsky coming by to visit, so when I was a young graduate student, the pioneers of computer science were fading from the scene. Eckert and Mockley were still alive, but were on their way out. had been gone for a number of years. Pioneers of AI were still teaching courses every day and I got to take courses from a couple of them and the pioneers of robotics were still inventing the field."
"Chuck Thorpe","Interviewer","Yeah, I got to email Simon a few times. Worked on the encyclopedia kind of science family too."
"Chuck Thorpe","Interviewee","Simon was this towering intellectual figure that you did not want to disagree with. I was once at a computer science faculty gathering and started to talk about Joshua Chamberlain who was the hero of the Battle of Gettysburg. He held a little round top and was a professor. By the time he retired, he was president of Bowdoin College and he had taught every course in the curriculum except for math and Herb looked at me and said, So what is wrong with math? Herb was that way. He was a founder of the business school, a founder of the computer science school, a founder of cognitive psychology, lectured in philosophy department, lectured widely across the entire university. He was just that kind of a polymath. Interested in everything. Newell was not quite as broad as Simon, but he was still very broad and respected across the university and he was a football player with a bad back, so We had be having a faculty meeting like this and he'd be standing up against the wall with his bad back. you would hear this voice booming down from above you and it was both physical and intellectual giant telling you what you should do and we all sat there and looked up to him again physically and intellectually and did what he told us to do. "
"Chuck Thorpe","Interviewer","There has been a lot of research about how people respond to voices that come from higher above."
"Chuck Thorpe","Interviewee","A voice from above, yes. Yes. Well, where should we start?"
"Chuck Thorpe","Interviewer","Well, why do not you start by telling us where you were born and where you grew up? Do we want to do we can do that again."
"Chuck Thorpe","Interviewee","We can do the crucial papers later."
"Chuck Thorpe","Interviewer","Okay. Where you were born, where you grew up, and how you got into school or robotics or both."
"Chuck Thorpe","Interviewee","I was born in Michigan, but I sort of grew up lots of different places. My father's a surgeon. In the different parts of his surgery training we lived in Michigan, Illinois, Texas, Dover, Delaware, eventually Brussels, Belgium where he studied tropical medicine, and then my father spent 30 years in the Congo which became Zaire, which became the Congo where he ran a hospital. So I spent eight years of my life out there, seven years as a kid and a year out there teaching high school. I went to school as an undergrad expecting to be a doctor like my dad. Went to North Park College in Chicago and I got tired of memorizing holes in skulls and discovered computers and thought that those would be kind of exciting, but did not quite know what to do with it. I was backpacking the summer between my junior and senior year with my chemistry professor and my psychology professor and my psychology professor said, So what are you interested in studying? I said, I think artificial intelligence. Oh, he said. You ought to go to Carnegie Mellon. They have this guy named Herb Simon who just won the Nobel Prize. I thought cool. I better go look up Carnegie Mellon and find out about it. Of course that was before the internet, so you have to go down to the library and look up Carnegie Mellon. I found out about Simon and Newell and all of that cool stuff. Applied for graduate school. Was quite fortunate to be accepted. Showed up in August of 1979. At Carnegie, when you are accepted into computer science, you are accepted into the entire department. Not to a particular advisor and we had the immigration course where each of the professors stands up and says, I am so and so. I work on this and I am looking for a couple of graduate students to join me. it is a good way to get the breadth of the entire school pretty quickly and a good way to start the match process. Raj Reddy stood up and said, I am thinking of starting a robotics institute. I said cool and I signed up to go to work for him. Raj, it turns out, was even smarter than I thought. He had decided to start the robotics institute, but was smart enough to convince the president of the university, Dick Siert , that it was Siert's idea, not Raj's idea to start it, and he, Raj, would let his arm be twisted into running it if Siert would go out and raise all the funds for it. So Siert thought this was great and went out and talked Westinghouse into funding our first industrial contract and Raj got the Office of Naval Research and Robo Choko convinced to fund the first government contract. So those two contracts hit about the time I became a graduate student. Now if you wander around here and talk, Lee Weiss came in in electrical engineering. Jim Crowley who is now in Grenoble came in electrical engineering. Each of them will claim to be the first robotics graduate student. I will claim to be the first one who went to work for Raj and joined the robotics institute. So the three of us all became robotics graduate students funded by the robotics institute in 1979 and pursued our careers from there on out. When we started the robotics institute, the entire institute could meet in Raj's office because it was just Raj and a couple of graduate students, but it expanded pretty rapidly. Jerry Agan came in to do industrial vision. He had been at SRI doing the world's first commercial computer vision system which may be the world's first commercial artificial intelligence system. The very simple binary vision system that had some pretty, in retrospect, obvious applications. Black chocolates coming out of the oven on a white conveyor belt, a nice binary vision system that could look down there and tell a robot arm where the chocolates were to pick them up and stack them so you did not have I Love Lucy women trying to load chocolates into their trays. Jerry came here early on. We attracted people like Art Sanderson who was an electrical engineering professor to be part of the robotics institute and one of the early hires was Hans Morevec and Raj assigned Hans to help me, so Raj and Hans were the co-advisors for my thesis. Mark Rayberg came in pretty quickly. Brought him in from Cal Tech to build hopping machines here. After a couple of years, Takeo Kanati who had been here as a visitor was brought back then as faculty and Matt Mason came over from MIT. So Raj, Hans, Takeo, and Matt were my thesis committee and I learned a lot from those guys. If you look at the directors of the robotics institute to date it is sort of Chuck Thorpe and his thesis committee because it was Raj and Takeo and then me and then Matt. It was fun to work with those guys. I have been working with those guys now for 30 years and I continue to benefit from them. Brief diversion away from robotics, Raj was my advisor. One day he called me up out of the blue. In fact, I was on a trip in China, and said, How would you like to go to Qatar? and I said, You mean like tomorrow? Oh no, no. He said, You got lots of time. I said, Well, let us talk about it when I get back to Pittsburgh. Raj had become an advisor to the state of Qatar on how to wire the entire country. They liked his advice so much that they said, we are thinking of setting up some universities. Do you know anyone who would like to come over here and teach computer science? He said, Sure. Carnegie Mellon would, but computer science is too small. Why do not we do two majors? How about computer science and business? They said, Fine, and so tapped me to go and start the Carnegie Mellon branch campus in Qatar which is what I did 2004 to 2010. I happened to be in Qatar and Raj happened to be in Qatar on a visit when we heard they had won the Von Noiman prize. So I threw a little reception for him and invited the people high up in the Qatari government who he advises and in my introductory remarks I said, You know, when I was a graduate student, Raj gave me invaluable advice, but he would walk into my office about once a month and say, What you should do is,&apos; and he'd have a whole other thesis for me. I had to say, Well, thank you, Raj, and the trick to dealing with Raj is to know which of his advice to pay attention to and which to file for later use. As dean in Qatar, Raj would call me up about once a month and say, What you should do is, and I would say, Thank you Raj, because it was invaluable advice, but I already had a campus to run and half the time he had ideas for other campuses I should go run. I have caught on that he does the same thing to entire countries. He calls up the sheikha of Qatar and says, What you should do is, and all my Qatari friends are sitting there nodding and smiling. Raj, at the age of 70-something, still has so much energy and so many projects for graduate students, for campuses, for entire countries, it is fun just to watch him and follow him around and I think he will never retire and even if he does, we have a lifetime worth of graduate theses and campuses and countries to go work on. So it is always fun working with Raj."
"Chuck Thorpe","Interviewer","So you came to study computer science AI and then "
"Chuck Thorpe","Interviewee","Came to study computer science AI. As part of that, Raj formed the robotics institute. At the time it was an interdisciplinary research institute. So you would still do your degrees in individual places, either in electrical engineering or in computer science, or oddly enough in the business school. Our business school here is way over on the extreme of being quantitative. If you think about business schools in general, there is the Harvard model where you read case studies and there is the Carnegie model where you do simulations and analyses and operations research and so forth. That is the heritage of the founding of our business school. Our business school was founded by one of the Mellons who was a general in World War II and was so frustrated with the difficulty of doing logistics that he said logistics should be a science, not an art, and he formed the graduate school of industrial administration, which for many years did not even give an MBA. They gave a Master's of science in industrial administration and one of the founding professors was a guy named Herb Simon. So our business school does factory layout and logistics and so forth and some of the early graduate students who did their Ph.D.s funded by the robotics institute lived in what is now the Tepper School and got their Ph.D.s in business. So I stayed in computer science and did my Ph.D. out of that. Jim Crowley, Lee Weiss did theirs out of electrical. Steve I will think of his name. he is now a dean in Singapore did his out of the business school. Mark Fox did his out of computer science, but with a joint appointment in the business school and so forth and so on."
"Chuck Thorpe","Interviewer","What was the first project you worked on as a grad student?"
"Chuck Thorpe","Interviewee","He sent me to work with Hans Morevec working on mobile robots. Hans had built a mobile robot for his Ph.D. thesis at Stanford that would take a series of pictures, use stereo vision to see where obstacles were, plan a path, move, and it moved so slowly. It moved about one meter every 15 minutes. It was such a slow motion that when he ran it outdoors in the 15 minutes between taking pictures, the sun would move and the shadows would move and in fact his system locked onto these nice sharp-edged shadows and saw that they were moving and saw that the real objects were not moving consistently with the shadows, decided it had more confidence in the shadows than in the real objects and threw out the real objects and locked onto the shadows and ran over his chairs, etc., that he had outdoors. It was a great success. Nobody else was moving at all using stereo vision, but it was very slow. So I said, You know, we ought to be able to improve the performance of that and improving the performance of that will undoubtedly show some interesting scientific ways that will be worth a thesis. And so That is what I did. Instead of 15 minutes, it was more like 30 seconds between moves and it was more reliable and it had some more interesting path planning and so forth. So that was my thesis. Hans was the director of that lab. Alberto Alfez and Larry Matthews were both in that lab and They are now off at JPL doing great things and I stay in touch with those guys."
"Chuck Thorpe","Interviewer","Was this funded by either of those two initial "
"Chuck Thorpe","Interviewee","This was funded by the Office of Naval Research. One of the shocks of my graduate student career was sitting there as a grungy graduate student wearing my jeans and t-shirt, hacking in the lab, and hearing a rustling at the door and looking up and finding Raj, the director of the institute, and Dick Siert, the president of the university, fighting over who got to hold the door open and in walked this admiral in his dress whites with his rows of ribbons on it. Nobody had told us we had a sponsor visit coming and we have empty pizza boxes and half-drunk cans of Coke and wires hanging out all over the place and did not necessarily have a demo ready to show and in came these guys. That could've been Robo Choko who was our first founder, but it could've also been the second funder from ONR was a guy named Brad Mooney and I have run into Admiral Mooney several times since then. He remembers visiting our lab, so it could very well have been him. Mooney was well, he had run the deep submergence rescue vehicle, DSRV, the one which, among other things, picked up the missing H-bomb that the US jettisoned off the coast of Spain. Mooney, as the head of the Office of Naval Research, was the publisher for the Naval Institute Press. Naval Institute Press wrote these dry tomes on sediment analysis off of the coast of Japan. If they were lucky sold 1000 copies. They thought they should maybe get into fiction publishing. One day they had an insurance salesman walk in with an idea of a book about underwater submarine warfare. They thought cool. Then they read the book and they thought, Wait a minute, this is too good to have been written by an insurance salesman. He must've had an inside source. let us make up some questions and see if we can catch him off guard next time he comes in and We will figure out who really wrote the book, and he came in and they said, So Mr. Clancy, about this Red October, have you ever considered publishing a book about say deep submergence rescue? He said, Oh yeah, that'd be cool. You could make this happen and you could do this and you could do this. Say, Admiral Mooney, did not you used to operate the deep submergence rescue vehicle? They decided Tom Clancy did know all of this kind of stuff and they went ahead and published The Hunt for Red October, which outsold all other volumes that they ever published combined and was so popular he went off and found a more mainstream publisher for the rest of his work. So that is admiral Mooney and That is one of our early funders in the robotics institute. Westinghouse, which was our industrial funder, they funded some of the early work here and I got to go on the first robotics plant trip. Westinghouse was interested in a bunch of things. Could we manufacture better light bulbs for them? Could we do quality testing? The first plant trip was to a plant that made turbine blades. This is one of the periodic downturns in the US electrical generating industry, so instead of selling new steam turbines for electrical generation, they were refurbishing steam turbines and someone would take down a steam turbine for inspection and would find one cracked blade and they would need one blade done now and they were losing a million dollars a day while the steam turbine was out of commission. A steam turbine blade is a long thing. Some of them are seven feet long with a complicated twisted, tapered airfoil shape and a big root and They are traditionally made in a They are stamped in a forge which takes days to set up and then machine to get all of the fine shape and cleaned, etc., and if you are building a thousand blades, you do not care if it takes you a day and a half to set up the stamp system, but if you want to build one, well, you have got all kinds of interesting problems. you have got could you build them in a different process that does not require setting up this stamp? How do you rerun your schedule for your job shop to get one blade through quickly without distressing the rest of it? Are there better ways to do the fine machining and the finishing so that you can do a better job of the inspection so you do not have as many blades fail? This triggered a whole batch of different projects, some of which live on today. Some of the job shop scheduling live on in things that Steve Smith is up to. The very first robotics plant trip, Jerry Agan, Raj, me, Mark Fox, a couple others, Paul Wright who is now off at Stanford, I think. We all went and piled into a Westinghouse turboprop and took off to go down to Winston-Salem and climbed up to altitude and it blew an engine right there, thereby demonstrating the importance of reliability in turbines. This was not a steam turbine; it is a gas turbine, and thereby perhaps endangering the entire future of the robotics institute. Turned around, came back into Pittsburgh, landed. No problem. During that time when we were circling, coming back in to land, I found out that Raj had spent part of his early career as a fighter pilot for the Indian air force, which I had not realized. Anyway, so I was not part of that research project, but I watched some of that early stuff and it was kind of interesting thinking about the industrial side of it as well as the mobile robot side. Those two themes have continued for the rest of the duration of the institute. Mobile robots and industrial automation. Somewhat to my surprise, the mobile robots have grown a lot faster than the industrial automation part of it and that has been the big thing that the robotics institute has been primarily known for. Jumping ahead, 1984, Takeo Kanati said, So what are you guys interested in? DARPA has asked us for some ideas what they should do next. I said, Well, I am interested in outdoor mobile robots. It turns out that was the right answer. DARPA was starting a program called strategic computing. You guys may want to talk with Clint Kelly who was at DARPA and putting that program together and has since retired as executive vice president of SAIC and still sits on our advisory board and other advisory boards. DARPA wanted to say let us have some revolutionary over-the-top new ways of having massively parallel computing, the thinking machine. The butterfly at PP&N, etc., and if we had this great new computing it should be useful for all kinds of different applications. let us pick oh, say three applications. Why three? Well, one to keep the Army happy, one to keep the Air Force happy, one to keep the Navy happy. The Air Force one was an intelligent copilot and a lot of it had to do with speech understanding so that a pilot of a single-seat aircraft could speak and have the system understand what he was up to. The Navy was fleet management and weather forecasting and so forth. The Army was autonomous ground vehicles. So they were launching the autonomous land vehicle project. So as a graduate student, I was busy helping write the proposal for what we would do with autonomous land vehicles. I defended my thesis in September of 1984 and Raj came up to shake my hand. He said congratulations. I was thinking I was going to take a couple weeks off to figure out what I wanted to do next. He said, Congratulations. What you are up to next is a meeting in my office starting in five minutes where we are going to talk about autonomous land vehicles. That was my break between finishing my thesis and starting my post-doc. And we had submitted the proposal for what was to become the Nav Lab in August. We had not heard back yet, but Raj said, let us get started anyway. We heard back pretty quickly that they wanted us to work on road following, so we built a series of vehicles to take outdoors and to bounce around off road. We had worked on vehicles until then. My thesis was still start-stop, start-stop, and our vehicles still had off-board computing. Now remember this is 1984. State-of-the-art computing was a VAX 11784 which was oh, about the size of the wall, maybe eight feet long, maybe eight feet tall, a couple of racks with whole million instruction per second processing power. A whole a VAX meant yeah and an attached digitizer that took up a whole rack. So the robots we were building were sort of the size of a table and the computer was sort of twice the size of a table, so we all had long umbilical cords. We said, All right, if we are going to go outdoors where we can not have an umbilical cord and if we are going to carry the computers with us, we need to have a real truck. So we built Nav Lab 1 which was a Chevy van and it needed to be that big because we wanted to have onboard sensors and onboard computers and onboard power supplies and onboard graduate students. I wanted my students to be right there rather than back in the lab for a couple of reasons. If there is a bug, they could be right there and they could fix it and then they could keep running the experiments. They were highly motivated to have high-quality software because they were going to be, as the saying goes, first at the scene of the accident. You write much better software when you know you are going to be riding on and very importantly when you talk about gut feel, if you have got an instability in your low-level controller and you are riding on the vehicle and it is going down the road like this, it gives you a gut feel that you better fix this and now. So we loaded this up with at the time Sun 2 workstations, loaded up with graduate students, and took it out and really had vehicles running continuously in the natural outdoor world for the first time and that was a big deal. It was a lot of fun to be able to do that. Also because we were not tied to an umbilical cord, we could run here in the park. We could run out on the streets around here. We could take it up to my house and run it around there. We could take it to the local slag heap and run there. We could run off road, on road, really start to discover what it was like to run in the outdoor world. "
"Chuck Thorpe","Interviewer","Did you need some kind of special permission to run those kinds of vehicles around?"
"Chuck Thorpe","Interviewee","We never had special permission to run those vehicles. We always had a safety driver sitting there and if something went wrong, we had a great big red button. You just hit that and you can take control or we deliberately designed the steering motor to be under powered so that you could overpower it and the amp would sense that and fall and you could take over and steer. We had the police show up once. When we were running it in my neighborhood, I think the neighbors were not sure what all of this noise was and because it had loud generators and stuff like that and so the police came. We put them on board and gave them a ride and they were not quite sure what to make of it. We did try to get permission to run in the drivers' test facility for the City of Pittsburgh because we thought here is a nice place. it is got parking areas where you can do autonomous parallel parking and they denied permission on that. I think they did not really believe that we had an automated vehicle. I think what they thought is these guys must be from a driver's ed school and They are trying to build very accurate maps so that they can teach people how to take the test without really knowing how to drive. So that police did not trust us enough to do that. Other than that, we have never had any issues with that."
"Chuck Thorpe","Interviewer","How many grad students did you have in the truck?"
"Chuck Thorpe","Interviewee","About the most you could squeeze in at a time was five and so that was about the most that we would have working on it at the same time. For instance, one person working on the laser scanner, one person working on the road following vision system, one person working on the path planning system, one person working on the system software that tied it all together, and then my job was to go fetch the donuts and to make sure that the other people all worked harmoniously together."
"Chuck Thorpe","Interviewer","How much of the architecture of that system was derived from your earlier work or Hans Morevec's earlier work?"
"Chuck Thorpe","Interviewee","Not a lot of it was derived from Hans's or my early work. Takeo Kanati asked us an interesting question at the beginning of the autonomous land vehicle project and our part of it which was Nav Lab. He said, Give me a unifying characteristic of all successful computer vision systems. Well, we had to think for a while because there were not very many successful computer vision systems by 1984, so We give up, Takeo. What are you fishing for? He said, They were all done by one person and now with the autonomous land vehicle, you have Martin Marietta as an integrating contractor and They are working with University of Maryland and Carnegie Mellon and Hughes and SRI and ADS and trying to bring in UMass and thinking machines and how are you going to have all of these people work together? That was the first time we really had to take a step back and say let us think about architectures, not just one person having it all in the back of their mind, but how do you build systems where all of this stuff can play together? How do you build interfaces so that one person's obstacle detector can talk to somebody else's path planner? So that was one of the roles that Carnegie Mellon played was thinking how the different pieces would fit together and supplying some of that system integration software to our friends at Martin Marietta. They were the integrating contractor on the big autonomous land vehicle. We were sort of a leading-edge integrating contractor figuring out how different bits and pieces can fit together."
"Chuck Thorpe","Interviewer","What were some of the strategies you used for that kind of integration?"
"Chuck Thorpe","Interviewee","Figuring out how it would all work together. We talked about a lot of different things. Should a robot have point-to-point connections or should it have a blackboard? How should the layers of the architecture be put together? Brooks was going around saying architectures are hooey. It should all be subsumption. You should just have something which can avoid obstacles and on top of that layer something which avoids obstacles while heading in some random direction and on top of that have something which avoids obstacles which heads in some random direction and the random direction is biased toward a goal. We said, Well that is a good idea if you have got artificial insects exploring some terrain, but if I am going down the road at 60 miles an hour, I do not want to be probabilistically right. I want to have something much more tightly wired that works when I am going down the road. So we had several different vision systems all of which tried to spit out the same description of the road to the road following software. We had a decoupling of the local navigation which was steering down the road versus the mapping and global navigation system which was telling us how to go down the road. That was important for the following reason. People who tried to put the whole system together into one coordinate frame, you were doing fine until you saw a landmark and oops, you all of a sudden saw a landmark and you said I am not actually here, I am here, and then your whole world jumped, but then you had to keep track of but the road was right here. Is the road over there and I am over here or was the road supposed to jump with me? We said no, no, no. We will keep those separate. We will have a local coordinate frame that says they saw an obstacle here. I saw the road here. I am steering this way and if we say, Oh, that obstacle is actually the landmark over here, oh, now I know that my entire local map is ten feet off from my map and I can keep around that ten-foot offset and any time I need to go look at the map I know to apply a ten-foot offset, but I have not tried to disturb the local map so that I know in local relative terms how to navigate to avoid that obstacle while going down the road. So those separations of the global frame from the local frame, those having multiple things feed into the local frame, the dealing with the asynchronous nature of landmark updates, obstacle detection, road detection, those were all some of the core clues that we had to look at. "
"Chuck Thorpe","Interviewer","And did that approach differ from other approaches at the time like say Aaron Stickman's and Germany?"
"Chuck Thorpe","Interviewee","Yes it did. Dick Munns had a very, very structured format where he had a small loop and then a bigger loop and then a bigger loop and a bigger loop and Coleman filters at every level. So something turning the steering wheel and wrapped around that was something that closed the loop to the vision system seeing the road and wrapped around that was something that steered the camera to look further down the road and it was very tightly integrated so that your prior probabilities for the road was going to be taken into account. The German autobahn rules for how quickly the curvature of a road was allowed to change. that is a wonderful structured approach if you have a wonderful structured problem. Some of our roads in western Pennsylvania do not follow the German autobahn rules. Some of our off road driving did not follow any rules at all. We did not think that we had those structured prior probabilities. We thought we had more asynchronous things coming and interrupting us. So we were not as focused on the structured environment and going at high speeds. We were much more open to lots of different inputs coming at different speeds. One of the things that I said at the time and I still believe, only half kidding, is that if you look at the way people design robot architectures, it reflects the structure of their research group as much as it reflects the structure of the particular problem. For instance, NIST, the National Institute of Standards and Technology. These guys do standards and technology and the Nazram architecture that Jim Albas did was one layer and then another layer and another layer and another layer and it was the millisecond layer and the 10-millisecond layer and the 100-millisecond layer and the second layer and the 10-second layer and the 100-second layer and it was sort of the millisecond layer was sort of looking a few centimeters ahead and the 10-millisecond layer was looking a meter ahead and the 100-millisecond layer was looking 10 meters ahead and the second layer was looking etc., etc., etc. Well, when you think about it, NIST is a government agency. you have got your researcher who is a member of a team who is a member of a group who is a member of a I forget how they have it division, branch, etc., etc., etc., and when Jim wants to get something done he assigns all right, here division. You have the problem of building the robot. Within the division, branch. You have the problem of building the 100-millisecond level of the robot. Okay, within the branch, you have the problem so this nested layer is how NIST is organized and That is how he organizes his work to get it done and so it is how he organizes his people. I did not want to organize the system like that partly because my graduate students do not organize into nice, neat hierarchies. I have got one who wants to work on collision of winds with stereo vision. One of them wants to work on collision of winds with a laser scanner. One of who wants to work on reactive collision of winds using sonar. These are going to be operating at different distances at different time scales. They do not fit into a nice hierarchy. I do not want to have an artificially imposed 10-meter barrier and 100-meter barrier when I have got a stereo vision system that works up to 25 meters. let us let it flow naturally at the limitations of the sensors. So I wanted to organize my architecture around what the sensors could do and what the graduate students could do and let different things flow in at different times. The other extreme was the Minsky extreme. Marvin Minsky wrote this Society of Mind book where you could read the book in any order because every two pages was a separate chapter and that was Minsky's theory as to how minds should work so that you have a whole bunch of experts and they sort of collaborate together to give the illusion of purposeful motion. I did not want the illusion of purposeful motion. I wanted my robot to go down the road and not run into things. So I wanted a little bit more structure than the MIT AI lab. Not the big hierarchical structure of Dick Munns or of Albas. So they had different philosophies and different organizations. Other players in this, have you talked with Red Whittaker?"
"Chuck Thorpe","Interviewer","we have been emailing him. did not get any response, but I was emailing him last year."
"Chuck Thorpe","Interviewee","Red was a professor here in civil engineering who had played around with robots for a variety of civil engineering applications and then Three-Mile Island happened and when Three-Mile Island came to us and said, Could you build a robot to go into the basement of TMI? Red stepped up to the challenge and built a very good, very simple but very reliable robot just to go in and take pictures of TMI. They liked that so well they said, Okay, could you go in and bring back wall samples? So he built a slightly more sophisticated robot to go in and drill core samples and bring back pieces of concrete from the basement of TMI so they could tell how far in the contaminated water had soaked so they could tell whether it was possible to decontaminate it by just abrading the top layer of it. That worked so well they asked him to build the workhorse. So he and his graduate student, John Bairs , built this monster stainless steel vehicle that could reach up 25 feet and rip things off of the ceiling and had high-pressure hoses, hydro jets that could cut through concrete and replaceable grippers to grab different kinds of things and all tether controlled, all beautiful polished stainless steel so it could be decontaminated. If you have not met Red, I have this theory that just like architectures sometimes look like the person, robots sometimes look like the person who built them. Red is a mountain climber and a gold-gloves boxer and a Marine. When he was in the Marines he played football for the Marines. I asked him what position he played. He said end. I said offensive or defensive? He said both. Red is 6 foot 5, 250 pounds, and when he talks about his robots he climbs up on the table and demonstrates how his robots are going to rip the ceiling down and he builds robots that can climb up on the table and rip the ceiling down and so forth. it is great working with Red. Red and his team was the mechanical geniuses behind Nav Lab 1. The first real outdoor mobile robot that we built. he is gone on since then to build, oh, I think probably over 100 robots and they have been in volcanoes, in Antarctica and in Alaska, in coalmines, mapping abandoned coalmines, all over the planet, in the Atacama Desert of Chile, in Devon Island north of the Arctic Circle. Of course in the DARPA Grand Challenges and the next one's going to the moon. If you can not talk to Red, you should talk to some of his students and colleagues and get Red stories. Get Red robot stories and get Red personal stories. He did box with an orangutan once."
"Chuck Thorpe","Interviewer","Did somebody see? Who saw this?"
"Chuck Thorpe","Interviewee","Red will tell you the story."
"Chuck Thorpe","Interviewer","Okay. "
"Chuck Thorpe","Interviewee","All right."
"Chuck Thorpe","Interviewer","Need to change tapes."
"Chuck Thorpe","Interviewee","Okay, where were we? I keep rambling on about other people and strange stories."
"Chuck Thorpe","Interviewer","No, this is great. With Nav 1, we discussed the architecture, right?"
"Chuck Thorpe","Interviewee","So, Navlab 1 let me get this straight it really came to life in about 1986, and my son was born in 1986, and we had contests to see when Navlab 1 was moving at a crawling speed, my son was moving at a crawling speed. When Navlab 1 picked up speed, my son was walking and learning to run. Navlab 1 got going a little faster, my son got a tricycle. I thought it was going to be a 16-year contest to see who was going to drive the Pennsylvania Turnpike first, because they were each progressing at about the same speed. Unfortunately, this really smart graduate student named Dean Pomerleau came along and built a neural network technique, which managed to be the most efficient use of the computing researchers that we had, and the most innovative use of neural nets at the time, so in 1990, he was ready to go out and drive the Pennsylvania Turnpike. ALVIN was a simulated neural net that you would drive for a few minutes, and it would learn. If the road looks like this, you turn the steering wheel like this; if it looks like that, you would turn the steering wheel like that. So if you trained it on the road that you were driving on, it was very good at spitting out steering-wheel angles, and he was able to outdrive the top speed of Navlab 1, which was about 20 miles an hour. We built Navlab 2, which was an Army Humvee, and Dean took it early Sunday morning and drove it up by 79 to Erie, Pennsylvania, and was able to drive, then, much faster. This was kind of revolutionary. People thought if you wanted to drive that fast, you had to have common filters and clothoid models of the road and detailed models of the dynamic response of your vehicle, and all Dean had was a simple neural net that learned, The road looks like this, you steer like that, and it worked pretty well. Now, it turned out that it worked pretty well. It had a little bit of hunt to it going down the road, so to fix that he had to have a little bit of a model that he built into it, and the model basically said, Okay, I know that if I am steering like this that what I am actually doing is headed toward a point up there on the road, and so the way to take out the lag is to record where these points are that I am headed toward, and then build a little path-follower that just tracks these points that I have going down the road. Dean went on to build smarter and smarter systems, and at some point said, You know, I am tired of having to retrain it. let us see if I can build a really smart system that figures out what the road looks like without me having to train it. And so he built a smarter system called RALPH the Rapidly Adapting Lane Position Handler. The acronym came first. He liked RALPH, and he had to figure out something it would stand for. And RALPH would look at the cross-section of the road and would say, Oh, you know, there is a dashed line here, there is a solid line here, there is a crack at the edge of the pavement here, there is a expansion joint here, there is a smear of the oil down the center of the lane here, there is a guardrail over here. All of those appear to be long, linear features that are pretty reliable. let us just track all of them. He put RALPH on a series of vehicles. It worked pretty well. He wanted something that was easier to drive than Navlab 2, which was this big, boxy Hummer, so he took his own Honda Accord, he put a robot surplus motor driving a belt to turn the steering wheel, he suction-cupped a camera to the rearview mirror, he put a laptop computer in there and plugged it into the cigarette lighter, and he had a robot car. So Navlab 3 was Dean's own Honda Accord, and that worked fine. Navlab 5, Delco loaned us a Pontiac minivan, and we put a extra truck battery in the backseat to power the computer, and hooked ourselves up to the cruise control, and, again, laptop computer and camera, and Dean and our student, Todd, took it from Washington, D.C., to San Diego, California. Why D.C. to San Diego? Well, they needed to get it to Denver to do a demo, and they said, As long as we have to get it to Denver, let us back up and start in D.C. And we are going to have to do a demo two years later in San Diego. let us just keep on going on out to San Diego so we can collect some video as to what the roads look like on the way out there. And as long as we are going out there, let us swing through Las Vegas and get an Elvis impersonator, and let us go through Hollywood and see if we can get Jay Leno excited, because he is a car buff. And so they did this series of stops along the way, and they were able to go this was in 1995 from D.C. to San Diego, 98-and-a-half percent of the way autonomously. This was their No Hands Across America run. The other one-and-a-half percent was things like new asphalt in Kansas, at night, with no stripes painted on it. Well, that is a challenge for a human. Given the cameras of the day, it was a even bigger challenge for the autonomous system, so they had to drive by hand. Or going through rush-hour traffic around Denver in a construction zone, they had to take over and drive by hand. But it really worked well, and it had some real scientific payoff. Driving in this part of the world, you are used to, Well, there is a painted line, and if it is yellow, That is the left edge, and if it is white, That is the right edge, and if it is a dashed line, That is the center line. And a computer vision system is pretty good at following a dashed line or a solid line, et cetera. You get out to Southern California, where they do not have snow, and they do not have painted lines; they have botstots . If you have not been to Southern California, you have these raised pavement reflectors. You can not put them on Pennsylvania roads, because the first snowfall, the plow would just scrape them all right off the road. Botstots are great for humans, but if your vision system is expecting painted lines, and you only see a dot every once in a while, you do not know what to do with it, so you have to tweak your vision system to deal with botstots. In Kansas, some of the gravel that they use to do their asphalt is red, so if you have a color-based system, instead of yellow-on-white or yellow-on-black, now you have yellow-on-red. So you got to learn how to deal with all of these kinds of variations in order to build a reliable vision system. The run in San Diego was important because, at the time, we were part of a DARPA contract and part of a DOT contract two DOT contracts. One of them was a driver warning system run-off road collision countermeasures, and We will talk about that in a minute. The big one was the Automated Highway System. Automated Highway System, the goal was to build fully automated vehicles that could drive down the road, and we knew that the demo for that was going to be in San Diego. there is a stretch of I-15 that goes through Miramar Air Base that has HOV lanes. In the morning, They are inbound; in the afternoon, They are outbound. During lunch and at night, They are not used, so they said, That is where the demo will be. And we went out and collected some data and discovered there were botstots, figured that our vision system could run pretty well on that, and worked on building better and better systems for that. Automated Highways was an enormous project. It was General Motors, it was Hughes, it was Delco, it was Bechtel and Parsons Brinkerhoff, and it was University of California, Berkeley, with their PATH program, and us. The PATH program those guys are, by nature, controls people, and they live in the crowded Bay Area, where you have got five lanes of traffic going each way, so their notion is, let us take over one lane and have it be a dedicated lane only for computer-controlled vehicles, and let us put magnets in the road, and let us have the computer-controlled vehicles all talking to each other, and all talking to a centralized control system. So it is. again, it is this nest of control loops: a control loop to control your own speed, and a control loop to control the headway to the vehicle in front of you, and a control loop to control a platoon of vehicles, and a control loop to tell this platoon what it should be doing, et cetera, et cetera, et cetera, and a control loop watching the buried magnets and controlling your lateral position a great idea if you can take over a lane for only automated vehicles, and then probably take over another lane so that you can have manually driven vehicles get up to speed and then merge, et cetera. Not a very good idea for Western Pennsylvania, where, if we have got two lanes going each way, you can not afford to take over one lane. We said, let us take the opposite approach. let us build our vehicles which are so smart that they can be automated even running out in mixed traffic mixed in with other vehicles. Of course, being robotics people and being perception people, this is a lot more fun than drilling holes and burying magnets down the road, so that was the approach that we built. For that, we built Navlab 6, 7, 8, 9, and 10. In fact, That is what these guys are. Six and seven were Pontiac Bonnevilles. Those were sweet vehicles because they had electronic cruise control, so it was very easy to tap into it, and General Motors gave us prototype electronically controlled brakes and electronic power steering to tap into. Navlab 8 was a minivan. We got tired of waiting for them to retrofit these vehicles, and so we just went down to the local Chevy dealer and bought a minivan. And 9 and 10, Houston METRO gave us full-sized passenger buses that we retrofitted and turned into robot buses. So our demo, we showed these five vehicles. We showed that we could use them in driver assist mode and in driver warning mode. Then we showed that you could hit a button and they became automated, and you would take your hands off the wheel. And they could talk to each other if there were other automated vehicles, so if one automated vehicle saw an obstacle, it would broadcast the location of that, and the other vehicles would be smart to change lanes. But our vehicles were smart enough to run mixed in with other vehicles. For instance, if a vehicle was using its radar to follow another vehicle and it was going too slow, it would say, You know, I would like to change lanes; use the vision system to say, Is there another lane next to me?; use the side-looking and rear-looking sensors to say, Is that clear?; because it was running with other vehicles, put on the turn signal these are polite vehicles; change lanes; and then pick up speed and pass the slow-moving vehicle. So we are working on all of this kind of stuff back in 1997, and it was kind of fun. More than kind of fun; it was great fun. We did the demo. Berkeley did their demo, we did our demo. The U.S. Secretary of Transportation came out. He chose to ride on one of our vehicles, partly because we had a cool demo, partly because we had buses and he wanted to demonstrate that this was friendly for transit. At the end of the demo, TV camera running, car's in the back. Secretary Slater, standing there, gave this wonderful speech. It went, in part, like this: Ladies and gentlemen, five years ago, Congress set us a goal to build the Automated Highway System. Today you see before you the first impressive steps towards that goal. Now the president has given us a new goal to balance the federal budget. And we said, Oh, no! And, in fact, That is what happened to Automated Highways. He said, That was a great demo, and we think that it is too long-term, and so we are going to redirect DOT to work on shorter-term funding. Well, the shorter-term funding is collision avoidance, and that was the other project that we were working on. DOT had people working on forward-looking collision avoidance, and lane-change collision avoidance, and intersection collision avoidance. Our task was single-vehicle lane departure collisions. If you think about people running off the roads, there are not that many collisions of that sort, but they tend to be deadly. A third of all fatalities are single-vehicle roadway departure. You fall asleep, you drift off the road, you wrap yourself around a tree. The lane-change merge ones, those tend to be fender-benders. The rear-end collision, they have designed crumple zones so that you bend a lot of sheet metal and you blow up your airbag and you walk away from it. If you wrap yourself around a telephone pole, That is pretty hard to survive that. So we did a lot of work on the human factors. We did a lot of work on the accident causes. If it turns out that you are drifting out of the road because you hit a patch of ice, well, warning the driver that you have drifted out of the patch of road because you are sliding on ice is not going to do any good. But it turns out that a lot of it is driver inattention, drivers falling asleep, et cetera. So we built a very nice system that could watch the road, and if you started to drift out of the road, warn you, and predict that you were going to drift out of the road before you even drifted out, and, even better than that, could watch while you were driving, and if you started to follow the telltale patterns of a drowsy driver, tell you that it was time to stop and get a cup of coffee. Dean spun off a company to build those kinds of warning systems, and commercialized that. His company was sold first to a Boston-based computer vision company, and now to a Japanese electronics company, and That is very rewarding to see this kind of stuff being out there in the market and starting to save people's lives. It also has a very funny personal tie. That little kid who was racing Navlab 1 just finished his Master's degree in robotics at Carnegie Mellon University, and now works for that company. His boss there is one of my graduate students, the guy who was in charge of building the architecture to merge this whole thing together. So when Jay, the senior guy who was interviewing Leland, my son, what kind of questions should he ask? Leland, how long have you been interested in obstacle avoidance and safety in robot vehicles? Well, Jay, when I was three years old and you had me drive my bicycle on training wheels out in front of your vehicle to see if your software could stop it, ever since then I have been a real fan of improving the reliability and safety of automated vehicles. It was a no-brainer interview, and it was very fun for him to get to work on that. So this is now a family mission to try to build intelligent robotics systems that can save people's lives."
"Chuck Thorpe","Interviewer","You mentioned that you had the Autonomous Highway System "
"Chuck Thorpe","Interviewee","Automated Highway NAHSC? National Automated Highway Systems Consortium."
"Chuck Thorpe","Interviewer","Yeah."
"Chuck Thorpe","Interviewee","AHS."
"Chuck Thorpe","Interviewer","You mentioned that you were working on a helper, like an assist."
"Chuck Thorpe","Interviewee","So the assist was the run-off road collision countermeasures part of it."
"Chuck Thorpe","Interviewer","And then there was the warning."
"Chuck Thorpe","Interviewee","And That is the warning part."
"Chuck Thorpe","Interviewer","Both of those were worked into the collision?"
"Chuck Thorpe","Interviewee","Yes."
"Chuck Thorpe","Interviewer","Okay."
"Chuck Thorpe","Interviewee","The warning part is interesting. How do you figure out what kind of warning to give a drowsy driver? There is a few places in this world we used the one in Iowa a driving simulator. it is like a flight simulator, where you have an aircraft cockpit in this thing that moves around in a big, graphic screen, only you have a car in this case, a Ford Taurus in this moving, shaking simulator with a big screen. So we would have people driving the car, and we would distract them ask a question like, Look for the Frank Sinatra 8-track tape, and there is not a Frank Sinatra 8-track tape, so They are looking down here input a simulated wind gust so They are drifting off the road, and then the system would warn and it would trigger an alert, and we would see if the person would react correctly to that. So, do you beep? Do you have a directional beep? Do you shake the steering wheel? Do you nudge the steering wheel? Do you play a tape of your mother's voice saying, I have told you it is time to wake up? I we did not know what was going to work. I thought sounding like an alarm clock would be bad, because someone who is drowsy would be reaching for the snooze button. It turns out that a beep is pretty good, that a directional beep is not that useful. We found that nudging the steering wheel helped, because the drivers learned, Oh, that means we should steer this direction. Our colleagues at Daimler-Benz tried the same thing in Germany and found the opposite: that if they nudged the steering wheel this way, their drivers reacted by counter-steering, which, of course, would pull you further into the ditch and make you roll over and not be a good thing. So what we have gone to, mostly, is just a beep. And you want to set the system so that it is sensitive enough so that, in normal driving, it sometimes beeps. So you say, Oh, yeah, sure enough, that meant I was getting close to the edge of the road. And so you program yourself to say, Yep, that beep means I am getting too close to the road; not so often that it is a nuisance, but often enough that you have learned and you have remembered. You do not want the first time that beep goes off to be the time that you have to react instantly; you want that to be a response that you have gotten used to. And we have eliminated the beep for some things. If the vehicle, all of a sudden, violently swerves, well, that may be because a moose just jumped in front of the road, and you are deliberately driving off the road, and the last thing you need is a beep going off during your moose-avoidance maneuver, so we suppress the beep for that; suppress it if you turn on the turn signal, because then you meant to pull off the edge, et cetera."
"Chuck Thorpe","Interviewer","In general, in these projects, did you have other collaborators that worked with you?"
"Chuck Thorpe","Interviewee","Other faculty?"
"Chuck Thorpe","Interviewer","Mm-hmm."
"Chuck Thorpe","Interviewee","Well, Dean Pomerleau, who had been a graduate student, became faculty and worked on that. Todd Jochem, who was with Dean on the No Hands Across America ride became a postdoc and worked on that with us. More on the off-road work, Marcele Baer has been our 3-D vision guy forever and ever. Tony Stentz has been our off-road path-planning person forever and ever, and Tony was a graduate student in the Navlab group who joined the faculty and came onboard with us. So, yeah, there is a big group of people that we work with all the time."
"Chuck Thorpe","Interviewer","I am curious about this demo in San Diego. You mentioned Berkeley. Who was leading some of the other demo research groups?"
"Chuck Thorpe","Interviewee","Well, what the Berkeley guys showed was eight cars running together, four-meter gap between the cars, and then showing how the cars could split up. So if this guy in the middle wants to exit at the next exit, you split, and then you let this guy change lanes, and then you merge back together again, and so forth."
"Chuck Thorpe","Interviewer","And who was doing that at Berkeley?"
"Chuck Thorpe","Interviewee","Steve Shladover, Jim Misener, We Bin Jong . They are the people who really ran that research project, and They are still there, and They are still active. They are not actually on campus. They are at the Richmond Field Station, which that gives them enough room to have a little track and bury some magnets in the ground, and so forth."
"Chuck Thorpe","Interviewer","What were the other big demos?"
"Chuck Thorpe","Interviewee","So those were the core demos that were part of the consortium. They also invited Toyota did a demo, Honda did a demo, Ohio State did a demo, Lockheed Martin did a demo. showing different kinds of technology. Ohio State was following a strip of metal put down with notches cut in it, designed to reflect radar. So they thought, This is cool. We will have one radar that will look for cars, and We will also, by the way, pick up this strip of tape."
"Chuck Thorpe","Interviewer","Who led that research group?"
"Chuck Thorpe","Interviewee","Umit Ozguner, which is spelled just like it sounds if you know Turkish."
"Chuck Thorpe","Interviewer","I do."
"Chuck Thorpe","Interviewee","O-Z-G-U-N-E-R. And Umit is still with DOT's They are scattered around, randomly."
"Chuck Thorpe","Interviewee","Yeah."
"Chuck Thorpe","Interviewer","Pretty much."
"Chuck Thorpe","Interviewee","And Umit is still there, alive and kicking and active. He and I were at a conference in Turkey in June. let us see. So those were the groups who did all of those demos. Each of the Japanese car companies has been working on various sorts of automated systems for a long time."
"Chuck Thorpe","Interviewer","Who leads those groups at Toyota, Honda, Mercedes?"
"Chuck Thorpe","Interviewee","I do not even know anymore. It was part of a big Japanese government push. They had their equivalent of the Automated Highway group, and that also has disbanded, and I have lost the links with most of the people over there."
"Chuck Thorpe","Interviewer","I know Mercedes' driver assist."
"Chuck Thorpe","Interviewee","Mercedes has done some very good work. The other group which has gotten a lot of press well, two other groups that have gotten a lot of press over the last month Alberto Broggi, from the University of Parma. he just finished doing a 10,000-kilometer run from Rome to Shanghai. Now, that is a cool run, and it encounters an awful lot of varied territory. We will not know until he starts to publish the technical papers what the real technical meat is. His first vehicle, the lead vehicle, was going to be automated where the roads were good enough for the vision system to work, but then it was going to be laying down a trail of GPS waypoints, and the following vehicle, which was following the lead vehicle either visually or by following GPS waypoints, was going to attempt to be automated as much as possible. So we have seen the press releases, but we have not seen the scientific papers to know how much as much as possible turned out to be. The other thing That is cool is that he was collecting all of the data, so he is got terabytes and terabytes of data, and now he is got to figure out how to index that and make selected samples of it available for the rest of the world. The other group that hit the press recently is the Google group. I do not know if you followed what they were up to."
"Chuck Thorpe","Interviewer","Sebastian Thrun, right?"
"Chuck Thorpe","Interviewee","Sebastian. Yeah. And Chris Urmson called me the day before that broke, and said, Look, we need to give the press the name of somebody outside to go ask questions of, in case they want an outside expert. We had like you to be that outside expert. We had like to explain to you what we did so that you can say something, like say, Well, those are nice guys.&apos; And so he told me a little bit about what they did, and they have done a remarkable job of building very detailed maps and models. Now, it is the Google group, and we are very grateful to Google, but we think of it as the Carnegie Mellon West group. Sebastian, of course, used to be here, and then went to Stanford and Google. Chris is a Carnegie Mellon person on leave. James Kuffner is a Carnegie Mellon faculty member on leave. If you go down through the list, they everybody except for one on that group either is a Carnegie Mellon person or has a Carnegie Mellon heritage, so That is our boys. And we are delighted that They are off with Google, and Google's given them the researchers to do really cool stuff."
"Chuck Thorpe","Interviewer","You said that the Automated Highway ended up seeming kind of too far away, but there is a lot of work That is going into automated vehicles, whether They are for civilian driving or for military purposes."
"Chuck Thorpe","Interviewee","Exactly. So there is a lot of the military robot work continues. The civilian work, if you go back to the 1939 World's Fair, GM had their booth of the City of the Future, and it was automated vehicles running around. Ooh, They are all excited. Then it kind of died down. In 1956, GM had the Firebird II, and this was. wow, is it a period piece! It has this glass bubble and aircraft-style controls, and the Fire the big tails of the back. And the vehicle was actually following a buried cable in the pavement, using these tube electronics with this big heat sink hanging out the side, and the videos of the artist's concept you have this family going down the road, the father wearing his coat and tie, and the two kids in the back, and the mother wearing her dress, and They are talking to the control tower: Control tower, this is Firebird II. It he says, You have permission to enter the automated lane. But part of the system really worked, and there was a big hoopla, and then the interest died down. It comes back around again another 30 years later, and there is this big push, and then the interest dies down. Part of it is that you get these visionary pitches, and they'd say, You know, but there is budget issues, et cetera. Part of it is waiting for the technology to get a little bit better each cycle. Part of it is limited attention span of the funders. If you had automated vehicles, you can do all kinds of cool things. You can eliminate accidents. We all know that 90 percent of accidents are caused, at least in part, by the humans, and you can make the system much safer. You can make it much more environmentally friendly. If you look at the number of hours that you spend idling in traffic, automated vehicles make for much smoother traffic flow, much denser traffic. If you sit there and you count the number of vehicles per lane per hour, the best you can do with human driving is about 2,000 vehicles. Two thousand vehicles at 100 kilometers an hour That is 50 meters between vehicles. It'd be very easy to have automated vehicles at half that spacing and still be very safe, and eliminate congestion, not have to pave over more lanes of highways. You could start to do lots of other smart things. You could have cars zip cars or station cars. You would not have to own your own car, but you could say, Oh, I need a car tomorrow to go to this particular trip. Could I have an automated car delivered to my door at 8:00 A.M.? And I will drive it as long as I need it, and then it can automatically go to the next person who is reserved it, et cetera. So there is lots of ways that you could use automated vehicles to reduce the number of cars that we have. So there is all of those kinds of things that are out there. What we have seen instead is the more incremental approach: let us take the vehicles we have, and let us make them smarter and smarter. let us make them more sensors, let us make them smarter control. So let us put adaptive cruise control on them. That works to a certain point. At some point, if you start to say, Okay, I am going to use adaptive cruise control to keep the gap to the car in front of me, I am going to use smart lane keeping to keep myself centered in the lane, all of a sudden, people are going to say, Oh, gosh, this car can drive itself, and They are going to take their hands off their steering wheel, and then They are not going to pay attention, and then the car better be 100 percent reliable. And you are not going to get to that 100 percent reliable unless you have a focused effort working on the fully automated system, and That is what we really have to have. Now, for military vehicles, that continues to be a very important problem for all kinds of different reasons. We recently had the 25th anniversary of the first demo of the autonomous land vehicle, and had a party to celebrate it, and had people from Martin Marietta, who were the integrating contractor who built the vehicle, and the different groups of us who contributed to it. One of the people who spoke there was General Rick Lynch, now a three-star general. Twenty-five years ago, Captain Lynch was this young combat engineer who was assigned to come tell us what the requirements were like for a real vehicle operating in real wartime scenarios. And he said, Sir, if you want to know what it is like to operate an M1A1 in combat, sir. you ought to read Red Storm Rising! Why, there is this place in there where They are bombing down on Germany, and they just rip the governors right off of the tanks, and They are flying down these dirt roads, and They are doing 50 miles an hour and, sir, That is what it is like to operate an M1A1 tank in combat, sir. Twenty-five years later, we find General Lynch a three-star, just back from his latest tour of Iraq. He said that in his last tour, he lost 156 men in Iraq, 130 of whom were doing jobs that should have been done by a robot. he is very serious about having robots do. not even the combat missions. it is things like robots carrying logistics; robots sitting up on a vantage point, looking for snipers. We know that the most dangerous job in the military is the scout. If you send a scout over the hill and the enemy knows that those are the people calling in the gunfire, and the scout is, by definition, going into an unknown place. If we had robots doing the scouting, if you send a robot out there and it tells you what it sees, great; if you send a robot out there and it does not come back, well, that is already told you something about what is happening on the other side of the hill. So there is a lot of those kinds of things that the military's interested in some of which look like combat, and some of which do not. There are, of course, these big ethical questions about robots, combat, particularly when you start putting firearms on them, and that is a whole, very legitimate set of things to think about. But There are a lot of unarmed roles for robots that are very interesting."
"Chuck Thorpe","Interviewer","In terms of the autonomous vehicles on the highways for civilian use, what are some of the hurdles that you see, in terms of law or social acceptance, and that kind of trajectory that you see it taking?"
"Chuck Thorpe","Interviewee","Let me tell you, first of all, what my group is up to now, and then I will come back to that. What we have been doing for a lot of years now is working for urban driving. So this is back to the warning system, but how could we do a warning, say, for transit buses? Transit buses are very, very safe, but they would like to be even safer, and they operate in crowded urban environments, and if you think about it, the rearview mirror on a bus has to be way up in the air so it does not clunk pedestrians in the back of the head, but that means there is a big blind spot underneath that mirror. So we have been putting sensors on buses all the way around, to tell bus drivers where it is safe to go and where it is not safe to go. And then you have to be smart about things like turning off the collision avoidance when you are sitting there with your door open, because it looks like, Oh, no! That pedestrian is about ready to run into me! Oh, he is not about to run into you; he is about to step onto the bus. So, those kinds of things. And it is been very interesting to work on that, because the crowded urban environments have such challenges, but, of course, That is where a lot of the accidents occur, so we have to be very good at operating in those kinds of environments. So that is a whole set of very interesting problems that do not require full automation, but the smarter your vehicle can be, the better off it can be in generating those kinds of warnings and advices. Driving in full automation has a number of social issues, some of which make sense and some of which make less sense. There are people who really like driving, who would love to have automated vehicles so that all of the other vehicles are automated so they can zip in and out among them in their manually driven vehicle. Okay, That is legitimate. You have to have people doing driving automated vehicles driving. People worry that automated vehicles might be expensive, and so only rich people could afford them. Okay, so that is a legitimate argument that says, Maybe we ought to put more of the intelligence in the infrastructure so it is supported by taxes, so it is available to everybody, and less of the expense into the individual vehicles so that they do become more affordable for everybody. If you have to build dedicated lanes for automated vehicles, then there is a question of who supports that. If taxpayers are paying for lanes that only people who can afford new cars can drive, that does not look very good. Maybe you build those on toll roads, and people who are willing to pay for the convenience of an automated vehicle are willing to pay for the additional costs of the toll road. If you had an automated vehicle that could drive itself to work, would you live even further away from work than where you do now, and if so, would you just cause more congestion, and if so, what are the social effects that would counteract that? Could you counteract that by making buses more efficient, and have personal mass transit? Could you counter that just by appropriate taxing and pricing strategy? So, when we studied Automated Highway, there was a technology study stream, there was a whole another stream studying some of those social and regulatory issues, and there was another very interesting stream studying precursors: What other high-tech things have happened in the past that we could learn from? For instance, if you go back in history, the elevator was around for 500 years, but it was deemed too dangerous to use for people, so they used elevators to transport food up to the Master's dining chamber without grungy servants having to walk up there, or to haul freight, or they did not trust people because they were worried about the rope breaking. Mr. Otis, after he invented the safety break, built this 40-foot shaft in Central Park, had himself hauled up in the air, and the cable sawed through, to demonstrate that his safety break would hold. It was that invention that made the elevator safe, and it was the safe elevator that really changed cityscapes the way that we know them. Used to be the tallest building you could build was seven floors, and the poor people lived up on the seventh floor because they were the only ones willing to walk that far up. Now, with the Otis elevator and with Louis Sullivan, you could start to build monster skyscrapers going up 20 floors, and put the penthouse on the top floor, because people started to understand that elevators were a safe mode of transportation. Even when I was a kid, I remember manually operated elevators, or if you went to a classy downtown store with push-button elevators, there was still an elevator girl sorry, it was sexist wearing white gloves, to push the button for you and to call out the floors. What was the change that took it to people being perfectly happy with automated elevators, and perfectly comfortable to push the button themselves? there is an example of automated transportation which is so safe, people do not even think about it anymore. How do we get automated cars to be just as safe so people have that same level of social acceptance? here is another example: It used to be if you wanted cash, you walked into the bank and you talked to a real live living person, and you gave them your passbook, and they stamped in the passbook what your current balance was, so you had proof right there on paper. People do not do that anymore. I can not tell you how long it is been since I have been into a bank. We trust these machines to you stick your card in and it spits out money, and your balance is correctly stored in some giant electronic brain. What did it take to make people comfortable with a machine handling their money, and what would it take to make people comfortable with a machine handling their transportation? here is an example that does not have as happy an ending: the supersonic transport. There was this big hullabaloo in the 1960s. We were not going to be we were going to have supersonic transports whisking us away to Europe in two hours. The French Concorde worked. The guys at Boeing who were designing the SST used to walk across the hall and laugh at the guys designing this 747 that nobody was ever going to fly. The 747, people got scared. They decided that the only use for the 747 was going to be cargo, so they designed their plane to have this big tube that you could fill with cargo, and that meant they had to move the cockpit up on top, which is why the 747 has the shape that it has. Well, of course, the SST never got built for a variety of economic and environmental and social reasons. The French built their Concorde; we never built their SST. What lessons should we learn about that, that kept that from being built, we should learn about for the Automated Highway System?"
"Chuck Thorpe","Interviewer","What about in terms of either an automated system overriding the driver, or the driver's ability to override an automated system, and what kind of issues do you see there?"
"Chuck Thorpe","Interviewee","Well, there is very big issues about who do you trust more the car or the driver and how do you make that handover, particularly if you do not know what the state of the driver is? The weirdest concern I got was, Suppose that a driver drove his car onto the Automated Highway ramp and pushed the 'Go' button, and the automated system took over, and then he had a party with his buddies and got completely smashed, and now he wanted to take control back, but he was legally drunk. Is it the responsibility of the automated system to detect that he is drunk and not let him resume control? I do not know. That is this is pushing the boundaries of social responsibility, of technology, of, Do you want Big Brother assessing whether you are competent to resume control of your vehicle? That is tough kinds of questions. In the U.S., it is particularly difficult to make some of these decisions. The United Kingdom has one police force; the U.S. has 18,000 police forces. We have 50 state Departments of Transportation, we have 390 metropolitan planning organizations, each of which has their own standards. This is another reason why Deckmanns could have his system, knowing what the Autobahn is going to do. we have got different standards all over the place for things like lane widths and markings and signage, et cetera, so we do not have those same kinds of standards. The same thing will be true when we introduce automated vehicles. We have to think about how all of those things carry out. here is another one: Suppose that we made a system 10 times safer than it is today, and saved 90 percent of the lives that are currently lost due to driver error. The car companies will tell us that the 90 percent of people whose lives are saved are not going to come up and offer General Motors a million bucks for having saved their lives, but if there is one car that, through a bug, accidentally causes a fatality, it is very likely that GM will be sued for the cost of that fatality. How do you balance all those off? The real conclusion that people came to is, if you look through history, as a society, if there is that big of a benefit, we have always eventually figured out how to take advantage of that benefit. It hasn't always been clear, it hasn't always been fast, but if we could save 90 percent of the lives that we are losing right now, as a society, We will figure out the way to do it."
"Chuck Thorpe","Interviewer","What about in terms of the recording of the driver's activities and things like that? I know there is a lot of concerns about privacy and surveillance, and that that system, if you made a mistake, would say, Ah, you were responsible for this accident, and people would not accept that."
"Chuck Thorpe","Interviewee","The well, there is a lot of that going on in cars today, that They are recording how fast you were driving at the time of a collision, and so forth. So that is an issue which is there and needs to be discussed, and proper uses of that technology. Again, there is ways of making safeguards like that. This came up, oh, 50 years ago on the Pennsylvania Turnpike. Well, the Pennsylvania Turnpike, when you get on at an exit, they hand you a card; when you get off, you give back the card so they can figure out how much toll to charge you. They could very easily say, Hmm. you have just come 200 miles in three hours. I do not think you were driving at the legal speed limit. it is illegal for them to use the information for that purpose. All right, so there is a case where there are legal safeguards against them using this information for a purpose other than collecting toll. it is easy to enact the same kinds of safeguards. So, yeah, these are issues, but these are issues that you can deal with. I am the wrong one to deal with them. I am a technology guy. But these are the kinds of things that technology guys have to make sure that somebody is thinking of if this technology's going to make a difference."
"Chuck Thorpe","Interviewer","And as a technology guy, what do you look back on as your biggest accomplishments or the most significant work you have done?"
"Chuck Thorpe","Interviewee","I have been happy about all kinds of different things. I have been happy about graduate students. I expect my graduate students to be smarter than me. I expect them to come in and say, Look at this cool idea. And I have had 17 Ph.D. students, and they have gone off to do all kinds of cool things that I could not have imagined, some of which look like robotics, some of which look like all sorts of other different things, and it is been fun to watch them, and watch their imagination, and watch them succeed. The most fun I have had is riding on automated vehicles. I forgot how scary it can be until I went and rode on somebody else's automated vehicle, and I thought, Wait a minute. I do not know the guys who wrote the code for this thing. What if it crashes? What if it when I am riding on the vehicle built by my own graduate students, it is like, Cool! Look at this! we are going down the road! Sure enough, it is seeing those kinds of things! All of our design is working! that is an awful lot of fun. it is that real gut feel that what you are working on is doing good stuff. it is not some esoteric theory that you have to wait until you go off to the right conference, where there is the right people who understand that set of differential equations. I can make a video of my car and show my mother, and she can understand, Yeah, automated vehicle going down the road. that has been the most fun. Seeing this technology get spun off into a company and go out there and start to save lives that is another kind of big emotional high. So all those things have been fun."
"Chuck Thorpe","Interviewer","Are there some specific companies that came directly from your work?"
"Chuck Thorpe","Interviewee","Well, Dean Pomerleau's company, which was AssistWare, which he sold to Cognex, which Cognex has sold to Takata. Takata's a tier-one Japanese electronics company, and exactly what Takata is doing with it, I am not sure that I know, and the closer the parts which are very close to commercialization, they can not tell me about."
"Chuck Thorpe","Interviewer","And you seem to trust this enough to, as you said, put your three-year-old son in front of it and wait for the vehicle to stop, even though there was obviously a person in there."
"Chuck Thorpe","Interviewee","I could show you a videotape, or you could find it on YouTube, of the Navlab driving and Leland riding his bike in front of it. And yeah, there was a person inside with their foot on the brake pedal. At the time, we were running on fairly standard computers, and I am not going to trust my son until it is triply redundant, et cetera. But it was good for the TV camera. Do I trust this stuff? I trust it more and more, and I trust people less and less. The more I work in collision avoidance, the more screwy things that I see people do out there, and the more conservative a driver I get because I see the kinds of funny things that people do. I also see the kinds of funny situations that occur out there. I collect stories of strange things that people have found on the road, because if an automated vehicle is going to have to avoid obstacles, I need to know what kinds of obstacles are out there. what is the strangest thing that you guys have seen on a road?"
"Chuck Thorpe","Interviewer","A boat."
"Chuck Thorpe","Interviewee","A boat? Now, what is a boat doing on a road? "
"Chuck Thorpe","Interviewer","It was in Kansas City. It fell off of a trailer."
"Chuck Thorpe","Interviewee","Now, what is a boat doing in Kansas City? But there is an example. there is something that, if you wrote the list of top hundred things that your automated car would have to avoid, boat would not probably be high on the list."
"Chuck Thorpe","Interviewer","I have another one which is something that happened to us, that we had rented a truck to go get some stuff from Ikea, and the lining, whoever had used it before apparently had not secured it, and on the highway, the lining blew out."
"Chuck Thorpe","Interviewee","The lining of the truck?"
"Chuck Thorpe","Interviewer","Yeah. So, in the bed of the truck, there was a huge plastic thing. So, yeah, that flew out. Thankfully, there was nobody behind us, but what you do in that situation, I do not know. I saw a bunch of plastic chairs when I was driving out to New York in September."
"Chuck Thorpe","Interviewee","Plastic chairs, if you ran into them, you would probably be a lot of plastic flying all over the place and a very scared driver, but you probably would survive it. I was giving a talk in Rochester, New York, and I asked somebody the strangest thing they'd ever seen recently, and they said, An alligator. I said, In Rochester, New York? No, no. This was down in Florida. But you think about it. An alligator's pretty dense and pretty low to the ground, and can move pretty fast, and it is pretty hard to see. That is not very good."
"Chuck Thorpe","Interviewer","There are deer all the time."
"Chuck Thorpe","Interviewee","Deer all the time, yeah. Yeah. Not as often as people would have you believe. It turns out if you have a collision with a deer, it goes on your comprehensive insurance and not your collision, and so your insurance rates do not go up. So a lot of people come into the body shop, Ah, I have hit a deer. And, well, that deer must've had red paint on it. But no, deer that is a common one. here is an odd one: cats. You do not think of a cat as a dangerous object, except people will say, Aw, the poor cute cat, and they swerve out of the way, and they run into somebody. One of the stranger things I heard about was a toilet. Again, it fell out of a car. But you think of a toilet as this ceramic object. Ceramics do not reflect radar. That is what they make stealth things out of. Your automated collision detection radar may not see it. It has this real shiny surface the laser may ping off, and the laser may not see it. If you have sun glinting off of it, your stereo vision system may have a hard time seeing it. This may be the perfect stealth obstacle. There are catalogs. One of the equipment companies wanted to build an automated trash-collecting system, so they commissioned this study to find out what kind of trash there is things like ladders. You run over a ladder, it spins, twists, it rips out the underside of your car. So, all of those kinds of things that you would have to deal with, those are the sorts of things that make this an interesting challenge."
"Chuck Thorpe","Interviewer","What kind of advice do you have for young people who might want to get into robotics?"
"Chuck Thorpe","Interviewee","Robots are cool. You certainly have to understand your math. You certainly have to understand your computer science. You certainly have to study little bits of engineering. But then you have to use your imagination. You have to be solid on the fundamentals, but there is all kinds of applications for robots that I will never think of, so robots and something turn out to be powerful combinations: robots and art, robots and design, robots and medicine. In my case, it is robots and driving. Robots and games. I was kind of surprised. A couple of my graduate students have gone off to the computer game industry, and they said, Look, Chuck, it is everything that you have on a real robot, with perception and intelligent planning and multi-agent coordination, except that we do not have to get our hands dirty. it is all simulated mud. Robots and games, robots and toys those things are all fun. So use your imagination. Play. Study the basics get those down but keep your imagination alive."
"Chuck Thorpe","Interviewer","Great. Thank you very much."
"Chuck Thorpe","Interviewee","One more piece of advice for young people: Come to Carnegie Mellon. "
"Chuck Thorpe","Interviewer","Work on robot cars."
"Chuck Thorpe","Interviewee","Work on robot yeah! Come with me. Work on robot cars. I am serious about the Carnegie Mellon part in the following sense: I do not know that our professors are any smarter than professors other place. The Berkeley professors are smart, the MIT professors are smart, the Stanford professors are smart, et cetera, et cetera. The difference is we have more of them, so if you know what you want to work on, and you really want to work on robot cockroaches, go to Berkeley because they have the world's expert in robot cockroaches. If you want to work on robot driving, or mobile robots, or robot origami folding, or robots and elderly people, or come to Carnegie Mellon. Or if you do not know what you want to work on, come to Carnegie Mellon. Berkeley has four really smart people doing robots; we have 60. MIT has people in a few different labs doing mobile robots. We have people in 50 different labs doing interesting robots. it is a fun place to be, just because of the variety of people and the variety of projects doing robotics."
"Chuck Thorpe","Interviewer","Great. Anything else you want to add?"
"Chuck Thorpe","Interviewee","Thanks for doing this project. I think It will be really valuable."
"Chuck Thorpe","Interviewer","Thank you for participating. Do you have any suggestions for people, if you were doing this project, that would be a must that we should talk to? Who are the two highest at Berkeley?"
"Chuck Thorpe","Interviewee","Did you get Bob Full? he is the "
"Chuck Thorpe","Interviewer","No."
"Chuck Thorpe","Interviewee","he is the cockroach guy."
"Chuck Thorpe","Interviewer","Okay."
"Chuck Thorpe","Interviewee","And you got Ken Goldberg?"
"Chuck Thorpe","Interviewer","We got Ken Goldberg."
"Chuck Thorpe","Interviewee","Okay. So I say four because I do not want to dis them by only saying three."
"Chuck Thorpe","Interviewer","Okay, so talk to the cockroach guy. "
"Chuck Thorpe","Interviewee","I think we got to. Yeah, yeah."
"Chuck Thorpe","Interviewer","Well, then there is the two guys at the Richmond Field Station."
"Chuck Thorpe","Interviewee","Yeah. Have you worked on underwater robots?"
"Chuck Thorpe","Interviewer","Not yet. we are looking at a little bit. I talked to Gino Marcovarario while I was in Genoa over the summer, just because I was there, and we talked to Bob McGee , who is done some ."
"Chuck Thorpe","Interviewee","Oh, good! He did the adaptive suspension vehicle."
"Chuck Thorpe","Interviewer","Mm-hmm."
"Chuck Thorpe","Interviewee","That was a contemporary of the autonomous land vehicle. McGee was this towering, full professor, and I sat next to him at a conference. He said, Oh, you are Chuck Thorpe. I read your thesis. And I thought, Oh, no."
"Chuck Thorpe","Interviewer","He was great."
"Chuck Thorpe","Interviewee","Yes, yes. The underwater robot community has not communicated a lot with the land community, but There are some very interesting stories to tell. Dick Lidberg , at University of New Hampshire if you see him, say hi. He was doing this experimental autonomous vehicle, EAVE, which he programmed the thrusters using binary, because they did not have assemblers and they had just invented the microprocessor. And he is just finished running the 20th unmanned, untethered submersible vehicle conference. David Yerger, at Woods Hole he is the robot guy who is worked with Bob Ballard when Ballard went off to find the Titanic. And these guys have fascinating stories of finding geothermal vents on the mid-Atlantic ridge, and so forth."
"Chuck Thorpe","Interviewer","is not there a group at the Monterey Bay Institute?"
"Chuck Thorpe","Interviewee","Hans Thomas and Jim Bellingham. Hans was an undergraduate student who worked with me. he is one of the ones who made me feel old. He said, Chuck, get out of the lab. You come into the lab and you hack, and it is old-fashioned C code, and then you go off to a conference and we got to debug it. And he came and found me 10 years later and said, I am so sorry. Now I know just one of my students came and said, Hans, get out of the lab because you have old-fashioned and I realized exactly what I did to you."
"Chuck Thorpe","Interviewer","it is okay. At least now he knows it comes back to you karma."
"Chuck Thorpe","Interviewee","Hans was just running underwater gliders around the Gulf of Mexico, looking for plumes of oil."
"Chuck Thorpe","Interviewer","Do you know who makes the robot that was actually cutting the pipes for the ?"
"Chuck Thorpe","Interviewee","there is been a big, tethered underwater vehicle, and they had four or five different companies' robots down there. Oh, shoot. Perisubmersibles , Oceaneering . I do not know who the other one was, but there were several companies working down there."
"Chuck Thorpe","Interviewer","We can get that."
"Chuck Thorpe","Interviewee","And those tend to be not terribly intelligent vehicles. All the intelligence is at the other end of the tether."
"Chuck Thorpe","Interviewer","Yeah."
"Chuck Thorpe","Interviewee","But you still want some intelligence because you want to do things like station-keeping, so they will hover even with it being bounced around by the current so you can do fine manipulation."
"Chuck Thorpe","Interviewer","You can probably also get them ."
"Chuck Thorpe","Interviewee","Not nearly as much as you would think."
"Chuck Thorpe","Interviewer","Yeah."
"Chuck Thorpe","Interviewee","Those are very simple arms down there. And the other guys who have done very, very simple arms are the bomb squad people, and That is because they say, Look, this is a bomb squad. we are going to blow the arm off once a year, and we can not afford to have a complicate arm. Just put the simplest possible dumb thing out there. Have you talked to Mark Rayberg ?"
"Chuck Thorpe","Interviewer","No, not yet. he is on our list."
"Chuck Thorpe","Interviewee","Mark was a professor here for several years. I kept thinking they were doing demolition on the classroom right behind mine. It was not a jackhammer; it was his hopping machine. Ka-thoonk, ka-thoonk, ka-thoonk, ka-thoonk, ka-thoonk!"
"Chuck Thorpe","Interviewer","It was driving you crazy. Anybody else in the early autonomous vehicles that we might have missed?"
"Chuck Thorpe","Interviewee","Well, an interesting guy to talk to at Lockheed Martin is Jim Lowrie L-O-W-R-I-E. And you want to catch him in the next few months because he is announced that he is retiring so he can go sail around the world. But he was the project lead of the Autonomous Land Vehicle program, and his former boss, Roger Chappelle , you could also track down. Roger is semiretired and spends his time diving for gold and Spanish wrecks."
"Chuck Thorpe","Interviewer","Wow."
"Chuck Thorpe","Interviewee","Yeah."
"Chuck Thorpe","Interviewer","That is very adventurous."
"Chuck Thorpe","Interviewee","Yeah."
"Chuck Thorpe","Interviewer","Who else would have been. I am glad you got Bob "
"Daniela Rus","Interviewer","If we could start with having you tell us what your name is and where you were born and when."
"Daniela Rus","Interviewee","My name is Daniela Rus. I was born in Romania. I spent the first part of my life in Romania, and my basic schooling education happened there. I went to a special mathematics and physics school. And eventually my parents immigrated from Romania via some stops in Europe to the U.S. And as a teenager, we arrived in Iowa City, Iowa. I had a big shock about American life, which is not at all what I had imagined from TV shows like Dallas, which were the only shows that were airing in Romania at the time. I did my undergraduate degree at the University of Iowa. I majored in computer science mathematics, and I had a minor in astronomy. And then, I went to Cornell University to work on my PhD with John Hobcroft . As a student at the University of Iowa, I met John and he was giving a talk on the grand applications of computer science. And at the time, he was convinced that robotics was the main big application, that computer science had made a lot of progress on basic fronts like theory, programming languages, operating systems. And it was really time to package it all together and put it in a grand application. And robotics was an extremely important and seductive application, so I was completely seduced by John's talk. And because as a kid, I grew up actually watching Lost in Space, and the robot in Lost in Space was what I often dreamed about. And so the opportunity of working on something related to these grand childhood dreams were just amazing. And I had an opportunity to meet with John Hobcroft after his talk, and he convinced me to apply to Cornell and join him in his research group there. So that is in a nutshell, the story of my education."
"Daniela Rus","Interviewer","So when you were in Ohio, was there actually "
"Daniela Rus","Interviewee","Iowa."
"Daniela Rus","Interviewer","Iowa, I am sorry."
"Daniela Rus","Interviewee","Ohio ."
"Daniela Rus","Interviewer","I always get those confused. "
"Daniela Rus","Interviewee","So maybe we can edit this part of the tape."
"Daniela Rus","Interviewer","I will be edited out of the tape anyway. But in Iowa, did you see robots? Were there already robots there, were people working on things like that?"
"Daniela Rus","Interviewee","No, not at all. In fact, Iowa was where my family settled, so the first years in the U.S., I was primarily focused on being coherent in English, so being able to express myself in English, making adjustments between my education in Romania and the expected education at the University of Iowa, because there were significant differences. So my math education from high school was strong enough that I was able to walk straight into graduate level math classes. But then, I had to take courses like rhetoric and history, and in particular, American History. And you know how the undergraduates' curricula are constructed, so there was a gap. And I really had to make a special effort on the language front. Also, for cultural adjustments and just in general to get more integrated with the American ways."
"Daniela Rus","Interviewer","And in Romania, how does one get into the special math and physics school?"
"Daniela Rus","Interviewee","So at the time, so this was communist Romania, the education was very different than what it is like today. So there were admission exams, if you wanted to get into one of these intensive schools, and there was a hierarchy, so there were the best schools and the next best schools and so forth. But you actually had to take two exams. So there was one exam you took in the eighth grade, and that exam was based on math and reading-writing. And then there was another exam in the 10th grade, and that exam filtered about half the people out, and allowed half the people to continue. And that exam was mathematics and physics, at my school. There were other schools. So during communist Romania, the Romanian leadership wanted to make sure that there is a good workforce for the future. And they wanted to start this education early on, so there were a lot of technical schools. Very few people got to stick to the basic education tract, and most people went to the so-called industry schools, where they would take classes for a couple of weeks, and then go work in the factory for a couple of weeks. And in fact, even at the best school in my town, which is this high school called Nicolai Chesk School I attended, even there we actually had to get factory experience. So every month, we would have three weeks in school and one week in the factory. And my particular place of work was a factory that produced spare parts for trains. And so I really did not enjoy that part of my schooling at all. And because you go in this big, noisy place, they are workers that really do not want to be bothered with you, who have things to do. it is not intellectually that interesting, but you still have to spend a whole week doing something there. And you have to repeat this experience, month after month after month. And so, I found myself learning how to use a lathe and how to use a screw-making machine and how to mold things. And I never thought I would use any of this stuff. I always thought, Oh, what a waste of my time. Why can not I just sit and write a story or read a novel? But in fact, in robotics, in my current work, I find that all this experience of building things and of learning how to run these machines is actually extremely valuable. So you just never know what comes across your path, and you just never know how what you learn today will help you or hinder you in the future."
"Daniela Rus","Interviewer","Did having these kinds of experiences with actually hands-on things, was that also part of what interested you in robotics when you heard about the "
"Daniela Rus","Interviewee","No."
"Daniela Rus","Interviewer","No?"
"Daniela Rus","Interviewee","Not at all. No, the hands-on stuff was, like I said, I was just not interested in that in the beginning. Although, the more I learned about robotics, the more I realized that a robot is the combination of a brain and a body. And in my robotics work, I have been very interested in thinking about how the brain and the body match together. And my interests are often in examples of autonomy for machines, where the kind of algorithms and capabilities we would like to implement require certain types of mechanical capabilities. And most of the times, you cannot buy machines that have those required mechanical capabilities. And so, that was kind of the flow of events that had me in a spot where, all of a sudden, I was interested in designing machines and thinking about new types of robot bodies, new types of machines."
"Daniela Rus","Interviewer","And so, to go back to when you started working on robotics with professor Hobcroft, when you got to Cornell, what was it like there? What was the lab like, what kinds of things were they working on?"
"Daniela Rus","Interviewee","So John was a visionary, and he had a significant group of people. And he had a big puma arm, so this was one of the few labs in the United States that actually had its own puma arm, this really big thing. And he was very interested in the capabilities of this puma arm. And I remember some people were working on tying knots with a robot, so rob manipulation, which is really remarkable to think that this was a problem that was being considered in the 1980s because it is still a problem that we have not solved. We still do not have robots capable of doing flexible body manipulation. John is also someone who has contributed fundamentally to computer science. He is a very distinguished scientist, very visionary. And in computer science, he is very known for his depth of thinking and for his theory work. So to continue in that spirit, John was also developing or looking at the theory of robot algorithms. And in fact, he has some of the fundamental results on the piano movers problem. So he had people in his group who were interested in theoretical aspects of robotics. When I arrived at Cornell, he was actually interested in what you could do if the robot was a little bit more flexible than the puma arm. And Ken Salisbury was building a very cool multi-finger dexterous hand, the UMIT hand was being developed at the same time. And so, John gave me a challenge that translated into some theoretical questions about how could you use dexterous manipulation to achieve a more capable manipulation than what was possible with a puma arm that had a pinch gripper. So in fact, I still remember how we were chatting in his office and he was drinking coffee. And he was saying, Well, I wonder if you could get a robot to do this? And he started turning the coffee cup in his hand and says, Yeah, how would a robot do this kind of manipulation operation? So five years later, I actually had some sort of theorems and algorithms and simulations on solving this problem. So I ended up working on multi-finger manipulation. And for my thesis, I developed a planning and control algorithm that used the fingers of a dexterous robot hand to reorient an object by some desired amount. So you give me an object, you give me some rotational motion you desire for that object, and I could tell you how to move the fingers, in what sequence and by how much, to guarantee the accomplishment of this reorientation. So this field of robotics is called in-hand manipulation because it was about moving something while holding it, rather than the kind of pick and place operations that previous robots had been programmed to do. So I learned a lot from John Hobcroft. I also learned a lot from Bruce Donald. So Bruce Donald was a young PhD from MIT. He was one of the Damasos Anaparazo's students, and he arrived at Cornell as a first day professor, just as I arrived as a graduate student. And in fact, he taught the first robotics course that I took. And he was very cool and very funny and very warm, and so all the students loved him. He was also very tough and he really taught us how to set high standards in our research and our behavior. And one of my fondest memories from those times was at the end of this robotics course with Bruce. He taught us about compliant motion planning and position force control. And we had the opportunity to do some experiments on this big puma arm. And then, at the end of the course, we came to know that it was Bruce's birthday in a couple of days. So we thought, Hey, would not it be great to get a cake for Bruce, and then have a party, and have the robot cut the cake? So a bunch of us got together and cooked up this story, and made a plan for how to do this. And we organized this surprise party for Bruce. And I remember, together with Denish Pie , we stayed up all night and we programmed this robot, essentially doing way point programming, how to cut round cake. And so, the plan was that we would get a big round sponge cake. We had a knife with a blade about this big, which we attached to the robot's arm using duct tape. And the program went a little bit like this with the big knife attached to the arm. But it was a fly by night operation, so we wrote the program, but we really did not have much time to experiment with it. Anyway, to make a long story short, the big moment of the surprise party comes, everybody turns up. And then, the guy who is tasked to buy the cake shows up, and he turned up with a square ice cream cake. So we look at this thing and we say, Oh, no. Our robot program was not that adaptive, but now everybody was there, so we had to go through with the motion, we had to do the dance. So I said, Well, let us try, let us see what happens. So the robot went because there was a such strong resistance from the ice cream cake. So sure enough, after a few struggling motions, the robot hit the singularity point and started doing this with this big knife attached to it, and it is a big robot. It was a very scary moment, but it was also a great teaching moment, because we really understood the importance of adaptation and the importance of doing reliable, provably correct algorithms, and not just little hacks."
"Daniela Rus","Interviewer","And was that still the puma arm?"
"Daniela Rus","Interviewee","Yeah, it was the puma, yeah, yeah, it was the only robot that we had at that time. Later on, we got some mobile robots from a company called RWI. So we got two robots called Tommy and Lily. So going back to my thesis, I never had the opportunity to implement my thesis algorithms on a dexterous hand because we did not have one. And the only hands in existence were at government labs, and there was great contention for time on those devices. But when we got these two mobile robots, Tommy and Lily, we thought that maybe an interesting experiment grounded in my thesis ideas was to work on distributive manipulation of large objects, where effectively the robots acted like the fingers in my algorithms. But now, there was no palm. The object was on the floor and the robots were executing the motions without maintaining a continuous grasp of the object. In fact, the floor provided that grasp. And this work culminated with some demonstrations of furniture movement, using these two robots. And so, those are really great times. That work was done in collaboration with Bruce Donald, and one of his graduate students, Jim Jennings. And we had a lot of fun together. And we were very excited because, at the time, mobile robots were just beginning to penetrate universities. In fact, Rodney Brooks had built the first inexpensive and reliable mobile robots, and actually showed the world that it is possible to have these devices. And these devices truly revolutionize the work on mobile navigation, because it is actually very important to have the physical prototype, the physical device to show that your theory means something. Because otherwise, all you have is a bunch of theorems in a book, and how are you to know that the assumptions in the theorem are actually the right assumptions. Even if you do it in simulation, you still can not know, so I think it is very important. So when dealing with systems that interact with the physical world such as robots, it is very important to go from theory to maybe simulation, because simulation is an opportunity to take some of the software bugs out, then all the way to experiment on a hardware platform. And the availability of these inexpensive robots made it possible for lots and lots of people to develop robot algorithms, and that caused a flurry of results in robotics, and really pushed the field of navigation forward. But when these first robots became available, there was not really much in terms of software environment. So there was a lot of very low level programming of robots, and that can be tedious. And you really have to be quite an expert at something else, other than robotics, to write good programs. And at Cornell, Bruce actually invited Jonathan Reese , who was studying programming languages at MIT. He did his PhD at MIT with Jerry Sussman . And he was working on functional languages, like scheme . In fact, he wrote some of the widely used scheme packages. So we had Jonathon come to Cornell, and he wrote the first programming environment for robots in scheme. And he and Bruce wrote a very nice paper that year, called Program Mobile Robots in Scheme. And that was exciting because it was really the first time when, in some sense, the system side of computer science merged with the hardware side. Because as I said earlier, robotics is really such an important marriage between computation and the physical artifact, the body. But in order to do computation, you need to have the right infrastructure. And oftentimes as robotists, we find that we think that is plumbing and somebody else will do it. But if we do not have a way to systematically move forward and integrate the two parts, we will not have good progress. And since then, actually the world has made tremendous progress in this direction."
"Daniela Rus","Interviewer","And at the time, was each lab developing their own environment, or was there some sharing of ?"
"Daniela Rus","Interviewee","No sharing. So at the time, everyone was building their own robot. They were building their own algorithms. And many papers were of the sort, I built this robot, I programmed it to do X, and here is how the robot works. And then, there were other papers that said, I built this other robot, and it is doing task Y and here is how it works. So that is sort of how it started. But then, very soon, we realized that there is a need for some common abstractions that would allow us to, at least from a scientific point of view, to compare each other's work. So how do I know that your robot that does X and my robot that does X have the same level of ability, and how do I compare? Why is my robot better than your robots? So how do you think about comparing robot algorithms, and how do you establish benchmarks and so forth. So it took a while for the community to figure out the answers to these very important questions."
"Daniela Rus","Interviewer","And maybe you can tell us a little bit about how that happened, as we go through the story. I do not know if you have a feeling for ."
"Daniela Rus","Interviewee","So how did that happen? Well, I think that the community started organizing discussion panels at conferences. And oftentimes, the theme of the discussion panel was what is missing, how do we move forward. And then, people started voicing the importance of pushing on the computation side, on the abstraction side. So there was one person and another person, and pretty soon, people internalized these challenges and started thinking about them, and started putting results out. And so, I think it was not one person saying, All right, robotics community, let us get together and let us start doing X. So it was not like that, it was a grassroots effort."
"Daniela Rus","Interviewer","And what were some of the first projects that actually brought this together?"
"Daniela Rus","Interviewee","So I worked with Bruce Donald, in fact, on an idea we called Information Invariants for Robotics. And the idea there was that, in order to do a robot task, you need resources. And there is some minimum amount of information that you need, in order to carry out the task. And the important question was, what is this information, and how does this information translate into different information sources for the robot? So I will give you an example. If you want to push an object on a straight line, if you know where the center of mass of that object is, in other words, if you have a good model for the object, you can apply a force directly through that center of mass and you will get the straight line motion. But if the location of the center of mass is not known precisely or not known at all, are you doomed? Well, no, you can achieve the same kind of behavior by maybe taking a two-fingered gripper and placing it towards the boundaries of the face. And then, the center of mass is captured in between the two lines of pushing. You can push forward and achieve the same results. So what is the trade-off, a precise model versus two pushing forces. And now, you can even consider removing the rigid link between the two force lines. So you can imagine doing the same task with two autonomous robots, but now the robots have to coordinate. And so, you have removed the rigid link, but you have introduced communication. So the idea of information invariance was to aim to articulate what is the minimum information required for a robot task, and what are all the different ways of extracting that information from the environment. And at the time, many of the robot algorithms were centralized, and assumed that the robot had access to everything. And people were beginning to work on distributed algorithms, but the theory behind these distributed systems was not very present, because distributed systems are notoriously difficult to analyze, even if you take a distributive system that does not move or a distributive computing system. Even in that case, the approving, the performance of such a system is challenging. So now, you had the extra degrees of freedom you get from interaction with the physical world. it is even more complex. So another interesting aspect of this information invariant theory was a method of automatically transforming programs. So you could start with a centralized program that had access to all information, and gradually replace the resources used by the program with something else. And so, you got to a distributed system. So you could start with a centralized program that has a careful model and the map and the central controller. You could replace the map with sensing, because now all of a sudden you do not need that prior information. And then, you could replace the central controller by communication. And so, if you did these transformations following a particular structure, then you would end up with a distributed system that inherits the properties of the centralized system. So that was really cool because the reason it was easy, I mean, in some sense it is much easier to analyze a centralized system. You have all the information there, you can reason about the system, but it is not that realistic. But if you can start with a well-analyzed system and transform it in a way that inherits correctness properties along the way, you could end up with the kind of robot system you want, the system that does not rely on too much information and a rigid coordination. And you could still predict the behavior of that system."
"Daniela Rus","Interviewer","And then, it would essentially be more flexibly adaptive environment."
"Daniela Rus","Interviewee","Exactly, exactly."
"Daniela Rus","Interviewer","And was this work that you did with Bruce also while you were at Cornell, or was that later when you were in ?"
"Daniela Rus","Interviewee","So I worked on this after I finished my PhD thesis, and I stayed at Cornell and did a postdoc. And I worked on my postdoc with John, as well as with Bruce. And it was just a great time."
"Daniela Rus","Interviewer","And when you were thinking about the fingers, were you thinking of them as a distributive system, or this notion of self-organization came up when you kind of translated that problem into the individual mobile robot?"
"Daniela Rus","Interviewee","So the multi-finger manipulation problem was centralized. I was not thinking about it as a distributive problem. In fact, it is a very challenging problem. I would say that it is still not a solved problem. I was very proud of my algorithm because it had very nice theoretical guarantees. But the fingers required a range of forces that was not necessarily compatible with what a physical device could assert. So there were a lot of issues. In fact, just writing that thesis and thinking about what it would take to do it for real on an actual robot was an extremely valuable learning experience for me. And the distributed part came about in some sense because that was the platform we had available. These two robots arrived and it was just one of these things where it seemed like an opportunity. So we had these two robots, we had this algorithm. let us instantiate some version of this algorithm in a context that could be executed by these robots. But now, all of a sudden, these robots are not a centralized system the way the arm was."
"Daniela Rus","Interviewer","And then, in your later work, you continued to work on these self-organizing and mobile ."
"Daniela Rus","Interviewee","Robots? Yeah, since my days at Cornell, I have been very interested in studying autonomous self-organization, and really thinking about what it means for a machine to exhibit self-organization, and what kind of algorithms and what kind of bodies are amenable to self-organization, and what kind of capabilities can you actually extract from these self-organizing systems. And I actually have almost two branches of work, but I actually see that they are deeply related. So I began to look at systems where the act of self-organization was a physical mechanical process, and this is how the work on modular self-organizing robots started. So you have robots, these robots are mechanically and physically connected. And you would like for these robots to self-organize, to achieve the body that is necessary for the given task. So in some sense, this work was really aimed at thinking about what happens if your robot does not have a fixed body, if the robot is not a fixed architecture machine. Can we even imagine those types of scenarios. And is it possible for the robot to figure out by itself what is the best shape that is most suitable for the manipulation navigation, or sensing needs of the task. And what would it take for the robot to aggregate that shape. And when the robot is done with that particular operation, and comes upon a different challenge, how can it reorganize its body to match the new challenge. So that is one set of problems I have been very interested in. But there is the equivalent of asking those same type of problems in the context of swarms, where the connection between the robots is not physical, but it is virtual via communication. And in all this work, it is important to realize that it is powerful to have multiple robot units cooperating to do a certain task. It is powerful because it provides parallelism, it gives the robot a wider scope of actions, of perception values. And it also is much more full tolerant, so if one unit from your team fails, you are not done. You can carry on, you can eject the bad unit from your system and carry on with your activities."
"Daniela Rus","Interviewer","So after your postdoc, you went on to Dartmouth?"
"Daniela Rus","Interviewee","Yes. My first faculty position was at Dartmouth. And at Dartmouth, I had the opportunity to start my own robotics laboratory. And the first thing I did was to buy a pair of mobile robots, I called them Bonnie and Clyde. And the next thing I did was I hired Jonathon Reese to write my scheme programming interface for these robots, so I really tried to replicate the infrastructure I had at Cornell. But then, I also felt like I had the opportunity to think about different things. And that is when I started thinking about self-organizing machines, modular robots. And it was a very interesting time because the whole idea that you might be able to build these robotic modules that could move about each other, changing shapes, seemed like such a wacky idea. But I was living in the woods, nobody was really looking over my shoulder on a day-to-day basis. I was carrying on with my work on mobile robots. But then, I had carved some time to think about these other problems. And it was a fun time for me, because as a kid, one of my favorite storybooks was about the Barbapapa family. Do you know about this? Maybe this is a European series. The Barbapapas are a family of blobs. And there is the father, the mother and all the kids. And these blobs have the ability of changing shape, according to whatever the challenge from the environment is. So for instance, on one occasion, this gigantic bean invades them, and all the kids turn into cutting devices, and they in parallel chop down the giant bean. And then, they turn into containers to pick up all the seeds, so that there is not another germination step. And then, they turn into cooking utensils to turn the beans into soup and have a party. So these were really cool ideas that spark the imagination of a child, so I loved those stories. And interestingly enough, I have a young daughter who, at some point, had no idea what I did when I was not at home. But one day, she said to me, I just dream of this world where, when you put me to bed at night, I could just reach into the wall and I could pull out a toy or a cookie, or I could just get everything I want from this wall. So in some sense, this was an expression of a desire to have some sort of a smart material that you could adjust to whatever your needs were. So I was very excited, I did not know how my daughter came up with this idea. But I just thought, Oh, maybe it is in the DNA or something. "
"Daniela Rus","Interviewer","it is your Barbapapas going over to her. They are kind of blue and pink?"
"Daniela Rus","Interviewee","Yeah, so they look "
"Daniela Rus","Interviewer","Big and fat, and they have little like "
"Daniela Rus","Interviewee","Yeah."
"Daniela Rus","Interviewer","Okay. I never read it, but I have seen them. They sell them and stuff in Japan that has them on them."
"Daniela Rus","Interviewee","Yeah, if you go to YouTube, you can see some of the shows. They are really cool. I think kids love them. In fact, I have indoctrinated my kids with the Barbapapas, so that was exciting. But there were lots of long hours of sitting in my office with my new students. Keith Scotte was one of my students, and Marty Vonar was another one, and so three of us sat in my office and we tried to break this problem down into some abstractions and then abstraction I was interested in at the moment was, could you imagine a robot module as a tennis ball, and so could you imagine putting two tennis balls together and rolling them and having them roll about each other by themselves? So we made a lot of experimental investments that did not quite work out. At some point I thought, well maybe if you take the ball and you coat it with magnetic patches that you could program to be on and off you could generate the necessary forces to do this lifting motion but it turns out you cannot for very good theoretical reasons. Then we had the idea of trying to do that operation mechanically, and we built a couple of different types of robots that use mechanical operations essentially to roll about each other. So the first robot we built we called it a molecule, it was two cubes that had a right angle joint between them and if you built a lattice of these cubes you could program- you had four rotational degrees of freedom in each module so if you built a lattice of such modules you could actually figure out how to sequence individual actuations by individual modules to convert any shape into any other shape. And then we had another system we called The Crystal where the basic idea was a cube that could expand and contract by a factor of 2, and so doing scaling we were able to show that you could achieve shape change. So those were the primary ideas that I developed with my students at Dartmouth. "
"Daniela Rus","Interviewer","And were you building all of them in house?"
"Daniela Rus","Interviewee","Yes, everything was built in house. In fact, I was in a computer science department so my students were very good programmers but they were not really trained in machining. And in fact, at this point, I realized that all of that high school experience in the factory was coming in handy but I bought a rapid prototyper so I bought machine and I think I was one of the first labs in the world that used a position machine to make plastic robot parts and to in some sense simplify the act of machining a robot and reduce it to programming because our students were very good at writing CAD models, and was such a rapid prototyper you could do your CAD model, push a button and then the part came out a few hours later. So now this kind of fabrication methodologies is considered a very current, very integral part of how robots are made, but at the time these machines were very expensive and not many labs were working with these tools. It was also- that machine also allowed us to build beautiful and fun looking machines because the plastics were colorful so now all of the sudden our robots did not look grey, but they had these beautiful bright faces and that appealed to my artistic side."
"Daniela Rus","Interviewer","Were the initial prototypes done in plastic too or did you have another set of things that you used to kind of think through earlier designs?"
"Daniela Rus","Interviewee","Well, We had make paper devices or Lego so We had try to prototype something in Lego but it was easy enough to print something that we did a lot of that. And of course we went through a lot of design revisions."
"Daniela Rus","Interviewer","And did you have funding for this, was this during your career award or prior? "
"Daniela Rus","Interviewee","So I had my career award on distributed manipulation and then Howard Morafef was the Program Director in Robotics at the time and one time when I visited him I explained to him my ideas for how to build these self-configuring machines and he was very excited about the topic and so he helped me out by giving me a small grant and I forget what these grants were called, but they were essentially seedlings to explore an idea so was probably 50K, but it was really enough to cover some time for my students and to do so some original prototyping. I also used my discretionary startup funds to help populate my labs, buy this rapid prototyper, to do things like this. "
"Daniela Rus","Interviewer","Were there any other people at the time in Dartmouth who were interested in robotics?"
"Daniela Rus","Interviewee","No, I was the only one. So Dartmouth was a very small department. The Computer Science Department had split from mathematics maybe the year before I joined and we had a brand new building. The facilities were very good but the department was very small and what was special about the department was that most of the faculty were essentially in my age group so there was a big explosion of hires and this was a really tough year to hire. In fact, I could not get a job after I finished my PhD, there were no positions, but after the then I had better luck, but it was still in some sense Windsor of our field in terms of hiring. So there were some really great people in the department. Everybody was ambitious, energetic. We could be friends because we were at a very similar stage in life. We were in a small department so we had to like each other and, in fact, this was a criterion for new hires and we worked together on a lot of other topics. So my colleagues were not interested in robotics but I partnered with one of my assistant's colleagues to work on transportable agents. So the idea behind transportable agents was building software that behaved like robots so a piece of software that could interrupt execution, move to a different place and start from where it left off, and these concepts, again, are taken for granted, but at the time they were new ideas and we were able to explore these ideas because we had the systems person and the robotics person who came together, wrote a grant, got some money and we were able to pull ideas from our respective disciplines to try to make this new thing."
"Daniela Rus","Interviewer","And who was the person you were…"
"Daniela Rus","Interviewee","David Coats . David Coats, and so while I was at Dartmouth my other most favorite collaborator, who became actually a collaborator a little bit later in my stay there, David and I started collaborating fairly soon after I joined, and I continued collaborating with Bruce Donald. In fact, Bruce Donald ended up being hired at Dartmouth so that was a very, very special coupe for me because we had such a good relationship. So what happened there was that Bruce got married and he had a problem and at the time he was married he had the problem. Again there were no jobs but we were able to make offers to both he and his wife so it was just wonderful. All of the sudden one of my favorite collaborators and my good friend was right there so that was very special. So later on I was at the conference and I sat at some dinner next to Peter Cork . Now Peter and I were working in areas that could not be more different. So Peter had these big machines and was doing a lot of fielded operations. I was doing a lot of theory and I was making little robot prototypes but I always admired Peter's work because it just seemed so real. So Peter was really doing Robots real. He was building these systems. He was putting them in very realistic environments and he was getting them to work. So I thought that was so meaningful and powerful and so we started working together and we sort of brainstormed problems and eventually we came up with two ideas that really combined his background with my background and one idea was related to sensor networks and so in that line of work we were really looking at how to take some of the algorithms my group was building and testing in the lab and put them in a realistic environment where we could use aerial robots to localize the nodes at the time the sensor networking was just starting so there were no results in the space and then we really built some of the most fundamental capabilities in sensor networks together. And while we were working on sensor networks we came across one of my friends from Australia who Simon who had been my student at Dartmouth that we somehow stayed friends and Simon was in Australia running the family cattle business and said to me, I really have this problem with fences because the farms in Australia are Gigantic and there is no way of knowing what is happening at one part of the farm or the other and I spend most of my manpower building fences and moreover I have to spend $500 an hour to hire a helicopter to move my cattle when I want to move them. So I had been thinking about this ideal of virtual fencing and this is something you guys can do something about. So the idea of virtual fencing was to do away with the hard fences and to replace them with electronic fences, a little bit like the dog wire but without the wire. So with Peter we built the first virtual fence, which we regarded as a huge sensor network for cattle. Then also with Peter we inspired by all his field work we actually took everything we developed together and put it in the field and I really learned a lot from him about how to make a robot system really work and how to do it for real, and how to put meaning into the lab results. And it is actually very interesting because yesterday during out of our discussions at ISAR 2011 this came up as one of the most important challenges for the next round of robotics results. How do you start from a theoretical result and push that theoretical result all the way into field and into real applications that somebody cares about and wants to implement. And I think in some way the early work that Peter and I did together had some of that flavor. So it was exciting to get validated in some sense. So yeah, we built these virtual fences for cows and we demonstrated that we could put these cow collars and we could actually steer the cows. We could stop them from crossing a line. We could drive them in some direction of our choosing and that was also fun. I still remember joking about how the cow was a very interesting robot because in terms of motion it is a non-holonomic system but it has volition so you do not have to worry about how to drive it but you have to worry about what it wants to do and then we were also kidding around about you do not really need a battery to keep it going. "
"Daniela Rus","Interviewer","Just grass."
"Daniela Rus","Interviewee","Just grass. "
"Daniela Rus","Interviewer","Thinking about applications and having things go out in the world, does that later reflect on some of your other work like on the self-organizing systems were you thinking of applying them somewhere?"
"Daniela Rus","Interviewee","Yes, I remain primarily interested in developing robot systems that have enhanced autonomy and ultimately understanding autonomy in the context of self-organization. But as a bonus I think it is also very important to see that somebody benefits from the results of this work and so in the most recent years I have looked towards environmental applications and talked to biologists about how our technology can be used to make a difference in their world and the first instance of such an activity was a whale tracking robot. It took a few years to build this robot. I started on this project because I was at the MacArthur Fellows Meeting and I came across Roger Payne who is a very famous whale scientist and I believe he received his MacArthur Fellowship in one of the first rounds. So he was one of the first batches of MacArthur Fellows and so I gave my talk about robots and he gave his talk about whales and I think we both fell in love with each other's work and then Roger started telling me about his passion for whales and all the challenges of doing whale studies, and in particular about 40 years ago he established a lab in Argentina and this lab is on the coast of Argentina at a spot that is extremely important for the migration of the Southern Right Whale. Between August and October Southern Right Whales go there, hang out for three months at a time and That is where they have their babies and That is where they mate and they swim in 5 meters of water, 5 meters from the shore. So They are really there, you can really see them, and about 40 years ago Roger started a census studies on whales but the way he does the census study is he sits on a cliff with a pair of binoculars and he looks at who goes by and he checks and in fact all the Southern White Whales have numbers or at least the ones that he sees. The individuals are distinguishable by the callosities on their heads. So it is actually very interesting to see who is around and nobody actually knows how long they live. This is the first instance where somebody's tried to answer this question, but how laborious is that? Occasionally they pay military planes to do fly bys and take pictures but the planes are quite high up and they cannot get very good resolution in their images and when they send helicopters They are so noisy that they just drive the animals away. So we took one of our flying robots and we showed that, in fact, with this flying robot, which is very quiet as compared to a real helicopter, you can get maybe 10 meters above the whale, maybe the helicopter makes the sound of a mosquito so it is like a big mosquito buzz, but the helicopter can actually take a really good look at the whales, take unprecedented imagery and footage of whale behavior. So we did this experiment with Roger two years ago in 2009 and this also provided another opportunity for Peter and I to collaborate because we need help with his vision expertise in parsing these images so that we can get the robots to follow the whales and some of those results are just coming out. And in another work we were looking at underwater robotics, cooperation underwater. That is where it started because my students were getting really tired of designing modular robots where they actually had to worry about how much weight each motor could lift and at some point one of my students said, can not we do it in water, because then we do not have to worry about weights. This was after I moved to MIT and we started building these modular robots in water and then we connected to some labs that had access to water and one thing led to another, at some point we were doing some water studies and realized that people primarily used sonar when they make water maps, yet there is so much information encoded in the color that you see underwater. If you look at the ship hull you can really see a lot of detail in the different colors. If you look at the coral reef you can see a lot of detail about the eco system in color, yet it was not possible to take an image because if you take a picture in water and you are more than a half a mater away from your subject, that picture is going to come out blue and green and you cannot distinguish anything if everything is blue and green, you can not really see the shapes, everything is just amalgam, and with my students we started thinking about color accurate imaging in water and how might we be able to provide that. So we designed a device that enabled us to capture color accurate pictures that did not require post processing so you did not have to mess with the image. The image was taken to reflect the accurate color, and essentially the idea behind that work was to apply the inverse of the absorption that the water had on the light- let me start all over because I am just rambling here. So the idea behind doing color accurate imaging is to recognize that color is absorbed by water and it is absorbed in non-uniform ways. So red is absorbed faster than orange and yellow and so forth, but the absorption are known. So if you know the distance to the object you are trying to image you can compute how much light of each color was absorbed between the camera, the subject and back to the camera. So now if you have that information you can design an illumination device where you can control the amount of light of each color, and so you could effectively use this illumination device to apply the inverse of the water absorption phenomenon. So we built this device and we took it to the field and it was a big success. Most of the people that came across this device saw a use for it immediately. So it is interesting some of these results happened by serendipity, and I think a lot about our field is by serendipity. You know we each have our aspirations, dreams, research agenda, problems we would like to solve, but it is not so nice to be an island worried about your serums and robots and mathematics. So when we come together and we exchange ideas with people a lot of interesting knew potentials, new ideas, new suggestions come up, and to me this is a very important part of my work in the field. I have been in the field for more years than I care to count at the moment, and I have developed some very nice collaborations and interactions with my colleagues. I look forward to seeing them when we have meetings, we always have interesting discussions and I always feel sort of richer. I feel I have more ideas and I feel better off after interacting and you can see how in these two cases, in the case of the whale work that would not have happened without my coming across Roger Payne and it was a lot of fun to do that project, and still is, and the underwater imaging work was also enabled ultimately it boils down to my students refusing to build robots for the ground, so they wanted to do it in water, and the line of scientific meandering is actually very interesting, you just do not know what you are going to discover. The virtual fencing work it would not have been done without Peter, without Simon. So I think that we focus a lot on the results and the science and that is very, very important but there is also a human aspect of our interaction and that is equally important. And it drives the ideas and it drives the field."
"Daniela Rus","Interviewer","The robot valet."
"Daniela Rus","Interviewee","Yes, oh you watched that?"
"Daniela Rus","Interviewer","Oh yeah, I thought that was really beautiful I loved that."
"Daniela Rus","Interviewee","Thank you."
"Daniela Rus","Interviewer","And so how did that interaction or collaboration come up?"
"Daniela Rus","Interviewee","Well it is all so serendipity. it is amazing. So I have a colleague at MIT with whom I always enjoy talking. he is actually , this is Silvio Micali, and Silvio is very gregarious and very positive and I always so enjoy running ideas by him. So when we meet at faculty lunch, he says, hey, Daniela, how is it going? What are you thinking about? I tell him something and then he gives me feedback. He tells me what he thinks and so he is also so taken to bringing all his visitors and friends to see my lab because we have a lot of toys and one of his friends is the executive manager of Pilobolus and so the two of them were talking about, would not it be great to have machines and humans in a show and then Silvio said, well why do not you visit Daniela and these guys dropped me a note and said, could we meet you? And I happen to be a huge fan of Pilobolus, and I happened to be a huge fan of Pilobolus and Pilobolus started at Dartmouth, I have watched them many times, so there is lots of connections to Pilobolus. So agree to meet with them. They came to my office and they were just wonderful. They were really warm and they were very- they were just incredible people. We had a meeting of the minds despite the fact that they were coming from art and I was coming from science, and at the end of the meeting we actually started brainstorming what kind of possibilities might be for putting a robot in a human show, and here again the field challenge, right. If you do an experiment in the lab and something goes wrong, well okay, you have had the problem. But if you are on stage and the people watching a robot failure is a complete disaster so we really had to consider seriously all possible failures for our system so it was a fun project, but it also taught us something about our robots and about our algorithms and they way we use them and the way we make them tolerant and so after that first visit in April I suggested- so I looked at my robots. We have a lot of weird small robots, these self-organizing robots. They would not really look good on stage and then we have some ground robots and those robots again are a little bit boring. I could not really imagine what to do with them because if the robot does not have a human-like body, if it is just like a garbage can it is really not so interesting to look at. We have the underwater robots, which again you cannot put on stage. But then I thought the aerial robots could be good but then how do you make the aerial robots visible in the darkness of a theater and then I thought, well if we cover them with lights, and if we could program the pattern of lights to convey emotion and to convey action as part of the story then maybe we can do something. And I think they were a little bit surprised by that. Their first reaction was, oh we do not really want to have a Christmas tree on stage, but then they came around and they really grew to like the idea. Enough that they actually decided to put in the effort to do the piece. And the piece came about very fast so they came back, the entire creative team of Pilobolus came to my team for three days, and I still remember, it was Halloween weekend last year, and we booked a conference room and we started developing the piece. So Itimar this is the man who made the first connection- we were all talking and then at some point Itimar remembered the poem The Serpent by D.H. Lawrence and pulled it up and read it and it was very interesting, it is an extremely interesting and powerful poem. It describes the emotions of a man who comes across a serpent at a watering hole and who struggles with, should I kill it, should I not? So what is my relationship with this foreign beast, and what do I think about myself as I respond to the beast. And I think that actually set the tone for how we could think about the piece. Then we came up with this idea, we wanted to have some sort of a triangle and we came up with this rough story of the girl or the boy in the woods looking for berries. She comes across this strange creature just like in the poem, and there is some fear but then also attraction. They get to know each other but then this is a baby robot so the mother robot does not like the fact that the baby robot is keeping company with these alien creatures and chases the human away, makes the baby obedient, but the baby really likes the human, and after the mother disappears the baby goes looking for the human but it is a little bit too reckless and hurts itself, and then when the mother sees that and needs the help of the human to revive the robot, they all become a happy group and we have technology and people together, sharing and living peacefully, and at the end of the piece, it was very important to me that the end of the piece was happy. So at the end of the piece the human decides to take a trip to the robot's world. So that was roughly the story and then from the story we have to actually choreograph it and the act of choreographing was interesting because we came up with- or at least the dancers came up with a weird list of abstractions so there were some behaviors that we are either robot behaviors or human behaviors, and I forget what they were but they would not be the kind of abstractions you would come up with as an engineer, and so during the choreographing the dancers were picking the various abstractions and they'd say, could not you do X, and then X meant something for the robots and it also meant something for the human. So the piece came together that weekend and then they came back in December. We had another one or two days of rehearsals and then we did three Boston shows, and the audience was 3,000 people both times, I mean three times, all times. And then we paused and we came back together this summer and we did a couple shows in North Carolina and about 12 shows in New York at the Joyce Theater. "
"Daniela Rus","Interviewer","And how much of your team needs to go to help with the robots?"
"Daniela Rus","Interviewee","Two students have been deeply engaged in this and they basically became part of the Pilobolus family and they had a really fantastic experience. But I view this also as a very important outreach activity because I think these robots did more for robotics than what we can do by going to visit this classroom or that classroom. Giving an inspiring show where all the kids in the audience get excited and then get inspired and they want to know more, I think is really fantastic visibility for the field and it is a great way to attract the younger generation to the field. During the New York shows the students were there with the robots so during the intermission they took the robots and they showed them how they work and they answered questions and that was a very valuable piece of their experience. "
"Daniela Rus","Interviewer","And kind of a different way of portraying it where it is more of a competition. Those robots seem very lifelike in a sense, very different from a lot of robots that I think people would come across even in educational contests. So if we can just go back."
"Daniela Rus","Interviewee","Sorry."
"Daniela Rus","Interviewer","No, no, this is great, but just in terms of keeping time and I know people get tired after awhile. "
"Daniela Rus","Interviewee","I do not know what we are doing and I do not know what you have on your list. Please feel free to stop me if I tell too many stories or I ramble."
"Daniela Rus","Interviewer","No, the stories are beautiful. Actually the stories are great, the stories are exactly the kind of thing that we are looking for, but I was curious, so you told us a little bit about the kind of things you were doing in Dartmouth and some of the people you worked with, and then we jumped over to some of the work you have done more recently. Well one thing I am curious about, in the beginning when you were doing the amazing robots, were there other people who were interested in that kind of modular robotic?"
"Daniela Rus","Interviewee","Yes, so there were not many people, just a class of people around the world so Mark Kim was interested in this field at Park. Greg Terikchin was interested in this area and he was at John's Hopkins. Toshio Fukuda and- can we stop for a moment? What is his name? I am just blanking on this guy is name. Did you stop it?"
"Daniela Rus","Interviewee","Because he is very important but it is- how embarrassing. I should know his name."
"Daniela Rus","Interviewer","We can Google it if you want."
"Daniela Rus","Interviewee","Yes. "
"Daniela Rus","Interviewer","You want me to Google it?"
"Daniela Rus","Interviewee","Yeah, I have my computer. "
"Daniela Rus","Interviewer"," include the other people "
"Daniela Rus","Interviewee","Who the other people were?"
"Daniela Rus","Interviewer","Um-hum."
"Daniela Rus","Interviewee","The other people in the field were Greg Chirikjian, Mark Yim, Satoshi Murata, Wei-Min Shen. And actually the field grew since those early days. Many new people came to the field."
"Daniela Rus","Interviewer","Um-hum. And how have the questions that you have been dealing with also developed through the years in terms of these self-organizing and modular robots or other types of robots that you have been working with?"
"Daniela Rus","Interviewee","In modular robots, a very big challenge was to design the robot body. And each robot architecture then had certain actuation constraints that translated into planning algorithms for doing shape formation. And the first flurry of activity was really centered on essentially figuring out how to build a novel body and how to actually do the planning and these two questions were done in parallel. But then as a science I think it is important to move away from architecture specific algorithmic approaches, so I became interested in more generic approaches for generating motion plans for these systems that enable instantiations to different types of architecture. So the first body of work was inventing new robot bodies and planners that go with their capabilities. And then when a sufficient number of systems were developed by my group and by other groups around the world, I actually became interested in asking broader questions about self-organization and abstractions that are required by self-organization. And we developed an approach, a more generic approach, to controlling these systems, that could essentially become down to each type of architecture. And after we learned a little bit about the field in this way, we started asking more practical questions about How do you actually build systems that are robust and have some sort of believable behavior? because there is one thing to say, Well, we are going to have thousands of robots working together and making, growing, a third hand or a second head or an alligator, and it is another thing to actually build it. Then when you have platforms that have 10, 20, even 100 modules you do not really get the resolution and the types of objects that we dream about getting. You do not quite get the Barbapapa family. So miniaturization became very important. But also robustness on the experimental side and we learned early on that making and breaking connections was a very difficult operation in these systems and they all operated by making and breaking connections. And I imagine doing that in parallel, because if you have a system consisting of a thousand modules and you have to wait for each module to do its thing before you can move another module, the time complexity is crazy. So you cannot have sequential algorithms. You really have to focus on parallelism. So you have parallelism, you have a lot of making and breaking of connections. it is a big challenge. So how do you then solve these problems? In the recent past, we have looked at two ways of addressing these challenge. In the first one, we wanted to do away with the making and breaking of connections that is necessary to make an object. And we call that so we tried to come up with a process analogous to sculpting. So we said in terms of actively making and breaking connections, why do not we start with a block of electronic sculpting material? And why do not we figure out how to peel the extra modules off this block so that the shape reveals itself much like the David revealed itself out of marble to become Angelo? And we started work on a system called Mica and that system evolved into a system that uses a smaller unit module that we now call Smart Pebbles. Our unit modules are one centimeter cubes. Eventually we would like to go to Smart Sand. But figuring out how to package communication, computation, sensing and actuation remains the challenge here. So when we built the Mica system, we had modules about this big. They were about four centimeter cubes. And they were essentially computers that had switchable magnets. So you could program the connections on or off. And we also had a communication system implemented through an IR mechanism. And we had distributed planning algorithms that enabled the modules to talk effectively and figure out who is in the final shape, who is not in the final shape, and then all the modules not in the final shape could reprogram their connections by switching their magnets and they could just peel off. They could just drop from the block. So the biggest component in that system was the motor that rotated the magnets. And so we were able to go from the four centimeter module down to one centimeter module by building something we call an electro permanent magnet. it is about one gram and can be used to do program connections but also to transmit communication between the units and to transmit power. So all of a sudden we no longer needed the space for batteries and the space for these complicated motors. And so now we have these really cool pebble-size pieces, but ultimately the challenge is to go to sand scale grains. And to build enough computation infrastructure that can actually run the algorithms. What we are finding is that even though the smart pebbles have small computers inside, those computers do not have enough space and They are not fast enough to run the entire gamut of algorithms we have developed for this area of modular robots we call shape formation by sculpting. So That is one direction. The other direction is to do away with making and breaking connections altogether and replace them with a different action. And here we are trying to make Smart Paper. So this is paper that has embedded computation, communication, actuation and sensing. And we are trying to get this paper to achieve the shape you desire by a process analogous to origami. And we call this self-folding sheets and we have some successful experiments and some successes with designing this new type of body and developing algorithms that generate the planners that tell the system how to bend each edge in order to achieve the desired shape."
"Daniela Rus","Interviewer","Um-hum. And all of this is at ?"
"Daniela Rus","Interviewee","So this is actually quite recent work. Maybe the pebbles and the smart sheets have been done at MIT over the past maybe two, three years. I have collaborated on the self-folding sheets with Rob Wood who is at Harvard. He gave a wonderful talk on insects and flight yesterday, if you caught him. he is a young guy with tremendous creativity and potential. And Erik Demaine is one of my colleagues at CSAIL and Erik has collaborated with us on the theory side on the origami planners."
"Daniela Rus","Interviewer","And when you moved from Dartmouth to MIT, how did that move happen?"
"Daniela Rus","Interviewee","I moved to MIT because MIT recruited me. And, in fact, when I was looking for jobs the year I went to Dartmouth my dream job was MIT. And I interviewed at MIT and my interview was a disaster. I did not get the job. I was really crushed. And so it was very interesting that a few years later MIT, my colleagues at MIT, invited me to give a talk and then we started discussing a potential move there and after some discussions I decided to go."
"Daniela Rus","Interviewer","Um-hum. And being, since the CS department there is also connected with electrical engineering in CS, does this kind of make it easier to do some of this work since you are "
"Daniela Rus","Interviewee","there is a lot of expertise at MIT and the students are trained in EE or CS and in fact, MIT encourages very interdisciplinary research. So at MIT we have a matrix organization. And we have our education activities that happen in departments and then we have our research activities that happen in interdisciplinary labs. So the laboratory I am in, the computer science and artificial intelligence laboratory, has faculty from many different departments and I also, I am also able to supervise students from many different departments. So my group at the moment is actually quite mixed. I have students from computer science, I have students from double E, I have students from mechanical engineering, I have students from AeroAstro. And we somehow find a way of bringing all of our skills together and the students help each other. Naturally, if they have a strong background in one area they would be weaker in another area, but the students have built a culture where they help each other and they learn from each other. So ultimately I think we are better off in this way. And robotics really needs this, because robotics is really at the confluence of computer science, electrical engineering and mechanical engineering. And these are the skills we want to see in all of our students. However, if you look at how we train students at the undergraduate level, we do not train them simultaneously in all these disciplines. But MIT is structured in such a way that it enables students to be multi-disciplinary."
"Daniela Rus","Interviewer","Does CSAIL and the media lab, do you work with people at the media lab at all or are they ?"
"Daniela Rus","Interviewee","Two separated labs and I personally have not had any substantive interactions with the media lab but there are other colleagues in my department who have."
"Daniela Rus","Interviewer","Um-hum. Because both of those do a lot of work in robotics, perhaps with slightly different "
"Daniela Rus","Interviewee","Different goals."
"Daniela Rus","Interviewer","Goals, yes."
"Daniela Rus","Interviewee","Yeah. Cynthia Braezeal is wonderful to talk to if you are looking for another name."
"Daniela Rus","Interviewer","Yeah, yeah. She is on the list."
"Daniela Rus","Interviewee","She is on the list. Great."
"Daniela Rus","Interviewer","Could you tell us a little about who has funded your work through the years and if there are any other project or any other collaborators that you want to mention?"
"Daniela Rus","Interviewee","In my work on distributed networked robotics That is in my aspirations to develop the network science of distributed systems, I have done a lot of collaboration with Vijay Kumar. we have had a very long history of working together and collaborating together and it is been really wonderful, I think. Many results happened because of this collaboration and they would not have happened had we not interacted closely. We have, Vijay and I, have several jointly funded projects and this has also allowed our students to get to know each other, to do lab rotations, to rotate as post-docs from one lab to another, so we really have a very substantive interaction. The other person I worked with closely in mobile robot systems is Guarav Sukhatme from USC."
"Daniela Rus","Interviewer","Just funding."
"Daniela Rus","Interviewee","Oh, funding. So yeah. Funding is always a toughie because there is not ever enough money. But my own funding comes from the NSF. I have had funding from DARPA, I have had funding from ONR, AFOSR, the Army Research Labs, and I have a significant project at the moment with Boeing on manufacturing. This project is actually pushing a collaboration with Howie Choset at Carnegie Mellon and Henrik Christensen at Georgia Tech. And recently I started working on a very cool project funded by the Singapore government on providing mobility-on-demand systems using small robots."
"Daniela Rus","Interviewer","Hmm. And how do you make these connections? You mentioned making a lot of connections in a sense serendipitously at conferences or during lunch at the MacArthur Fellow and things like that. What are some of the other places where you would make these kinds of connections?"
"Daniela Rus","Interviewee","The connections happen because you are interested in the same topic and we follow the research from other groups and we read each other's papers and so if there is a natural synergy between the paths we set out to follow, then we start a dialogue and if it makes sense, a collaboration comes out of that."
"Daniela Rus","Interviewer","Um-hum. And I think we can ask you the final question. This is kind of a fun question. it is meant to go to the educational part of the site, but it is basically if you are thinking of new people who are interested in the field, young scholars, students, what kind of advice would you give them about getting into robotics in the first place?"
"Daniela Rus","Interviewee","Well, I would tell them to follow their passion. So to the young graduate students I would give them the same advice I was given by Rodney Brooks when I was a graduate student, which is to do different things, to have the courage to try new things. So when I was a graduate student, Rod gave me a wonderful piece of advice. He said, Look at what the others are doing and just do the opposite. So look at what assumptions people make and see what happens if you negate the assumptions."
"Daniela Rus","Interviewer","Great. Thank you."
"Fumio Harashima","Interviewer","So we are going to start with where you were born and when."
"Fumio Harashima","Interviewee","Oh yes, this is my life. I was born in 1940. This is a special year. Do you know that? it is Emperor's Year, 2600. But this is a they plan government plan to start a war this year. This part of Japan. This is my kindergarten. And so this is . Then they decided to start the war. This a very strong war , Arizona, Hiroshima, 1945, March 10, Tokyo. Completely destroyed. The end of the war. At that time we right to left. This not mine. This not me. Primary school, 1946, next year of the war. This building survived the war. Still other war started in the neighbor country, Korea, the war. This is a city of . Incredible war. Only sixty years ago now, 1950, in summertime, at the time of . Dinner. My family is a big family, five children. My father survived the war. Very lucky. And he is in the summers at dinnertime he told us, to the children, this year is just a of a century, 20th century, and this he said these children will survive. We arrive until the next century. And he said Japanese people will his age is guilty in the war for destroying the whole Japan and he expected in the next century that next century, this century that he expect on science and technology. And my father was a physicist very well known physicist. And then this is not the reason why I went to science and technology. This is a totally different reason. And this is high school, private high school. It is like Eton in England, something like that. Very special education. I did not like it. No freedom. And for six years, from middle school to high school, I was always reading books. Another time we are very poor and we cannot we could not afford to purchase books, so I went to library most every day after school, . And I wish to be a novelist, not science and technology, until the end of the high school. And I suddenly change my mind because I found I was not talented in writing. And in university I went to a science and technology. And I chose electrical engineering because this I believe this is the most far from writing. So I went to University of Tokyo classroom. At that time we have us on black uniform. I am here. I do not have a uniform. And came out oh, this is the teacher of this class. Forty people, forty student. One month ago we got together. Only one guy missing. All other arrive. They all over 70 years old. Incredible. So you understand how our life expectancy is long. The teacher passed away."
"Fumio Harashima","Interviewer","How did they allow you to not have a uniform?"
"Fumio Harashima","Interviewee","I do not know. And they go to different direction. All of them are in science and technology. Some of them are physics, chemistry or engineering, or mechanical, aeronautics or something like that. And probably I think over 70 percent of my classmate become the top executive of the companies. And the other, professors. "
"Fumio Harashima","Interviewer","The University of Tokyo was one of, or was the best school at the time, and still?"
"Fumio Harashima","Interviewee","Right. Right. Another time . Engineering student number one engineering student are very small at that time. So this is around 1960, and there Japanese industry started growing very fast so they needed good people. So most of them went up, very top of the companies. And they supported this Japanese economic growth."
"Fumio Harashima","Interviewer","How did you see the change in the way they saw science and technology in Japan after the war? So since you kind of you have experienced the whole from the 1940s to now."
"Fumio Harashima","Interviewee","I think most Japanese people have this kind of feeling, and then very good people, good student, came to science and technology. that is a major reason why Japanese science and technology grow so fast. And until middle of 1980s, we had very bright student in science and technology. But in the middle of 1980s, people felt they are rich enough. So good student or not started going to other area. Now I am sure science and technology student also not good enough. And in most of well developed countries in the world, the situation is almost the same. Even the U.S. or U.K. or in France. But the difference is, for example, the U.S. can get the bright young people from outside the country. The same thing in U.K. or in France. And Germany was in a similar situation like Japan that they cannot get good people from outside. But after the 1990s, the Soviet Union collapsed, they get good people from Eastern Block. Probably you know that very well. "
"Fumio Harashima","Interviewer","But in the beginning when you had democracy justice and science and technology, why was science and technology seen as being so important for development along with these kind of other humanistic goals?"
"Fumio Harashima","Interviewee","I think that people believe the first step is to get rich, and after the society has matured they feel society's goal changed to, number one, health; number two, justice. it is based on rich society. "
"Fumio Harashima","Interviewer","So just like your son and daughter, right? Health and justice."
"Fumio Harashima","Interviewee","Oh, That is right. Exactly. So my daughter is a medical doctor and son is a prosecutor. Probably when they are small children, probably we talked such a thing at the dinner table or something like that. But they remember that. So this is a typical Japanese history of 60 years. Okay, let us go. Can you see? This is 1960, just after I enter the university. This is student power was very active. And two issues. One is renewal of military treaty between U.S. and Japan. The number two issue is government proposed a military service role, duty role, and then we fight it against the government. And the first one we lost, and we won then the second one. So this military duty role was canceled. That was very good. But other result of this one, student power time we did not study at all for two, three years. University was always closed. But still they study by themselves. No lectures, no classroom there. I myself was very much depressed mentally, and I gave up to take job in the industry. So I went to graduate school at the time we were young, time. Mentally I was miserable, very miserable. And John Kennedy, the president in 1962 or I am not sure but we felt that the world had changed. Many thing happen. Castro. Cuba crisis. Castro. Gorbachev. John Kennedy. But John Kennedy started the Vietnam War. We are so disappointed. Most miserable war. This we closely defend so we know it very well. The only thing on John Kennedy, only good thing is that he started a civil role. And it is a big influence on my life. This is probably you are here, Institute of Industrial Science University of Roppongi. Yeah? At the graduate level, I studied here, and we started on our space program. And we moved to another place. This campus was too old, this building too old, and we moved to a new campus which is several kilometers. And at this time, this movement, I was director of the institute. So this whole building was my design. it is a rough design. I am not an architect, so this is a rough design. I enjoyed it. This is my research floor, 1965. This is PhD. Submechanism , it is a nonlinear control theory. Another example of this theory, I started power electronics just after I got a PhD. "
"Fumio Harashima","Interviewer","Who did you work with for your PhD, your professor?"
"Fumio Harashima","Interviewee","it is a funny story. Just after next year I enter the graduate school, my professor had a disease on the lung and hospitalized for three years, four years. So no supervisor. I monitored his laboratory by myself. Only 22 years old or something like that."
"Fumio Harashima","Interviewer","How did you become the manager of the laboratory rather than some older student or something?"
"Fumio Harashima","Interviewee","Because a student did not do that, but I volunteer for funding of education, so. Many things. And then I think this I got a PhD here. Electro-drive motion control. And this is starting of manipulator control, robotics. I think do you know Hideki ? Hideki came to my laboratory I think in this year and he started this project, the robot controller. And then this is interaction, , interaction between human and robot through computer intelligence. And this is a big project, national project. I am the leader and I formed some team, not till later on. And also this is a second stage of this project. Well funded. Oh, 1974 I attended this Industry of training society a major conference called ICON , and I was deeply impressed by this area, technical area. At that time they covered motion control for electronics of computer control and factory automation. And then I think I was only one Japanese. At that time this is still at that time still it is U.S. domestic conference, not international conference. It was domestic conference. And then this is a picture of that time, in Philadelphia. He was society president at that time."
"Fumio Harashima","Interviewer","Who are some of the other people?"
"Fumio Harashima","Interviewee","here is Troy Nagle . He was to be president around 1990, and he is also some I think my successor as society president. And then I was so interested in new society. I invited my friend to be involved in this activity with the society. So then we started changing this society. We have from industry Mitsubishi, Hitachi, Toshiba Oni Sensei . At that time he was still I am not sure PT student , as our youngest professor. And Hiro , Fernando Darme from Madrid and Andrew do you know Andrew? From Taiwan. he is here. he is a nice guy. he is also a society president later on."
"Fumio Harashima","Interviewer","So how did you get to know these people? At least some of them."
"Fumio Harashima","Interviewee","Oh, the first three supported my laboratory. That, or engineer. High-position engineer. Manager of for electronics, motion control and microprocessor. Then we changed the society. It is 1990 or 1980. We introduced the word mechatronics , robotics, informatics, and the memes . So society was totally changed. We created several societies, Society, and this is the Robotics . We cooperated with the computer society and the control system society and the industry society, and then we formed this new society and also we started names."
"Fumio Harashima","Interviewer","While you were trying to change things, how did other people react?"
"Fumio Harashima","Interviewee","We have a long, long discussion, overnight discussions and things like that. And this is just a result, you know. We have discussed so many things."
"Fumio Harashima","Interviewer","What were some other ideas, if you remember?"
"Fumio Harashima","Interviewee","At that time we discussed about also some semiconductor device for control or something like that, and also communication technology. Anyway, our decision was like this. "
"Fumio Harashima","Interviewer","And was Nikotronics known at the time? "
"Fumio Harashima","Interviewee","Do you know the word Nikotronics was invented in Japan around 1970. And, oh, most of the U.S. people are against that because this not an English word, he said. And finally I think we voted whether or not we should use this word or not. And we won."
"Fumio Harashima","Interviewer","What was the composition of the society at the time? Were there a lot of Japanese members?"
"Fumio Harashima","Interviewee","When I started, no Japanese only one. And then these people came in, and they brought many people around them. And when we started, members from outside the U.S. are the very few. This time, I think the majority of members are from outside U.S. Also European here, and Fernando, and also must be here. Yeah. He he was involved in there. So must be here. So European people came in, and also after Japanese, Korean and Taiwanese, from Singapore and the people following us. And the society. This is my activity in society. This shot, this color shot, in the U.S., the other in Japan. So from this in 20 years and that, probably I mainly worked in the U.S. This is chief in Japan. I started funding electronics and also I worked as editor in chief of IE Transaction. And around year 2000 I came back to Japan, probably because I was too old I was around 60 years old. Sixty years old is a very interesting age in Oriental countries. In the old days, human life is 60 years. So I came back and I served as the president of Japan. I was on Science Council of Japan member. Oh, this the people around 2000: , Ren Ru , Toshio Fukuda . Do you know ? Passed away. Kohe , Kazahiro . All of them are out on here in this conference. And we created this IROS conference in okay, probably it is here. Around 2000 or 1990 through 2000 we started new transaction on mechatronics and Toshio and do you know Tomitsuka -san?"
"Fumio Harashima","Interviewer","No."
"Fumio Harashima","Interviewee","he is a professor at Berkeley here. I met him three days ago. he is the leader of controller engineering in California area, Ren Ru. Let me think. he is the very last guy. We also started informatics transaction, and Richard and did it. And also Toshio Fukuda start this IROS conference and Kobayashi Sensei started Rumen Conference. Do you know Rumen Conference. And AI conference for Hideki. I created conference for each person. This a gift to him."
"Fumio Harashima","Interviewer","How do you go about creating a conference?"
"Fumio Harashima","Interviewee","How do you what?"
"Fumio Harashima","Interviewer","How do you create a conference?"
"Fumio Harashima","Interviewee","Oh. Good question. Number one is you must be very top of some society, society. Otherwise you cannot make a proposal. The second thing, if you have people like this, you can do that. One is position. This is very important thing. And then anyway, if you find a good founder then That is okay. And probably I gave chances to more than ten people, and then these, only five are surviving. The other conference disappears. They are successful, especially in IROS. It was very successful. "
"Fumio Harashima","Interviewer","And so there must have been increasing interest in the field as well to support more conferences."
"Fumio Harashima","Interviewee","Right, That is right. Right, That is right. Exactly you are right. that is a very important thing. Yeah. Oh, this is a very small one. This is a citation index. Number three, the IE transaction. Number one is signal processing I cannot see that."
"Fumio Harashima","Interviewer","it is a signal processing magazine."
"Fumio Harashima","Interviewee","And second is PIE . They are not regular paper journal. They are just for invited people. So actually IE is the number one in regular transactions, and also mechatronics transactions are . This is something like that, over 300 or something like that. So Japanese is good. Anyway, we are very successful in this. Important thing, except IE and mechatronics, other things are semiconductor or signal processing. So this is very special cases. Oh, friends. We have New Year party at my house every year, on the first Saturday of the year. "
"Fumio Harashima","Interviewer","Some are sleeping."
"Fumio Harashima","Interviewee","Oh, . "
"Fumio Harashima","Interviewer","Oh, I see. "
"Fumio Harashima","Interviewee","And I think 30 percent come from outside Japan. Oh, this is a picture of picture of, Ren Ru, myself, . This is TJ Tarn. Do you know TJ Tarn? Washington University. TJ Tarn, T-A-R-N. He is Washington University in . And he is a leader or robotics and the control in Chinese American society. it is like a mafia. He was here until yesterday. He left. And then Toshio. And this is Kasuga-san . This is Kasuga-san. So some people come from Taiwan and Korea and China, I think even from Hungary or Germany or something like that. We start this party 3 p.m. and the end is next day. Next day."
"Fumio Harashima","Interviewer","that is a good party."
"Fumio Harashima","Interviewee","Yeah, 30-40 people, and I think five dozen beers and 10 bottles of scotch and 40 bottles of the wine. "
"Fumio Harashima","Interviewer","Wow. Good job."
"Fumio Harashima","Interviewee","And my wife ."
"Fumio Harashima","Interviewer","No wonder was sleeping."
"Fumio Harashima","Interviewee","I will give you this copy. Oh, this is ITV board of directors, 1990, 20 years ago. I showed this picture because you see only two ladies, only two female. This is 30 years after . Incredible. U.S. society now is diversity society, but still in some part of the society only two female, only one not white. I was so disappointed by that at that time. But situation in Japan is different. All men. This is year 2002. I was the president of this society, . No female. No foreigners. We have to improve our society. Very . This is board of directors last year."
"Fumio Harashima","Interviewer","there is one woman, two."
"Fumio Harashima","Interviewee","Only two."
"Fumio Harashima","Interviewer","Three. there is one in the back."
"Fumio Harashima","Interviewee","Three? How many not white?"
"Fumio Harashima","Interviewer","One, two, three. I am stuck."
"Fumio Harashima","Interviewee","Four."
"Fumio Harashima","Interviewer","Five. I think that five."
"Fumio Harashima","Interviewee","Well, six or seven. it is improving, but still not enough."
"Fumio Harashima","Interviewer","But in 20 years "
"Fumio Harashima","Interviewee","Right, 20 years, a little bit improved."
"Fumio Harashima","Interviewer","Are there specific things that the directors and that you tried to do to make the situation improve?"
"Fumio Harashima","Interviewee","Yes, continuously with the well, I was on the board board I started to improve the situation, and then people agreed and then we started, but still slow."
"Fumio Harashima","Interviewer","What kinds of things did you do?"
"Fumio Harashima","Interviewee","Oh, I think if you read in the bylaws, it is mentioned. Probably it is on some part. And bylaws or Actually… Let me see. On some document, yes. Read some on the web. And we believe a society without diversity cannot be so innovative. The history shows that. So we are much behind the U.S. Very bad. "
"Fumio Harashima","Interviewer","And is this situation oh, That is 2002. Okay."
"Fumio Harashima","Interviewee","This year only one. See, only one female, Uma. This is a first in the history of this society. Okay. This my team, research team. I am here. I looked for your husband in the picture, but I cannot find it."
"Fumio Harashima","Interviewer","My dad? Really, he does not have a picture online?"
"Fumio Harashima","Interviewee","After you have seen my computer."
"Fumio Harashima","Interviewer","Okay. I will tell him to send you one."
"Fumio Harashima","Interviewee","Okay, okay, very good, and have his picture in, okay. "
"Fumio Harashima","Interviewer","Oh, Shibata-san in your lab as well? "
"Fumio Harashima","Interviewee","he is "
"Fumio Harashima","Interviewer","Because he studied with right? "
"Fumio Harashima","Interviewee","After PhD, he joined in my research group. I have a big fan, and I gave him a fan. This is Ren Drew, this is Martin Burse, so oh, do you know him? "
"Fumio Harashima","Interviewer","Ah, Utkin. "
"Fumio Harashima","Interviewee","Vadel Utkin, yeah. it is Richard. Oh, this is he I invited him to stay for one year as a visiting professor. "
"Fumio Harashima","Interviewer","he is familiar, too. Was he in your lab at Tokyo Denki?"
"Fumio Harashima","Interviewee","Right, exactly, exactly. sensei yeah. And the problem, probably only two Uma is on here among 30 or 40."
"Fumio Harashima","Interviewer","So since there is so few women, even as students, in terms of the career, how does are there barriers to women, I mean, even in the US, they always talk about, you know, you get pregnant and then that is a different situation, or "
"Fumio Harashima","Interviewee","Okay, number one thing is, anyway in engineering, women students are not only women students are very small. Some exceptions are computer science, also in architecture. And companies, industrial companies want to employ female researcher, because they like to develop a product with a women's feeling, so they need it, but very few women engineers want to go to industry. They want to be teacher, rather than go in a industry. Anyway, we have to change something. But it takes a long time for anything happen, having 1990 during war, 1995, Kobe earthquake. Japanese people do not trust civil and earthquake engineers after that. Nine-eleven after 9-11, I almost stopped visiting US, because, you know, travel in the US is not so comfortable . And I think this IRIS conference is only my exception I visit the US, so I propose them to have IRIS conference in the US, in Hawaii or in Las Vegas, and we do that. So that I can enjoy that. San Francisco is one of the good cities. And then, 1998, I moved from the University of Tokyo to Tokyo Metropolitan Institute, as the president. I was invited to be the president, and then. Do you know, the mayor of Tokyo, , very well known writer, novelist, and he invited me to be the president. He is a I do not like him in his philosophy, his rightist. But good friend, but I locked in the KIST after that. This was a very good experience for me. And I learn the Hangul. You know, Korean Hangul language grammar is the same, just the same as Japanese, but the writing are different, totally different and pronunciations are different. "
"Fumio Harashima","Interviewer","So how was robotics in KIST in general, in Korea, different from Japan?"
"Fumio Harashima","Interviewee","Growing very fast. And they have good students, PhD student, so probably taking a level of Korean, all of robotics are the same as the Japanese, and will grow up within a few years, because they have good people. Yesterday we decided to have this IRIS conference, in 20 ?"
"Fumio Harashima","Interviewer","Sixteen. "
"Fumio Harashima","Interviewee","Sixteen, yes. "
"Fumio Harashima","Interviewer","I mean, Korea seems I have never been to Korea, so I do not know what it looks like there, but just from talking to some of the Korean students, and reading some of the news, it seems to have taken the kind of initial Japanese promise of just really accelerated technological development, in a sense, even more seriously. Is that what it is actually like over there? I mean, they seem to be funding a lot of robotics projects for immediate application and "
"Fumio Harashima","Interviewee","Right, That is right. They are, you know, how do I say? They are very good in application over some technology or something like that, so they are complaining, no, we are not there, no one is there. And when I was here, I gave some talk for whole student, the whole and with professor, and somebody asked me, and this year, now we have Japanese, two or three robot project there. They asked me about why no Korean Nobel Prize. My answer was the KIST is a very good university, very high level, but no professor work in the Nobel Prize areas, basic physics, chemistry, biology or something like that. The only one Nobel Prize from Korea is past president, a peace here, Kim Dae-jung so my suggestion is Korea should work more on the basic science. And then they said, some of the professors said, you know, Korea is still developing stage, so they cannot afford to use people at the very basic sciences. I think it is not true. You know, Nobel Prize winners from Japan, started studying when we are very poor time, you know. So it is something they should something wrong. Okay, but the very good thing is oh, this is most well known TV stars, and my wife and I. I think that this is a summer synthesized picture. "
"Fumio Harashima","Interviewer","They were not standing right next to you? "
"Fumio Harashima","Interviewee","Right. Oh, this is French. I organized that, it is actually a conference on robotics in the robotics area in Bordeaux. And the mayor of the city of Bordeaux, believed that this robotics could be a prior to now, a wine harvest or This one never the first thing there, so they are so happy, and they gave me some title of Wine Master."
"Fumio Harashima","Interviewer","Wow. "
"Fumio Harashima","Interviewee","In some church. I was so happy then. "
"Fumio Harashima","Interviewer","And hopefully lots of wine. "
"Fumio Harashima","Interviewee","Oh, a good customer. Oh, this another French award, national award. I supervised a French national project on the MEMS. One time in early 1990, the French and the delegate people came to Japan, and they go around the world trip, to investigate the MEMS technology, in the US, Germany, and Japan, and at that time, France was behind in this technology, and they decided to lock together with Japan. And I was on Japan's so I we accepted almost 100 French engineers in our institute, Institute of Industrial Science, University of Tokyo. And we send out some of our PhD student to live together, and finally, they still going. This project is still going. They established a new national on MEMS, and then they gave me some national award, Palme Academique. This award was established by Napoleon. So I think this is given by French "
"Fumio Harashima","Interviewer","You think it is the Prime Minister "
"Fumio Harashima","Interviewee","Prime Minister, Prime Minister. "
"Fumio Harashima","Interviewer","For services to French culture."
"Fumio Harashima","Interviewee","Right. And they after I came back from Korea, I was elected President of Tokyo Tech University. This university has a long history, almost 100 years, and professors are very good, but I was disappointed, the quality of students was very bad. So I give up to improve this university. The professor and students must be almost the same level. "
"Fumio Harashima","Interviewer","Why, why would they have that situation? It seems is the funding very good, or why would the really great professors want to be working?"
"Fumio Harashima","Interviewee","The reason could be anyway, good students do not go to area. And total number of trouble we have, in Japan, we have now over 700 universities. Among them, I think we have 200, more than 200 faculty So many students, too many, so these are not very good students who go to University of Tokyo and any other university. They are they do not come to . Private university, very bad, so I give up. Then I join, again, I Tokyo Metropolitan University as the president. You know, at this time, city of Tokyo has now four universities. This is one of them, and then I proposed, the governor, to combine the four students into one, merge it into one, and then this university stopped. It started in 1995 and I was second president. This is a comprehensive university now. Just after I the president of TMU, only two weeks later, I had a car accident, almost dead."
"Fumio Harashima","Interviewer","Oh no. "
"Fumio Harashima","Interviewee","And my wife was driving, and I was the next, and our car stopped at a traffic jam, then end, then two ton truck hit from the back, at the speed of 100 kilometers per hour. And my wife and I, watching on the back mirror, so was prepared. But I was suddenly hit back, you know. I lost consciousness, and woke up in the hospital. My neck was injured. I still have some aftereffect. For example, my finger fingers do not work independently. This time okay, so I have some difficulty in typing. I started from a wheelchair, and I have and the walking machine, and a stick, and standing up. It took six months."
"Fumio Harashima","Interviewer","Oh, very long time."
"Fumio Harashima","Interviewee","To recover, to get normal. It was a hard time. This is IRIS. Oh, I think it is not IRIS, probably Ikara I am sure in Kobe, three years ago. Probably Ikara. Already drinking wine."
"Fumio Harashima","Interviewer","It does not hurt the recovery process."
"Fumio Harashima","Interviewee","And you know, my daughter said, I have some pain in the neck, then you know, some medicine or alcohol? "
"Fumio Harashima","Interviewer","One of the other, not both. "
"Fumio Harashima","Interviewee","That is right. So I chose alcohol. "
"Fumio Harashima","Interviewer","it is tastier. "
"Fumio Harashima","Interviewee","Right. Oh, this is in this area trying some other thing, it is a special issue, only professor Fumio Harashima for can not see that. Celebrating his contribution in robotics and mechatronics, yeah. "
"Fumio Harashima","Interviewer","it is June, 2010. "
"Fumio Harashima","Interviewee","And this picture, my wife took this picture. No one, in such a case, you know, professor sits on a table, and on the books behind."
"Fumio Harashima","Interviewer","You look much more relaxed. it is better."
"Fumio Harashima","Interviewee","This is a well known place. This is this is a very special geographical structure. This is close to Kyoto, and my wife and I went to this place just for taking this picture. "
"Fumio Harashima","Interviewer","Well then it is good they put it on the magazine, so everybody can see. "
"Fumio Harashima","Interviewee","Right, exactly. This year, and this is followed by still going, and people do not trust science and technology anymore. This is a human accident. I know as you know, I was a president of and at that time, I was already critical to a nuclear power, and I write some articles several times on criticizing nuclear power, but I know, I am very sorry. I did not take any strong action, I did not start any strong action. I feel guilty of that. So 20 kilometers, 30 kilometers, I think we cannot people cannot come back into this area for the next half century. it is like on Chernobyl, more than that. Radiation is more than that. "
"Fumio Harashima","Interviewer","So how has that changed now, the discussion about science and technology. In the beginning when you started, it was very positive, and it was seen as a potential kind of way to save and improve society. How is the discussion different now? "
"Fumio Harashima","Interviewee","I think, and as I told you now, people are already rich. You know, it is a mature society, so they are expecting, you know, home appliances and the cars and something like that. Number of car production in Japan are going down, and semiconductors are going down, and the computer is also going down, and our science and technology are going to the direction of, biotechnology or medicare technology, and also some anti-earthquake technology. Most serious problem is we are losing our bright students, young students, so we have to import. Like the US, but our problem is, you know, it is difficult for foreign people to be happy in Japanese society because of some culture difference, you know. You know from Europe and the US, is originally the same cultural the same culture, so their happiness is compatible. But Japanese people and western people are different, totally different, so you know, they come to Japan, but they cannot be happy here. And Japanese people in general, cannot be happy in a western country. But why Chinese people and people from India come from the US totally different culture, but they can be happy, because here is extreme poor. that is a big difference, you know. And another thing, why people from Korea and China, do not come to Japan? Still aftereffect of the war. You know, China Japan is something like a past, like German, France issue, something like that, but Germany and France is now changes, they are very close. You know for the last 30 years, they exchange young people, high school student, starting there. But unfortunately in Asia, in the far east Asia, we did not have such a policy. Still, you know, personally we are friends, but as a group, they are conflicting each other, it is very bad. Probably we are guilty for that, I am sure. This is another history. Home appliance in my family. This is you know, 1948, just after the war, radio, vacuum tube radio. I watched this radio now so carefully, and from the back, and I have seen that. Telephone, tape recorder, washing machine, refrigerator, transistor radio. These are Sonys, and TV, black and white, car, the first car. I was married here, I was married here."
"Fumio Harashima","Interviewer","Oh, when you got the car? "
"Fumio Harashima","Interviewee","Just after. Yeah, and the cassette tape recorder and air conditioner, color TV, microwave oven, okay. From here, you know, this are not that one is traditional home appliance. From here, everything is, you know, computer based. In 1974, the first microprocessor came out, and from ten years, 1970 to 1984, we did not buy any. it is already there. Some time, it is already there. And the new stuff, new kind of stuff is here, Nintendos and TV game, microprocessor, word processor from Toshiba, MS DOS, Windows 3.5. And the internet, 9.8 kilobit, do you remember that? "
"Fumio Harashima","Interviewer","Not really, I was too small. "
"Fumio Harashima","Interviewee","Probably you were small then. And Windows 95, and the digital camera, mobile telephone, you know, ISDN, TV, DVD, car, I got a new car, Lexus, these are mostly electronic, not mechanical, you know, electronic product, navigator, wireless route, fiber, optical fiber came to my home. it is a car, this Nintendo's Wii, do you know Wii?"
"Fumio Harashima","Interviewer","Mm-hmm. "
"Fumio Harashima","Interviewee","Okay, this the last one. But this year, I bought an iPad. I enjoy it. This is the history of my family, very interesting. "
"Fumio Harashima","Interviewer","And how do you think that in terms of, you know, robotics or science and technology, how is do you see kind of a similar change in the type of research or type of questions that people are dealing with? "
"Fumio Harashima","Interviewee","Oh, robotics is the robot industry is very similar, as you know. We introduced a robot into the manufacturing process in the middle of 1990 probably the beginning of 1980, and then this is we introduced robot in place of the human workers, and the machine is the same. That is the reason why robot is human-like, mechanically, but at the time, no intelligence on that robot, just the replacement of the human worker, mechanical replacement, you know. And then from 1990, you know, certainly we developed an intelligent robot, but at that time we redesigned the whole manufacturing plant, then we do not need the robot. The whole manufacturing plant is robot-like, we do not like the human-like, mechanical human-like on the machine. So robot are getting out from the manufacturing. And then they lost their job there. So we introduced them we tried to introduce them into houses, human houses, but still the market is very small. But observing this robotics from other aspect, you know, robotics is not an industry, this is a basic engineering, and so ideal, and the philosophy of the robotics is applied to every almost everywhere industry, That is enough. So robotics it serves industry is very small, but it is very important research subject, so I think that we expect the bright student coming to robotics and go to other working now, automobile, and aircraft, or even on nanotechnology, you know, we need nanorobotics for the manipulation of a single molecule, and so robotics is a very basic it is a regular it is magnetic theory, or theory or control theory or something like that. it is not an industry itself."
"Fumio Harashima","Interviewer","But even in Japan it seems like the focus is very much on trying to find specific applications, and then there is a lot of disappointment when robots, as you know, just a robot, are not able to be applied in society. So but you seem to be pointing out that it is actually something different, that it is much more kind of a not a basic science, but practically on that level."
"Fumio Harashima","Interviewee","People but for now, for us it is a basic technology, and probably within ten years, robot will come into houses for, you know, nothing, nothing, or to help aged people, you know, for working or taking bath or something like that. I think that would be the largest application. Certainly we have some cleaning robots, but it is a small thing, you know."
"Fumio Harashima","Interviewer","Do you have one?"
"Fumio Harashima","Interviewee","Oh yeah."
"Fumio Harashima","Interviewer","Okay. it is not on there."
"Fumio Harashima","Interviewee","Oh, it is not here. "
"Fumio Harashima","Interviewer","it is not Roomba, is there a Japanese version?"
"Fumio Harashima","Interviewee","No. Sure, Toshiba. We think such a robot is not it is like a toy. Yeah, not so interesting."
"Fumio Harashima","Interviewer","Not a serious appliance yet. "
"Fumio Harashima","Interviewee","Right, That is right. Okay, let us go. Anyway, this is almost a history of Japan, you know, the Japanese technology, history of Japanese technology. Okay, my comment on that, something a joke, do not take it seriously. This transparence I made, is 30 years ago, we had we started a project with the institute, and then we go to this or something like that, we go to panic, and feel guilty, and we punish some innocent guy. And when the project is over, we give praise and honor for the non-participant. This is a typical Japanese research project. "
"Fumio Harashima","Interviewer","So you do this over and over again. "
"Fumio Harashima","Interviewee","Right. Something we can on the PowerPoint more beautifully, but this is a transparency at that time, I made this copy. This is sort of my experience, you know. Okay, so I go to "
"Fumio Harashima","Interviewer","These are the awards you got for not participating. "
"Fumio Harashima","Interviewee","That is right, exactly, this is an example. This is an example. This has first, this part is award for one paper, a single project. The middle one is for the last ten years activity. And this is the whole life honor. People say, if you received this kind of an award, you can get out. The end of the life. "
"Fumio Harashima","Interviewer","you are done."
"Fumio Harashima","Interviewee","This is the end of life, the middle of the life, beginning. "
"Fumio Harashima","Interviewer","we are in the 2010s now though, so what kind of award are you going to get next?"
"Fumio Harashima","Interviewee","Yeah, it is a dangerous honor. Okay, next joke. Oh, then I create several fellowship awards. Now this is IRIS award. This is IRIS award. And this is I wrote this is mainly in Europe. This is in Korea. The reason why this award was established is I was very much paid by KIST, incredible amount of salary, so my wife and I, do there, and a very good life, but still a big amount of money left in won, Korean won, and my wife advised me, do not take Korean won into Japan. So I donate it, whole thing, whole money to Academic Society of Korea, and then they establish a Fumio Harashima award. So I like this award, and actually it is my wife's award. "
"Fumio Harashima","Interviewer","So they should have put her name on it. "
"Fumio Harashima","Interviewee","Oh yes."
"Fumio Harashima","Interviewer","Or both of your names or something. "
"Fumio Harashima","Interviewee","Yeah, okay."
"Fumio Harashima","Interviewer","Tell them."
"Fumio Harashima","Interviewee","Okay, you know, two are different, and next month we go to Korea for presenting this award. Okay, I will change. "
"Fumio Harashima","Interviewer","She will be happy."
"Fumio Harashima","Interviewee","Very good, very happy in that, okay. This award is presented on Thursday at an old luncheon. Yeah, probably I will do that. Look at this. "
"Fumio Harashima","Interviewer","I am here. "
"Fumio Harashima","Interviewee","I was appointed as a professor "
"Fumio Harashima","Interviewer","In the no money stage."
"Fumio Harashima","Interviewee","No money. An the beginning, a graduate student with me. No money, no time, no brain, no body, no body power, and now I am 70. "
"Fumio Harashima","Interviewer","I think, enjoy should be in there. "
"Fumio Harashima","Interviewee","Good, I will change this around."
"Fumio Harashima","Interviewer","Enjoy what you have. "
"Fumio Harashima","Interviewee","Oh, very good."
"Fumio Harashima","Interviewer","do not worry about no "
"Fumio Harashima","Interviewee","Okay, this is my experience, my history as a professor."
"Fumio Harashima","Interviewer","it is good to know what to look forward to."
"Fumio Harashima","Interviewee","So you study here?"
"Fumio Harashima","Interviewer","Yes."
"Fumio Harashima","Interviewee","Long way."
"Fumio Harashima","Interviewer","Yes, very long way."
"Fumio Harashima","Interviewer","I am getting here slowly. I still have little money, but the no time is slowly happening."
"Fumio Harashima","Interviewee","This time 40s are not very hard. You are very busy in university jobs and also family leisure. Extremely busy. No time. And so exhausted and then 50s are no brain, but in other word in 50s you have time, money, and students."
"Fumio Harashima","Interviewer","So they have the brains and they can take care of it."
"Fumio Harashima","Interviewee","That is right. You do not have to have a brain."
"Fumio Harashima","Interviewer","it is good to know."
"Fumio Harashima","Interviewee","Yeah, this is of the end. Thank you."
"Fumio Harashima","Interviewer","I have one question for you which may take a little bit, but going way back to the slide where you had your research, I was wondering if you could kind of just lead us through some of the different kinds of projects and robots you worked on and the kind of concepts that you think are important with that one."
"Fumio Harashima","Interviewee","I started from control and that one of the applications I was interested in motion control. At this time we did not have any microprocessor, no computer. We use an analog circuit so it is impossible to develop a robot at that time. Microprocessor came out here at this 9975 out here from Intel."
"Fumio Harashima","Interviewer","I think Inoue Sensei was showing we were at ISRR, but he was showing some very early things that they did before with analog."
"Fumio Harashima","Interviewee","Right."
"Fumio Harashima","Interviewer","Yeah."
"Fumio Harashima","Interviewee","Right. So exhausting job, yeah. Incredible thing at the time. On that anyway he did get started this project in my lab. Many critical robot system control like also came into our group and intelligence group, this is a government project and I think over year one billion yen and "
"Fumio Harashima","Interviewer","So That is "
"Fumio Harashima","Interviewee","Ten million."
"Fumio Harashima","Interviewer","Yeah."
"Fumio Harashima","Interviewee","Dollar and we formed a research group from young researcher from throughout the world, throughout Japan and they work his own place. We communicate every day through internet and every three or four month we get physical get-together to exchange idea and something there and Shibata was one of them and we I think this is more than ten years ago, almost ten years ago. At that time they are early 30 or something like that. They are reading professors. Most of them. So we some of them in computer sciences and some of them from mechanical control and the other is a psychology because we need interaction. The basic idea of this project is we understand thinking about an interaction between a human and a computer and a mechanical machine. We understand the computer, how the computer works, how can the mechanical works, but they do not understand human. This is a mismatching on a coexistence. For example probably this is not a good example in the U.S. in the Japanese we can say my wife and I have been married for over 40 years. We do not talk a lot. We just do not understand easily just a very simple behavior or doing nothing. Just watching a face. For example, if we get up she was in my face. Look at the weather. Then she decide what kind of coffee is the best for me. Yeah. No conversations here. So the interaction must be like this. So we this technology the goal of this technology, computer side understand the human psychology. it is a is one of the good example. How this animal understand human customer for example and we have been successful in this in some sense just we start a similar thing. Another example is we try to connect our human brain to the computer, but this caused some ethical issue here. We should not do that."
"Fumio Harashima","Interviewer","What were the issues?"
"Fumio Harashima","Interviewee","For example, when you have a baby put into here in a fixed number then this baby can use it forever. Do you think it is a good thing or not?"
"Fumio Harashima","Interviewer","Mm-mm."
"Fumio Harashima","Interviewee","No, probably not. This something like that."
"Fumio Harashima","Interviewer","Oh so it was meant to be kind of a permanent connection to the robot? Okay. Not just okay for ten minutes we are going to okay."
"Fumio Harashima","Interviewer","Implanting it, yeah."
"Fumio Harashima","Interviewee","That is right."
"Fumio Harashima","Interviewer","Okay."
"Fumio Harashima","Interviewee","Probably we have the society, whole society should discuss over the issue. Gives you more time. Take me there. This is impossible. But we stopped it."
"Fumio Harashima","Interviewer","But there also seems to be a issue with how people understand robots, so engineers understand computers very well, but the typical user and I think in Japan there is talk about elderly or children or different people who might be sick. They do not necessarily understand what is going on."
"Fumio Harashima","Interviewee","No, they do not have to understand the details inside electronic or not. That is only if they are after some training they understand what the thinking about and another thing how do you say? This project include another research in the area that is human adaptive is machine adapt itself to human. Normally we must adapt ourselves to machine by training, so this idea is a training the mechanics automatic adapting to a human. This is the second stage of this. This project is the second. This is also government funded this project. At this project I was a university and I followed this project and professor were university are good, but the are very poor so this unfortunately this project was not so successful because you need a good student, young and student while carrying out this sort of project. This is bad. So many thing. "
"Fumio Harashima","Interviewer","So what were some of the kind of important robots or projects, applications that came out of some of these projects?"
"Fumio Harashima","Interviewee","?"
"Fumio Harashima","Interviewer","So what were some of the if you were going to pick just a few kind of example like robot projects that you worked on or results that you had with some of these."
"Fumio Harashima","Interviewee","Oh yeah."
"Fumio Harashima","Interviewer","What would they be?"
"Fumio Harashima","Interviewee","At this time my technology was used to machine tool control was even a or another way and then motion control oh, I forgot to tell you an important thing. In the middle of 1975 I met on a topic set with Toyota. We draw together at the ginza, a nice crowd, and this existed number two and number three over on Toyota. He said Toyota will give you any amount of my research fund so I asked back. I am not a automobile engineer so I do not know if anymore, but he said at the time he said after 30 years from this time electronics will be the major technology over automobile industry. He said incredible this 40 years ago he said and it is actually happened and so my robot team was not 100 percent supported by Toyota. Also Toshiba was a supporter and as a baby we started developing hybrid cars here. Can you imagine that? Forty years ago Toyota and I joined that group and they are almost in the mechanical engineers. I mean 20-some years ago who we worked together to make kind of concept of hybrid cars at the time and it is commercialized here for 30 years and 40 years after. This is the biggest thing which I achieved. Still so Toyota top executives are very familiar to each other. They still think together."
"Fumio Harashima","Interviewer","So what kind of things did you build for Toyota?"
"Fumio Harashima","Interviewee","On hybrid cars?"
"Fumio Harashima","Interviewer","Yeah."
"Fumio Harashima","Interviewee","Oh, 1975 is a special year is a fossil oil crisis, another crisis and Toyota worried about in the future in a few years, so they started on several concept cars. One of them is a hybrid car and other time we still we do not have a computer so it is very difficult to control engine and motors and batteries. it is energy flow and the most important on this subject to the long-life battery. The second is the connection mechanical and electrical. This is a technology and in control and another time we put in the batteries, engines, motor, it took too long. This power train is too long so we made a very long car batteries like this and then we one time we give up using a gas engine car internal combustion car and one time we use a external combustion car engine like on a gas turbine or something like that, but the gas turbine, the rotation speeds are too high, so we needed to control that. So many trial and error, and finally Prius was born. it is a long history and also is a this I did not show this story because it is a something of a secret for Toyota. How is the hybrid cars was in the develop . it is a secret, you know. So it cannot officially open and this a little more supported by Toshiba and "
"Fumio Harashima","Interviewer","So more from the manipulator robot human adaptive."
"Fumio Harashima","Interviewee","Right, right. Toshiba, I think when you are in Tokyo Toshiba people are always staying and are fully supportive for this project and so Tomizosan invited he Toshiba's money also from Taiwan. Even . he was a visiting professor supported by Toshiba, so they are called Toshiba professors. and also Joe Mua from Australia. Probably one more . Some European I thought. "
"Fumio Harashima","Interviewer","So what does Toshiba, do you know, expect if it is not secret, expect to do with the human adaptive yeah."
"Fumio Harashima","Interviewee","Probably for home appliances future. it is just a basic technology. They, Toshiba as a manufacturer can apply this technology to any home appliance. Home appliances are always in human use, so human machine interaction is a key thing for Toshiba. See Toshiba is a leader in this area. Panasonic is also. Sony is okay. So my life, many thing happened incredible. I was born 1940 and the end of the war is in 1945 and in July just one month before the end of the war we had air bomb by U.S. and my whole town completely destroyed and we fortunately the whole family survived. Many people died around me and this was probably very shocking for me and I my last memory before that so I cannot unbelievable. I cannot today we can enjoy such a beautiful life. Probably I am afraid you and your family have such a similar experience."
"Fumio Harashima","Interviewer","Yeah, we just were not actually there because we were in Japan when the war started so then we stayed there."
"Fumio Harashima","Interviewee","Oh yeah."
"Fumio Harashima","Interviewer","Yeah. "
"Fumio Harashima","Interviewee","You were outside the country."
"Fumio Harashima","Interviewer","We were accidentally."
"Fumio Harashima","Interviewee","Oh accidentally?"
"Fumio Harashima","Interviewer","Yeah."
"Fumio Harashima","Interviewee","Here in the Ropongi area."
"Fumio Harashima","Interviewer","Right. No, actually that was when we were with Onishi Sensei ."
"Fumio Harashima","Interviewee","Oni Sensei, oh "
"Fumio Harashima","Interviewer","Yes because my dad was doing the one year sabbatical and then we went to Fukuoka for a year."
"Fumio Harashima","Interviewee","Right. Very happy. Oh so you know Fukuoka?"
"Fumio Harashima","Interviewer","We were very lucky. Yes, yes. I went to Fukuoka International School."
"Fumio Harashima","Interviewee","I was born there, yeah."
"Fumio Harashima","Interviewer","Yeah, so we only knew it from talking to family."
"Fumio Harashima","Interviewee","Okay and some secrets. started 1974 the story here is official. Some secret is before 1974 when I was a teaching student I thnk transaction is a very wonderful thing, publishing in the paper there. I read some of the papers in the library. We could not afford to join because when I do is very hard and probably the first time I published the papers actually the Ph.D. Thursdays or another then two or three. Then sometime before that my submission, submitted papers were rejected and other time we did not have internet so it takes a long time to for by airmail correspondence. So I felt irritated. So what I decided is to take over the whole society then I would be able to easy to publish paper."
"Fumio Harashima","Interviewer","that is a good plan."
"Fumio Harashima","Interviewer","I should just take over."
"Fumio Harashima","Interviewee","A lot of people laughed, but I was serious and I did it. This is not a second story this is official story."
"Fumio Harashima","Interviewer","How do you plan to take over?"
"Fumio Harashima","Interviewee","Okay. I did not intend it but what I did and the results, what I did is I attended every meeting of this society. The other people in one time the other time then I know whole thing of the society so no other people can manage this society."
"Fumio Harashima","Interviewer","The knowledge."
"Fumio Harashima","Interviewee","And as a result I was elected the president and probably I am the first to not America to be society president that is from outside the U.S. What happen is we have a someone coalition so somebody ask me where do you live? I live in Tokyo. For what? So I was I am a Japanese and I live in Tokyo. I am a professor you know at the university of Tokyo. And I live in Tokyo."
"Fumio Harashima","Interviewee","So I said I joked. I am professor of Tokyo. In short this is called IUFT."
"Fumio Harashima","Interviewee","University of Tokyo. Somebody not believe. U.S. people are so nice people. They do not feel any border of the country or something, a geographical thing."
"Fumio Harashima","Interviewer","I guess you can call that nice."
"Fumio Harashima","Interviewee","So I loved it."
"Fumio Harashima","Interviewee","So I like U.S. very much and I love many thing diverse a number one issue which I learn from the U.S. Most important thing, and I have been watching in the U.S. society since the end of 1961 or late 1970s. The society has been changing after the civil war started. I was so impressed by that and comparing the U.S. and Japan, they do not recognize this problem until probably ten years ago and ten years ago we stop it. it is a big difference in our two countries. So now at the present of Tokyo University I stopped last year. My main subject at this university is diversity. I said that and we formed some committee and and we started and last month no, in July this year we decided to employ we employ a new professor and we decide attrition 30 percent over newly employed professor must be female. Now in a total professors only five percent so a new professor must be in 30 percent or female. We decide so now whole university in a panic that We will do that. "
"Fumio Harashima","Interviewer","So if I want to move to Japan I should just do it now."
"Fumio Harashima","Interviewee","Oh yeah. Sure."
"Fumio Harashima","Interviewee","Okay. Female and 49. it is a ."
"Fumio Harashima","Interviewer","Great."
"Fumio Harashima","Interviewer","I will start getting my university panicked straight away."
"Fumio Harashima","Interviewer","Great. I do not know if you want to add anything else or "
"Fumio Harashima","Interviewee","No thank you. Any other question I am happy to answer."
"Fumio Harashima","Interviewer","We have a quick one. We want to put a little education part. So this is going to go on the website for IEEE and we want to have a little part for education for students who are interested in robotics so would you have any advice for young people who are interested in getting into robotics?"
"Fumio Harashima","Interviewee","Robotics. Robotics is in general it is a you think about robotics is part of engineering, but my feeling is as I told you interaction between human and machine is robotics. Now exact okay. I can not give an exact definition of robot. Robot is a machine. It must be mechanical and sense the environment and then based on this information from environ take action to the environment over to other people. That is a definition of a robot. So the shape is not necessary human, right, and so the robotics study must include certainly mechanical engineering, electronics and the computer science and must include the psychology to understand the human behavior and then also some sociology. So occasional robotics must cover wider disciplines. So recently even in the U.S. university level education for some persons becomes narrower and narrower and in the old days undergraduate education in the USA universities were liberal art based, but it is changing. MIT is a typically change. They are a very small area at undergraduate. I think are still liberal arts label . I think most of the U.S. university used to be liberal arts label, that is changing. So they should go back to liberal art just for robotics. If you have us on a broad background to make them a good researcher in robotics. Only mechanical, only narrow computer science, I think you may make a narrow. So criticize to the U.S. robot is a U.S. robodics research is mainly funded by DOD. So anyway DOD research is to kill people. The goal is to kill people. This is very bad. Korean robot researches something like that geographical geopolitical situation. But, researchers in Japan is completely free from defense technology. So in the sense we Japanese robotics engineers are very, very proud of that. We are the only research group which is totally free from the military research. This is I am sorry I criticize some of the U.S. and China, and probably you know in Nevada City they have some Middle East-like town for training of robot battle war. Technically this is very interesting research for robotics engineer, but this is ethical issue. We never accept another research fund from DOD Japan. This is not the rule, but our own decision and even if it was very attractive subject and attracted to big fund, we already reject that, because of the . Our life started like that. We still remember that. The young people I do not know how young people think about that. Still so far we are leaders of this in the Japanese engineer so in a sense we have been keeping a distance issue ."
"Fumio Harashima","Interviewer","Do you think It will become more difficult now that I mean there was a lot of promise about human robotics verges the general market and there was before the industrial robot market, but the general human market is not so easy to develop technology for, so do you think that maybe there will be more military applications as or no?"
"Fumio Harashima","Interviewee","In general government pay a big amount of fund to for human human robot interaction is probably applications start from handicapped people. In general handicapped people are poor so they cannot afford to buy such a expensive machine, so I believe government must support this kind of project. Otherwise this kind of project cannot be developed without big fund. So I suggest no, I do not have a strong power, but anyway I suggested government, some section of government to support this robot for handicapped people in place of a military robot. You do not have to use big money for military. Use the money for this. Otherwise it cannot be done on a commercial basis. Medical care and surgery, something like that. This kind of technology can be developed commercial basis because some patients are very rich. But in general, handicapped people are poor. They do not have a good profession and jobs. That is the problem. So medical robot is okay. Any other?"
"Fumio Harashima","Interviewer","This is really good. I think that is good advice."
"Fumio Harashima","Interviewee","So how common in U.S. societies you know, Medical technology in the U.S. is the best in the world for rich people, but in general Medicare system is the worst in the world it is among the wealthy countries and for us Japanese That is such a U.S. situation is very good. U.S. developed high tech Medicare system very good situation for us. "
"Fumio Harashima","Interviewer","Great."
"Fumio Harashima","Interviewee","Okay."
"Fumio Harashima","Interviewer","Thank you. I think yes we asked and answered everything."
"George Bekey","Interviewee","Hour or so."
"George Bekey","Interviewer","Each tape's an hour so I am sure you will have more to say."
"George Bekey","Interviewee","Well, We will see."
"George Bekey","Interviewer","So why do not we start by just having you tell us where you were born and where you grew up."
"George Bekey","Interviewee","I was born in Slovakia, in the City of Bratislava which is the capital. Our family immigrated just at the beginning of the Second World War and by then it was impossible to get the visas to the United States because United States had nationality quotas in those days, from each country. So we went to South America and lived in Bolivia for five years waiting for our number to come up, and when it came up we moved to Los Angeles."
"George Bekey","Interviewer","And how old were you then?"
"George Bekey","Interviewee","When we got here I was 17."
"George Bekey","Interviewer","You did your undergraduate at UCLA?"
"George Bekey","Interviewee","I did my undergraduate work at UCLA, except for the senior year, which I did at Berkley. UCLA was just starting its engineering curriculum when I went there. Basically they added on year every year so when I became a senior I could've stayed at UCLA, was the first time they offered a senior year, but I was also eager to get away from home and so I really wanted to go to a more established place and not be a guinea pig in the first years so I went to Berkley and had a wonderful year. "
"George Bekey","Interviewer","You wanted to be an engineer."
"George Bekey","Interviewee","Yes, and my father was an engineer, and I guess it was largely inspiration from him and I was good at mathematics and so I have always wanted to be an engineer, but That is not completely true. Once I got my masters in engineering, I went through a period when I seriously considered becoming a minister, and I actually I was working a computer at UCLA and in the afternoons I came to USC, which at that time had an accredited theological seminary on the campus. So I came here, I spent 2 1/2 years, almost 3 years in a master of theology program and the first year were undergraduate deficiencies that I had because engineers have almost no humanities and social sciences. So I spent the first year taking Sociology 101, Psychology 101, and so on. The second year I took all the things that I wanted. In the third year, second and third year, by the fourth year it would have been entirely professional courses like in running a church, and I could not stand it so I dropped out. "
"George Bekey","Interviewer","Were you studying robotics from the beginning or when did ?"
"George Bekey","Interviewee","No, my interest in robotics started in the 1980s. I was at USC, of course, where I started in 1962, so I was at USC 40 years before I formally retired and came here to Cal Poly where I now have a faculty position. In the 1980s we hired a young man from Stanford who was the first robotics person in the School of Engineering at USC."
"George Bekey","Interviewer","And who was that?"
"George Bekey","Interviewee","Why am I drawing a blank on his name? It will come to me in a moment. you will be doing editing anyway, right?"
"George Bekey","Interviewer","Yeah. "
"George Bekey","Interviewee","So as soon as I get the name I will tell you. He dropped out of robotics by the way, sometime after that, but he got his PhD at Stanford and when he came he really wanted to have a robot manipulator. When he came in the 1980s we really had no mobile robots yet, except a few remotely guided vehicles on factory floors, but largely it was manipulators. So I wrote a grant proposal to NSF and got money to buy a Puma manipulator and so that came and then he and I started a robotics lab. It was only in the 1990s when I had a number of students working in the lab with me and we began to get interested in mobile robots and then we built 4-legged and 6-legged and wheeled machines that ran around and we also got interested in robot helicopters because the tradition that Gaurav Sukhatme followed and took on for me and continued in the process. "
"George Bekey","Interviewer","I saw one of those helicopters."
"George Bekey","Interviewee","Good. there is a picture on that wall that shows some of my students and some of the various assorted robots that we built. "
"George Bekey","Interviewer","We will have to get a shot of that."
"George Bekey","Interviewee","Yeah."
"George Bekey","Interviewer","So what were you doing for the 20 years from when you started on the faculty until you started working in robotics?"
"George Bekey","Interviewee","I wrote my thesis on mathematical models of human operators in control systems. It was how do you represent a pilot, for example, flying by instruments? What is the mathematical relationship between the visual input and the manual output in controlling a joy stick, let us say? And then I continued in that kind of work for a number of years, maybe 6, 8, 10 years after I came to USC, but I was also very interested in biomedical engineering, and this started because I met one of the people on my PhD committee at UCLA had called me in one day and said, George, you are the one with the most peculiar interests among the students I know here. there is a man at the medical school who needs some advice from an engineer because he says he is getting very strange results. He says he is got blood flowing against the pressure gradient in the sheep that he works with. it is flowing uphill and he does not understand it. And he said, I am not interested, can you go see him? So I went to see him. So I went to see Professor Assali, A-S-S-A-L-I, who was in physiology and obstetrics at the UCLA Medical School. It turned out that the reason for the mysterious uphill flow was that he did not understand that this is a dynamic phenomenon and not a static one and so when blood is ejected by the heart it has inertia. Each bolus of blood, you might say, has inertia, so that even when the pressure stops and the pressure gradient reverses, the blood continues to flow against the pressure gradient but with decreasing velocity. Does that make sense?"
"George Bekey","Interviewer","Yeah."
"George Bekey","Interviewee","So That is what it was and then we began to build mathematical models of this process and I worked with Dr. Assali for maybe 5 or 6 years, then I started the Biomedical Engineering Department at USC and did a number of other things involving respiration, circulation, muscle function and so on."
"George Bekey","Interviewer","What year was the department founded?"
"George Bekey","Interviewee","Probably in the early 1970s. I would have to look it up because I do not remember but that is approximately right. So I started in human operator models, then at the same time as I moved into biomedical engineering things, I also started to get interested in signal processing and in introduced the first course in digital signal processing at USC which is kind of amazing because when I left my undergraduate years I actually had been consulting for Beckman Instruments and working on analog computers. Now most people do not remember what an analog computer is like but in those days That is what I did and so some time in the 1960s I co-authored a book, this green book right here, hypercomputation refers to a combined analog and digital computation. So the idea was to be able to get the speed and bandwidth out of the analog computer and the precision out of the digital computer. And I think the copyright date is 1968. So, as you can see, I did a variety of things. Then in the 1980s, it was interesting, because as I started learning about robotics what I discovered was that in some ways the field of robotics was a blend of many of the things I had studied before. Certainly the robot was, in some sense, modeled after a human, so that what I learned about manipulation in manual control systems was also applicable, to a large extent, here. There was a great deal of signal processing, there was a lot of control, of course I was a controls person. So many of these things fitted very well and they began to click and come together. So then as I got into robotics I stayed in the field, and I am still there."
"George Bekey","Interviewer","So who was your thesis advisor? "
"George Bekey","Interviewee","My thesis advisor at UCLA was John Lyman whose field was biotechnology. They did not call it biomedical engineering. He was really more interested in human factors, the ways in which humans relate to machines and operate machines, and this whole idea of human operator models came out of my PhD thesis. He has since died."
"George Bekey","Interviewer","Yeah, what kind of influence did cybernetics have on that field?"
"George Bekey","Interviewee","Well quite a bit. I was personally very influenced by it, meeting Norbert Wiener who invented that word, as far as I know, and particularly I have had, from the very beginning of my college career, I have been very interested in the broader impacts of science and technology so Wiener's book on The Human Use of Human Beings was one that had a great deal of influence on me. I always felt that we really needed to make sure that human beings are not treated like machines or become machines and this clearly had a lot of effect on my studies in robotics as well. I think in a curious way I have always had the feeling that as you study robots and the way in which particularly humanoid robots, particularly the way in which they behave, we also learn something about ourselves, and that gives you, in one sentence, some of my philosophy of life. "
"George Bekey","Interviewer","So what are some of the things you have learned about people by studying robots?"
"George Bekey","Interviewee","it is particularly the things where robots and people are different, makes you appreciate the way in which we as humans process information, the way in which we are able to do multitasking in ways in which robots can not do very well. We certainly slow ourselves down by multitasking, but that does not mean that we can not do it. As you know, this is one of the curses of the present time is that everybody wants to do multitasking. So That is one of the issues. And I am enormously impressed by the human sensory system. We have an amazing way of receiving information from multiple senses simultaneously, and then assigning weights to these so at times vision is more important than hearing, and other times hearing is more important than other times. The sense of smell dominates everything if you smell smoke, and so on. So these kinds of subtle changes in the way we relate to the world are very important in robotics, because after all a robot is a machine that senses the world, and so sensing is very important but senses for robots tend to be uni-functional. They do not have the ability to do that kind of blending, but I think It will happen more and more. "
"George Bekey","Interviewer","Fusion."
"George Bekey","Interviewee","That is right, sensor fusion I think which humans do all the time, and it is becoming more and more important in robotics as well. "
"George Bekey","Interviewer","So what are some of the central problems that you have focused on in your robotics career?"
"George Bekey","Interviewee","Well I was particularly interested in ways in which robots can learn and display some intelligence. So in the early days, as you know, we spent so much time just keeping them working that mean time between failures was not very long and also in the early days we just could not buy inexpensive robots to use in the lab. So when I built the robotics lab at USC I actually put in a small machine shop. So we had a lathe and a drill press and things like that so that my students actually made parts that were needed to put robots together, and this was unheard of in a computer science department. You probably know, there is a famous saying, never trust a computer scientist who carries a screwdriver. So we did a lot more than screwdrivers. So initially our goal was to try to do things about locomotion. Actually Tony Lewis worked on one of the projects having to do with enabling robots to learn how to walk. We built several 6-legged machines, and I think he carried on some of this work at Iguana Robotics as well. So we built these machines where we did not specifically program a movement sequence for the legs, and so when you first turned it on and it had some kind of a reward system to see how far it could travel in the direction of the body axis, and of course it does nothing but fall down and its legs flail wildly, but little by little the machine learns how to select the leg sequence that gives it mobility forward, and so our robots learned how to do a wave gait so that they used the two front legs, the two middle legs and two rear legs in sequence in a way that travels across the body, and so on. So that was one of the issues, then I had a contract from JPL which involved comparing wheeled and legged robots on a simulated moon-like surface. So we built a sandbox with sand that followed JPL specifications as being something equivalent to moon sand, and we put in rocks and whatever."
"George Bekey","Interviewer","Sand is not particularly good for robots."
"George Bekey","Interviewee","Yeah, and we found that legged robots actually do better than wheeled robots if there are a lot of obstacles that they have to climb over. Otherwise They are much slower and use a lot more energy than wheeled robots. "
"George Bekey","Interviewer","What was the first robot that you worked on?"
"George Bekey","Interviewee","I do not remember. Well the first robot was a Puma, of course. The first robot we worked on in the lab was the robot manipulator and then because of the interest I had had in manipulation in manual control, one of the things that we wanted to do is to see whether we could get robot arms to pick up objects and manipulate them. So this led to collaboration with a man named Tomovich from the former Yugoslavia who had been the developer of probably the first five fingered hand for robots. Actually he originally developed it as a prosthetic device, and then we adapted it to become a robot hand and having five fingers, which were not independently controlled, but were synergistically controlled, so that what happened was if the hand reached any kind of an object, then the fingers would all begin to close until they made contact. So it just meant that it was passively shape adaptive. It could pick up an object of any arbitrary shape without having to be individually commanded for each finger. So this got us into some work on robot hands that we did for maybe 10 years or so. "
"George Bekey","Interviewer","What were the biggest challenges in grasp and manipulation?"
"George Bekey","Interviewee","I would say from my point of view one of the biggest challenges was just simply mechanical reliability. We had a lot of trouble with these hands. We installed pressure sensors on the sensitive surfaces of the fingers and palm so that worked pretty well, but you see the whole goal was to try to build a very simple and inexpensive hand to compete with the usual parallel jaw grippers that were used in industry. And when we could keep the hand working it worked very well. But I never was able to find, to be honest with you, the killer application for a multi-fingered robot hand, as a robot hand. Ideally it would be excellent for a prosthetic hand, but for a prosthetic hand now one needed nearly total reliability. For the robotic hand the applications that we tried which were primarily having to do with manufacturing, the idea being that since the human hand is highly adaptive and can pick up objects of a variety of shapes and sizes, the robot hand should be able to do the same. And the answer is yes, it could, however to build a 5-fingered, reliable hand is very expensive, and it was much cheaper for industry for the robot arm to go and pick up a different hand from some magazine of hands then you could get one that would be designed to pick up small round objects, or fat square objects, and so on. And that was a lot less expensive to have a series of special purpose grippers, but nevertheless, we did what professors do, we published a lot of papers on grasping. "
"George Bekey","Interviewer","Are you still involved in the field of grasping?"
"George Bekey","Interviewee","Not anymore really. Last year I was invited to give a talk on the history of grasping, but I do not have anything to do with it anymore. "
"George Bekey","Interviewer","And did you build other hands after that hand?"
"George Bekey","Interviewee","No, that was really the only hand that we built. I still have one, the latest model, in a file cabinet in my office at USC, and it comes out occasionally for historical reasons. "
"George Bekey","Interviewer","What was the first mobile robot that you worked on?"
"George Bekey","Interviewee","Well we built two or three of them and I am trying to remember which one was the first one."
"George Bekey","Interviewer","You can just tell me about all of them."
"George Bekey","Interviewee","The first mobile robot that I worked on was actually done jointly with Bob McGee who joined E. faculty at USC about the same time I did, he had just graduated, and we had a PhD student named Andrew Frank, Andy's now in the faculty at UC Davis, but he had the marvelous combination of having had a Bachelor's degree in mechanical engineering so he really understood mechanical things, and so in the 1960s we built the first 4-legged walking machine in North America, to the best of our knowledge, and it was mechanical and slow, but it did walk and it walked with a variety of gaits, slowly, and it could do the equivalent gait of a trot for example. We called it a horse, but of course it did not really look like a horse, but more or less, it had longer legs. That green book has a picture of it. If you look in the index under Phony Pony, you will find it."
"George Bekey","Interviewer","Phony Pony was the name of it?"
"George Bekey","Interviewee","The Phony Pony was the name of it. It shows up in other people's robotics books. "
"George Bekey","Interviewer","What year was that?"
"George Bekey","Interviewee","I am guessing 1968, 1969. "
"George Bekey","Interviewee","Not there?"
"George Bekey","Interviewer","Not in the index."
"George Bekey","Interviewee","I will show it to you. "
"George Bekey","Interviewer","This was before you really got into robotics?"
"George Bekey","Interviewee","I have a video of this thing walking."
"George Bekey","Interviewer","So you did not get into robotics until the ?"
"George Bekey","Interviewee","Well That is really not true. I sort of repressed this idea, because this really was a robot, but then we did not do anything for 20 years. "
"George Bekey","Interviewer","You considered this robotics at the time or did you consider this just a control application, or?"
"George Bekey","Interviewee","Well I was not using the word robotics. I do not think we did. "
"George Bekey","Interviewer","What word were you using?"
"George Bekey","Interviewee","Well, this was an artificial quadruped and so I do not know. I do not remember whether we used the word robot. I am not sure, to be honest with you. But I remember that also somewhere, it may have been in the 1970s or 1980s when I would talk to people from DARPA, and I used the word robots, I remember these people telling me, if you use that word in a proposal we can guarantee you will not be funded because That is considered a bad word at DARPA because so much money has been wasted on robots and they do not work. But then they came back with a vengeance, so I have seen some of these trends in society as well. Anyway, that machine was very interesting. It really did walk very nicely. It did not have any ankles, it had a large horizontal bar to provide lateral stability, but it had hip and knee joints, and so it was able to pace and walk and trot and so on. "
"George Bekey","Interviewer","And what kind of control system did it use?"
"George Bekey","Interviewee","It was a digital control system designed largely by Bob McGee. Let me borrow the book for just a second. Well there were some ideas there which appeared in later things that I worked on. So I always felt that an animal or a human does not control every miniscule element of the motion of their limbs. Right, I do not solve differential equations of motion in my legs when I am walking. So there is a combination of learning and autonomy that occurs in the way in which we do this and so we adjust the nervous system in the process of learning from childhood. By learning you do not have to solve the inverse kinematics of motion for every step that you take, because that would require matrix inversion and things of that kind which you certainly do not do in our heads. So those principles appeared here and we called it, at the time, <audio skips> autonomy, so that each limb was as autonomous as possible on its own and that principle showed up in other things we did later. "
"George Bekey","Interviewer","Like what?"
"George Bekey","Interviewee","I guess I should not have said that, and I should have known you would ask me how it showed up later. It also showed up when we began to work on hands, because you see the hand was meant to be completely autonomous. It was triggered by a single contact, and then it would autonomously close. So it certainly showed up there. "
"George Bekey","Interviewer","You think there is some relation architecture approach that Randy Brooks developed later?"
"George Bekey","Interviewee","Oh yes. "
"George Bekey","Interviewer","Similar concepts."
"George Bekey","Interviewee","Well certainly similar. Lee Rod and I are friends and I like him a lot and I respect his work enormously. In fact, the first 6-legged robot we built in the lab we called Rodney. When I told him that he said, Thanks a lot. "
"George Bekey","Interviewer","So were there any other robot-like machines that you built before you called it robotics?"
"George Bekey","Interviewee","Frankly, I do not remember, but I do not think so because after this, as I told you, I went into other things. I was trying to do visual signal processing, and hybrid computing, and one thing and another. So I do not think I do not remember, but I do not think so. I think that basically the idea of these kinds of autonomous machines sort of disappeared from my current things and then reappeared when we formally started the robotics program in the 1980s."
"George Bekey","Interviewer","Do you think you would have maintained your interest in analog computation if you would had the kind of high performance digital computation we have now?"
"George Bekey","Interviewee","it is I am not sure. Oh by the way, the young man that I worked with who came with an interest in robotics was Barry Soroka, S-O-R-O-K-A. So Barry worked with me for three years. And, in spite of my best efforts, I could never get him to write a paper, even when I outlined it and wrote the introduction for him. He just did not have the discipline to write. And USC is a publish or perish school. So after three years Barry left and went to Cal State University Cal State Polytechnic University in Pomona, where he became chairman of computer science. Very bright guy and wonderful sense of humor, and a great breadth of interest in art and so on. He and the woman who worked in the dean's office jointly composed an opera at USC where all the characters were faculty members. Yes, Amber. Now you stay down. You stay down. Stay down, do not get in the way. You stay down. "
"George Bekey","Interviewer","So what were the first robot helicopters?"
"George Bekey","Interviewee","Well there was a competition for robot helicopters at Georgia Tech. Amber, stay down. I am going to evict you out of the room if you do not do that. Stay down. Stay there. And so I entered our lab into the competition even though we had never done it before. But I had two outstanding Ph.D. students, Andy Fagg and Tony Lewis , both of whom were very imaginative. And we, basically, turned them loose on the project. So this competition had I have forgotten. Let me guess, maybe 15 entries that arrived with various flying vehicles. And the goal was for the vehicle to fly from a starting position into an enclosure area, pick up something, and then bring it back. The first year of the competition, which let me guess, must have been in the mid 80s, but I do not remember exactly. None of the vehicles actually left the ground. They all crashed, or disintegrated, or fell apart in some way. So, actually, the winner was declared to be the vehicle which fell in the direction of the target. By the second year, they were beginning to fly. And they were unusual creatures. There were vehicles with four propellers, and so on. And so our helicopter actually did quite well. And, though I think it may have been Tony Lewis who came up with a formula for calculating how much it would cost to repair it after every crash. And the formula was it would cost a hundred dollars times the number of feet above the ground at which it failed. So if it failed ten feet above the ground, that'd mean it would cost a thousand dollars to fix it, you see. And as a result of that we flew them very low until the 1990s where we began to do really serious high altitude flying. And who got much of that work done."
"George Bekey","Interviewer","So who are some of your other students and what kind of work have they gone on to do?"
"George Bekey","Interviewee","Well I have had I graduated thirty-eight Ph.D.s in my forty years at USC, so almost one a year. And so, of course, the first ones were not connected with robotics. But after some time in the 1980s, they were all in robotics. And so what can I tell you? So let me begin with a few the one's that I can remember, immediately. we have mentioned Tony Lewis, whom you know, who is still in the field and doing very well. Huan Liu is now at Arizona State University in the computer science department. And he worked on grasping, and models of grasping, and so on. he is completely left that area. He now does information retrieval from social networks, so completely different story. he is completely changed fields. let us see who else? Andrew Fagg is at a university in the south no east. And he has the last time I heard I have not heard from him at least five years, but he was building a humanoid robot. And so he is still in the field. Who else worked in robotics, specifically? Yeah, I mentioned Fred Hardie earlier who does this group flying synchronized group flying of satellites. He did not work in robotics at all in his Ph.D. program. He was working on methods of doing system identification, which is one of my interests for twenty or thirty years. That is given input and output measurements of a system, can you build a mathematical model of how those are connected? And you can see that this grew out of my work with human operators, see? So I was interested in connecting the sensory input with the manual control output. And some of those projects were very successful. And others, which I still thought were a great idea, failed fairly miserably. So I will give you one example. I proposed a project to JPL, which was funded, where I said people who have paraplegics who can not move their legs, some of them actually have, in principle, the possibility of moving with canes, or with walkers, or the equivalent. But they will not walk with canes because They are afraid of falling. And That is because they do not have the afferent signals from the nervous system that would give them the indication they were starting to fall. So I said why do not we do this? Why do not we install accelerometers on their belt that would provide an indication of falling, either forward-backwards, or laterally, or create a vector to show you that you are falling at 45 degrees, or Whatever is happening? Okay? And then use that information let us say that you are falling to the right, and use the information to tickle you on the left hand side. So now that gives you the indication what you should do is to push on your canes, or whatever, to straighten up the body in that direction. So I still thought that was one of the better ideas I had. And, but what I did not figure with was by the way, it worked very well, but for a short time. Why? Because the human skin habituates. And the electrical signals that we used for tickling, they did not feel them after a while. So you had to raise the power. And then eventually we got the point it was burning the skin. You see? So you can not go that high. So this you can see how that would happen, right? So, anyway, so That is why that never became a Ph.D. thesis. Now let us see who else did work in robotics, specifically? Danilo Bassi who is currently in the United States at Valparaiso University in Pennsylvania, I think. He was"
"George Bekey","Interviewee","Back to Chile after getting his degree, and stayed there for many years. So he worked on control of manipulators using genetic algorithms and other related mathematical methods. So he returned to Chile and then became interested in using robots in mining. There are a number of copper mines in Chile. And so he got interested in this. And then he tried to form for a long time was working on forming a consortium of American and Chilean companies to do mining robotics. And he formed a mining consortium, and so on. He was never able to get it quite off the ground. And now he is trying very hard to get an immigration visa so he can come to the United States permanently. he is here on some kind of a temporary visa. I just wrote a letter for him. So he really moved so he really was in robotics in the beginning, but what he did was in something quite different after that. We never did anything on mining. I had have to pick up a list of my students, which I can certainly do."
"George Bekey","Interviewer","We can just go on for now."
"George Bekey","Interviewee","Yeah, let us just go on. But, as I say, there are many of them."
"George Bekey","Interviewer","Who are some of the people that you have collaborated with over the years, other institutions or at USC?"
"George Bekey","Interviewee","Well, Michael Arbib . Michael and I had several joint grants from the National Science Foundation. And so we worked on those things together. Who else did I ? I collaborated with Bob McGhee, the man who I mentioned to you was involved in the construction of the original horse. Bob left from USC and went to Ohio State University, where he built a humongous four-legged walking machine that was originally designed to carry soldiers in Malaysia, or someplace. It was never successful for that purpose, but it was a remarkable machine. And from there, when he retired from Ohio State, he went to the Navy Post-Graduate School, from which he is now retired also. And there he was working on robot fish. So he is a man who was in robotics from the very beginning and pretty much stayed with it from the time of the 1960s."
"George Bekey","Interviewer","What was his name again?"
"George Bekey","Interviewee","McGhee, M-C-G-H-E-E. Now let us see who with whom ?"
"George Bekey","Interviewer","Is he still in Monterey?"
"George Bekey","Interviewee","He still lives in Monterey. And he will be at the talk on Friday. So you will have a chance to meet him. Yeah, right. You should look him up on Google. And I think you will find that he is a very interesting guy. he is pretty much dropped all professional work when he retired from there, concentrating on his grandchildren, I think. So, but that was That is now been probably four years, five years. And I believe about a year, year and half ago, his wife died. And that confirmed his sort of leaving aside Though I have been told that one of his students, who is a faculty member of the Navy Post-Graduate School, now does some technical collaboration with him. So he may have returned a little bit. Sometimes, we as robotics, it gets in our blood, and we can not quite let it go. And it sort of comes back. Where were we, I am sorry? You asked me something else."
"George Bekey","Interviewer","Collaborators."
"George Bekey","Interviewee","Oh, collaborative, okay. So, Bob and I had some joint grants with I think with the Army research office, or AFOSR . I do not remember at this point. The my last major contracts, which were DARPA contracts, Mia and Gora were co-PIs. I was a PI and they were assistant, or co-PIs. And then, actually, when I a year or so after Mia came, I turned it over to her because I was too busy. I was working in the dean's office. I was an associate dean and like she is, too except that she is super-human and can do several things at once, which I can not do. Okay, now let us see. Who were other collaborators? I never formally collaborated with Rod Brooks . I wrote some joint papers with people like see I think Arthur Sanderson at RPI. Do you know him? Okay, so Art Sanderson was a actually he was president of the I triple E Robotics and Automation Society before I was in the, maybe, mid 1990s. But his and he is built some very interesting machines at RPI. The latest one, which he did jointly with the Navy in some context, is a fairly large ocean going vehicle, which is completely covered with solar cells on its horizontal surface. And so what it does, it charges up all its batteries and then dives. And then behaves like a submarine until it needs to be charged again, and then it comes back up and charges up. So that is a very interesting robot vehicle, very interesting. Well I am sure I will think of other collaborators before the time goes too far. "
"George Bekey","Interviewer","Can you talk a little bit about the Society of Robotics and your involvement with it?"
"George Bekey","Interviewee","Sure. So in we are talking fifty years, right? So we are talking about the 1960s. And so at that time, one of the leaders of the well there were several people who were among the original leadership of the society, George Saridis was one of them. He was actually probably considered the founder, and he was the first president, I believe, of the Society. I am not sure about that, but I think so. George Saridis eventually moved back to Greece, where he came from. And I believe he died about five years ago, seven years ago, something like that. But George was a very imaginative and hard working guy. He and I collaborated in the organization and running of a couple conferences. One of them was the International Federation for Automatic Control Conference on System Identification. And so the proceedings of that are available, edited by George Saridis and George Bekey, or the other way around. I have forgotten which. But That is what we did. So I knew George fairly well. The other people who were involved in the original society, one of them was Antal Bejczy who was probably, historically, the most interesting roboticist at JPL. he is now retired, but still lives in Pasadena. B-E-J-C-Z-Y. And he goes by Tony, though his real name is A-N-T-A-L. But so Tony Bejczy was a pioneer in space robotics. And so he was involved in the construction of some of the first manipulators that were used in space and prototypes of the big space arms. The ones on the shuttle now are built in Canada, but there were a number of prototypes built at JPL. He was also, I believe, the inventor of providing rate feedback for manipulators. The point here is, for anyone who is worked in control theory, you realize that if you do not give the advantage of being able to read the velocity when something is moving, is that you can get some a measure of anticipation. See, let us say for example I am aiming from here to here. And if I want to use position control, when I shut it off, the system has inertia. It will overshoot. If I measure the velocity, then I can use a combination of position and velocity and have it reach, precisely, the target. So I believe he was the first person to use that in robot arms. And That is one of the strong features of DaVinci surgical robots. They use rate feedback, which I think makes them significantly more stable that it would be if used only position control. So Tony was one of the other early people. There were two or three others and, I believe, at least one or two of them has since passed on. And I do not I have not been in any contact with them. Larry Ho from Harvard was an early participant, but his field was not robots in the way in which I knew it. It was more Well, I do not remember what he did, but it was not exactly robots. "
"George Bekey","Interviewer","And were there other robotics societies? Or was that the first?"
"George Bekey","Interviewee","At the time when we started this one, I believe the Robotics Society of Japan was already in existence. And so we really became the second society. And then somewhere, about the same time, or perhaps a little later I do not remember, the ASME, the American Society of Mechanical Engineers, began to do work in robotics primarily through one of their sections that dealt with control and structures and so on. But I think that this was really the original society. And as the I triple E does you know when your form a new society, they usually do not give the society name right away. That is reserved for people after some level of maturity, apparently. So it is called a group or something like that, and its so it was jointly sponsored by two or three other societies initially. And so we were not permitted to call our journal the Transactions at that time. Again, it is another I triple E formula. I think it was called it was called what? Maybe Well, the society was always called Robotics and Automation. It always had the automation component in it as well as straight robotics. But the word transactions only came when we formally called it a society, and that took about five years. I was president from 1996 to 1998. I am pretty sure that That is right. But I had been active from the beginning because I had started the journal. Oh, it was called the I triple E journal of robotics and automation, that was the word. And we were not permitted to call it Transactions until the society was formalized. "
"George Bekey","Interviewer","But you started the journal at the same time as ?"
"George Bekey","Interviewee","Yes, the it took about a year longer because we formed the society, and then I spent about a year fighting with the I triple E bureaucracy to get this thing started. "
"George Bekey","Interviewer","So what year was that, then? Do you remember?"
"George Bekey","Interviewee","I do not. We could probably take the current Transactions and look at the volume number and work back. Should we do that? It'd be interesting. I do not remember. I mean, obviously, I could look back at my various CVs. Okay this is volume 26 dated 2010. So that would make it 1984, right?"
"George Bekey","Interviewer","1984, yeah. So that would have been as Transactions."
"George Bekey","Interviewee","I think they kept the volume numbers continuous. In other words, journal volume let us say that there was journal volume 5, then when it became Transactions, it became volume 6. They did not start all over again."
"George Bekey","Interviewer","But it was a volume every 2 years, or ?"
"George Bekey","Interviewee","No, no the volume was for the whole year. So there were, I think initially we had, maybe, four issues a year, quarterly."
"George Bekey","Interviewer","And then the you were also involved with the Autonomous Robots journal?"
"George Bekey","Interviewee","Yes, well that started significantly later. And I was at one of the I triple E robotics conferences, and I was chatting with the editor of Kluwer publishers. Kluwer no longer exists. They were taken over by Springer. Okay? But we were chatting and he said, You know, we should really do something in robotics. So would you be interested? I said, Sure, let us start it. I mean That is how it happened. And so then Kluwer sent out questionnaires to every member of the society and some other people to try to get feedback about whether there was really a need or an interest in another journal. And so That is what happene3d. So we got it. Now, the year I can tell you very easily because that hasn't changed. So That is still in the continuous numbering, and I think it was roughly twenty years ago. Volume 29. Now That is interesting because that means that I may be wrong, that the journal volumes terminated and Transactions volumes began."
"George Bekey","Interviewer","Yeah, that could be."
"George Bekey","Interviewee","Because this was definitely later. Oh, but in But I believe Autonomous Robots, for a long time, numbered their volumes twice a year. And so, I am no longer sure when this thing started. I can not be sure. You can find out, That is right. So That is the story with Autonomous Robots. I also I have in my in the bedroom closet because there was not enough room in here in my office. But I have volume number one. So if you are really interested in this I can pull it up and look at it."
"George Bekey","Interviewer","Oh wow, yeah, actually."
"George Bekey","Interviewee","Rodney Brooks was one of the authors involved in volume one number one."
"George Bekey","Interviewer","So what do you consider your most successful, or your proudest robotic accomplishment?"
"George Bekey","Interviewee","Well I think that even though it was never a commercial success, I thought the work on robot hands was one of the things that I always was most pleased with. And there my collaborator was Professor Tomovich from Yugoslavia, you see? So that was a very clear collaboration. And he would travel to the states once a year. And I went to Belgrade about once a year. So that was a very interesting and very fruitful collaboration. And I still have contacts with one of the people from Yugoslavia who worked on the original project who is still there. So that was one. And then the second thing was the project that Tony worked on, which I always thought was one of the major accomplishments of our lab, which is the project on using genetic algorithms to enable a robot to learn how to walk. And I think that was actually probably one of the more successful things in the and I can not Andy Frank who built that four-legged robot in the 1960s was formally my student, that is I was his major professor. But he was guided much more by Bob McGhee than by me because I did not understand the digital technology very well having just grown out of the analog side. And I was moving into the digital, whereas Bob stared on the digital side. And he had some analog background, as well."
"George Bekey","Interviewer","What kind of computers were you using at that point?"
"George Bekey","Interviewee","Well when I came to USC we had the only digital computers we had that the university had were some ancient Honeywell computers. Honeywell no longer makes general-purpose digital computers. And so and it was as I recall, it was difficult to keep them running. But they were the only machines around. And then in a year or so after I came, I wrote a proposal to NSF to get a digital computer that we could use as part of the hybrid system. Beckman Instruments, where I had worked, gave us an analog. And then NSF gave us enough money to well we had enough money to buy maybe half of an IBM 1620. The 1620 was a process control computer. It was originally was a serial digital computer, which meant that each word processes each bit serially one at a time, rather than going in parallel. This was early technol—"
"George Bekey","Interviewer","So you were getting an IBM "
"George Bekey","Interviewee","IBM 1620 and then we formed, we created this hybrid system by connecting those things together. The Beckwin analog computer was very large. It was a vacuum tube computer and "
"George Bekey","Interviewer","What was it? What was it designed for?"
"George Bekey","Interviewee","It was designed to be a general purpose computer."
"George Bekey","Interviewer","General purpose analog."
"George Bekey","Interviewee","Only computer and the do not forget that the early digital computers, the earliest ones actually had patch boards also and you had to do a certain amount of programming by moving cords around and then the stored programs came later on digital computers. So and they were very slow. So the idea of a joint, of a combined analog/digital system was really a very interesting thing at that time and you know we learned a lot from doing it. I was at TRW before coming to USC. I had actually been there full time and then I went on part time and went back to campus to write my thesis, but I did almost all my coursework while I was working at TRW and there we built a sizeable hybrid computer and I have forgotten what the digital component was, but the idea there was to try to use the hybrid computer to simulate the flight of intercontinental missiles because we had been using analog computers to study the high speed dynamics, high frequency dynamics of rockets because these early rockets, like the Atlas for example, are very flexible. They had to be because the skin was made as light as possible so that they would carry as much of a payload for these long distances. So they were full of liquid fuels and they were very flexible. So there were two phenomena that occurred. One was bending. So these things bent and not only this way, which is in the first bending mode, but also this way and even this way. They were to the point where there were three frequencies where we had to look at because there was significant bending in the first, second, and third bending modes and then the fuel, as a result of this bending, the fuel began to slosh. This was liquid fuel and if you have ever sat on an airplane and have coffee sloshing in your cup, you realize that if you excite it improperly, It will slosh right out of the cup, right? And That is why airplane cups often have a lip so as to prevent the coffee from or whatever liquid you have from sloshing out. So those things happened at such high frequencies it was impossible to do on a digital computer. They were too slow. So what we thought was let us do all the high frequency dynamics, control system sloshing, bending on the analog and use the digital computer to integrate the equations of motion so we can maintain the accuracy That is needed to hit within a few feet of a 5,000-mile trajectory. Okay? Because the analog computer drifts. it is not able to maintain precision for that long a period of time. So it was I still think it was a hell of a good idea and so you know my name is associated with some of those early experiments. We succeeded in building it, but it took us a year longer to get it fully debugged and the reason was that while we had taken into account the possible advantages of the analog on the digital side, we did not take into account the disadvantages and the disadvantages were that the digital computer accumulated round-off errors and the analog computer drifted anyway, so we still had problems with it and so it took us a year longer and the Air Force just did not want to wait any longer. I mean after we had promised them we would have simulations that they could use for guiding their missiles, they had a schedule to meet and they could not wait any longer, so they flew the first missiles toward some island in the Pacific and what they discovered was that the and experimentally from seeing it is that the high speed oscillations had a negligible effect on the trajectory. So therefore you could solve them separately and it did not matter how long it took on the digital computer to do the other equations because it was not relevant, you see. You could do them separately. So That is what happened and but so this was not robotics, but it was certainly part of my own background and had to do with learning computer technology from both sides."
"George Bekey","Interviewer","Yeah and at that time analog and digital computation were sort of comparable in their "
"George Bekey","Interviewee","Yes, in the late 1950s and early 1960s there was a great deal of competition in fact and at the Western Joint Computer Conferences there were always panels that had to do with analog versus digital and that kind of thing. In fact I will even tell you about a poem. The worst of computing perversion is analog to digital conversion."
"George Bekey","Interviewer","So why do you think digital was so successful in the end?"
"George Bekey","Interviewee","Well, I mean increasing speed. I mean we are still this is the benefit of the early days of Moore's Law. They began to move away from vacuum tubes and move to a solid state switching and faster and faster speeds. The analog simply could not keep up. On the other hand, there is been a rebirth of analog computing at the chip level. So there are clearly advantages to being able to do some things and without having to convert things into digital form, process on the digital and then reconvert back, you see."
"George Bekey","Interviewer","The analog VLSI."
"George Bekey","Interviewee","Right, absolutely. Analog VLSI is exactly it. Okay, and now let me think back. Would you like me to look up the names of former students and talk about them for a little while?"
"George Bekey","Interviewer","Sure."
"George Bekey","Interviewee","Was at Rockwell. Okay, so on the robotics side Huan Liu who I mentioned to you is now at Arizona State. He did grasping, knowledge based planning for grasping with robot hands. Dityen Young who was in Hong Kong worked on non-linearities in connectionist or genetic algorithm kind of learning, but he is completely dropped all that sort of interest. He does other things now, so he has nothing to do with it at all. Patti Koenig, with whom I have almost no contact anymore, she was at JPL for many years and I do not know where she is now. So she came to me saying, I would like to do a BHD thesis, but I really would like to do something with horses because I am a horse woman and I like horses and particularly I like horses that do dressage and other unusual movements of one kind or another. So we came up with the following kind of peculiar project. So the idea was so I went out and bought a plastic horse, full-size plastic horse, and we instrumented the horse in such a way that if you, you could pick up signals from pulling on the reins because we put string gages on the two sides of the mouth of this horse and then we put pressure sensors on the flanks so that if you kick it, you could pick up that signal. Okay, so then those were used as inputs to a simulated horse on the computer screen so that you could now see a person would be sitting as a rider on the horse and they would command it and the simulated horse would move accordingly and so the idea was that you could train people by this combination of actually sitting on a saddle on a full-size horse, but doing the control on the computer and people who came to use it who were experienced riders said that it was spooky how realistic it was and they would begin to forget that they were sitting on a mechanical horse and visualized themselves on the simulated horse on a big screen. So was that robotics? Well, in a way. "
"George Bekey","Interviewee","That is right and when she published oh by the way, the simulator horse had unusual colors. So she published some of this stuff about a green horse and so that was Patti. Then Arvin Agah who is now a professor at the University of Kansas did his work on coordination in robot colonies and so he initially did a simulation in which he had a hundred simulated robots on the screen and the idea was that these robots would be tasked with picking up objects of one kind or another. Some of the objects were smaller, some were larger. The robots were able to call for help if they found an object that was too big for themselves to carry and so a second one would come to help. There was a lot of interesting sociological experiments in that particular study. There was a we discovered that depending on how wide you made the communication radius, that is how far each robot's signal would carry out to the rest of the colony, what you could do is you could make the robots move in clusters rather than individually, but if you made the radius either too large or too small, I can not remember, then they would begin to move as individuals. So there were many interesting things in this and he actually built some small physical robots that were used to pick up a piece of pipe and carry it. It was still two robots cooperating. Maja was the original developer of the multi-robot thing at MIT when she was doing her thesis. She was able to get something like twenty of these small robots operating and she called it a nerd herd. You probably have heard this before. She was very good at that. Okay, so That is Tony Lewis worked on locomotion controllers in robots and animals and so he was very interested in models of the spinal cord and the spinal reflexes and how they could be imitated in robots. he is always had an interest in the biology, particularly the nervous system as well as and locomotion as well as building robots. John Kim is a very interesting person. I was consulting at the time at a chronic rehabilitation hospital in Downey, California called the Rancho Los Amigos Medical Center and I was really interested in sort of how you use knowledge based methods to try to understand what is going on. I did not really want to build expert systems in artificial intelligence, but I usually refer to them as knowledge based systems to see how you could use accumulated knowledge to make decisions. So the lab where I was consulting was concerned primarily with issues of human walking, both normal walking and pathological walking like with people with cerebral palsy and so on or people who had had spinal cord injuries and that kind of event. So and the physician in charge kept saying, You know we really do not know when we see a particular pathology which muscles are responsible and we might be able to do corrective surgery if we knew, but the trouble is there are 20-some muscles in the lower leg and you know in the legs and so therefore we have to identify which ones they are. So what I did is the same thing we would normally do and try to build this kind of a system in AI. What we did is we hung like butcher paper around a whole gigantic conference room and then I began to interview the various doctors about what the conditions are that they saw and what things could happen if a particular muscle was defective or inactive and so on and so out of this, this fellow John Kim developed a diagnostic knowledge base to make predictions about which muscles are responsible for particular gait pathologies and it was very successful. This worked very well. I am not sure how well it was used, but it certainly did work. So he had a Ph.D. in computer science and then he worked in AI and then he graduated and decided that this was really not for him and he got a job as an intern in a law firm which had dealt primarily in patents and patent law and as you know patent attorneys usually employ engineers and computer scientists because they need the background. So they sent him to law school and he spent almost three years going to law school while working part time at the law firm and then he decided that law was not for him. So this was career change number two. He currently is he went to school again and he is now the minister of a Korean church in one of the suburbs of Los Angeles and he is happy as a, whatever you want to say, a clam, whatever, but he is very happy. So I do not know whether That is relevant or a story that you personally would find interesting."
"George Bekey","Interviewer","Yeah, yeah."
"George Bekey","Interviewee","Gaurav Sukhatme worked on ways of evaluating autonomous mobile robots and he is the one who compared the legged and wheeled robots on the surface of Mars. Alberto Behar worked on intelligent telerobots, smaller robots that could be sent to a space sent by space vehicle either to a planet or a comet or some other vehicle to do exploration and some of the stuff was done in hardware and some was done in simulation. Ayanna Howard, who is now a professor at Georgia Tech in electrical engineering, did her dissertation on grasping, but it was grasping of deformable objects, which nobody had done before. Everybody grasped rigid objects, but now if you grasp something rubbery that squishes, the dynamics become completely different and her work was beautiful and she is still in robotics. She now so she teaches in electrical engineering and but I do not know exactly what she does, but she is definitely still in the field. Jim Montgomery did his thesis on robot helicopter flying and still does that kind of work at JPL. He still flies robot helicopters or simulated helicopters to be used for planetary exploration and things of that kind. And my last student is Stergios Roumeliotis who is now an associate professor of computer science at the University of Minnesota and he did his work on using common filters and other statistical methods to help localize robots to determine where they are from some surrounding measurements. This is the usual question which is sometimes referred to as the kidnapped robot problem. What information does a robot have to have if you kidnap it to determine where it is."
"George Bekey","Interviewer","This tape's going to run out too and I will do one more and this "
"George Bekey","Interviewer","So what do you see as the biggest challenges and problems facing robotics into the future?"
"George Bekey","Interviewee","Well, so I think among the current problems of greatest interest in robotics, one of them is certainly human-robot interaction, the ways in which humans and robots can not only interact, but collaborate, work together, and a lot of this is related to the increasing capability of humanoid robots so that we mentioned sensing before, but clearly humanoids do a lot more than sensing. They not only move, they not only sense, but they process information in increasingly humanlike ways and my feeling is that it is not necessary to build identical models of the human brain. What we want to do is to try to build into robots the functionality in some sense of aspects of the brain. So I think the greatest challenges, I believe, will come in two or three different ways. So one way is to try to continue to improve the capability of humanoids so they can interact with human beings in a more and more significant way so that they can receive commands by voice; they can interpret our gestures; they can display emotions. A very important research area, robot emotions, at the present time. And that means that a robot then could be a genuine household helper. It would not be Rosie from the cartoons, but it certainly could be a genuine household helper. So and not simply a unifunctional device like a Roomba vacuum cleaner, you see. I mean we are talking about something that has a great variety of capabilities and these things are not easy. I mean my friend, Rudiger Dillmann in Germany has been working for the last five or six years at building a kitchen helper robot That is supposed to clear the table, pick up all the dishes, put them in the dishwasher and so on and it is not an easy problem. I mean it displays all the difficulties of coordination, sensing, activation and so on. he is now able to the robot now stacks dishes in the dishwasher reasonably well, but they use plastic dishes to make sure that they do not break. So it is these are not easy things. So That is one of the areas that I think. And the second area that grows directly out of that is that I think society is going to have to pay attention to the way in which robots relate to people and what functions they perform in society. As you know, Kurzweil talks about sometime in 2020 or so that robots will demand to be treated before the law as if they were humans and they will succeed, he says. Okay, I do not know about that, but I do believe that we have no basis in our legal system currently for how to deal with quasi-human beings, with we have no way of handling issues of responsibility and ethics and so on. So these are That is one reason why I am so interested in now in this whole area of robot ethics. So I think that those issues and that includes, by the way, the use of robots in the military and robots in war as I am sure you know there are now more than 40 countries that have military robotics programs. we have had a monopoly on the use of robots in the field, but we no longer have a monopoly on guns. Every country has guns, you see, so I do not think We will have a monopoly on robots either and that means that there will have to be some pretty dramatic Amber oh, you got it. it is okay. it is okay. That is fine, That is fine. You can go ahead, go away. Go away, go away. The why is she always "
"George Bekey","Interviewer","Hey, hey, hey. No, no, no."
"George Bekey","Interviewee","I will get her. I will get her. Sorry about that. close the door. Out you go. Out you go. you have been very charming, but out you go. Go on, out. Go on out. Go on out. "
"George Bekey","Interviewer","Okay."
"George Bekey","Interviewee","I think autonomous vehicles will be one of the major challenges in robotics from the time that Sebastian Thrun won the DARPA Challenge as you know, the idea of using robot vehicles has become much more prevalent and there are programs in Europe as you know as well as in the United States and other places that could create these vehicles, but again I think we need to find ways in which we can adapt to such vehicles in terms of our legal system. We do not have the appropriate rules of the road. We do not have the appropriate vehicle codes and we do not have the right questions of risk and responsibility. The third area that intrigues me a great deal is robots in healthcare in a variety of ways. We know that we have robot surgery devices like the DaVinci system, but it is really a teleoperated robot and I think that the time will come here as well as in the military that these robots will have increasing degrees of autonomy and will be able to perform surgery on their own just like I believe the robots in a decade or so in some unknown conflict would be able to find their own targets and release their own missiles without human immediate consent. So but in healthcare, this of course raises a whole series of new ethical questions as well and if I wake up from a surgery and it was done by a robot and I thought it was going to be done by a physician, by a human physician, and it did not go well, then whom do I sue? You see and to what extent will hospital administrators begin to rely on robots to perform surgeries if it is less expensive both for the hospital and for the patient? So these are things again that we do not know how to do. We do not know how to deal with the we do not have the social and I would say emotional machinery for integrating robots into society in any kind of a proper way. So we need legal and social frameworks which we kind of do not have and I think That is going to be one of our biggest problems. A second area in healthcare is the prosthetics and where I think robots are already playing an important role, the Otto Bock computer-controlled knee, which is fit nearly all the amputees coming from Iraq or Afghanistan, is a wonderful device, but it is only the first one of what I think will be many more. there is a large DARPA program to create artificial arms with the full functionality of a human arm. So those are robot arms. They are clearly autonomous devices with a lot of sensors and the ability to actuate, but there are lots of other things going on. You see there are programs for replacement of portions of the central nervous system including portions of the brain by chips, which will be able to pick up information from the outside world that would normally be sensed and sent to them by the eyes or you know and so on or by stretch receptors in muscles and then this chip will process the information in a way in which say a diseased section of the brain would have processed them and then provide output signals to the world. So I think that there is an almost unlimited horizon in what can be done in creating new bionic people and many of these replacements will be from my point of view robots and you see so that puts the whole thing into a larger context in which we really begin to ask ourselves the question of what it really means to be human and to what extent do robots and humans share concerns and to what extent are they completely different. You know I told you that I had spent some time in school of religion and even now in the years when I do not teach robotics, I teach a class of world religions here at the California Polytechnic University at Cal Poly where I do not do comparative religions in the usual sense, but I do talk about Hinduism and Zoroastrianism and Buddhism and so on and I try to look for the ways in which people in those traditions look at the meaning of life and their relationship to the universe. Now how can you in any one of these philosophical traditions, let me call them philosophies rather than religions. How can you not relate to something which is quasi-human? I do not know if you have seen the movie Bicentennial Man? Okay. Well now that raises the kind of questions that I am raising here, you see. Here was a robot with the greatest desire to be human even though it meant becoming mortal and it clearly makes wonderful theater, but I think it also raises the kind of question that I was asking from the very beginning. To what extent does working on robots teach us something about ourselves and what it is that makes us unique and special? it is clearly not the things that we used to say. I mean there was a time when I mean I remember when I was in college there was a book called Giant Brains and the reason it was called that is because it referred to the first machines which were able to compute astronomical tables by doing huge numbers of additions and multiplications and divisions and print them out and we thought that was the activity of the brain. You see I mean now it is considered so trivial that we do not look at it at all. So I do not know if that helps, but I think in terms of the future, I really think that as robots become more capable and more able to interact with humans and on many levels that I think We will begin to ask ourselves more and more of these kinds of questions and who knows what the future holds, but it certainly will not be boring, I can tell you that."
"George Bekey","Interviewer","In terms of technical challenges, what do you see as the big problems facing robotics?"
"George Bekey","Interviewee","In the design of humanoid robots, for example, I think that there is still issues involving actuation. Sensing we have done very well. Sensors have become small and have enormous capabilities, but our actuators are still too heavy and too big and so I think we still need to find better ways of imitating biology in the design of arms and legs and tentacles or whatever we might use, which are lighter and more flexible and so on. So I think That is still a major area of concern and then obviously the question of how do we model the activities of the brain and I do not need to tell you there are many projects in this area going on around the world. People are doing one thing or another with respect to the brain and eventually some of these efforts will become integrated. Increasingly we are beginning to talk about having a direct connection with the brain even by implants, by implanting electrodes directly into the central nervous system. So from those we should be able to derive the kind of information that might be useful in designing brains for robots. But I think that is a that should keep us and our children busy for a while."
"George Bekey","Interviewer","And over the course of your career, what do you see as having been the biggest breakthroughs or innovations in robotics?"
"George Bekey","Interviewee","So I think that what has helped robots the most is Moore's Law; the fact that we can do so much computing so fast in such small packages that use so little power and cost so little. I mean That is the most interesting thing to me, you see. You talk to people now who do computer design and they basically tell you that the hardware is for free. The cost is in the software and that was inconceivable when I was in college, where the hardware was all the cost. We did not have enough software to know how to price it, but hardware was extremely expensive. One of the first computers at UCLA when I was a student was called the SWAC, Western Automatic something or other computer and it used cathode ray tubes for memory, huge banks of cathode ray tubes and you can imagine now the cost of that kind of memory. See it just was completely different from where we are now. So I think in terms of what is improved in robotics, it is happened on many fronts, but I think that Moore's Law has been one of the major sources of improvement because we can now build robots with a lot of intelligence and for very little money, using very little power. So I think that has been one of the major changes and I think in the last decade or so social acceptance of robots in the United States has improved dramatically. I think part of it is due to Rod Brooks and the Roomba, of which as you know something like four million have been sold, so now it becomes a commodity rather than some kind of an unusual specialty item and whereas in Japan robots have been a much more accepted part of the culture for many, many years, in the United States they were not. There was always this question about how soon will they take over and so but I think that That is one of the changes that I have seen so that now it is expected that robots will be doing many things that are not now possible for them and that it is becoming much more accepted in society. For the United States that has been a relatively recent development. Not for Japan, but certainly for the United States. I am concerned about oh, one of the things that we desperately need, to come back to your earlier question, we need robots to act as live-in assistants for the elderly because with the aging population that we have, we simply cannot afford as a society to put everyone into old folks' homes. It just costs too much. We just do not have the resources to do it as a country when as you know the usual age pyramid is now inverted so that the number of people over 80 is becoming significant. So the answer is to let people stay in their homes, but provide them with one or more robots to assist them and we are doing very little in that area in the United States. I led a team supported by NSF to study the status of robotics in Asia and Europe five years ago in 2006, four years ago, and every lab we visited in Japan and South Korea and most of the labs in Europe were working on eldercare robots and so I think unless things change in terms of finding ways of supporting such developments with venture capital or elsewhere in this country, I think another 20 years We will be importing all those robots from Europe or Japan if we have the money, and we may not. But that is another story."
"George Bekey","Interviewer","Anything else you would like to add?"
"George Bekey","Interviewee","Well I would like just to say what I said earlier. I really think that robotics is an incredibly fascinating field of study because it enables you to combine interests in psychology and sociology and philosophy and engineering and computer science and I do not know of any other area of study which provides that kind of breadth and the possibility of integrating all these areas. So That is my feeling. I would like to say to young people if you are looking for a challenging field, go into robotics."
"George Bekey","Interviewer","Go ahead. Okay, I think That is—"
"Jean-Daniel Nicoud","Interviewee","Because it is 65."
"Jean-Daniel Nicoud","Interviewer","Wow, yeah."
"Jean-Daniel Nicoud","Interviewee","Before the transistors with relays and "
"Jean-Daniel Nicoud","Interviewer","Analoger."
"Jean-Daniel Nicoud","Interviewee","Okay, so I can briefly comment on this. This one also is very significant, because if you have heard about the Evano-Trento Conference with Rodney Brutz , etcetera, I demonstrate these set of robots, which of course, they have a camera, and they were following each other, keeping the distance, and the ground was very rough with stones, and I was really surprised to see that it was working. So with your camera, we can prepare them on the ground, and you just make a it is too complicated and takes too much time to really make it work. So we should see that it was a very first linear camera. So I think we can zoom on this. And now I have here a little bit of the Capra story. So Francesco continue the story, but this was my motivation to go in that direction, so I think it is and I have not yet given it to Francesco, because his building, this museum, and I give him all the work, I do not want to keep it. So I will give this to him sooner or later. So this is a Capra. Okay, so we do not need so I do not know how well. The comment I can do is I have tried many solution to develop small robots, also for toys, like toys for kids, and my company is trying to do business with this, I do not succeed, but I like to develop and this is my satisfaction. So I can make some comment about this later. And of course, an important point, but I do not have the hardware, but the hardware is not so far. We have been working with an excellent technician and one cubit centimeter robot, and one inch-cube robot. So I can make some comment about this. And if you want to take picture of these, they are in my former lab, where Francesco you stay how long here?"
"Jean-Daniel Nicoud","Interviewer","Till tomorrow, yeah."
"Jean-Daniel Nicoud","Interviewee","Till tomorrow."
"Jean-Daniel Nicoud","Interviewer","Then I go to "
"Jean-Daniel Nicoud","Interviewee","You have some other people to see like , . No?"
"Jean-Daniel Nicoud","Interviewer","I would love to "
"Jean-Daniel Nicoud","Interviewee","Francesco, I can make a list of the people of the key people. Okay, so maybe I will and this is I started a paper some day about the constraints of designing some more robots, and it does mention the one cubit, centimeter, and the problem to put the battery, and the reference to my no, maybe there are no. In Japan, they still have this contest for one cubit centimeter, not robot, they are tele-operated. But it is amazing, because it was they started this almost 20 years ago. And the field of things are moving very fast, but in this field we have no energy sources for this dimension, so everybody has to find new tricks to try to make it slightly different than last year. Okay, so you can put it on your thing. "
"Jean-Daniel Nicoud","Interviewer","Okay. So We will start just asking you to tell us where you were born, and where you grew up and went to school."
"Jean-Daniel Nicoud","Interviewee","Okay, yeah, so my name is Jean-Daniel Nicoud. And I was born in Lausanne, and I stayed in Lausanne for my study. I did, let us see, Ecole Polytechnique, the study of physics, and I was my intention was to be professor of physic. And I like very much experimentation, and physic is a way to make wonderful experience and building special devices to better explain physic. So after my study, I went to a college, but the situation in that college is the professor of physic was using all the lessons, and I could not teach physic. So I get interested in electronics, and I was I had been fascinated years before the robot of Gray Walker. And so when I had time to teach, and I finished my studies, I built this robot, clearly inspired from Gray Walker, with the technology I knew. I had been playing with planes, and it was the very first radio-controlled plane. We had difficulty to control, and I was looking for tricks to get several channels from one channel with gears. Okay, but anyway, and you see the logic with telephone relays, and the motor which was the driver and the direction. Okay, so this was my discovery of relay logic. And then as soon as I got transistors, it was more interesting to study logic by itself, and start to do a calculator. So I spent I came back to the Ecole Polytechnique to study calculators. And then there were the first minicomputers, and a project in teaching with minicomputers, then microprocessors. I designed my own micro personal computers. Nobody knows it, but in 1974 I was at Digital Equipment, I built personal computer for them, but as you know, they did not believe the big person did not believe in personal computers. But anyway, I came back to Lausanne. I built six personal computers for Digital Equipment. In yes, it was 1975, 1976. And then I had my own family of personal computers, so you can look on their website. And then in the 1990, there was no more interesting things to study with personal computers. The market was coming with all kind of machine, so I directed my team toward robots. we are the first robot contest, like at MIT. And one of the first designed was the circular robot, which it was in 1991/1992, you can take the picture here. And the circular robot is named circular, because it has one linear camera, and with a small lamp behind. It was very funny to have all these robot following each other and losing quickly control, of course. But this one already had HC-11. So it was a lot of fun to program, and to have the students doing contest with this, etcetera. And of course, I was fascinated by small things from . And the project, I asked student was to make a five centimeter robot in a modular way. And you know, the problem with robots, you need a power supply, you need a motor. And every time things are moving a little bit, you get new battery, you get new motors. So the constraint here was these very poor batteries. The two motors with a gear was justifiable from . So this was acceptable to have the wheels not exactly well-positioned. And so this was named Khepera, which is word in French. So the processor here in this direct is an HC-11. And this was in 1971, student project. And from this Francesco Mondada redesigned everything. The technician made a special motor, so it was more compact. We had better battery, etcetera. So Francesco Mondada really make a wonderful adventure with this. But I had invented the name of Khepera, and the name of Cartene , so it was a good stuff. So now when you talk about small robots, one kind of motor of interest is the stepping motor. And these are the kind of motors you find in all cars for moving the needles. And they are made from develop by watchmakers. And they just have enough power to move a robot. And of course, the advantage, if you have a stepping motor, it is very precise. You can do exactly the kind of movement you have. Here it was a basic stamp as a processor. And of course, the battery I hate batteries, especially the nine-volt, but this was a way of doing this. And okay, now you can imagine the different architecture, if you want to have it floating, maybe, or here this one was an idea to go in the sand and be able to move with all kinds of obstacles, so this was not finished. But it was already there was another project in another lab, That is why I did not continue this one. And now, okay, so this was another design with the stepping motors. The circuit board flex-around, there is a hole for a pen. And with a lithium polymer, this was the very first lithium polymer, it is possible to get a lot of power, which, of course, solved many problems in robotics. So there was only distance sensors with infrared. But anyway, and I like very much magnets to bring the power, make a small noise. But you see the lights, and now I just have to depress and make a demonstration of it. And I just turned the magnet in the other sense to no power-on switch. Okay, so now the interest by that time in 1995/1996, or even earlier, there were these contest in Japan for one cubic inch, and one cubic centimeter robot. Well, it was named robot, but they were just moving in the maze, and avoiding obstacle while following the maze either with mechanical constraints or with sensors. And the robots are in another lab. But it was a lot of constraint. In one cubic inch, it was possible to put a battery and have the two motors, have the wheels, etcetera. We make two or three design with it. With one cubic centimeter, we had another design with Swiss motor, and gear box, and wheels, etcetera. But of course, no possibility to put the battery. This design was a research project, not done in my lab, because the wheels include a electric motor. So all the central is empty. it is really two wheels, and okay. But of course, the electronic outside is rather complicated and cannot be put together and especially with a battery. But okay. this was helping to understand the limit of the technology. And still some people are dreaming about very small robots that can do useful work in our bodies, surgical work. But we do not have the correct power supply. So this is a toy, but it is a nice design. It use lithium polymer accumulator. It used two motors. And the problem with electric motors, they spin very fast. So either you put gears, or you put a very, very small wheel, which is the option I have taken here. And so I do not have the ground to make a demonstration, but it spin very, very fast on itself. And the interest of the electronic control, we can take another picture on the table after if you want. there is a microprocessor, of course. Microcontrollers are very, very small, and it is no limitation now to do a lot of things. And okay, that is all. The difficulties, even like these motor are spinning too fast, so that by software you can make them as slow as you want, as long as you have some torque. So this is , I have a small company now and I try to encourage kids to invent their own robots, and of course, it is well the technology is you can buy cheap microprocessor, you can buy a lot of cards, you can find motors, you can find everything which was difficult to find five years, or ten years ago. But unhappily kids have different interests now and it is very difficult to motivate them spending time on one subject. We are solicited by so many things on internet. They try to do everything, and they do nothing. Or very few do something. Okay, so this is basically my story."
"Jean-Daniel Nicoud","Interviewer","Okay, well, let us go back to the first robot that you had. And when did you build that, and when did you first come into Gray Walter's tortoises, or come to know about them? And what motivated you to build "
"Jean-Daniel Nicoud","Interviewee","Okay, Gray Walter, there was this paper in Scientific American in 1950/1955, I do not remember exactly. And of course, this was something every young kids was dreaming about. You know, they dream about too complex things. We were dreaming also about something that was too complex for this day with all the electronic inside, radio tube. And of course, this was what I was able to do with the technology I had. It was the very first printed circuit board I made. Very naïve, very primitive. One sided, no hole, no hole, etcetera. And of course, the next step was to develop the technology, get the manufacturers and with microprocessors, I do not want to tell the story of all my microprocessors. You can see it on microdot-CH . "
"Jean-Daniel Nicoud","Interviewer","So this was 1965?"
"Jean-Daniel Nicoud","Interviewee","This was in 1965, yes "
"Jean-Daniel Nicoud","Interviewer","Yeah. And were you "
"Jean-Daniel Nicoud","Interviewee","And then I came back to the Ecole Polytechnique two years later, I finished my thesis in 1969."
"Jean-Daniel Nicoud","Interviewer","Now did your thesis draw on this?"
"Jean-Daniel Nicoud","Interviewee","Sorry?"
"Jean-Daniel Nicoud","Interviewer","Was your thesis about this?"
"Jean-Daniel Nicoud","Interviewee","No, no, not at all. No, my "
"Jean-Daniel Nicoud","Interviewer","This was just a project on the side."
"Jean-Daniel Nicoud","Interviewee","This was just a very no, no. Because as soon as I was back at Ecole Polytechnique, I had possibility to develop things with better technology. And I invented the logical teaching equipment. We developed calculators. Okay, so that is another story, huh?"
"Jean-Daniel Nicoud","Interviewer","Yeah, yeah. What was your "
"Jean-Daniel Nicoud","Interviewee","Very proud to make a big calculator for operation, make it smaller, smaller. And then everything was in one single integrated circuit, and it was no more gain. But the microcontroller came."
"Jean-Daniel Nicoud","Interviewer","It was a physics thesis?"
"Jean-Daniel Nicoud","Interviewee","No, it was about decimal to binary conversion and relays. And I studied all the possible algorithms, and showed the hardware implementation. It was a time where we were not yet sure if computers should calculate in decimal or calculate in binary. But anyway, we needed some conversion, and so I think I studied all the possibilities to do it. "
"Jean-Daniel Nicoud","Interviewer","And when you came back to Lausanne, was it an engineering department that you joined?"
"Jean-Daniel Nicoud","Interviewee","No, it was the electrical engineering department, which was five/six professor by that time. And in my study about I had two one hour about logic system, as an example of electronics and half the semester was on the radio schematic. And only one hour on logic functions with transistors. And maybe two hours on transistors only."
"Jean-Daniel Nicoud","Interviewer","And when you were working with DEC, were you still on the faculty here, or did you leave for a while to go work on this personal computers with digital?"
"Jean-Daniel Nicoud","Interviewee","Okay, well, I mentioned that I was teaching in school. And of course, still being at that school, I built a calculator with the first integrated circuits that were viable, but it was still RTI logic, not yet TTL, as you know, and plenty of transistors. But it was a very nice machine. And then as soon I did my thesis in parallel, and then having I finished my thesis being full-time assistant at Ecole Polytechnique. And I very quickly had students doing work with me, project for making a very small calculator, and even starting a design with an integrated circuit being done at Neuchâtel . But we were very, very slow compared to the Japanese, and we had to stop all these projects."
"Jean-Daniel Nicoud","Interviewer","And so where did you get the integrated circuits from? You said Neuchâtel, was that a private company there? Or other researchers you were working with? "
"Jean-Daniel Nicoud","Interviewee","Well, the integrated circuit were just the standard integrated circuit from US, from Texas Instrument. we are distributors there. But really the beginning of my story, but it is not directly related with your concern is Abosch which is a very large company in Switzerland now still working. They had started to do transistors in, oh, well, in 1960 because in 1966, 1965? 1965. In 1965 Abosch decided to stop the manufacturing of transistors, because there was no future. And I got 1,000 transistor in a plastic bag. They were very small transistors, very nice, perfect for me. So I use these transistors to do this calculator I was mentioning. And to do a lot of logic block, to study logic. I gave a course with a free course at a school. And okay, that was really my possibility to do something really interesting. Because with relay you cannot go very far. And with the Ecole Polytechnique , with all the time I had to spend on this, we really did and I got excellent students. One of these students, I have been working a lot with transistors by that time made the success of Logitech. Because he was very smart for everything about logic. Saving power, etcetera and he worked for Logitech and made the success. So Daniel Borel made the commercial success, but this guy made the technical success. And you need to have a product which competes, because if Logitech has progressed so quickly, it is because they had really good better product than the competitors."
"Jean-Daniel Nicoud","Interviewer","What was his name?"
"Jean-Daniel Nicoud","Interviewee","René Sommer . But he died one year ago, unhappily, and so That is one of my reason I still try to attract young people, because we need young very young people. They have to start very early to get the experience, and you need a lot of experience, unless you are in a big company with very specialized engineers, and but okay."
"Jean-Daniel Nicoud","Interviewer","So during the early 1970s, was there anybody else working on robotics at EPFL? Or other kinds of electric-controlled machinery?"
"Jean-Daniel Nicoud","Interviewee","Nobody was considered about mobile robots. And Professor Brugger , he was trying. I was not in contact with these people, but you see, I was in the electronic department. And the mechanical department built up micro-engineering with Professor Brugger. But he was very concerned about optical system, making small mechanical system. But nothing in the direction of mobile robots. And then Clavell invented the Delta robots. And of course, everything was in the direction of the Delta, and these two professors, by the time they had a team of two/three person. So with my contact, natural contact, I had rather quickly a team of ten people when it was only 1995/1996 that I had 30 people, about, to work on robotics. Robotics. What was really a possibility to make a lot of research in many directions. And with personal computers, of course, it was quite interesting. And the company was taking our prototype to make them a product with usually a former assistant, former PhD students of me. So it was a very funny period, because everything was growing. And the motivation to study robots was I still was searching something better than the computers. And neural networks by that time were something we believed in. We had to study neural networks. And an application, a very nice application of neural networks to see if they can do something useful were robots, of course. So you can try to park a car and do some music with neural networks. But I got several research project in saying we tend to apply neural network in robotic mechanism, in general. So and people like Francesco Mondada, before going in the Khepera, he was playing with a kind of a Delta arm, doing juggling, analyzing shape for the Khepera, and we searched hardware architecture for neural networks. We made a special integrated circuit, and special architecture for this. It was also two/three/four thesis."
"Jean-Daniel Nicoud","Interviewer","And were those successful? Or were you able to get good performance from the hardware?"
"Jean-Daniel Nicoud","Interviewee","Well, everything you built in hardware is obsolete after two years. Because of the Moore Law. So you should restart and restart and restart, and of course, we can do the first step, because the next step imply an investment in technology, which is much higher. So most of our project were first steps. And with the Khepera was a very good product, because once we had this hardware with a very powerful processor. And the possibility to add to that, depending on the application. We could make plenty of thesis related to the behavior of robots to, well, you know, all would have done ach, sometime the name Daniel Floreano . So this was genetic category with also direction. So That is why I ask Daniel to come in my lab. And he was you see, I was a very bad researcher myself. But I wanted to go forward and I was attracting good people to go in these directions. That is why now I am surprised myself that I have five professor here which made a PhD or post-doc in my lab. And but I was just giving them the freedom and the money they needed to do their research, and okay, so I think That is what most professors should do instead of some professor, they try to be the big boss, and the other just servants. Which I think is not a good way to go, unless you are really, really smart. But when you are not smart, you have to find other people being smart. "
"Jean-Daniel Nicoud","Interviewer","So many questions, I do not know where to begin. So who were some of your early graduate students? When did Francesco start working with you?"
"Jean-Daniel Nicoud","Interviewee","Francesco, it was in the 1990s. And before him, they were just making a project and building something. There was a very nice vacuum cleaner project. But it did not stay in the lab. It went to Zurich and then to US. No, Francesco really was a key guy interacting with everybody. And then Martinoli was also well, I try to think to the people who influence other students and build their own group. So Martinoli, he is around, if you want to see him. And Dario , of course, made plenty of project with a lot of people. And, oh, they spend a little bit of time in my lab, but with they had also plenty of ideas. But they this, you see, in 1997 I had to stop all my projects , which is very hard, but anyway everything was because my lab went to a different direction with the I still well, it is too complicated to explain and not of your concern. But one great thing, which you should mention, is I had a technician, André Guignard, who made the mechanical design of the mouse, which was copied as long as mechanical mouse were built. It was André Guignard's mouse and he made all my small robots. He really worked with everybody to have mechanical things which were perfect. And he is still working because he retired five years ago, but, happily, he is still working. You can meet him. And working with Faroud Billard , he has built the Salamandra. He has built well, he is paid now by Francesco Mondada in industrial projects. So I think we if we got two good results in that school, it is, I think, because the structure of the school allowed to have technician which stay for a long time and you need to have well, Francesco went to industry very quickly, so That is good. But I have another good student who stayed in the lab and interact with everybody. The professor does not usually have enough time to interact with everybody. And anyway you need to be several people to interact in a group and not only one. So in U.S. I have seen wonderful projects made by PhD students, but then the PhD leave and everything is in a corner and the next PhD have to re-invent everything. If you have some permanent person, they transfer the knowledge more easily. And Guignard was one of these guy who is transferring the knowledge and building also things in addition, keeping the experience and allowing PhD students to really use the best technology, and do not lose their time buying small tools and doing things by themselves in a dirty way."
"Jean-Daniel Nicoud","Interviewer","Yeah. So where did you get most of the funding over the years for your research projects?"
"Jean-Daniel Nicoud","Interviewee","Oh, the Swiss government has a research-funding organization and there was a very good applied research funding well, we have the strictly research funding, we have the applied research funding and we have funding where the company we work with a company and the company pay half of the expense. But for the company it is not so expensive, I would say, because they say, Okay, we will put an engineer one of our engineer working on this project, and they pay him very expensive and he does not work so much , etcetera. So we were in this industrial project we were doing most of the work. But, anyway, for us it was very interesting. It was real project and we had money and possibility to interact the Logitech mouse with a sphere, with dots, with one of these projects, for instance. In robotics I do not remember about that because there were so few people working on mobile robot in industry. But we had a project on , so it is not okay, okay. I do not remember everything, but it was half of my I had, at least, ten people paid by the school, eh? So this was very easy money. And the twenty other were research project and very quickly people, like Dario Floreano, they were themselves doing the project, getting the money. I was just signing. It was easy. "
"Jean-Daniel Nicoud","Interviewer","So what was the motivation to build the first small robots, the five-centimeter? You said it was a student assignment. But why chose small robots before sort of working with big robots and middle-sized?"
"Jean-Daniel Nicoud","Interviewee"," I am just fascinated by what is small. I know some people, they like what is big, what is noisy, etcetera. I always have liked to make it as small as possible. And with my company, the first project was to build a five-gram plane when everybody was mastering that technology. And it was Jean-Christophe Zufferey who made me see this with a flying robot in a room. And flying in a small room like this mean you cannot go fast. If you cannot go fast, you need large wings and very light weight. So it is interesting to study the battery, the propeller, the motors, etcetera. It was a very good thesis I build. But and you see with these small robot okay, if I could make it smaller I do not like flying when it is large. "
"Jean-Daniel Nicoud","Interviewer","So when did you start the company initially? And was that the same company that was doing the PCs or was the robotics company a separate company?"
"Jean-Daniel Nicoud","Interviewee","The name of the company is DIDEL. So DIDEL is from didactiques électroniques. And the first letterhead I have is in 1971 . Because in 1971 I had finished my thesis and I was interested to get or to stay as professor, but I was not at all sure to be appointed as professor. So I develop a lot of industrial contact because I was expert in integrated circuit and digital design. By that time it is the kind of design I make with integrated circuit the telephone responder. Well, I had a lot of contact with the industry was asking for this because they knew it was moving in that direction. Okay, so I was ready to build my company. And I always have been disappointed to see that I was a professor because and I made, you see, most of my project was very application-oriented because of that kind of industrial mind. And so I keep at EPFL two years in advance at sixty-two and I wanted to see if I was good for building a company. But, of course, the situation was different because if you are young, if you have family, you push very hard and by that time probably I could have done oh, I am not sure I would have done a good company, because at least for the last ten years I have developed quite interesting things. I still have ideas, but of course I have to restrain these ideas to what I can do by myself because I do not want to grow. I do not want this the era I am alone in that company and my idea was to stay alone. And, of course, you cannot build a company being alone. You need to be two or three with complementary ideas, comple interests, etcetera. So now it is a complete failure but because I am not interested to sell. So the good if you are interested to this but it is very quickly said: I was interested in doing these small planes, ultra-light and small robots. I needed small motors. These motors, they do exist for pager motors but I needed gears for these motors and I invested with people in China to get the good gears from application and now I get the money which allow me to survive well, to pay for the things from the gears I am still selling. You need plastic gears of modular 0.2 or modular 0.3? I have them."
"Jean-Daniel Nicoud","Interviewee","And I have been selling. So this is also an interesting business for me because if I sell ten gears to a U.S. university, to a PhD or a researcher, I prefer this than selling one thousand gears to a company I do not know what they will do with it. So, no, it is amazing because two or three years ago I had a lot of contact with U.S. Now I have many more contact with Korea and less Japan. it is Korea and China, which is beginning to ask for my components. And, of course, big industry they invest in the gears they need and do not work like this. But "
"Jean-Daniel Nicoud","Interviewer","And the motors, They are Swiss motors, right?"
"Jean-Daniel Nicoud","Interviewee","No, because "
"Jean-Daniel Nicoud","Interviewee","No, even these were not Swiss motor. Here you can see a gear and I have slotted gears with a sorry, you want to "
"Jean-Daniel Nicoud","Interviewee"," slotted gears to have an encoder. The encoder is from mice Logitech give me a lot of mice encoders to make and I made the special gears. And Swiss motors are too expensive. it is wonderful, but not only they are too expensive, but they are designed for industrial application with higher voltage. And if you need two- three-volt motors there is little choice with Swiss motors. But all the pager motors, they are quite efficient, quite good, and so cheap that I can buy a lot and sell them to researcher also at low price. Okay."
"Jean-Daniel Nicoud","Interviewer","And the idea to make it modular so that you can plug in different turrets and things like that. So when did that come about? When did you start working on that idea? What motivated that?"
"Jean-Daniel Nicoud","Interviewee","Yes, also, it is a kind of a personal attraction. I have always liked what is modular. And when I started to understand electronics I made small module with wires connecting there. You do not know what it is, but it was really a very good teaching tool for understanding logic, logic circuit, with advantage that you assemble your block and you can very easily change the schematic and test different solution. And then once you have well understood, you make a PC board and you go to production. And now, recently, that is one year ago, I have started to develop module for teaching C language, understanding REAR embedded system programming embedded system in C. And what everybody's do is they take a big board, they put it full of LEDs and switches and the connectors. And I prefer to have something modular because you have the processor, you would have a clear identification of the processor and its bases, its input-output ports, and then you connect a dedicated board, which allowed to study an application and test different way of programming that application, like a small elevator, for instance. And, okay, it is my pedagogical approach, which well, I should try to make some promotional papers about this. But, of course, now several years ago I was doing all my documentation in English and since my contact was mostly with local people, now I do all documentation in French. Because it is more easy for me, first, and the day somebody abroad is interested in what I do, it is so easy to translate technical French to technical English, uh. compared to all the investment of improving the hardware, improving the documentation so it match the mind of the I would like very much to touch kids at twelve forty years ago well. With the first personal computer, the first Smaky this was in the 80s in , in the 80. I was opening my lab on Wednesday afternoon, when the kids are free and I had ten- twenty young guy coming, typing on the keyboard. They were quite free to do what they wanted. And I got very good students later from these kids indeed. But apparently now it does not work the same. "
"Jean-Daniel Nicoud","Interviewer","Hm."
"Jean-Daniel Nicoud","Interviewee","Okay, but, well. But I still have very good contact with people who have experience all that story of personal computers getting more complex, etcetera, and we meet and talk about new design, new robots and things like that. "
"Jean-Daniel Nicoud","Interviewer","Well, and here at EPFL, there is a lot more people now who are working on robotics, right? So there is new labs and professors. So over that time period that you have been here, how has that evolved? And have they mostly come from your lab and become professors, or has the university decided that they want to bring in other kinds of roboticists and develop that as a specialization of this institution?"
"Jean-Daniel Nicoud","Interviewee","Well, I understand two questions. One, two made project with robots, what did they do later? "
"Jean-Daniel Nicoud","Interviewer","Yeah, yeah. That is bigger question, but "
"Jean-Daniel Nicoud","Interviewee","Okay."
"Jean-Daniel Nicoud","Interviewer","Yeah."
"Jean-Daniel Nicoud","Interviewee","And, well, it is difficult to be closer "
"Jean-Daniel Nicoud","Interviewee"," but I would say that I have influenced this professor who was still around here. But 1995- 1996 Professor Siegwart came here. And you have heard about him, etcetera. And, of course, all the robotic interest went to Siegwart because I had no future. It was clear that I had to leave at year 2000 then all the and there was a big exhibition in Switzerland and where there was a house for Robert how do you say? Not a bourse there was a wonderful experien exhibition with Robert. And, of course, all that effort was done with Siegwart. And all these people who did the project, the thesis with Siegwart, they continue and went to industry, build their own industry like BlueBotics and Hanna Pauli Khartim had some problem. But, anyway, I would say that Siegwart influence a lot of people to stay in robotic activity. And maybe I influence more to stay in the academic kind of activity. But, anyway, Khartim was really and by that time of Khartim very few there were very few start-up. Now, you have to do a start-up to show that you are smart. "
"Jean-Daniel Nicoud","Interviewee","But by that time, it was not so easy to do a start-up: a lot of paperwork, explanations and the worse with the personal computer, the Smaky, I designed because my wife made a business with this, with former students, and people in the industry could not understand that my wife was doing the work. It was me who was using EPFL to do the research, using my salary to do the business with the Smaky and not teaching my students. it is amazing how mentalities have changed and it is happy that They are changed because now it is I see Jean-Christophe Zufferey who made the flying robot. He spend a lot of time and now he has a company, a start-up. So he was really encouraged to spend time preparing his start-up."
"Jean-Daniel Nicoud","Interviewer","Was that the five-gram flying robot, or was that a different flying robot?"
"Jean-Daniel Nicoud","Interviewee","No, my structure the structure the le the accumulator, the propeller, the motor was five-gram. And Jean-Christophe added five grams of radio sensors, accelerator , speed control, etcetera, transmission, so he could see exactly what was happening. And I had enough power for ten grams, because I wanted to have something which was acrobatics. So with five grams I was able to do almost vertical flight. And so with ten gram it was staying almost horizontal and avoiding the obstacles."
"Jean-Daniel Nicoud","Interviewer","And when was that?"
"Jean-Daniel Nicoud","Interviewee","This was three years ago."
"Jean-Daniel Nicoud","Interviewer","Oh."
"Jean-Daniel Nicoud","Interviewee","Three years ago and then this there was nobody is doing five-gram planes anymore because the situation is with better battery, which still progressed. And with the motor, which saw brushless and brush motors, you get so much power that you can build a twenty-gram plane and you can do anything in the twenty-gram range. So all the commercial product are twenty grams. Personally, I have no interest to do what everybody else is doing. So I have stopped these kind of activities and also I have difficulty to make robot which are really better than what other people are doing. I am back now to educational constraints, trying to help people to build their own stupid robots, between brackets [sic], instead of my well, let us see. This was something which is not completely stupid. I put a display so the exercise is not only to avoid obstacle, because you build any kind of you see any kind of robot now, it do exactly the same than twenty years ago. The sensors are maybe slightly smaller. This was twenty years ago. And we already have the infrared sensor, the camera, and I cannot do something really better now. So if you have a laser beam but it is a five-kilogram robot immediately if you have a laser beam. And what is interesting, you get all the cleaning robots; they do things which are very difficult to copy. So, well, here the idea was to put a display. Of course, I do not have a lot of power, but well, a Swiss cross, at least."
"Jean-Daniel Nicoud","Interviewer","So in that time I mean within this size-frame or not a lot has been done, but there is been big advances in batteries, for instance."
"Jean-Daniel Nicoud","Interviewee","Yeah."
"Jean-Daniel Nicoud","Interviewer","But also different kinds of sensors, but I guess They are big sensors. But LEDs, too, have improved significantly."
"Jean-Daniel Nicoud","Interviewee","Yes, things improve but these the fact of the matter is the only real progress, recent progress, and, of course, it is in iPad. How do you pronounce iPad in English? Ee-pad or eye-pad?"
"Jean-Daniel Nicoud","Interviewer","Eye-pad."
"Jean-Daniel Nicoud","Interviewee","Eye-pad? Okay. Okay, but, again, it is not specially for robots."
"Jean-Daniel Nicoud","Interviewer","No. What about the microprocessors or the kind of control that you can program them with? That is developed."
"Jean-Daniel Nicoud","Interviewee","Well, it depend on the application. So I like very much to work with a six-spin microprocessors. But if you need a larger one, okay. The idea was a kit. People had to solder the components and learn I am changing a little bit my mind because if I say to people, You have to buy a soldering iron first, they say, No, I am not interested. they have no space at home. They have no motivation to do things by themselves, especially young one. Those who made it okay. Now I do not have all my idea here, but well, this one is important. Well, this one aspect is that really was I am not sure if you have something similar in U.S., but in Europe there is we have Astérix and Obélix, which are Gaulois people living in France, Roman-time. One is fall He fall in the no, I cannot translate it. "
"Jean-Daniel Nicoud","Interviewee","But you should have the equivalent in U.S.: Some people they are special because from always they try to do things and they succeed in doing things and where we say in French, Qu'ils sont tombés dans la magie. They fall in the magic bottle and due to this everything is magic with them."
"Jean-Daniel Nicoud","Interviewer","Charmed."
"Jean-Daniel Nicoud","Interviewee","Alors, tombé dans la marmite [So, falling into the potion cauldron] and now, you see, I still continue to try to invent things and interact till tomorrow. But I have only five- six people between forty and sixty who come to follow a course on C. we are using my logic modules. And I would like to have contact with young people. Francesco is a great success with his festival, but all these guys, they come for a spectacle. Uh? I was very disappointed after the first one, because they all say all these kids say, I would like to do robotics, but they are not ready to buy a soldering iron first and build some small kits and learn. It takes time and usually when we remember thirty years ago with enthusiasm of these young kids okay. But continue to ask your question, because "
"Jean-Daniel Nicoud","Interviewer","What about the Lego robots? I mean those are more just programming, but they also sort of build it. it is a kind of a way to get them involved. "
"Jean-Daniel Nicoud","Interviewee","Okay, okay. No, no. I am quite positive about Lego. But I am an inventor, I am not a buyer. So if something exists, okay. I will criticize it a little bit because it is too expensive. But if you take the Lego if you take the new robot from Francesco it has a strange name, which I do not come by . He has a wonderful robot with a software support at a level where you can write the behavior, develop the behavior, develop the behavior of the robot, plenty of LEDs and accelerator, plenty of application. Wonderful. But both these tools you come to an end where you cannot do anything more, because you cannot work inside. You cannot change the parameters, you cannot build your own brick in Lego. You cannot add memory and the things. So I position myself by saying, If you learn to do C, if you learn to do bread board, you can do everything. it is the limitation is your intelligence and not the intelligence of a toy manufacturer. So That is why I would like to propose how do you say? A set of robots well, I have a rather successful robot, which I did not bring. It just larger than the very small mouse-like robot, which 2000 have been sold as kits in the festival, in holiday activities, etcetera. So it is, I think, a reasonably good result for the French part of Switzerland. Because the French part of Switzerland is one million person. This is, of course, my big problem to have a company who sell other places. Because in U.S. you have twenty million. Or two hundred million. You make a little bit of publicity, you are sure to sell one thousand pieces. But here in the French part and France is very protective; Italy, it is a different language; German Switzerland is a different language. So. Okay, but back to what I was trying to say I do not remember. I am sorry get tired."
"Jean-Daniel Nicoud","Interviewer","That is okay. Well, I thought it was a good point about being able to really create systems "
"Jean-Daniel Nicoud","Interviewee","Okay, okay. We was talking about Lego and all the what exists on the market."
"Jean-Daniel Nicoud","Interviewer"," programs and solders."
"Jean-Daniel Nicoud","Interviewee","Exactly. Exactly. So Arduino, if you know, is something good so people can start with it and well, what I am doing now is in Pinguino but it is a similar product, except that Arduino is hiding things which, I think, prevent to really understand the microcontroller, which is below."
"Jean-Daniel Nicoud","Interviewer","Hm. Even though it is open source, it is got some hidden elements?"
"Jean-Daniel Nicoud","Interviewee","It has to be open source today, because and well documented. So I try to improve the documentation so people really understand. Because I was mentioning Arduino; people impressed because there are plenty of hardware, plenty of libraries, but what is important is to have one hardware that you understand and a library you can modify and understand. So people are impressed because they see publicity and there are plenty of forums mentioning things, but you see a forum the questions are completely stupid. People do not understand usually. Okay, but anyway. This is what I am trying to do. "
"Jean-Daniel Nicoud","Interviewer","I am still fascinated by your original 1965 robot. So what did it actually do? So it has a light sensor and it follows the light like the tortoise, or it is got some bump sensors?"
"Jean-Daniel Nicoud","Interviewee","Well, apparently because I am discovering, myself."
"Jean-Daniel Nicoud","Interviewee","It was in a corner, I say, Okay. That could be fine to show if they are concerned about the history of robotics. So the motor was already a kind of brush no, no. Okay. This mechanism to have the motor, which give the motion and the direction, is rather simple for robot. If you see, I have photo-sensors and the lamp. So with this I can follow a track, which is still a typical application of toy robots. So it did not change in almost fifty years. And I wish also to avoid obstacles. So, again, if you want to do something so by that time, we had no way to measure distance. We could follow we had the first well, for the photo-sensors we were using germanium transistors, which were inside a glass and black paint. And by removing the black paint we had a transistor that was sensitive to the light. The efficiency was not as good, but with a good infrared lamp like this, it was possible to do something. And then, apparently, I see that I have some switches here to probably detect when I am in the center. I must have also some limit of angle position. So with this digital information and getting a digital information from this I do not see an electronic board, but okay. I do not remember everything."
"Jean-Daniel Nicoud","Interviewee","But at least with a relay I was able to avoid the work of oh, I do not remember."
"Jean-Daniel Nicoud","Interviewer","Did it do the sort of scanning behavior like the tortoise? That was kind of it actually kind of swirled around on its front wheel, Grey Walter's version of the tortoise."
"Jean-Daniel Nicoud","Interviewee","Apparently, I do not have the good sensors, but with the end switches I was able to scan."
"Jean-Daniel Nicoud","Interviewer","Yeah."
"Jean-Daniel Nicoud","Interviewee","And if the light is in the good direction, I could probably. But I build the hardware. I would I did not really make it work as well as Grey Walter because I was more concerned about using the relay to do logic and then using the transistors. As soon as you have transistors, of course, you do arithmetic units and you can go to the complexity. I built either a set of small modules and I built it was on a table a kind of calculator and what was amazing is that it was making music because I put some resistor to get from the digital some digital system, the digital logic to go to something that was changing the frequency. And for making a division, it work for five seconds playing the melody of the division because the division is a sequence of subtraction, correction, etcetera. I was studying all these algorithms by that time and, okay, that was the kind of many people who saw this still mention this calculator was making music while calculating. That was funny."
"Jean-Daniel Nicoud","Interviewer","And what is your recollection of the first kind of robotics conference or meeting that was specifically on robotics that you went to?"
"Jean-Daniel Nicoud","Interviewee","Hm. Well, I remember even in Trento because I was very it was really the very first one conference dedicated on robotics and "
"Jean-Daniel Nicoud","Interviewer","So tell me about that? When was that and who did you see there?"
"Jean-Daniel Nicoud","Interviewee","It was in well, hm. I was showing well, it was in 1991, something like 1991. Yes, about sure: 1991. I search on Internet but I could not find exactly the reference to that conference. But I saw in a publication from , if I remember well, that he was mentioning the paper he had presented it Trento . It was in 1991 and it correspond usually my technician was putting the dates. Well, November 1992. Okay, so maybe it was 1993, because I remember these were the robots I brought it Trento where in the case; I kept them carefully. But [sic] not working; I do not have the battery pack anyway. In 1993 Fukuda was organizing these micro-robot contests. This was well, apparently it went very quickly because it exploded interest in mobile robot exploded. All the work of Rodney Brooks was widely published and it is easy to see from the publication of Rodney Brooks what the small robots he was building. And it was the time in 1992 where the PC was getting so cheap there was no more interest to work on the architecture with the new microprocessors. And so the Khepera came well, the Capri well, not the Khepera. This one is mention 1991. But it took probably two years before. Francesco will give you will say exactly when he started. "
"Jean-Daniel Nicoud","Interviewee","And there was as soon we had enough Khepera to make collective behaviors this was fascinating. We had plenty of interesting projects and just to making the robot learning to avoid the walls with Dario. That was really something. Well, I see "
"Jean-Daniel Nicoud","Interviewer","Did you have other collaborations with labs outside of your own or in Switzerland or around Europe or Asia or the U.S.?"
"Jean-Daniel Nicoud","Interviewee","I was visiting people as frequently as I could. So I have been several times to Japan, to U.S. I knew the places where some action was happening. But I was interested, but I did not had a team really working on this. This was after 1992- 1993, that. But, of course, before all the technology around personal computers discs, screens was moving and I was very concerned about the technology in general. "
"Jean-Daniel Nicoud","Interviewer","Just any other students you want to mention? you have already talked a bit about Francesco and Dario and Martinoli. But other students of yours that have gone off to start labs or done important work in robotics and industry? You had a Logitech student. Cause part of our project is to "
"Jean-Daniel Nicoud","Interviewee","Yes, yes. I am thinking. But nobody build a company in that direction. Nobody became professor in another university."
"Jean-Daniel Nicoud","Interviewee","One of these guy was Francesco me mention it [sic]. He made the vacuum cleaner project and he was progressing very well in U.S., but he got dead in a street accident. That was really stupid. But I do not remember about "
"Jean-Daniel Nicoud","Interviewee"," and even Aude Billard I do not remember if because she quickly she made study here, but she quickly went to England and got all this knowledge from there. But you well, you talk with her this morning. So you must know."
"Jean-Daniel Nicoud","Interviewer","Well, she said that you helped her to translate the robot that she would built in Scotland into the lab here before she went to USC. So there was a humanoid robot that she had built."
"Jean-Daniel Nicoud","Interviewee","Yes, she came from England with a doll and robotic inside the doll I was not at all pleased about that, that electronic. So I propose her to remake that electronic and this was the doll we built five or ten of them she continued to play with at USC. But it was just a very simple electronic. Because the electronic I made was only the interface between computers sending orders and my microcontroller was distributing to the motors. "
"Jean-Daniel Nicoud","Interviewer","Okay. And what do you see as the big problems facing robotics over the next five to ten years? Or what do you want to see solved?"
"Jean-Daniel Nicoud","Interviewee","Hm. it is energy problem. There is no hope really improving the power sources and we can improve a little bit the motors. But I was quite impressed with a video I see is not so far with a moving arm with a speed and a precision, which now is possible with the electronic. Because the electronic is still progressing so if you have better information from the sensors and enough power to send to the motors you can really do things which are faster than a hand and things like that. And, of course, now it will not save energy. So if you want to have something which is autonomous for some time that will stay a big problem and specially if it is getting small. Now I have very little hope and the only hope for the future is to master some biological effect and be able to have them work for more than a few seconds. Because a muscle is something incredible efficient. And so what can we do with cells and with living organisms? And that is a big challenge, but I think it is not impossible to find mixed solution. I have looked carefully to artificial muscles for a long time. But very, very little hope in chemical pure chemical or pure physics. So."
"Jean-Daniel Nicoud","Interviewer","Did you have more?"
"Jean-Daniel Nicoud","Interviewee","No, no. Nothing more to say. But it is now the market is opening with these cleaning robots, but anyway. Even the big cleaning robot exist for twenty years and they made no progress. And this is of course, I was used with the Morgan [sic] Law to have some new things to study every year in robotics. it is a little bit disappointing, but "
"Jean-Daniel Nicoud","Interviewer","What do you think will be the big applications, especially for small robotics in the next decade or so?"
"Jean-Daniel Nicoud","Interviewee","Well, they will be not necessary humanoid-like because walking with two legs is really something we have difficulty to do now. Even with battery pack [ph]. Again, if you bring the power from outside you can make wonderful things. But as soon as you have to carry the battery, we have I do not see any solution. So for helping the elderly, for there will be a growing market. That is clear. I worked with a lot we did not mention this: on mine, searching mine. And I made a funny robot, which was not supposed to explode the mines and search for them. And we had to stop the project because we had no sensor. So sensor for finding mines it is a field which do not progress because there is no market. Nobody is interested in removing mines in a country where people can buy only for few dollars a month of technical equipment. So microcomputer progress, USB-key progress very fast because there is a market which develop. But so a robot for removing mines could be an interesting application, of course. Now one of my worker on this project, he is building big tanks to prepare the fields, because there is no good way to remove mines instead of scanning by hand and recognizing very small signals and doing it in an appropriate way. But if you do it in an appropriate way, it is not dangerous. So the cost of these people is very low, compared to the cost of possible technology you have to develop, etcetera. So it is a field which does not move and now robot for farming exist for some time. It develop also very slowly for taking foods or apparently, people are still so much efficient with a vision and hands that it is very difficult to build robots for this. And so I think it is so surgical robots are quite interesting, if they can be controlled by hand, controlled by the vision of somebody and since you can put more small camera and sensors and avoid to make a big opening to That is wonderful application for this I think. But mobile robots, no. Well, you know the application who are military is still paying a lot of money to improve some operation. And, of course, I follow from very close the flying robots. Well, the flying camera. it is only flying camera so the soldier can spy, see better what is around it and evaluate the dangers. So there are beautiful progress, but still they have energy problem and cannot fly long enough, cannot go far enough. there is a Morgan [sic] Law, which is a progress a factor by two every twenty years maybe, which is very slow. "
"Jean-Daniel Nicoud","Interviewer","Yeah. You mentioned it a few times, but That is usually the question we close with, which is for young people who are interested in robotics, what do you recommend for them to do? what is your advice to them?"
"Jean-Daniel Nicoud","Interviewee","Well, they have to master embedded system programming. That is, I think, a very first step because microprocessor can do so much things to help with interaction of the man. The man is always here to check that things are going well and if they are more automatized, That is perfect. But I think we still need the man to really be true, be sure that everything is going well. So you need to master programming. And now processor are getting so powerful that you can program with language which close from the application. But I think you just do the same as other people if you wait to have the tools. So if you can develop yourself the tools or develop yourself the application with simple tools which allow to make complex things I think it is an economic advantage. I mentioned Logitech with good engineers and good organization. This is what is important and not just the buying a tool which make things more easy, but limitation a lot of limitation with what you can do with these tools because okay, now for the hardware for the mechanical construction, you need also people with some feeling about how to assemble things and CAD allowed to check a lot of things. 3-D printing allowed to build prototype, which may give the impression it is easy to make something which works, but I think you still need to be clever and just by using existing tool you will just do have the same limitation as all the other people using the same tool. No, That is why you need to invent and be able to invent solution and this means that you need to know a lot of things to select among our technological world what will solve your problem at best. And now once you master the technology I think there are so many application and in the application you are interested in and you see there could be a market, you will find a solution which is better than the other people. Then, of course, you do not need only to produce prototype. You need to manufacture and sell and this is getting more and more complicated, because it is a lot of investment just to go to the market being sure that you do not infringe patent, that you do not that you can sell large quantity, enough that then you have to go abroad to manufacture. Everything is getting out of the hand of one or two smart people who would like to succeed by doing the start-up also. Is it more easy if you do poor software? Well, apparently all the fast-growing company are more or less pure software now."
"Jean-Daniel Nicoud","Interviewer","Great. Is there anything else you would like to add or anything we missed?"
"Jean-Daniel Nicoud","Interviewee","Miniaturization is a but really I do not "
"Jean-Daniel Nicoud","Interviewee","In relation with all these small robot I was looking for similitude law how do you say this, loi de similitude? Similitude? Or it is another word?"
"Jean-Daniel Nicoud","Interviewer","Similarity."
"Jean-Daniel Nicoud","Interviewee","Similarity? Similarity laws. And, of course, for very small dimension you get different kind of electrical motors which could have a better efficiency, etcetera. But what made the success of computers and tablet, etcetera, is we know how to improve a technology which is flat. And with optic, with chemical attacking, we can do wonderful things and we are not yet at the limit. But as soon as you have to build in three dimension, apparently and this is true for making well, you can make flat motors but then you cannot make the gears and all the layers which are required as soon as you need to transmit power outside a flat chip. So I do not see how to do things in three dimensions instead of machining them and gluing, screwing and using the present technology when the watchmakers made the wonderful things for watch for many, many years. And I do not see well, first, how the watchmaker technology when they make these movements or rotating to compensate the orientation of the hand. it is wonderful, really wonderful on the mechanical design and the mechanical assembly and they can produce it very cheap. So can we use that expertise to make special robots? Of course, medical application are good, because there is a lot of money for developing medical applications. Okay, so I do not have wonderful solution or wonderful direction to indicate. But I think I would encourage young students to work in that direction because they are really well, for me, of course, it is interesting study and there are many things to invent, if the pleasure is to invent."
"Jean-Daniel Nicoud","Interviewer","Great. Did you have an interest in clocks and "
"Jean-Daniel Nicoud","Interviewee","What?"
"Jean-Daniel Nicoud","Interviewer","Did you have an interest in watches and clocks prior to your work in robotics? Was there any relationship?"
"Jean-Daniel Nicoud","Interviewee","No, not specially. Except I like the stepping motors, which are some kind of watch technology, because it is what? it is low power. But, of course, a hundred years ago I would have became a watchmaker, clearly. "
"Jean-Daniel Nicoud","Interviewer","Yeah. Okay, thank you very much."
"Jean-Paul Laumond","Interviewer","So if we can start with your name, and where you were born and when?"
"Jean-Paul Laumond","Interviewee","Okay I am Jean-Paul Laumond. I born in 1953 in countryside north from Toulouse in France, in a small villages in France."
"Jean-Paul Laumond","Interviewer","And where did you go to school?"
"Jean-Paul Laumond","Interviewee","I have been to school at Briwhich is the main city of the area in that countryside, and after that I entered the university in Toulouse, first by following special training in French which is what we call the classes preparatoires for the engineering school. But in fact after two years I moved to university to in the mathematics department and I got a diploma to be a teacher in mathematics. "
"Jean-Paul Laumond","Interviewer","What did you study while you were in university and how did you decide on that particular direction?"
"Jean-Paul Laumond","Interviewee","At the very beginning I was not very convinced by the choice I made to enter into engineering, because engineering is to go towards the industry world while I was more interested by the academic position. And at that time I did not know that engineering could be a possibility to enter the university or to make then. Then for me it was just pure abstraction or like literature, and then this is why and of course I was very enthusiastic with mathematics, and this is why I chosen to enter in the university in the department of mathematics."
"Jean-Paul Laumond","Interviewer","So after the university you did one year of teaching or longer?"
"Jean-Paul Laumond","Interviewee","No, no, no, no. Not one year, five years, five years. And in fact this has been with the French system you know the position of the national level and then my first position where in the very north of France, and I enjoyed teaching. I enjoyed the relationship with the kids, with the girls, you know there were 17 and 18 something like that. And I was very quite young. I was only 24. Then the relationship was quite interesting. But the problem is that teaching mathematics is kind of repetitions and I very often summarize my wish to escape teaching by saying that with the profession of teacher there are two aspects: one which is knowledge transmission and one which is education. And I was not very interested by the aspect of pure education, to be involved in the life of the student. Not the student but the kids and the girls. And then I start thinking about how to make reconversion to go towards academia. It was a kind of nostalgia. And it took four years to do that, to make that transition. First I enter in contact with some friends, chosen at that time to enter in engineering and I have seen that they were working in academia and I was very surprised, and then I remember a critical discussion with a friend of mine and explaining what are you doing and I am involved in artificial intelligence and robotics. Wow, artificial intelligence and robotics but I never heard about that world. What is that? What is that? I just pure training in mathematics and I then he tried to it was 1977 or something like that. This was the very, very beginning in France of robotics and okay and then I remember he advised me to enter in contact with George Giralt who was the chair of the Robotics department in Toulouse at last in Toulouse. And it was the very, very beginning and it just started that group. And then there has been very good contact with him because what were my position. First of all he accept to welcome me and I call him and I say what I can say? I did not know about him. Then I just say Okay, I am a teacher in mathematics. I am interested by doing other things by using mathematics to do something else and then is it possible to meet you? You know we- after several years you should understand that listening so famous researcher saying Yes, you are welcome it was completely fantastic! Why? I am welcome. And then this is I think one of the fundamental qualities of George Giralt and the UNT to take. And then the first rendezvous has been a failure, a complete failure. Because of course I was a little bit intimidated and then I tried to explain something a little bit confused. I am a teacher in mathematics. And I would like to use mathematics to do academy hours and then his main advice has been Okay try to be graduate in the Mathematics department and get a Ph.D. in mathematics, this is natural. Then I have some contact at the university then call these guys. And after that finishing this first rendezvous I was completely disappointed because I knew at that time the situation of the mathematics department and in Toulouse and I was not so enthusiastic to do that. Then this was a failure. And then after thinking but just a few minutes does that mean- I call back George Giralt two hours after the first meeting saying I am sorry, Mr. Giralt. I cannot express. I would like second rendezvous. You may imagine, this was in some sense this was very impertinent. And then he say okay yes, okay. And then the second one, he understood that I was a little bit flustered and then the second one he said okay the only possibility then we are working in robotics, robotics is such and such. Of course they may be very useful to get some students in mathematics but you have no graduation in robotics and so on. Then I propose to you to structure a little bit your future. But first you try to get the graduation in computer science and since you are teaching because he was teaching at that time and full time and then that you can go to the lab on Wednesday afternoon and on Saturday, then Sunday you are welcome as well but and then but since the charge is quite heavy okay it is possible to organize this first year within two years. Okay then the first one for the theoretical issue, the formal homework and examination and the second year for the training phase where there are some projects to realize. Let us fix that and there will be the following possibility. Either you fail in getting the graduation and then we will stop the relationship. Either you will succeed, and in that case there are two other options. Perhaps you do not care about that and if enjoy we will see at that time. We will see what has been done and after two years I succeeded in getting graduation in computer science computer science for me it was completely an abstraction. I did not know what it was. I have some anecdotes about that which is- which is incredible. Just to tell you what is the level of training, of mathematics. My advisor was a friend now was belonging for this training first was and then belonging to the group of George Giralt and a good friend of mine now asked me to work on some algorithms. Oh come on, what is algorithm? Okay I remember that okay we made that in mathematics to compute the biggest integer which is the common divisor of two numbers. Okay I know a little bit but in general I do not know what is an algorithm. And he gave me for the study the study of some work by Opcroft and Targent . I remembered it was an algorithm to decompose graphs into simple or big connected components. And this is very abstract. I do not want for you to explain what is this but and then at that time the algorithm were presented in the some informal language called algol . And that means that you explain the algorithm in the paper and there were I, letter I, double dot, you know, equal, I plus one. Then we see the affectation of I becomes okay then this is algor. I duh duh duh, okay, no double dot, what is this sign? Then I remove that sign in my mind. Then I equal I plus one. But come on, it is impossible. I promised you that this was my level, okay? And I tried of course, I do not want to say that I do not understand and okay now after several years oh what was the original problem? The problem is that the training in mathematics in France was at that time very, very abstract. We study the structure of the mathematical structure of the mathematical object but we thought constructive view. The question is to prove the existence of an object, understand? The existence for the mathematical object but you do not care how to build the object. Building the object is a problem of engineering, oh come on, it is not very interesting from the mathematical point of view. The critical point is to prove that these objects exist. Building the object and that means that the dynamic character of the mathematics that building something is completely abstract but this is computer science. That means that variable that takes value at a time T and then another value at time T plus one. I do not understand what does it means? You see the point. Then I had to learn a lot. And the cherry on the cake is that several years after that I realized that the paper I was working on by Opkof / Targent was one of the most sophisticated algorithms which has been ever published in the . But means that my advisor put the level very, very high to understand that. Okay and this is that by that way I enter into the domain of computer science and from the mathematical background and to all of that. And then after that my talent of programming in programming was has been always, always very bad. I stopped programming in 1984, something like that. And then I was enthusiastic with a language which were at that time APL. You heard about that very abstract, very completely in opposition of the current language, the modern one with the object level and so on and the competition was to make the program, as short as possible. Okay you know we sought , we sought impossible for somebody else than you than to understand what the program was doing. And then after that I enter into the PHD, where the subject was to use the graph d'oei to better understand the environment which is captured by mobile robot and the idea was how to provide mobile robot with the capacity to understand its environment by using graph decompositions. Then it seems that I was at that time welcomed in the robotics community. First paper was about that and so on and this is that."
"Jean-Paul Laumond","Interviewer","Where was it published your first paper?"
"Jean-Paul Laumond","Interviewee","Ah, it was very interesting. It was at Ichikai 1983 in Carsou . And to continue about anecdote I never learned English at school. I just learned German, Latin, or Greek. Then I am completely autodidact with English and then you may consider that with my accent and voice with my capacity to speak in English that this is clearly that I am completely autodidact and my first presentation at Ichikai was totally phonetic. I learned- I remember the very beginning the first sentence I am presenting to aspect of learning for mobile robot navigating in a given environment. This was the first sentence that everything has been- it was phonetic. And each guide and it was I did not realize I was the single author of the paper and my advisor was very, very good for that. He was encourage me to he made the correction of the paper but he was considering that he was not sufficiently involved to be a . Again this is not at that moment that you realize this is years after that okay, my first paper I was single author in a very selective conference in Ichikai. You do not realize that. You say okay, it should be normal. No but in fact it was not so bad. "
"Jean-Paul Laumond","Interviewer","And so when you started working in the lab what kind of robots were there? What kind of projects were there?"
"Jean-Paul Laumond","Interviewee","It was the beginning of the project HILARE the mobile robot promoted by George Giralt. At that time my colleagues Roger Chatilliard was working on the navigation system of HILARE using ultra sonic sensor and so on. But for me I was far from the physical robot. It was at the level of artificial intelligence, of the abstraction of the concepts, then I was not touching the sensor and so on. Again, remember I am not an engineer. If I tough the robot it will be a catastrophe and but speaking this has been a real problem for me. I was considering myself as not allowed to be involved in such engineering part. I was observing and of course part of my thesis of some piece of software have been done at that time in collaboration with Roger Chatilliard ,who were much more involved than me on the real robot. And this another aspect of the situation in Toulouse at that time. George Giralt knew about creating a true group. And this is definitely very, very important. A true group, what does it mean? That means that how to make a researcher working together. Then of course when you are at the level of the Ph.D. it seems to be natural. You have a mentor and then everybody is working under the supervision of the mentor. But in fact the management of George Giralt were much deeper in the sense that after that along our careers we maintained this capacity to work together. it is not simple. it is not simple at all, but George Giralt succeed in creating a critical mass to conduce very ambitious projects where you need to combine a competence in perception, in vision, in signal processing, in decision making, in control. it is not possible for a single guy to get that and robotics is all of that. And I think this has been a very, very good point at that time to create a synergy allowing several researchers working together. In that sense the organization is completely under opposition at the opposite with the American system for instance where there is or Japanese system where there is one professor and then the student. And your former colleague okay? And then has to create his own team, one professor and then his former students and then it is very difficult to work together. While with the French system of the national lab like this which is not exactly the university lab, it was possible to have a critical mass and today the number of researchers in robotics at last is 80. But 80 within an organization of only three groups. That means that there are perhaps 25 or something like that, 20 or 25 senior researchers with tenure, with permanent position. But only three groups. I think this is very, very important. "
"Jean-Paul Laumond","Interviewer","And so after this first paper and kind of your initial work, what were some of the other projects you worked on while you were doing your Ph.D.?"
"Jean-Paul Laumond","Interviewee","The paper was in 1983 I got my Ph.D. in 1984 and at some stage I had some proposition to enter the university in Paris in the department of pure Computer Science. That means graph theory because in my Ph.D. committee there were professors in theoretical computer science who were very interested by my work and encouraged me to go to Paris. And this was the only offer. And I declined the offer, why? Because at that time I understood that entering the university that means teaching at the university would be exactly the same job as teaching in for kids and girls and I did not want to enter again in that system. And then there were the possibility in France to apply to a CNRS position in the National Center for Scientific Research that allows researchers to do only research. And then I applied for a position. It has been not easy but I applied and I entered the CNRS in 1985. Then you remember the date I born and that means 32 years old. it is not so young, eh? And but keep in mind there were five years of teaching and in fact I never regret that period of teaching. Why? Because I remain a teacher, but I remain a teacher with complete freedom, complete freedom; I just teach in some institutions what I want. If the people do not care about me, okay but I teach my topic of research and not the undergraduate course and not everything like that with the administration of the university. Just this is a module and then I definitely enjoy teaching that. "
"Jean-Paul Laumond","Interviewer","And so at CNRS what kinds of things did you do and who was there when you went there? "
"Jean-Paul Laumond","Interviewee","Okay then I enter CNRS in 1985 and then I got a Ph.D. in 1984 to do what? And then this is the first question of the researcher. You have to pay the freedom, okay, then you have to define by yourself your own topic. Of course you are discussing with your mentor, with the colleagues and so on. And then this is the time where I will say computer science, math robotics in the following sense. I was interested by geometry and this was the I remember as an anecdote which is very interesting, in Carceau conference each guy 1983, I gave a talk just after or before I do not remember another talk which were given by Rodney Brooks and Thomas Losano-Perez on the motion planning problem by using cell decomposition at that time. There were other geometry ideas in the like this. And then with my background in mathematics I was studying by myself some element of computational geometry and how to solve a geometry problem with a computer. Where the model was quite abstract and sophisticated and I started a little bit working with that and the first connection has been theoretical paper. We sought an interest for robotics which has been to prove that it was possible to draw a planar graph than a graph classical data structure; it is a planar if it is possible to draw that graph by putting the notes on the plane in such a way that there is no edges crossing outside the the node . Okay. Then there were theorem by Fari mathematicians, I do not remember when but it was in the 1940s or 1950s I do not remember exactly, that proved that it is possible to draw such a graph just by using not curves but straight line segments. It is possible. But nobody provide the algorithm. Okay just the existence yes, it is possible to do. And then I provide one of the very first algorithms. Unfortunately just three weeks after Japanese computer scientist who did exactly the same work and published just before me. That means that the algorithm that I propose I remember it was to the Journal of Algorithms which is quite a selective journal in computer science. And then the reviews say okay then it is the review after I do not remember, three months or six months something like that. The algorithm is very nice. But this is exactly the same algorithm as the algorithm by Shiba and Nakanosaki I think. Shiba, I am pretty sure, I do not remember the second name, which has been published but the date was after my submission. You know it was not possible for me to accept that. But the algorithm was completely current then I never published that algorithm in a journal. But okay. I mentioned anecdote because this is the first link between graph theory and geometry. And then I discovered that a structure of or visibility graph everything. There were another Ph.D. student finishing the Ph.D. Laurent Gouzelle and also Tierey Simion they were studying deeply the concept of the configuration space promoted by Thomas Losano-Perez and then we were working together and trying to do that. And then a key idea appears at some stage. It was in 1985. I am correct? Yeah, it was in1985 when George Giralt enters my office and tell me Jean-Paul, okay I understand everything you are doing in configuration space and how to translate the physical problem in to an abstract problem. How to move bodies, how to transform that problem to how to move points in the configuration space, the configuration space approach. Okay I perfectly understand what is this. Tell me Okay come with me. Give a look at HILARE. Yeah, and then what is the dimension of the configuration space? XY and and the configuration space is three. He told me But there is something I do not understand. HILARE moves like this but it cannot move like this. Now because you told me that the existence of motion is characterized by the existence of the passing connected components but if your algorithm provide motion like this, it cannot be executed by the robot. HILARE has wheels. This is not a manipulator with all the degrees of freedom which are controlled by a given motor. Okay then this was the very, very beginning of a very enthusiastic topic that all along make motion planning which has been truly the starting point of my career. And I will be always jealous against George Giralt because he asked the question. And the right one with the intuition that these questions were very, very deep. And I just solve in some sense at some stages the problem but the intuition to say Okay Jean-Paul, there is a difficulty here. The intuition comes from in and this is why this is truly a mentor. Because the problem was very, very deep and very exciting and in what sense? Because the solution of that problem comes from the combination between computer science and control theory. And for that there are some concepts to make the connection which are purely abstract and mathematic. There were definitely the need to use sophisticated mathematic tools, and then my first conference was in Amsterdam on that. I solved the problem in Amsterdam in 1986. This has been the first paper showing that it was possible to reduce the problem of the decidability that means the existence of a trajectory for mobile robot to the classical piano mover problem. The piano mover problem was the seminal problem of the motion planning. That means that it is possible to in some sense to kill the constraints of holding without sliding by an approximate scheme where you first solve the problem for the mobile robot as if it was a piano and then after that you approximate the pass by a sequence of a visible one. That means that you solve the problem like this and then after that you approximate the pass like this and this is the parking this is the parking task. The first algorithm was not so efficient of course, but there were formal proof that it was possible to do that. Then Amsterdam IAS symposium in symposium one of the very first promoted by Groen, I think professor Groen, from the Netherlands, the symposium already exist and is running and there are a lot of anecdote because at that time I had questions after my talk in the room there were persons that had questions, yes. I think that your theorem is wrong. Oh come on in public, I just proved that. Okay please could you develop? Okay if you are considering these example such examples then that case your algorithm will never converge. Of course you are right. Of course you are right. But the hypothesis I was completely destabilized, huh? You may imagine. You are proving something and then something in the room say okay in a public manner your theorem is wrong. Okay in fact he was a mathematician and the hypothesis under which my theorem were wrong is a hypothesis where you should consider an infinite number of obstacles was the size of the obstacles converged to zero again so all like this. Okay then but this is not the real world. This is not the real world. If you are considering the true world, that means that the number of a chair here is finite and the length of the trajectory is finite, and then okay and they say okay in that case you are right. You know there are a lot of like this but that makes you very enjoying you know because there are a lot of stress and some people tell you okay your theorem is wrong. Okay and then after that I continue and after that I think this paper had some success in the sense that I have been for the first time invited to give, to present an invited paper in some conference in Jerusalem, in Jerusalem it was very fantastic for me to travel in Jerusalem and discover that magic city. Okay, there are a lot of anecdotes. And then this has been my first lesson for researcher. You have to take care to what you announce and then you are completely free to give a talk any topic you want but mainly related to your presentation in Amsterdam and then in Amsterdam I proved that it was possible to park a car. Just a car parking problem. I said oh, what would happen if we add a trailer, mobile articulated system? I put some question and paper like this okay and okay it will be yeah, okay then. In my presentation in a few months I will prove that the results about the carlike problem can be extended to the mobile robot with one trailer and then we will present the proof of that system at the time. And then I send that. But I did not make the proof. And then the proof is not so simple. And then it was let us say I do not remember exactly the timing but let us assume that the conference is supposed to be in December. Then we have to send the paper in September, the final paper to be printed in the proceeding. Then in September, then I had the abstract in the February before. Okay then at some stage, perhaps in July I say okay I have to make that proper way okay and then I start working on it. I do not succeed in proving the theorem. Come on. And then September arrives. No. I made the proof in November after the edition of the proceedings. And then I was not very comfortable because I gave my talk with the printed copies of the paper but outside from the proceedings, then that means that this paper exists, but nobody except the audience get that paper. And this has been a very good lesson. Never announce a result before you are sure to have proven that. And then at that stage I made some critical meeting there with new people and mainly there were very active collaboration thanks to George Giralt between Toulouse and Berkeley, the University of Berkeley and I met some nice guys like . And then we had my very first discussion with him to see that we have to continue in that direction of the non-anomic motion planning. This is a very, very rich topic, and I started promoting that area at the European level then applying for project where the main- the key ideas was together not only roboticians to work on that but roboticians, computer scientists, control theorists, and pure mathematics, not applied mathematicians but pure mathematicians. You know that I made this strong distinction between applied mathematics which is very well known topic, very well numerical optimization, numerical analysis, and so on. Okay then it could be mechanics. It could be probability. No, no, the pure mathematics in terms of topology, the study of the structure and so on. And this has been three years between 1992 and 1995. Very, very exciting years of where we made a lot of new results and we create very synergetic relationship and I made all my friends at this moment which has been truly very, very important for me but also for the prediction of the . That means that the key idea to make different people working together, keeping their own competencies. And the question is not to transform a pure mathematician into a robotician. it is not possible and the converse is also true, but making them working together we provide a lot, a lot of very exciting results, training very enthusiastic students who are no permanent researcher or very huge position at that time. There were connections with Richard Murray, for instance, a former student of Jean Gasastri There were Paul Jacobs who is the president of Qualcomm at that moment. Then there were you know a lot of people that we met, Hector Soucemann a scientist from Rutgers University and then the core group in Europe was the group of Allesandro Deluca in Roma, Marco and Alexander Deluca from the control theory part. Marco computer scientist in Utrecht. Jean-Daniel Boisonard a French specialist in combinatorial geometry. And Jean-Jacques Chrysler a mathematician at Ecole Normale Superieure in Paris and myself. And then this kernel has provided a lot of results. I remember the first group I organized at the time in some countryside close to Toulouse. This was the very first workshop of Leah Kavaraki for instance, you know? There were also of course. There were you know this was the standards. And during all this period there were parenthesis which has been very critical for me for several viewpoints which has been the summer 1990 where Jean-Claude Latombe invite me spending some time in Stanford. And I spend three or four months here. And then I just provide one result but I learn a lot that this was the controllability of the multiple D trailer system. That means that the proof I made for the college system but and then for the carlike with one trailer can be extended to an arbitrary number of trailers. Nobody cares about that. This is a purely mathematical results and we sought in the effective application but very, very nice results from a mathematical point of view and we learn a lot about the structure of the non-autonomic system. And during that period then I am just reporting enthusiastic manner because it was very, very exciting period. Then something which may appear as very abstract and we provide new results but in fact we kept in mind the robotics application and the true robot. And then I succeed in convincing myself to build a trailer, an effective one to attach to HILARE. And thanks for an ingénue at that time, he passed away too early, he made the trailer for me because I do not know how to make a trailer and then to attach that to a robot. And then we had an effective experimental platform to test the abstract algorithm and then we succeed in making the first, very first experiment of the mobile robot parking itself by pulling or pushing a trailer. And this is very, very spectacular and it remains today very, very spectacular. And everything, the solution we have developed, use are based on the mathematics we have developed. And this has been very good lesson again with the feedback after several years that do not reduce robotics only to technological development or to engineering or just to apply mathematics to that. Take the time to think about your system and then to see the true problem which are do not avoid them. Try to capture and then after that, if you cannot do more, if you can solve the a question, then ask perhaps some other method numerical optimization or something like that to solve the problem for you but before that spend some time to think about the way to solving, I will summarize that by saying to solving the analytical way before using the numerical method. And this has been- this remains for me very, very important. Okay and we have to convince young students which are attracted by mathematics, by pure mathematics that robotics may offer a very, very nice room for enjoying the development of their favorite tools in mathematics."
"Jean-Paul Laumond","Interviewer","How did people from both more pure mathematics and also more kind of applied robotics react to this approach? Jean-Paule Laumond: You mean the people from mathematics?"
"Jean-Paul Laumond","Interviewer","Right so from one side there is kind of robotics and how they thought about having this more analytical approach prior to application and things like that and then also from pure mathematics, how did people respond to-Jean-Paule Laumond: Okay I will tell you. Now this is an interesting question. From their perspective, from the perspective of pure mathematicians, how would they react? I can give you a perfect example. This is it was in 1987 I think. There were a huge congress has been organized, national one in France at Ecole Polytechnique which were called mathematic avenires . That means the translation will be there is a joke in mathematic avenire means the future of mathematics okay? But also mathematics to-go. What will be the mathematics? And then there were several symposiums, huge symposiums and then some mathematicians invite me invite me to speak about the robotic problem, piano mover problem and the non-autonomic system and soon. But what has been very interesting is that the congress was organized with several topics and probability and then there were applied mathematics, and then but I was invited in the session of pure mathematics. And I was introduced by the chairman by saying This is a perfect example of not applied mathematics, but a perfect example of the application of pure mathematics. You know the distinction? That means that the mathematicians were very, very excited by the idea that the very abstract concept which are developed in geometry, in very sophisticated mathematics are have application effective application in robotics. And then you see that this is truly a critical point with this perspective. Very often you know we put walls between the discipline and then there are pure mathematics applied mathematics, okay applied mathematics is for engineering. it is obvious, this is the mathematics for engineering and then we are the specialists. But the pure mathematician do not care. No, no, no, in fact the reality is much more complex than that one and that means that as an engineer in robotics we need some tools which are not developed in applied mathematics. That comes from pure mathematics. This is why we have to take care about the walls and to push them at the maximum and then to maintain, but not to become a mathematician. I am not a mathematician. I define myself as a robotitian. I am not at all a mathematician but I may work with some mathematicians. And the key point is the human relationship. You should make friends or people who would become friends. That means that to have mutual respect about the problems you are addressing because you may some people say oh, you are robotitians, only robotitians, okay. Your problem is very easy, it is not very interesting. Okay. But after that you are very, very nice people who are respecting you and to the discussion and this relationship has been very, very good. "
"Jean-Paul Laumond","Interviewer","And when you were working with Latombe in Stanford University what else was going on there at the time and how was working with Latombe?Jean-Paule Laumond: It was a fantastic experience because I was working more than Jean-Claude Latombe at that time and you know working more than Jean-Claude Latombe it is impossible. I mean it is, no there were not competition between us in that sense, but for me it has been very completely crazy period. I was sleeping only three or four hours a night, completely immersed in the and and then the theory of the distribution, spending time in the Stanford Library, discussing with Jean-Claude Latombe and his students about the emerging probabilistic approach to motion planning discussing with the student about that. No it was a fantastic period where we worked with Jean-Claude a lot. It was perfect condition for me and you know this is what I say several times from the beginning of this interview. What you are doing at some stage in that period takes a value months and even years after. You do not realize what you are doing at that time, okay? And everything I learned during that period has been a fantastic period with me but truly I never worked again so intensively. At the very end I know that I wanted to prove that the multi-body trailer was controllable and then I remember I finished the report, the Stanford report which is existing now still. At some stage at perhaps 4:00 in the morning I would like to finish it before Jean-Claude arrive to see What do you think about that? But it was very, very, very nice. And of course this has been completely reconnaissant I do not know the word in English. I thank Jean-Claude for having given me the possibility to spend such a time in Stanford, yes."
"Jean-Paul Laumond","Interviewer","And did you work closely with any of his other students? You mentioned discussing with one student. Jean-Paule Laumond: Yeah, I remember Yotokoga at that time he was using the- he was developing the seminal idea by Gerome Bartron and Jean-Claude which are the very first probalistic approach combining gradient descent and random work. When you finish in some trap. And again, for me this was a strange feeling because we spent years and years to solve the piano mover problem by using sophisticated tools based on algebraic geometry developed by all the teams at the Quantum Institute in New York, , Jacob Schwartz , and providing sophisticated proofs of the disability of the piano mover based on the disability of elementary algebra proved by mathematician Tarski in the 1950s and very, very sophisticated tools. And then of course completely un-useful due to the complexity of the problem. And then you arrive here and then you have a young student showing a system with eight degrees of freedom which are eight bars like this, articulated bars. Where you see that in few seconds is solving the problem to go to the final position. Come on, come on, how are you doing that? And gradiant descent, random work but random work you do not control anything, you do not know. No, but works. Come on. And then this was the very, very beginning of the probalistic approach and that means that we have to revise everything and forget about the completeness of the algorithm. Forget about that introducing new concepts, try to- and then the challenge is to understand in some sense okay before saying that I was a little bit disappointed in the sense that okay then these guys are solving problems which are out of the scope of the current method. Okay then I tell- I was discussing with the student and then I tell him okay, with your system which is articulated like this, I put the starting configuration in such a way there is okay you see I put it in that shape. That means that the solution to find the solution to the problem should be something like that. You have to make several turns and then to go back here. That means that if you start by being attracted directly like this, you cannot. You know you have to go back. Then that means I create very, very deep trap and I was pretty sure that any random motion will never escape that. And after one night of CPU the day after I I did not succeed in solving the problem. Ah, come on. I am very, very happy with that because there is no miracle, there is no miracle you did. But the key point is that I had to think about counter examples. That means that in general it works well. And in order to make the algorithm I have to see to counter example. That means that in general it works. Then you know this is still the current status of the probalistic motion planning. Then we try to understand that and I remember when I went back to Toulouse I ask a student of mine Feron Miro who is a very well-known researcher in my group in Toulouse to address that problem. The question is not to provide a new algorithm but it is the question is to understand why this algorithm works so well and we spend one year of full time research on that problem. We publish one paper. I do not remember when we do it, 1992 something like that which is the explanation of a very, very simple case a small toy example where we understand a little bit what happens, but impossible to generalize that. And then impossible at that time. How to- this is another lesson, how to stop a line of research? Because this has been exactly the case. Then Feron Miro provide that results giving the estimation of the number of loop, gradient descent, random work, gradient descent, random work in one specific example you say okay the average number of loops should be six and it was not ten. It was not 100. It is six. it is not four, it is not it is the constant six. And then we may understand that according to the time then it is very efficient, six. And the question was to compute the effective experience, the mean of the of the . And six is nice, okay. Then let us try to generalize and with these results it is no more robotics. it is no more- we have to take some advice to mathematicians. I do not know a physicist and mainly a nuclear physicist. And there is a lab in Toulouse at the university where we enter in contact with those people saying okay we are robotitians and it could be interesting to for us to give a seminar because we are using some tools which are we think to statistical physics. Okay, welcome, you know this is getting out and the ambiance is very nice and then we give the seminar here explaining what we are doing and in front of us we have the researcher from statistical physics and the people who were oh, the robotitians are interested by that kind of problems. Oh yeah, yeah. You perfectly explain. We understand very well your problem but what is your ambition? To understand why the algorithm runs so well. Okay yeah, if you want that ambition forget about robotics and come with us. We are working on that type of problem for several years and we are still working on that, but forget robotics. it is too much complicated and then you will do a pure statistical physics. And then after the seminar the Feron Miro had a discussion with him okay perhaps it could be good to change the subject of the Ph.D. And then this is what we did at that time. We resign and we the ambition that it was a deadlock and you know as an advisor you have the responsibility to advise the student and to take care not entering in a trap where you will provide nothing for his own career and so on. Then okay we stop here. And that means that this problem remains in my mind okay but I consider it is very, very difficult. And the main contribution today has been done by Jean-Claude Latombe and his school with David Sou with some concept of expansiveness of the space is to be explored. And the results are very, very deep. We understand that the conversions of the algorithm is quite fast but there remain for me that is from miracle. To summarize my opinion, my view on that very often I say that if this algorithm was appearing in the 1960s, let us say in the 1960s the success will never been the same because the time of computation the famous constant, the average thing of computation due to the power of the computer that had been much less. And then there is I think that the clear view of Jean-Claude Latombe and at the very beginning has been to see that the technology were mature enough to allow some new algorithms using the probability etcetera to solve some problems which were out of the possible scope of the pure mathematics and so on. That means that in some sense the solution may appear in some sense and with double caught as a technological solution which is not a bad point1 for that time. This is the new contribution of engineering to the development of a new algorithm. And but it remains the idea of why this they work so well, why these crazy ideas in some sense work so well. Okay then in fact I have been convinced why because after that in that period in 2000 and with my colleagues Tierry Simonon, we were developing our own algorithm probabilistic motion planning. Okay then we were of course using the same idea then we start making the platform and then after that we decide to create a company to promote that kind of technology and start a company where Kineo Cam computer motion, and that means that the companies are still alive. We have no more . I managed the company during two years and then after that I go back went back to my lab. But the company is sailing that kind of algorithm. And very often in a very prophetical way I say that we are selling a technology that we do not understood, we do not understand why it works so well but the customer does not care. The customer does not care about the philosophical attitude, the thing oh yeah, but why it works so well? No they are not interested by they are going. They want just to have their problem solved and this is applied in virtual prototyping, virtual prototyping to check if it is possible to disassemble some part like this. The customer happy, then this is the key point for a startup. do not care about the conversions and the expensiveness of the spaces and etcetera, etcetera. They do not care about that. And Kino is very happy that they do not care about that. They just provide the technology that allows them to solve the problem which were not solved for them. That means just to give you an idea that today when you are working in the digital mock up for instance in the automotive industry when you are designing a motor, an engine and then when you want to check if a given part of the motor has been well-designed and to access to be maintained, just to be maintained. Then you have the problem of piano mover and how to remove that part. Then today there are years ago they were using physical mock up and you design and then you build the system and then you check and then there is a loop to adapt. Of course the digital mockup and virtual prototyping give a lot of money saving in some sense that to perform the same task in the virtual world. Okay this is just a mockup but you need an operator that move the pieces using sophisticated interface to make the reasoning entreaty and so on. And then I have seen the people working on that. They are very expert to see if it is possible to extract a given seat from the car habitat the main part of the car. "
"Jean-Paul Laumond","Interviewer","Chassis? Jean-Paule Laumond: Yeah the chassis from the chassis, thank you. And then it is moving that checking, oh it become red. That means that there is a collision and so on. Okay to do that task for let us say for a seat of a car the operator in some case, this was the case of the car maker Renault in France, it takes two days where you say the trajectory and then you try because the engine is very, very tight and the guy has to check where is the collision and then two days. By using that technology it is done within ten minutes. This is very simple. Ten minutes, two days, this is money. They do not care if this is not probabilistic complete. They do not care about that but the problem is solved, and of course, the problem cannot be solved as we know from a theoretical point of view it is not possible to say that. But in that case if there is no solution we have some formal models that show that even the guy will never find a solution because the is very, very, very narrow and very challenging. And then this is completely effective. This is a technological solution and this is another point which is very interesting. This is not exactly robotics. This is the output of the robotics research towards which hare virtual prototyping and this has been a very nice period that one, and completely different. Before starting- before thinking about creating a startup you have to take care. Give me a call. And I will give you some advice because the life truly changes, okay?"
"Jean-Paul Laumond","Interviewer","And when was your startup? What time were you working?Jean-Paule Laumond: It was in- I managed the startup in 2001 and 2002. Then I have been after that scientific advisor from 2003 to 2007 and now I no more connection except that we remain friends, but no more interest with the company. "
"Jean-Paul Laumond","Interviewer","After before the 2000s in the 1990s you also had one or two large European projects on motion planning?Jean-Paule Laumond: Yeah, yeah. After the very first one I mentioned with pure mathematicians I promote another one which were more effective in terms of application and I participated in two other ones. I just mentioned the seminal one because it was truly my baby in one sense. The other one also but it was less important, not in terms of results but in terms of investment and key new ideas it was less important."
"Jean-Paul Laumond","Interviewer","And who were some of the people that you worked with there?Jean-Paule Laumond: What?"
"Jean-Paul Laumond","Interviewer","Who were some of the people that you worked with on those projects?Jean-Paule Laumond: On the second one?"
"Jean-Paul Laumond","Interviewer","Uh-hum. Jean-Paule Laumond: It was okay then their idea was to be much more effective. That means that we revised the initial consortium to have practitioner and then at that time then this was the idea to apply that not directly to robotics but to virtual prototyping and then there were already and it was in 1996 something like that, yes, should be 1996. Then their idea was to better understand the structure of the market in virtual prototyping and who are the actors, who are the customer, and then we identified EDF, the electricity company in France, then involving the nuclear power plant. They wanted to have automatic system to make robot programming in the nuclear power plant, how to make obstacle avoidance to operate robot in very confined space in the nuclear power plant. Then there are effective problems. What tools they are using in terms of virtual prototyping, then this is a question of software development. What are the platforms and what are the provider of that platforms? And the provider at that times were a subsidiary of Intergraph Cat Center where the company providing the system to model the digital mockup of the nuclear power plant. Then we work altogether to be effective. At the very end it was possible to plan some trajectory and so on. But of course with Kineo, then after that there were basis how to go forward and know more in developing the new European project but to be much more effective for our self with respect to the platform, the software platform we have developed at last and this is the beginning of Kineo Cam. But the question is again, what are the customer beyond the AV industry and the maintenance of the power plant and so on. And the more mature market was definitely the automotive industry and were the provider of mainly the Soso system with Katya platform and Unigraphics and the company which were the closer to our community at that time were a company from Israel Technomatics. And Technomatics now is part of Unigraphics and now Siemens you know them. But there are very few providers and then a lot of customers. Then, okay two words about the strategy of Kineo. The question is not to address directly the customer. Why? Because if you are a small startup then in that case you need to have a huge department for marketing for you know a lot of people traveling everywhere convincing everybody. Now the idea was to the final target was clearly the Soso System with and Unigraphics with Technomatics or Siemens now. And but it takes then to summarize and to be charicatural only two customers, the provider, you can concentrate the effort only on software development and on the technological part of the company. But it is very easy to analyze as I am doing at that time to convince the huge company like Soso System or Technomatics to diffuse and to get the technology you are developing is not so easy. And that means that the strategy has been to work very closely with some final customer where we prove that there is another value and to impose that customer to make the situation where the customer ask the provider to integrate the solution in their offer in terms of the software development. And this is the current strategy of Kineo, which is quite successful to say I think quite successful because they are in good shape. With that strategy which were at the very beginning my strategy the strategy we discuss from the very beginning you do not need to have a huge marketing department. Kineo / Cam remains a small company with only 15 people or 20 people, between 15 and 20 I do not know exactly but more than 60 percent I think of the people are engineers, developers and engineers that are developing the technology. And on the market I think there are no concurrence at all and almost all the automotive industry are using that technology with rather success. "
"Jean-Paul Laumond","Interviewer","And your current research group also has some of this combination from what I understood motion planning and also the virtual kind of virtual agents or virtual actors I think you were saying, and then human motion analysis or studies of human motion. "
"Jean-Paul Laumond","Interviewee","Okay. "
"Jean-Paul Laumond","Interviewer","So how ."
"Jean-Paul Laumond","Interviewee","Okay."
"Jean-Paul Laumond","Interviewer","Is that something that came out of your work with the company?"
"Jean-Paul Laumond","Interviewee","Yeah. Okay then now if we summarize at the time you can see that the interviews follows a historical perspective, okay. But in my mind in my mind I have the movie then we are in 2003 okay, we are in 2003. I told you that in 2003 I resigned as the chairman and CEO of the company and then I went back to the lab. Okay a new page is opened, new pages of the book new sequence of the interview. New sequence of the movie. Okay but you know this is very important, what next? And this is always the question for the researcher. What next? And then you are right. We at some stage in the virtual prototyping domain and so on, then there are only mechanical parts and there are very sophisticated simulation of robot. Where is the human? Where is the human? And at that time there were some actors on that and mainly the most performing I think were in Canada in Montreal people coming from computer graphics and there were also the people coming from robotics who was created Jack which is the name of mannequin so yeah, I do not remember his name. he is a guy very close to the robotics community, very good one that makes and so on to animate characters. And all this technology was very interesting for the provider, the Soso system or Unigraphics and so on. They were interested on that. But of course if you give a look at that time it was less than 10 years ago and even today if you give a look to the current status of the animation of the mannequin in virtual in digital mockup the result is not so nice and there are a lot of research to do to improve that. And what we should understand is that a digital mockup for industry, this is not Pixar or Disney. And this is completely different while there are some connections. There are truly some connections again the technology which has been integrate within Katya or the Katya product which are the we see system product which is for instance are based on a technology that was developed at the very beginning by people working in computer graphics. Okay but then I had that idea in mind, why not developing motion planning technology for anthropomorphic motion? Okay then the pages was white completely white and I start this line of research. Then I ask a student working with me okay you know what is the human body? The human body is a robot manipulator. A little bit complicated because the shape is a tree. You have two legs, okay but it is just a mechanical problem and then you have just to solve the question. I think we may apply all the robots technology to animate a character and I was right. It was okay. And then the student finished his training period with success. Then the mannequin were avoiding the obstacles, were working but how it were working? It were working like this making motion like this completely unrealistic. That means we solved the problem of course, but the motion were not natural at all. Then the collision checking, probabilistic method etcetera, etcetera. Everything were working very, very well but the results were very bad in terms of realism of the motion. Then okay oh come on, it is not possible to say that. Okay then how do the people in the video games in Pixar and Disney are doing? Because the people in virtual prototyping and so on are not so not better than we have provide, then how do Pixar is doing? And of course I discovered for me it was completely new. I discovered the topic of motion capture and motion imitation and you put the sensors and you put the markers on the bodies and then you try to imitate. Okay. Come on, to imitate, that means that you record motion and then you replay the motion but how to adapt the motion to a given environment, this is the question of the autonomy of the planning. No it seems that the question is challenging then how people are doing in computer graphics that they are using motion graphs and they are making blending the sequence and it is possible to fuse that. But okay then this is computer science solutions in some sense. I would like to have a better understanding in terms of control. And then I start research with Ph.D. Julien Petrie and with Julien Petrie I ask him to okay, you record some motion for instance from at that time which were arguable at Carnegie Mellon then providing recording motion of walking people and you try to transform that into a control system. And then he did a good work because he succeed and it was possible to control a virtual artifact, a human artifact just by using a joy stick. Then giving two input just two input the linear velocity angular velocity and then all the degrees of freedom, the 30 degrees of freedom of the mannequin were animated in a very, very credible way. It was very, very impressive, yeah the results was very good. And then to tell you the story for me it was completely normal. I asked him to do that. He did that. This was just with double cut signal processing using foier transform and then combining the coordinates of the main components of the Foirer transform based on the using the angulations of the databases of all the motion captures okay then okay then I asked you to do that. You did that. Okay then let us continue. No we want to provide truly motion planning. We may start studying the motion planning for the actual artifact. Okay and this is what he did but at some and then the first paper has been on it was in symposium on computer animation in San Diego in 2003. Then we provide the system that avoid the obstacles in a realistic way and so on. Then for us symposium on computer animation. There is no robotics at all. You see that we change a little bit the focus. This is the area where that kind of technology is the better understood. But at some stage I have some remarks from some colleagues saying Oh, your mannequin is working quite well. How you do that? Oh we just make that that that etcetera. Okay but it is not so bad. it is very nice. Oh yeah, it is not normal and in fact I did not succeed in evaluating at that time the work the student did. For me it was completely normal but in fact I was unable to evaluate the quality of the work and the people told me No, no, it is very nice. And then the locomotion controller has been published after these results. And in fact I was not aware about the deepness of that techniques based on signal processing and some numerical method to make the mixture. In fact it was much more clever than the evolution I made by myself. And why? Because this is not the same area, this is not the same topic. We have another view and then we enter a little bit this domain of computer animation. Then from that perspective a lot of possibilities were open and mainly two main areas which has been developed in parallel. One has been discussion with neuroscientist to better understand human locomotion. And then I met some very important people in that area in the connection between robotics and neuroscience and cognitive science, then main leader professor Laurent Bertose and we worked together and on trying to better understand the general laws which are at the basis of the generation of the locomotive trajectories. And then the discussion has been very, very exciting, very nice because they were a mutual synergy between the way the neuroscientists were approaching the problem and the tools we may provide coming from robotics and you know that the seminal discussion with the Professor Laurent Bertose was the deep discussion about the relationship between the position of a body in space and it is orientation. It seems to be very naïve, very simple but this relationship is very, very critical. It means that when some people is working is traveling, when it leaves some tracks in the snow or in the sand if you want, you have the track of the guy. The traces are left in the snow understand? But there are traces of the position, not the orientation. But you have no ambiguity to decide where what was the orientation of the body. Why? Because the orientation of the body were in the tangent direction of the body. Then this is the characteristic of non-autonomic system. That means that we walk as a mobile robot rolls. Okay? That is a connection. Of course we may walk like this. Then this is another story and we are shooting that. And then this has been the seminal discussion. That means that there is a coupling, a differential coupling between the body position and the body orientation, and at that time all the experiment in no science to better understand was consisting in drawing trajectory on the floor to be followed by the subject. But by asking somebody to follow a given trajectory your first variable which is the body orientation. Then that means that at the cumulative level this valuable is no more free. Okay then how to address the problem, I do not know. And then we start the discussion like this and we put together a new protocols for studying the human locomotion and for studying the intentional motion with goal-driven locomotion and then we start really fruitful research where the neuroscientist knows are publishing in robotics conference and professor Laurent Bertose is an invited speaker tomorrow in that conference. And where I have two papers I am very proud in Journal of Neuroscience. And this is very exciting topic. Then this is one line. And then there is a line has been the opportunity in France to reactivate collaboration with a Japanese lab and we have been very lucky because we the CNRS my institution in France, got a copy of the HRP2 Robot and then from 2005 to 2008 I have been with my colleague Yashi Yoshida co-director of French and Japanese lab. Then Yashi Yoshida spend five years in France working together where there were exactly the equivalent in Japan where and were directing the Japanese part of the lab. And working on the same robotics platform has been a very, very huge success because it is been possible to exchange the expertise, the students. The students were traveling a lot and then fantastic period and this period continues of course except that the recent tsunami in March has been catastrophe of course for the Japan but also all the French researchers have been asked to go back to France and then we have to reactivate the work but I am optimistic with that. And then today my own is around anthropomorphic motion. Then that means motion for the , human motion, better understanding of the human motion and the humanoid motion. That means that it makes an occurance where I create in that perspective a new group in at last called Geppetto. Geppetto the father of Pinocchio of course, that which is made not by new people but just by reorganizing the people interested in folks using their research on human robotics. As an example for instance my colleague Feron Miro then who has been my former student who made the very first experiment of non-autonomic motion planning for mobile robot with a trailer, now is fully involved in motion planning for humanoid robots where the challenge here is to take into account the dynamics and the balance and so. Then this is the end of the story but of course the story is continuing. It is continuing in that direction of the anthropomorphic motion and the future perspective on anthropomorphic action the perspective of research and developing. "
"Jean-Paul Laumond","Interviewer","What are some of the different types of issues that you are dealing with anthropomorphic motion compared to your previous focus on mobile robots and- or are they different?"
"Jean-Paul Laumond","Interviewee","How they are different?"
"Jean-Paul Laumond","Interviewer","Uh-hum. "
"Jean-Paul Laumond","Interviewee","Then let us speak just humanoid robot and mobile robot. I think that the main challenge for a humanoid robot is to maintain the balance. The question of the balance for mobile robot is not so critical. It has mainly four wheels and there is no . Humanoid robot is by definition unstable and then that means that there is truly a challenge how to with respect to the technology in motion planning which address mainly the problem of the obstacle avoidance then this is the main goal. In a singularly way how to take into account the kinematic constraints then the close kinematic chain for instance or the non-autonomic constraints of the moving car, but there are I like to summarize by saying that the collision checking is the level zero of the geometry then kinematic constraints are the level one in terms there are the first derivative of the motion and then there are constraints at this level. This is typically non-autonomic motion planning and dynamics, this is the second level of the geometry you have to consider the acceleration because the force and the gravity are expressed with the secondary of the mechanics and to make sure there is two levels in my mind. You can do reasonably motion planning and control for mobile robot with the two first levels. While for humanoid robots you are definitely involved with the second derivative of the motion. And then this is truly challenging and then for instance the workshop on Friday I will present the last results which has been provided in the Geppetto group about some extension of the notion of controllability to provide well-grounded algorithm that allows effective motion for the humanoid robot to avoid obstacles with the guarantee that you maintain the balance of the robot. "
"Jean-Paul Laumond","Interviewer","And how did you get involved with the Japanese with the AIST and the HRP2 group to begin?"
"Jean-Paul Laumond","Interviewee","Oh yeah, may I take a pause? "
"Jean-Paul Laumond","Interviewer","Oh we should have brought some stuff. "
"Jean-Paul Laumond","Interviewee","Okay the question is how has been the starting point of the collaboration with the Japanese team? This is the IOS congress of sendai in 2004. Then in that sense this anecdote will prove that this congress was very, very fruitful. Okay then you remember that I told you Julien Patin my former student was presenting a paper in the symposium of computer animation showing some virtual character avoiding the obstacle and so on. Okay of course we continue doing that and with more sophisticated system and then for instance considering virtual character to manipulate the object, okay. And in the digital mockup or collaborating with mobile manipulator to collaborate to transport to given load and so on. And then there were a little bit more robotics in terms of application. The algorithms were roughly the same, but the way to present that, it was possible to present that also in the robotics community then we submitted a paper on it. IOS, It has been accepted, and then strangely the paper appeared in the session humanoid. There were no humanoid robot at all, but you know how to organize the session. Okay I was a little bit disappointed to be in that session with people speaking about the very first pattern generator for humanoid robots and so on. And then my mind I say okay in that audience nobody is interested by the computer science approach to motion planning for digital mockup. In fact I was completely wrong. After my presentation two guys came to me and it was Yashi Yoshida and that told me Okay we have seen your work. Do you think that it could be applicable humanoid robot? And then we start thinking about that But you know your system is too sophisticated. How do you consider the balance? Oh we know how to do that. robot is very nice robot. We have very reliable and robust stabilizer and we know how to control thing and then okay then, if you want we may try to- we make computer directory and then you try to execute on the robot. Okay, why not? And then we start like this and in fact this has been a success. And of course there were also some strategical action at the level of the institution IEST and CNRS promoting a joint lab. The structure were existing. I use the word reactivate the lab. The lab was existing but this has been a new direction of research which has been promote with great success. And the very first experiment on Chapiteux for us has been a Chapiteux on you see the robot Chapiteux manipulating a barbell and very then the problem is truly a 3D problem because you have to coordinate the motion of all the limbs, the arms to avoid. The legs to walk and so on and so on. And this has been the starting point."
"Jean-Paul Laumond","Interviewer","You are getting close to two hours so you may want to wrap up. That was a movie. "
"Jean-Paul Laumond","Interviewer","We have one question. We have a part of the website That is kind of for education purposes so we ask everybody this so if you had advice for young people who are interested in robotics what would that be?"
"Jean-Paul Laumond","Interviewee","Do mathematics. it is not too short. And no, no, of course it is possible to develop but I think that in the interviews I gave some element to do that. Okay?"
"Jean-Paul Laumond","Interviewer","Thank you so much. "
"John Craig","Interviewee","1967 probably and so that was the beginning of the fascination and then when I myself made it to high school, there was a science fair thing and I built a robot in the style of the walking plywood box and so I was the kid with the robot in high school, but that was like 1971, so this is still going back pretty far and then I went off to college at RPI in Troy, New York, and in my mind I always wanted to build robots in the basement and my idea was get a job, get a real job and then in the basement I had build robots to keep myself happy. By the time I interviewed for jobs around 1977, there actually were robots in factories. There were starting to be robots and so it suddenly dawned on me, Hey, maybe I can get actually a job in robotics. So I started looking for that and I interviewed at places that were using robots like Procter and Gamble and so forth, but I finally took a job at JPL in Pasadena because there was a research group doing research on robots and I thought that would be even better. So that was really the beginning at JPL, NASA JPL in Pasadena, and my initial mentor was Marc Raibert who had recently gotten a Ph.D. at MIT and he went to JPL and he hired me and I came into his little group and the very first thing he did is showed me this six-axis force sensor that Vic Scheinman had designed and had a robot there. They had a Scheinman arm. Scheinman had made like three arms originally. Two were at Stanford, one was at JPL and Marc said, Okay, we have got to figure out how to do something with this force sensor and this arm, and that was the beginning of that and we did a literature search and read every paper written about force control at that time in the late 1970s and there were only about a dozen papers as I recall and they were written by people like Bruce Shimano had written something. Dr. Inoue from Japan had written something and a few other folks. Not much stuff out there. So Marc and I worked for a year and that led to this thing called the hybrid position force control system and we wrote a paper. Marc and I wrote two papers on that, one in 1979 and I think one in 1981 and I think those papers were highly cited and something I guess I am proud of and it was basically one of the I think we were some of the early people that were doing things sort of in Cartesian space and formulating the control that robot in Cartesian space fundamentally instead of in the joint space in the mechanism and that was not happening too much back then. At the same time, unbeknownst to me at that time this fellow, Oussama Khatib over in France was doing something similar and formulating the dynamics of the robot in Cartesian space. So later when I met Dr. Khatib That is when we could marry this all together and it became a beautiful thing doing force control and motion control in Cartesian space. So but that was the start of it. So that one year with Marc Raibert at JPL was good. My second year, things got shuffled a bit at NASA and I had sort of a new mentor who was this fellow named Carl Ruoff and he had worked at Bendix doing industrial robots and of course the industrial people, especially in the 1970s were keeping everything hush-hush. Back then rather than buy a robot from some robot company, you sort of made your own robots. So Bendix had their own robot group and Texas Instruments I consulted for once had robots internally. It was kind of a crazy thing in retrospect that each company would try and design and build their own robots. Pretty soon that got sorted out that there should be these things called robot companies that made the robots that they use. Carl had done all this great stuff at Bendix, but they were not allowed to publish and no one ever knew about Carl Ruoff, but he was a great teacher and I learned a lot of stuff from him, particularly in programming languages for robots and all the geometry of how you set up vision systems with robots. They were doing vision-guided robotics and stuff at Bendix back in the 1970s and no one knew about it. So basically the JPL years were one year with Marc Raibert doing force control and one year with Carl Ruoff doing programming languages and I read this thing called JARS which stood for JPL Autonomous Robot System, but it was a programming language for robots which was also popular back in the late 1970s that was a legitimate thing to do as research is to develop a new robot language, which also at some point got to be goofy. there is a lot of ways they do it now, but back in the day we were developing new robot languages every other week. So we did that and then at some point at NASA, most of the people I was working with had Ph.D.s and my wife said, John, got get a Ph.D. because you like this stuff, and I started looking around and it turns out at Stanford they actually had more robots and more computers than NASA did at that exact time. So I said, Hmm, I could just go keep doing the same stuff with better tools at Stanford and do it for N years and I had get a degree at the end too, so I went off to Stanford. Actually, nearly went to MIT. Nearly went to Purdue. Lou Paul who is a well-known guy was at Purdue at that exact instant and I was about to go out to Purdue because I was so enamored with working with Lou Paul, but just as the decision was coming, he called me and told me he is going to leave Purdue, so I decided not to go there just for him and MIT was attractive and I was accepted there, but I finally settled on Stanford and my thesis advisor was Tom Binford who is well known for doing computer vision stuff and he was in the computer science department. I was always an electrical engineering student, but doing my research in CS department."
"John Craig","Interviewer","Were you in EE in RPL as well?"
"John Craig","Interviewee","Yeah, I was in EE at RPI and at Stanford and so the robotics lab at Stanford was this wonderful place at that time. It had just a few years earlier been off campus and there are a lot of these stories from the real old days at Stanford AI lab when it was off in the woods near Stanford. You might have heard some of those stories. When I got there it had just moved to campus. It was in the basement of the computer science department, so it was a bit more mainstream, but there were all these fascinating characters there and That is where I also met Oussama Khatib. He just came as a post-doc at the same time I started at Stanford and Ken Salisbury was there. He was a few years ahead of me, so he was working on his thesis and I got involved one of the first things I did there was work with Ken Salisbury on his three-fingered hand that he had built, tendon-controlled hand, and I helped Ken write the software that controlled the hand and we got the fingers to wiggle for the first time and all that stuff. That was a lot of fun and Ken was a great guy to work with and learn from. He was a mechanical engineer, so I was starting to learn through osmosis more about mechanics. I was pretty much on the control side of things generally. And the other thing at Stanford at that time they had their robot control language and they were rewriting it from some old assembly language into I think Pascal or something back then and I was rewriting all the control side of that and that was code that originally Bruce Shimano had written and Lou Paul had worked on and other people. So I was pretty involved in all of that and then let us see. What happens next? At Stanford I took the introductory robotics course like everyone else did and Professor Bernie Roth was teaching that and he was a fun guy to learn from. So I got to know Bernie and I would just take that class every year even though I had already taken it for credit, just sit in it. I was also fascinated with seeing how someone teaches robotics and how one puts that material out, so I had this sort of growing interest in education and how you write about the stuff and how you teach it and how you make it interesting and what it is is a subject made up of some mechanics and some control theory and some electronics and some computer science and so it is kind of a neat thing and I like the way Bernie taught it, so I had go listen. And then there was this "
"John Craig","Interviewer","Sorry, how did he teach it? What was different about ?"
"John Craig","Interviewee","Well, I guess Bernie's a lively guy from New York originally and talks with his hands a lot and is just a kind of crazy guy and fun to listen to and I always remember some other students in the back room would go, Oh this guy makes me nervous, because they were like laidback Californians and they thought, Oh this guy makes me nervous to watch him teach, but for me it was like great and made it exciting. So it was just kind of more of the human side, I think, that you felt Bernie's humanity and you enjoyed being in his presence. I certainly always did and so there was this fateful day when I heard Bernie was going to go on sabbatical the following year, like maybe 1983 or 1984 and I said, Oh who is going to teach the course when you are gone? and he right away said, Oh you could, and I went, Oh, and I was kind of but I said yeah right away. Okay, yeah. I will teach the course. And the course was kind of a big deal. There were like 80 students in the classroom and it was televised out to Silicon Valley companies. There were like another 80 watching it out there, so it is a pretty big deal and graduate level course Stanford and I had never taught before, so I was sort of a little bit terrified and I had nine months before it started the next year, so that is actually what led to me writing this textbook on robotics because I thought okay, if I am going to teach this, if I hand out written notes at each class, I will know the material cold because I wrote the notes and that'll help me get through this adventure of teaching this thing. The only book at that time was really a book by Lou Paul and That is the one Bernie had used. So I drew on that quite a bit when I wrote my own book, but That is what I did. I wrote a chapter it was a ten-week quarter at Stanford and I would give a chapter out each week for the class and so that became the ten chapters of the first edition book. Later it went up to 13 in the second edition, but so I taught the class and that got me kind of into teaching and as I said I was fascinated with how one teaches this stuff and wanted to try and do that well. And it was right I think now this is 1983-1984. Robotics is pretty hyped up. Like I recall at that time there were several covers of Time magazine about robotics and it is going to take over the factories, it is going to make all of our cars cheaper, and it would not be weird at Stanford in the robotics lab to see someone you would recognize like a national newsperson coming in to try and interview people and I got interviewed once by I think John Stossel or some of these characters that were cruising around and so it was really hyped up and so I was just teaching this class, minding my own business with the notes and book publishers started showing up saying, We had like to get your notes and make a book, so I was flattered and I had not really thought of writing a book prior to that. By the end of that quarter I had 13 offers to publish the book. I do not think they would fight over a robotics book these days like that, but this was the good old days. There were not many books and it was hyped up and so I finally signed up with actually I called Addison Wesley and I said, Hey, I have got 12 other offers and you guys have not shown up. Because I talked to some professors at Stanford and they said, Oh Addison Wesley's the best company to work with, so I called them. I was getting cocky and so Addison Wesley showed up and took me to lunch and I signed with them and they published the book and so that was a long and then it took another couple years to turn the notes into a book, so the book came out in 1986, about the same time I graduated Stanford. So the book was a big deal and a lot of work and then it did turn out well, which is good, because I guess you can work just as hard and have a flop. The book in the late 1980s and into the mid-1990s had something like 80 percent market share for people teaching robotics. And then everyone else started writing books and there got to be a flood of books and probably the market share is down now. I do not actually know what it is now, but it is still going. it is in the third edition, so that was a good experience writing the book."
"John Craig","Interviewer","How was your book different from Lou Paul's book?"
"John Craig","Interviewee","Well, interesting. Lots of little things that might be too nitty to get into, but I was definitely the thing That is interesting about the book and it might be wrong for some people is that I was trying to teach this thing in ten weeks and so we do all of dynamics in one week and we do all of control theory in one or two weeks and crazy stuff like that. Now at Stanford there is a three-quarter sequence for dynamics. If you really want to learn dynamics, you study it all year and it is hardcore stuff and I wanted a way to teach everything in this class even if you had no background in mechanics when you started. So how do you teach mechanics in a week? And so I did it in a way That is just totally tied into and amenable to a serial chain of links which most robots are and if you kept in that little domain, there was a way you could formulate dynamics and that way you could make it understandable within a week and it built on the previous week which is about this thing called a Jacobian matrix that is all about velocity analysis of robots and that also was the way I did it was all based on the serial chain nature of the linkages and so if I did it just right, I felt I could teach velocity analysis in one week, dynamics the next, and people could follow that had basically no background. So and the book mirrors that. So That is what I think I was proud of. Again my interest in how you teach these things and how you make it through and actually Bernie Roth would always tease me that he would say some sort of backhanded compliment like, When you take a classroom, John, at the end you think you have learned something. Because I had a way of sliding stuff in, wrapping it up and getting these things across I think and then the next week the students realize, Oh, I do not know how to do anything in dynamics, but you know. So the book was that was what I was trying to do with the book, make it coverable in ten weeks and cover all these things and it was also sort of a computational book because back at that time I was writing robot software control codes and working as a consultant. In those days you could get these high-paying jobs in industry just because you could do kinematics, which again these days you can not do that. So the book is also very mechanistic like if you really wanted to sit down and write your own robot control language, you could do it by going through the book. I mean the book is not just sort of theoretical like there is some way to make this thing called Jacobian. It shows you literally here is how you write code to make it Jacobian. So those are some of the things the book hit on. "
"John Craig","Interviewer","Where were most of your students from? Or do you have a feeling for what department they "
"John Craig","Interviewee","The students taking that class back then?"
"John Craig","Interviewer","Uh-huh."
"John Craig","Interviewee","I think it was something like 80 percent mechanical engineering. It was listed as an ME class and then sort of cross-listed in other departments. So and most of the book material is ME stuff and That is why it was kind of weird because I was a EE and I was working in the CS department, but I wrote this book That is kind of mechanical engineering and around this time I also switched advisors from Tom Binford to Bernie Roth. So the last couple years I spent six years at Stanford. Actually the last two or three I was with Bernie as a student and so then I was sitting in the ME department. So That is what robotics is. it is interdisciplinary and sort of mixed up and now along in there too one summer I went and worked for GM at the tech center in Warren, Michigan and the guy that hired me, his name is Steve Holland and the other fellow there who was Bob Tylov was my direct boss and they were in a way mentors. Not so much in the technology side, but sort of American industry and big auto and what is going on with robotics there and Steve Holland is still at GM and that might be someone interesting to talk to and so I was just there a summer and I basically I think they were hoping to hire me long term afterwards, which in the end did not happen, but so they were very nice to me. They sort of bent over backwards. I said look and that was just before I was going to start teaching in the fall and I said, Look, I am really working on notes for this course I am going to teach at Stanford, and they said, You can just work on those notes. Just come here, sit at GM, but work on those notes. That is kind of what I did and I wrote a paper along the way and a paper on adaptive control stuff. So that was one little experience at GM and then back at Stanford and so then I was working on the thesis, so my thesis work at Stanford was on adaptive control of robots and there was a bit I had done at GM, but there was a different bit that I mostly did at Stanford and stuff I am pretty proud of too. it is really to get a thesis at Stanford you have to do something kind of heavy and mathematical. At least That is what I thought at the time and so That is what I did, so this was the most sort of advanced mathematical stuff I did as far as pushing myself, but it was all good stuff. It was a control scheme where the robot was controlled utilizing a full dynamic model of the dynamics of the robot and it would learn the parameters that appeared within that model and that was different than there at that point had been a hundred papers written on adaptive control of robotics, but what was different is a lot of the authors said, Oh the dynamics of robotics, it is too hard. They throw up their hands, so we can not possibly compute it; we have to just kind of adapt for it. But that would usually lead you down a road where you would get a low performance control system. It was trying to adapt and keep up with every time the arm changed configuration to get effective inertia as each joint is changing. So they were just trying to keep up with all that. The better approach that I was doing was I had a structural model. I said okay, I am not afraid to compute the whole dynamic model of the arm. I know the nature of the structure of that model. I just do not happen to know what the massive link to is or what the friction in Joint 3 is and so what I was identifying were fixed numbers as the arm moved. I was not trying to update numbers changing with configuration and I think that gets you to a way That is more performant and also fits into some other control ideas that were going on at the time, the model-based reference control ideas. So That is what I did for my thesis and Addison Wesley then, they were all thrilled because the book did quite well. They wanted to publish my thesis, so they published my thesis as a book called The Adaptive Control of Manipulators, and that, unlike the main book, sold like 500 copies. It would only sell to weird guys at universities, whereas the book sold a lot more to general students. So we did that and to implement my adaptive control ideas, I asked Brian Carlisle at Adept Robotics, Could I come over to your place and use one of your robots and do this? So he said yeah. So I went over to Adept and worked there in evenings and broke one of his robots once. He was not too happy, but it is research science. So I did that over at Adept and then so I knew Brian for years. I had met him earlier at conferences and around Stanford. So he was a mentor in a way too and then he'd show up later in my life again after that. So then let us see. I guess I graduated from Stanford and what happens right around graduation time is the folks at Berkeley invited me to come up and give a talk and so I went up and talked about my thesis and one of the fellows in the audience is this guy named Stephen Boyd who is now faculty at Stanford actually. He was just finishing his Ph.D. at Berkeley and he is like a control theory guy and he sort of spotted an error in my mathematics of my thesis which he told me about sort of during the talk, so it was sort of frightening, but he said but everyone knows a solution to this problem. it is been published in literature how you fix this little flaw, so We will show you after your talk. So they helped me fix that. That was kind of neat. So I got to be kind of buddies with him and some of the Berkeley folks and a few days after I gave that talk, Berkeley called up and said, Hey, we have got a faculty slot for you here, and so I was sort of flattered. I really was not planning to go into teaching. I was planning to go into industry. Had some buddies, we wanted to start a company in Silicon Valley, but I was so flattered that I said yes to Berkeley and then there was about a six-month period where I am finishing my thesis at Stanford and telling Berkeley I am coming, but as that went on, my buddies in industry kind of talked me into just going with them. we are going to make a million dollars with this startup company in Silicon Valley, so sheepishly one day I called Berkeley and said no, I am not going to come after all. And so that was a hard decision because that would have been a nice path. So there is a fellow at Berkeley named Ron Fearing who is there now. He was from Stanford also. He basically got the slot that I left open. So I hope he appreciates that. he is there now with tenure and having a great life. So and so then we started a little company called Silma, S-I-L-M-A, and it was one of these it was like the first company that made 3D simulations of robots in factories so you could program them offline in the virtual world. They did not call it the virtual world back then, but That is what we call it now I guess. So simulate robots, get them all working in the computer and then press a button, code goes down to the real devices and they do the same thing on the factory floor. So we used CAD models of cars and teach robots how to spot weld without tying up the factory. So it was the next way to program robots because back at that time, and I still kind of think it is true, I used to say the world does not need a robot That is twice as fast or twice as strong. It needs a robot That is twice as easy to program because robots were not living up to the promise because to put in a robot to replace a worker you would have to hire a higher-cost programmer to get it to do its thing and so it was not sort of working out economically. So I think the action is in like sensors and software programming systems, make them easier programming more tied into CAD and other factory automation stuff. So That is what we tried to do in a little company. The little company went along for ten years and then got purchased by Adept eventually. So we became a division of Adept and That is when I sort of hooked up again with Brian Carlisle and he was a great proponent of sort of pushing the technical side of robotics in the industrial world. Because the industrial robot companies, some of them were pretty stodgy. They were coming from machine tool building background, but Brian was always forward thinking and trying to get things like force sensing into the real world and so forth. "
"John Craig","Interviewer","Who was with you at Silma?"
"John Craig","Interviewee","I am sorry?"
"John Craig","Interviewer","Who was with you at Silma?"
"John Craig","Interviewee","At Silma the main technical guy was a fellow named Chris Goad who was a Ph.D. I guess he was a Ph.D. from Cornell. He came to Stanford and did a post-doc, so I met him at Stanford as a post-doc and he is the sort of computer science genius guy. I mean if people ask me who have I worked with who I think is a genius, he is the first guy that comes to mind and not too many others, really. Because he was just he invented this new language that we used at Silma called Sil which in retrospect, bad idea to invent your own language and base a company on it, but it was basically Java before the guys invented Java and it was kind of part of C++ before C++. Kind of he was one of these guys that if he'd been at the right place, he was a contemporary of the guys that invented C++ and Java and he was their equal or better and so he made this thing called Sil. We just used it in our little automation company and it was a lot of fun and I learned a ton about computer science by working with him, but so yeah and then that became part of Adept and Adept was Bruce Shimano, Brian Carlisle, so I worked with them for seven years and then eventually left Adept and this is almost up to the real time now and just a few years ago and then Bruce and Brian actually left Adept as well and they have a new company called Precise Automation now. So I left a little bit before they did, but there were some things going on at Adept that made us all leave. So That is the quick synopsis."
"John Craig","Interviewer","What do at Adept? What kind of projects?"
"John Craig","Interviewee","Well it was always in the context of trying to do this offline programming system in the virtual world and the thing was it is hard enough to program a robot and That is what we were trying to conquer, this problem to make it easier to program a robot. it is hard enough to program robots when you have got it there and you can understand the 3D geometry of how it is got to reach around this thing to get the spot weld in here. When you are trying to do it on a flat computer screen, it is not necessarily easier. it is almost kind of harder, so we are trying to make this somehow easy, but are we getting there? So I was focused on how to make this stuff easier and so in the end at the Silma division of Adept, I worked on a product called Rapid because it was supposed to be so rapid to install automation, called Rapid, so and there was just a lot more it was kind of object-oriented and things in the little simulator world knew how to do certain things. You could take conveyor belts and kind of snap them together and parts would know how to flow onto them. We could simulate vision systems and parts knew how to tumble because some part feeding things have parts tumbling and they come up from different so-called stable states and the vision system looks at them. If They are right-way-up, the robot can pick them up and I should say this is when I worked with Ken Goldberg who is now at Berkeley. He came out. He actually lived in a crazy trailer parked on our property up in the mountains for a while as we were collaborating. He had an algorithm that would compute stable states of parts and so I put that right into this thing called Rapid that I had built and we could simulate that. Also there was a lot of knowledge in the parts and how conveyors could snap together, how parts feeders could produce parts and all these things and then in the virtual world you could kind of snap these things together and press go and it would all start running. It was very easy-esque compared to some sort of tedious programming you might do and then the thing that people found out about programming robots in factories is there is probably like ten percent of the code has to do with robots moving and picking, what you think of as robotics, and 90 percent gets to be controlling all the peripheral equipment and recovery of loops. If an error happens, how do you back up and when do you signal the human to come fix it and when do you schedule the parts to get reloaded and all this sort of ancillary stuff. So if you are just focused on traditional robotics and motion programming, you are missing where all the difficulty is. So we were trying to address all that and That is what I mostly did at Adept after they bought Silma and with Ken."
"John Craig","Interviewer","What kind of stuff were you working on at JPL and how did you wind up at JPL?"
"John Craig","Interviewee","Well JPL, That is when I was first looking for a job in robotics and I interviewed at places. I remember a famous story. I interviewed at Procter and Gamble in Cincinnati. They were getting robots to work in the factory line and where they were actually automating their line that made tampons and there was a problem with the string not being the right length or something and they wanted to have a vision system in robots and I just thought, Do I want to devote my life to working on tampon production? and at the same time I have got this offer from JPL which is like research, NASA, robots in space. Okay, I am going there. So I went out there and the first big project was the hybrid position force control and someplace there is a video I think Oussama will have it of a robot sort of shakily dragging a pin across the surface and putting a pin into the hole. That was the big thing back then is robots were good in free space like spray painting cars, but if they had to touch things and impart forces on things, they would just break stuff. So we wanted for a robot to put a pin in a hole or a bolt on a nut you had to feel forces and not let them jam up. So the big famous experiment was I got this robot to put a pin in a hole and we had one hole with a big that was easy and one with no that was harder and the robot could do that and there is a video of that somewhere and That is from like 1978."
"John Craig","Interviewer","What kind of robots were you using for that?"
"John Craig","Interviewee","That was a Scheinman arm. He had I think at that time there were just three. There were two at Stanford called the blue arm and the yellow arm and then there was one at JPL which was a longer one that was kind of special and it was built on the front of a rover. This was the group at JPL which is the great ancestor of the group today that sent the rovers to Mars. Back then it was like a car-size rover with this Scheinman arm on the front of it that could reach down and pick up rocks and stereo cameras and vision stuff. So most of the group was doing like rover stuff and vision and there was just me and Marc working on the arm, Marc Raibert. "
"John Craig","Interviewer","Who else was in the group?"
"John Craig","Interviewee","Well there were these vision guys, Bob Cunningham and Ray Eskenazi. I do not even know where they are these days. Those are the guys I remember. Well Tony Bakesy who is a well-known guy was at JPL at the same time. There was a second there were two groups at JPL. There was the autonomous robot group which I was in and then there was like the teleoperator group and Tony Bakesy headed that group and he had done some great work in dynamics and things that we all knew and he was one attraction for me to go to JPL because I had already heard of him and he had a group. Each group was about 12 people I think and they were sort of sister groups there and let us see. What else was I just something else. I can not remember it now. Something else. Oh, I was going to say going way back to RPI, I did undergraduate and then I did a fifth-year graduate thing so you can get your Master's after five years. There was a project way back then funded by JPL NASA at RPI for a Mars rover and at RPI there might still be some lore around about the Mars rover project because it was kind of well known back then, 1976-77, that era, and it was this kind of four-wheeled vehicle. We had take it out and drive around the campus of RPI. It was amazing because it was kind of before there were like PCs and microcomputers, so it was all threaded, boarded, hard-wired chips to make our own computer effectively and it had this laser rotating each side of the mirror and collecting data and looking out for obstacles. So it was an early example of something trying to pick its way through a boulder field and I worked on that a little bit when I was a junior and then when I was in my fifth year I was in charge of like the electronics side of that thing and there was a professor named Steve Yerazunis who headed that and he was a good sort of money raiser and Yerazunis got funding out of NASA JPL for this rover and That is how I eventually knew of JPL and got an interview with JPL because I had worked on the rover they were funding at RPI and that rover is featured in one episode of this TV show called Cosmos that Carl Sagan did and this was a cool thing when we were Master's students at RPI. Two of us got to go out to Death Valley with the machine because we had to remotely from off camera and keep it going and Carl Sagan was there and he filmed this episode where it looked like he is on Mars and this Mars rover drives around and That is the rover I worked on at RPI and I met Carl at the salad bar in the hotel and he started talking about how it is interesting that biological systems never evolved wheels because it is hard to get blood vessels and things through a continually revolute joint, so maybe rovers should not have wheels; they should have legs. And so that was cool. I got to meet Carl and then Marc Raibert at JPL who hired me essentially and I worked with on force control, I mentioned my second year at JPL I kind of worked with Carl Ruoff in programming languages. Raibert got interested in hopping machines and started working on hopping machines and I remember going over to his house one day for a picnic and he has a pogo stick and he is like hopping around in his backyard and he says, Oh it is just something I am working on, and he would not tell me in the very beginning what was going on and I thought he was just acting nutty, but then he got into doing leg locomotion and hopping and was at CMU for a long time and the leg locomotion lab was his at CMU and I think he then started a company called Boston Dynamics. he is at MIT now part time . So yeah, that is another piece of the story there."
"John Craig","Interviewer","So what did you do after Adept?"
"John Craig","Interviewee","Well, after Adept I worked for well, let us see. Yeah, as Adept winded up, I worked for a small company called Invenios in Santa Barbara and it is kind of a robot company. They make little, tiny, very high-precision they make a little stage that just moves in X and Y and its total range of motion is like two millimeters, but it can do it to like 30 nanometers or something, so crazy precision, and I worked specifically on encoder technology to measure where this thing was and I actually designed an encoder which is pretty cool that uses a lot of old-fashioned encoders are sort of resister ladder networks or just sort of fixed. Our encoder had a DSP in it so it was programmable and we could do all kinds of fancy compensation and it could learn and improve its performance over time and sort of adaptive control was always my thing since the thesis. So we made these high-precision encoders that put out a million counts per revolution and could tune themselves up as they ran and so we did that sort of for little robo-like things, stages. Actually that encoder got sold off to a company that built two degree of freedom camera positioning systems for security systems actually outdoors in parking lots to look around for criminals or whatever. So it was kind of robotics, but it was more encoders, encoder technology."
"John Craig","Interviewer","Do they use that for chip manufacturing? "
"John Craig","Interviewee","They did not."
"John Craig","Interviewer"," kind of nanotechnology?"
"John Craig","Interviewee","Yeah, a lot of the other all these little fine automation stages that they built, another part of that company's business was they had it is called photostructurable glass, so it is a special glass that has been doped with chemicals and if you shoot a UV laser at it or the UV hits it, it changes the glass into kind of a ceramic and you can then very precisely draw patterns and you can make things like the optical disk portion of an encoder, so we would build the glass disk part of the encoder with our own technology and then marry it with the firmware that I wrote the DSP and We had make this incredible encoder. But they got into making all kinds of things out of glass at a very small scale. So they would call themselves a nanotechnology company, although it was not quite nano. It was more like micro, but further where the glass was hit and turned into ceramic, if you then etched this glass in hydrofluoric acid, it eats away the ceramic part and leaves the glass. So you could actually make things with little tiny channels in them and there is a way that you can holes and different things so we could mix in little micro fluidic devices and so when they sequenced the human genome, at least one of the ways they do that, they have a little glass plate with all sorts of things and little channels running around and our company made that plate. So that was our big sort of claim to fame and made a lot of money from that. So the encoder technology and everything was sort of in support of putting a piece of glass on a positioner with a laser pointing at it and then moving the of the laser to draw these patterns. It was actually at that company I wrote a whole robot programming language, once again, which was to control the laser and the robots and to do all this stuff and make it easy to program interpret the language. See, what was that called? It was called IRS, Invenios Robot System, and we had vision systems, cameras looking through microscopes to check if things were in the right place and it was quite elaborate, several axes. They also, that company built a six degree of freedom robot with very tiny actuators and a parallel mechanism with three legs coming up and it could manipulate things over a workspace of just a couple millimeters, maybe plus or minus 4 millimeters and plus or minus 30 degrees, but they did very fine positioning of optical fibers that had to be aligned with an LED or something and then bonded and that was so a six degree of freedom robot was also supported in my robot programming language along with all the stages. So I worked at that company for about, I think, six years. And then just a year and a half ago left them and now I work primarily on software for radiographs of animals. So if you get your cat, dog, or horse X-rayed by a veterinarian, it is possibly using my software. So I am now doing image processing stuff to present the best looking image and markup measurement tools, calibration things. So it is kind of veterinary radiology and then I help my wife with her company which is a plastic horseshoe company, so it is polyurethane horseshoes. Better for the horse than the old steel shoes and so we have these two little companies going. So I am sort of an entrepreneur and still writing software these days."
"John Craig","Interviewer","And as somebody who is written a lot of—"
"John Craig","Interviewee","Coat away on and then I used all his stuff in Miami product. Also yeah high school robotics was probably not considered cool, I was the kid with the robot ever since I see actually what happens we ."
"John Craig","Interviewee","There were two science fair projects we had to do that year, had to one like the first half of the year and one at the end of the year and as soon as the teacher announced that at the beginning of the year I said I am going to make a robot, this is my chance to make a robot like my older brother had. But I knew that it was going to take all year to do that. So I said okay I need something for that first project. So I made this lameoid thing which I got an A on because the teacher did not know that I was a budding robotics genius and so he gave me an A on that and then at the end of the year I bring in this robot that of arm, could walk, could follow a light beam, could talk a little bit, could do some of these things and it blew the teacher away and blew everyone away and then I was the kid with the robot. That was not necessarily a good thing to be the kid with the robot but yeah."
"John Craig","Interviewer","It turned out well in the end."
"John Craig","Interviewee","It worked out, yeah. Well up until then actually I was in high school, I thought well maybe I am going to be a playwright, I wanted to write things and maybe I will be a psychiatrist and all kind of crazy ideas but the robot thing I stuck with the whole year, every day, go down the basement and work on the robot. That is when I decided okay this stuff is not going to jazz by itself, so maybe it makes sense to do this for a career."
"John Craig","Interviewer","What were some of the important conferences that you went to and how they changed through time?"
"John Craig","Interviewee","Conferences, well let us see, the big one was the IEEE Robotics and Automation Conference and that was kind of a thing each year you wanted to go to, one to try and get a paper ready for. So that was certainly I went to that many years in a row because I worked sort of on the control side there was a conference called the ACC American Control Conference and the paper Ken Salisbury and I wrote about the hand, actually won the best paper of the conference award, so that was memorable and then there was this International Journal of Robotics Research that started up and they had a by invitation only sort of symposium thing they did each year and so when I first got invited to that that was good, like I had made the inner circle and that was actually held I think right around here in Monterey once. So those are the ones I remember, IEEE, ACC and International Symposium on Robotics Research."
"John Craig","Interviewer","How would you define a robot, do you think that the notion of what a robot is has changed?"
"John Craig","Interviewee","Well what I guess my standard answer to that and this is to back in the day I wrote the book, so maybe it is changed now a little bit but it is always been a gray thing, it is always been some sort of programmable machine, so basically it is a programmable machine but I think when you cross the line between it being hard automation and being a robot, just has to do with how sophisticated that programming is and certainly if the thing has a sensor on it, you can do something based on the sensor then that probably crosses the line and it is a robot. But it needn't have a sensor, I think to be called a robot, if it is programmable and it is a machine that moves around a bit then I say it is a robot. But there is this fine line because back in the day there were all sorts of fixed automation being driven by PLCs and I would not call those robots, They are just two sort of hard coded and too simple in the software aspect of it. So That is my vague answer."
"John Craig","Interviewer","What where you see robotics going in the future, what do you think are going to be some of the important challenges?"
"John Craig","Interviewee","Well I still think and this has held for about 20 years now or so that the name of the game is trying to integrate sensors fully and integrate them in a way that makes robots easier to use. You have to program to tell the machine what to do and for it to do its job and probably to do it in a way it is not too tedious as far as how we have to explain what it should do, it needs to use sensors and make some local decisions on its own. So I think the name of the game as I mentioned before, robots do not have to be twice as fast or twice as strong, they have to be two times easier to program and get them doing useful work and I think the lynch pin to that is the successful integration of sensors when using that. So I am really fascinated by some of the work on manipulation, the guys that really like Nat Mason is one of the original guys doing a lot of this thinking how robots feel things, how they can push, slide and just manipulating the 3D physical world and how they get good at that and then early on I thought well our only hope is to make some sort of adaptive or learning component to it because it is going to be too hard for us to teach them everything about how to be a being in this world, they have to learn it on their own kind of thing. So I think that area's still ripe for progress and is still the right thing to be working on, sensors, ways to program them, ways they can learn it on their own, all aimed at making them easy to use, that'll bring down the cost of using them and then they will do more things for us."
"John Craig","Interviewer","You seem to have worked closely on industrial kinds of robots, so now there is a lot of discretion of having robots in even more unpredictable spaces like the real outside world, outside of labs, outside of factories kind of with regular people and regular spaces, does that ?"
"John Craig","Interviewee","Yeah I think That is crazy hard, I mean getting robots out of factories and things is really challenging, so it is fun to see people trying to get that to happen. In my point of view it is still so hard to make it happen properly in factories when you have got a controlled environment that wow to try and take them out and put them in an old person's home to help them or something like that is a big challenge, so yeah I think That is the way it has to go but it is one more it is harder than what we used to do, back in the day. Nice structured environment in the factory, life's easy, life's good, you can do it."
"John Craig","Interviewer","you are right, ?"
"John Craig","Interviewee","Right, yeah Mark Raybird got military funding for his hopping robots because wheeled robots can not like run through jungles necessarily, so they wanted to build the hopping robots that could hop over downed trees and all this sort of stuff. he is going crazy, unpredictable things, but those robots needed to be mobile and hop around and get through strange places but all they did in the end was probably surveillance. But you can imagine that could work. Trying to have robots do that stuff plus be dexterous and be able to interact with things and do physical tasks That is really getting tough."
"John McCarthy","Interviewer","Tell us where you were born and grew up and your early education."
"John McCarthy","Interviewee","Okay, go ask them. Boston. "
"John McCarthy","Interviewer","And where did you start your education?"
"John McCarthy","Interviewee","In Boston public schools. "
"John McCarthy","Interviewer","Where did you do your undergraduate work?"
"John McCarthy","Interviewee","Caltech."
"John McCarthy","Interviewer","And what did you study there?"
"John McCarthy","Interviewee","Mathematics. "
"John McCarthy","Interviewer","When did you start to become interested in artificial intelligence?"
"John McCarthy","Interviewee","In the fall of 1948 there was a conference at Caltech called Hixon, H-I-X-O-N, Symposium on Cerebral Mechanisms and Behavior and they compared the brain and the computer and it gave me the idea of using computers for to behave intelligently and many years later when I got the Kyoto Prize and was asked that my lecture be autobiographical I went back there to look up who had talked about using computers to behave intelligently and discovered that no one had. That I had simply jumped to the conclusion that people were interested in that."
"John McCarthy","Interviewer","Both John von Neumann and Warren McCulloch were at that symposium, do you recall hearing either of them?"
"John McCarthy","Interviewee","Well, I have had subsequent interaction with von Neumann. I never had any personal interaction with McCulloch. "
"John McCarthy","Interviewer","And was that interaction on theory of computation or automaton theory? "
"John McCarthy","Interviewee","No, on artificial intelligence, but so this was in 1948, I had just graduated from Caltech in mathematics and spent an additional year at Caltech as a graduate student and then I went to Princeton as a graduate student in mathematics and when I went to Princeton, I went to see von Neumann at the Institute for Advanced Study and told him about some ideas that I had had. And he said, Write it up, write it up. And after just a little bit of further consideration, I decided that the ideas that I had explained to him were not very good. So, I did not write them up. I should have, but because they were reinvented by other people or at least some of them were. And my judgment that they were not good ideas, they were probabilistic model of automaton connected to a brain. And the problem with it was that there was no way in that model of putting particular facts, that is of the braining learning particular facts or representing the brain having learned particular facts and so that was 1949. And it was 1958 before I could write a paper in which I did discuss how to make the brain learn particular facts such as representing facts and mathematical logic. And that was a paper called Programs with Common Sense and I think that did play an important role in starting off the field of logical AI. "
"John McCarthy","Interviewer","Did you continue your conversations with von Neumann on these topics?"
"John McCarthy","Interviewee","No, I did not which was dumb of me. When I organized the Dartmouth conference on artificial intelligence I wanted to invite von Neumann as a participant but he was already dying. I kind of doubt that he would have liked my subsequent ideas because Newell told me about his negative reaction to Newell's ideas on the chess program. And was not quite the same thing but it allowed me to feel that, of course this is many years later, that he might have had a positive reaction to my ideas. "
"John McCarthy","Interviewer","What was his objections with the chess program?"
"John McCarthy","Interviewee","I do not know. Maybe Newell told me and I do not remember or maybe Newell only had it second hand, that is Newell was a consultant to Rand Corporation and so was von Neumann and maybe von Neumann discouraged the Rand Corporation from supporting Newell's work in that area which is bad advice which Rand Corporation fortunately did not take. "
"John McCarthy","Interviewer","So what led you to organize the conference at Dartmouth? "
"John McCarthy","Interviewee","I am not a very good organizer, but I have quite good initiative in deciding that something should be organized. And previously, I got together with Claude Shannon and we sent out invitations to contribute papers to something that later was published as Theory of Automata. I think that was it. Maybe it was published as Automata Studies, anyway it was published by Princeton University Press in the Annals of Mathematics Studies. "
"John McCarthy","Interviewer","And did you know most of the contributors before you issued the call or did you meet them through the process of the conference and the publication?"
"John McCarthy","Interviewee","I think I knew less than half of them. Now, I knew Minsky because he was a fellow graduate student at Princeton, but in general I did not, unlike Minsky who has a big talent for knowing everybody, I do not have that talent and when I was at MIT, I never went to see McCulloch although I should have. And actually, attempted to avoid Norbert Weiner because, having read his book, I did not think he would like my ideas. "
"John McCarthy","Interviewer","The cybernetics book?"
"John McCarthy","Interviewee","Yeah. "
"John McCarthy","Interviewer","Why did you think your ideas were not compatible with his?"
"John McCarthy","Interviewee","He was wedded to the idea of direct feedback and mathematical feedback in the sense that there was numerical measure of the difference between where you were and where you wanted to get to. And my ideas were quite different, were interested in logical deduction from facts that you had about how to achieve a goal. Now you could put that in a pseudo-cybernetic form but neither I nor anybody else ever did. I talked about it from time to time but never did it. Now cybernetics was very popular, particularly in the Soviet Union as soon as they were allowed to stop attacking it. As long as Stalin was alive, they had to attack it. "
"John McCarthy","Interviewer","How did you meet Claude Shannon?"
"John McCarthy","Interviewee","I spent the summer of 1952 at Bell Labs. That was after I got my Ph.D. in 1951. "
"John McCarthy","Interviewer","What was your Ph.D. thesis on?"
"John McCarthy","Interviewee","It was on solving differential equations by projecting between a space of gradients and a space of vector fields that satisfied an algebraic condition. "
"John McCarthy","Interviewer","When did you arrive at MIT?"
"John McCarthy","Interviewee","What?"
"John McCarthy","Interviewer","When did you start at MIT?"
"John McCarthy","Interviewee","Excuse me?"
"John McCarthy","Interviewer","When did you go to MIT?"
"John McCarthy","Interviewee","When I got my Ph.D. I stayed two years at Princeton as an instructor then I went to Stanford and after a year, Stanford decided they had three acting assistant professors and they keep two of them and I was the third and I went to Dartmouth. And then IBM set up the New England Computation Center and it was physically at MIT and a third of its time went to MIT directly and a third of its time was available to New England colleges and I ended up being the Dartmouth representative on that. And somehow, I picked up computing very fast. That was because I had a spent a summer at IBM, summer of 1955. "
"John McCarthy","Interviewer","And what kind of projects were you working on in those years between 1951 and 1955?"
"John McCarthy","Interviewee","Still most of my time was in pure mathematics. And in my opinion, considering pure mathematics, which is what Stanford did, and they made quite reasonable decision in deciding they'd keep the other two guys and let me go. Partly that was because while I was a pure mathematician I tended to be distracted by thinking about AI, but at that time not really getting far enough in my major ideas to publish. I only got that far in 1958."
"John McCarthy","Interviewer","Now when did you start actually programming computers with what you considered to be AI?"
"John McCarthy","Interviewee","Well, the first thing I did was start to write a chess program which I wrote in FORTRAN and I wrote the easy part, which were the legal move routines and so forth and then I was stuck on the main strategy and dithered about that, but I turned the program over to some MIT students, undergraduates, who completed it and they first completed it for the IMB 704 and then redid it for the DEC PDP-6 and they called it in, in their version, Mac Hex 6. But I noticed that it still had even in that PDP-6 version a lot of my symbols in it. "
"John McCarthy","Interviewer","And why did you choose to do a chess program? "
"John McCarthy","Interviewee","What?"
"John McCarthy","Interviewer","Where others were talking about mathematics of chess?"
"John McCarthy","Interviewee","No, it was actually about the second program that played a full game, the second American program played a full game. I do not know when the Russian program came along but it might have been a little earlier. Turing had all the ideas even earlier, but never had sufficient computer access even on computers of which he was the main person who designed. Now I had a new idea or at least it was new in the West, the Russians also invented it independently, although I was first. At least their paper on it was 1963 and I was haranguing people on it in probably even in 1956. That was the alpha beta heuristic, but alpha beta heuristic was complicated by thinking of optimistic and pessimistic evaluations. So, the fact if you gave up that notion and just took a simple evaluation, the fact that it gave the same result as Minimax was discovered by Mike Levin and Dan Edwards who actually wrote a paper on that fact. The person who disentangled who did what was Don Kunoth who wrote a paper for artificial intelligence in which he interviewed people, but I was the first person outside of, no, I think I was the first person to try to identify that was a kind of separate thing. Arthur Samuel had something like it in his checker program, but he never sort of picked it out as a separate intellectual object. "
"John McCarthy","Interviewer","When did you come to understand that AI would become a field of its own?"
"John McCarthy","Interviewee","Well, okay in one sense you can say on particular date which was August 31, 1955. No, maybe earlier, maybe 1952, I wrote this call for these papers on the automatous studies and when the papers came in, I was disappointed, too many of them were about automata and I remember having a discussion with Claude Shannon where I was interested in machine intelligence and he thought any such title was much too flashy. And so we picked this automata theory or something like that as being the title. No, actually, that we should have suggestion was made to me by a Princeton graduate student by the name of Jerry Rain which was just a purely oral suggestion made in conversation. But anyway, the August 31 was when I wrote the proposal for the Dartmouth summer study. I got three other people to go in with me on it, Minsky and Shannon and I am forgetting who else. And we proposed to the Rockefeller Foundation for a summer study where some number of people, like, ten, would devote the entire summer to thinking about artificial intelligence. And I introduced the term of artificial intelligence on that date when I wrote the proposal. I had to think of a name to call it and I called it artificial intelligence. Now, later Donald Michie used the term machine intelligence and my opinion is that that was a better choice. "
"John McCarthy","Interviewer","Who ended up coming to the conference?"
"John McCarthy","Interviewee","Well, my idea that a bunch of people would devote the entire summer to it did not work. In the first place, the Rockefeller Foundation did not give us anywhere near enough money, but the second place hardly any of the people who did come were willing to devote that much time. It was more like they were willing to come for a few days and tell us what they were doing and they would go off and do it. Now, the only people who were seriously devoted to artificial intelligence at the time were myself, Minsky, Newell and Simon and I would say Ray Solomon. Now, of these the furthest advanced were Newell and Simon. And I got the idea of this processing from them. But they used an absolutely terrible language were the IPL which they stuck with for quite a long time and finally a sea of new people switched to LISP or maybe That is not quite true. Anyway, IPL was abandoned and LISP took the idea of list processing from them and then for the form of the language took Fortran as its model. But then it turned out that to write a program for symbolic differentiation would go well if the algorithm was allowed to be the function of differentiation from first of all, if differentiation was considered to be a function applied to the symbolic expressions. And secondly, if that function was allowed to be recursive, in the sense of, in the computer science sense of calling itself. And so I think that LISP, which was introduced, or I started on it in the fall of 1958, was maybe the first language. No. That is not quite true. I think IBL, the functions could call themselves, but not through an automatic mechanism built into the structure of the language. So anyway, that was started programming LISP. But the curious thing is that I wrote a report in the beginning of 1959, in which I wanted to show that LISP was universal as a computational means, and so I wrote universal function, and I wanted to show that compared to a universal Turing machine, which took Turing about six pages to describe in his 1936 paper, was only a few lines, and LISP was functioning well. Well, the thing that I wrote down had a bug in it. But in any case, one of the programmers, Steve Russell, saw my report and programmed me that, in the sense of what we were doing then with LISP is we were hoping to have a compiler, but we did not have a compiler, so we were doing hand compiling, and he hand compiled. Alan said, No. We have an interpreter for this. And after a little, I put up a little resistance and then had to agree that Steve was right. And, okay, well, enough of that. let us go."
"John McCarthy","Interviewer","Tell me about the AI lab at MIT. "
"John McCarthy","Interviewee","Well, Minsky and I started that. Now, here is my version, which may not be entirely correct. That is that I encountered Minsky in the corridor and said, We really ought to have an artificial intelligence laboratory. And he said, that is a good idea. let us do that. And then along came Jerry Wiesner, who was the head of the Research Laboratory of Electronics. And I said, Marvin and I want to have an artificial intelligence laboratory. And he said, All right. What do you need? And I said, We need a room, and a secretary, and a keypunch, and two programmers. And Wiesner said, And how about six graduate students? And we said, Yes. And that was it. And the reason why that was it was that MIT had just received a Joint Services contract, and what MIT had done was that it had divided the prize up among various departments, and the Mathematics Department's share was support for six graduate students, but it was not clear what this Joint Services contract, would do with the six graduate students. So when Minsky came along, when he and I came along, Wiesner had a solution to his problem, and sent over his six graduate students, so somehow the resources were suddenly available. So it spoiled me in the sense that I felt that That is the model of a proposal and its acceptance. You meet the guy in the corridor and ask him, and he says, Yes. He says, What else do you need?"
"John McCarthy","Interviewer","So who were some of the first graduate students that you trained?"
"John McCarthy","Interviewee","There was David Lucketim and David Park. They were both Englishmen, and they wrote theses in pure mathematics, but they later switched to a topic they had resisted when I proposed it, which was proving programs correct. Both of them did that. A guy by the name of Braiten , I have forgotten his first name. He subsequently went to work for IBM. Now, there was Jim Slagel , but I forget whether he was one of the six, or not. He was a mathematics graduate student. "
"John McCarthy","Interviewee","In the spring of 1962, by then MIT had promoted me to oh, I had not finished confessed to double crossing Dartmouth. John Kamine , who had hired me at Dartmouth sorry, was Dartmouth's representative on this thing, and I got a Sloan Foundation Fellowship, which I spent at MIT, that is for one year. And MIT was willing to hire me as an Assistant Professor of Communication Sciences in the Electrical Engineering Department, and so gave up the Dartmouth appointment, and went to MIT. And by the spring of 1962, I had been promoted to Associate Professor at MIT, and I got, quite out of the blue, a telephone call from George Forsythe at Stanford, who asked me if I had be willing to come to Stanford, and being slightly miffed by Stanford having previously decided not to keep me, I said, Well, I have been at Stanford before. I could only come as a full professor. And I thought that would turn him off, but he said, I think I can manage that. And I was very startled, because I had been just made an associate professor at MIT, and that would be a jump in one year to full professor. And I had never heard of Forsythe before, and later on, when I looked him up, he is a numerical analyst, and he would have had no occasion to have ever read a paper of mine in the course of his work, but he had the ambition to have a computer science department, and I already had developed some reputation there. I do not know precisely what their reputation was. It certainly was connected with AI, and also with proving facts about computer programs. But anyway, MIT was willing to there was also a jump in salary associated with the Stanford offer. Now, MIT was willing to more than match the salary, which was startling to me. From nine thousand, MIT was willing to go to fifteen thousand, but they were not willing to make me a full professor right away, because they considered Minsky and me to be a pair, and could not promote did not feel they could promote one without the other. We were in different departments, and the Math Department would have had to agree to promote Minsky. So they were willing to make me Director of Research for the Computer Science Department, and so forth. But I really did like California and wanted to go back to California, so I ended up accepting the Stanford offer. I hate shoveling snow out of my driveway. "
"John McCarthy","Interviewer","So was anybody else working in computer science at Stanford when you arrived here, or was anybody else working on artificial intelligence? "
"John McCarthy","Interviewee","Well, Forsythe was a numerical analyst, and he considered numerical analysis to be part of computer science. I was the first person he hired, and then the second person was a young numerical analyst, Gene Gollen , and he launched a great campaign and eventually got Donald Knufe to come to Stanford. So Forsythe has a real talent for building a department, so we were the second computer science department in the country, and maybe in the world. Purdue was ahead of us by a few months. "
"John McCarthy","Interviewer","When were you able to set up an AI lab?"
"John McCarthy","Interviewee","Well, the students who worked for me, or one of them, who worked for me on the chess program, on Kotok, went to work for DEC, and was one of the designers of the PDP-6. And one of the ideas that he and the other people at DEC took from me, the idea of timesharing, which I had not mentioned before. Somewhere at MIT there is a big set of oral interviews with me on the subject of timesharing. But anyway, PDP-6 had in it an interrupt system designed for timesharing, and also some instructions that were suitable for LISP. It did not require much, or rather it did not make LISP much better. Without it they were half word manipulation instructions. But, oh, it did give a big advantage over any other computer that existed at the time in any country. It had an 18-bit address, and the IBM 704, and its successors, could have had an 18-bit address, but the engineers could not build such a big memory at the time, and so they designed it so that a 15-bit address was the maximum a 704 could have. And when the Soviets copied American computers, they also did a 15-bit address, but the Soviets copied the 15-bit address just about the time when IBM had decided that, no, a 15-bit address was too small, and the Soviet BESM-6 had a 15-bit address. So anyway, let us see, what is relevant here. Oh, we want to make the path to the Stanford AI lab. Well, DEC gave me, or you know, Stanford a PDP-1 computer. Oh, I had designed a timesharing system for a PDP-1 computer, and the one day a week consultant at BBN, and it was programmed by Sheldon Boyland , who just graduated as a history major. I forget from where. So the actual programming of it was a one-man effort. He never did anything else in computing after that, maybe I wore him out. Jack Dennis at MIT did another timesharing system for the PDP-1, because the PDP-1 that DEC gave MIT was more limited than the one that BBN bought, so it could not have the same timesharing system. So now the Stanford AI lab okay. I read a book called, A Study of Thinking, by Jerome Bruner, and it had a notion of concept in it. And the notion of concept was a bullion combination of elementary concepts, and I thought that was wrong, because it did not allow for relations, and they were particularly interested in vision. So you could consider the concepts of the shapes of the letters. That is, is it convex? Does it have a hole in it, and so forth. If you think of enough elementary concepts, then you can make enough combinations to discriminate the alphabet, but my complaint is it would not enable you to draw a letter. You should consider, for example, a letter that has a vertical line segment and three horizontal line segments, which point to the right from the top middle and bottom vertical, and each about two-thirds the length of the vertical. Now you can tell somebody that over the telephone, and they can draw it, and It will turn out to be a capital E. Or you can take the same thing and rotate it counterclockwise by ninety degrees, and it is the Russian letter, Sha. So my slogan was, Description not discrimination. And in particular, I pointed out that if you wanted to do manipulation, then description was what you needed of the objects that you were going to manipulate. So if you were going to do robotics then you needed description. So I asked for money for the Stanford AI lab to get a PDP-6 computer, not being satisfied with the PDP-1 computer that DEC had given me, and that I got beefed up by programs and sharing with Patrick Simpese . And so we did get this AI lab, and now I am not sure when the word, robotics came in. Now, of course, the word, robot came up in science fiction long before it came up in any science. Are you familiar with the history of that?"
"John McCarthy","Interviewer","Yeah, the topic."
"John McCarthy","Interviewee","Yeah, right. Now, I was certainly not interested in undertaking a complete robot, and it was I might not have believe it at the time, but it turned out not to be possible with the resources that we had even for just the mechanical part of it. What was possible was arms, that is to build a single arm, and that was possible, because there was a graduate student at Stanford, Victor Scheinman, who was, I would say, a real genius as a mechanical engineer and designer, and he designed several mechanical arms. He designed one. The first one he designed was a hydraulic arm, and it had, I remember, these plastics tubes that had the high pressure, hydraulic fluid in them. And it was decided, not by me. I did not do any close supervision of that, but if one of those tubes ever broke, that arm would swing and anybody who was in the way would really get hurt. So it was put into a little house that was built around it, but it was never used, and Scheinman designed some much smaller and weaker arms that were electrically powered, and those were the ones that were used by the Stanford AI lab. "
"John McCarthy","Interviewer","When did you first meet?"
"John McCarthy","Interviewee","let us see. I came to Stanford in the fall of 1962. It seems to me we got the Stanford AI lab, and our big increase in money from DARPA that enabled us to buy the PDP-6 computer, was 1965. And when I thought we needed an arm, my first idea about that was I had read about these remote arms that had been used during World War II, to handle radioactive material, and I said, Ah, that must have led to further developments. And I discovered, no. They had simply been abandoned at the end of World War Two, so that we were going to have to design our own."
"John McCarthy","Interviewer","I got DARPA to write some letters saying it really would not be a good idea if someone with her training went back to Czechoslovakia. That did not help, but what did help was that her the University of Pennsylvania, which is where she was after she got her Stanford PhD, got a congressman to intervene, anyway. Well, if you are going to interview her, she knows, I am sure, her story more correctly."
"John McCarthy","Interviewer","What was she like as a student to work with?"
"John McCarthy","Interviewee","Hardworking. She worked on vision. "
"John McCarthy","Interviewer","Who were some of the other early students that were interested in robotics?"
"John McCarthy","Interviewee","Well, there were a couple of other faculty members who did it, younger faculty members. One of them was Raj Reddy. Are you interviewing him?"
"John McCarthy","Interviewer","Yeah."
"John McCarthy","Interviewee","And Jerry Feldman. He invented this language called SAIL, which in his original naming stood for Stanford Artificial Intelligence Language. And I objected to that on the grounds that LISP was senior to SAIL. And so he said, All right, it just stands for SAIL. Well, LISP survives and SAIL is dead, so. And now I am trying to remember the student who did most of the programming of the arm. He was an electrical engineering student, not a computer science department student. Now, from a robotics point of view, let us see, there is from a robotics point of view, a key thing is that there were a number of PhD theses that were associated with what you would call today components of a robot, rather than complete robots. So there was Bruce Baumgart who now, I think it was he who wrote the one about driving the cart around the lab. We inherited from the mechanical engineering department a cart that could be radio-controlled, so we radio-controlled it from our computer. It had first been built as a prototype of a cart that could be driven on the moon, with a two-and-a-half-second delay. So it might have been an ancient prototype. The vehicle, it was driven on the moon sometimes, with the two-and-a-half-second delay. So I think it was Baumgart who did that, but maybe he did something else. Then there is a guy who did a thesis on face recognition. Who else are you going to interview? "
"John McCarthy","Interviewer","Well, somewhat later students were Hans Moravec and Rodney Brooks. we have talked to several people at Stanford , Ken Salisbury, Vic Scheinman."
"John McCarthy","Interviewee","No, I was thinking of those people the one whom I am sure would know what everybody did is Baumgart. Now, if I were, so to speak, a normal professor and had not lost bit amounts of memory through getting old, I had remember all of those names, and maybe I will remember them tomorrow, but well, the names I remember most of the names I remember, but who did which thesis. All, the topics are the cart now, the question is who did the actual programs in which the all right, there was the block-stacking program. So somebody did that one. It was then there was the assembly of an automobile water pump. That was somebody's thesis. Baumgart would know that. And then there was some speech recognition that Reddy supervised. Reddy's thesis that he had done on the PDP-1 was speech recognition. So we never made a complete robot. That is, we could have, in principle, have put the arm on the cart, and so forth, but remember that all of these things were done on a PDP-6 computer in a timesharing mode on well, it was possible to sign up for time for wee small hours of the morning, in which it would get oh, there was a complicated sign-up in which you would sign up for whams and bams . I do not think I remember that because I never bothered with it because my own use of the computer was not CPU-intensive. I never did use it for anything but typewriter, for writing papers. "
"John McCarthy","Interviewer","What would you say was the relationship between artificial intelligence and robotics, particularly at Stanford?"
"John McCarthy","Interviewee","Well, as I say, my motivation for starting the robotics was having this slogan about concepts, which is, after all, an AI idea. But I never even met Brunner, so I did not get into an argument with him. I should have, and he was there at Harvard when I was at MIT, but I did not do it. Though I suspect he I did not write a paper about that, but I suspect that the point was in my proposal to DARPA that got us the large sum of money that permitted me to hire quite a large number of graduate students in computer science and electrical engineering, and permitted us to get our own PDP-6 computer, and to keep updating it to a PDP-10 and a KA10. We also Deck gave us big discounts on the all of our upgrades. And I never really tried to figure out to what extent they were matters of gratitude for what we had done for them, and to what extent they were merely making the sale. I do not know. But they certainly did a lot of gave us a lot of credit, and they used our drawing program to write the drawings for the I think maybe the KA10. At some point, one of the guys had a project to design our own PDP-10-like computer, only much faster, and prepared the design and got sent off to DARPA. And DARPA said yes. I had a bunch of consultants look at it. They said, Yeah, it will probably work, and then DARPA decided, No, we do not want to be in that business. did not support it. Well, Park designed their own PDP-10, built it. So the robotics was, in some sense, an illustration of this argument about AI, but of course it was useful, or led to things being useful, and certainly let us put it this way: When Walter Cronkite came to interview me, I did not try to make him understand this more abstract notion of discrimination versus description. But there was quite a bit of industrial robotics already. But they were even less likely, or they were to write papers about it than the academic part. So we did, I remember, pay a visit to a Ford plant. They showed us where they were doing assembly. And also I once paid a visit to IBM, where they were doing some automatic assembly partial automatic assembly. It was very interesting there because you could see things being assembled automatically, and then there was some part of the work where it would suddenly expand out to a part where it could not be done automatically. And you had a department of 40 women doing a manual assembly of some part of it. Now, let us see. So the AI lab I think moved to campus from it seems to me in 1989, and then we had a lot of trouble getting funding from DARPA and dissolved it. We did not get the space on campus that we were promised. If you want a lot of detail, have you interviewed or are you going to interview Lester Earnest?"
"John McCarthy","Interviewer","We should."
"John McCarthy","Interviewee","Lester Earnest is the executive officer of the AI lab, and he did a lot of our interaction with DARPA and with suppliers and a lot of the supervision of projects. He had a fair amount of initiative on projects. I once remember Larry Roberts asking me what the relation was he said, Can you fire him, or can he fire you? And I said, Well, I believe I can fire him. Would you like me to try? several years when the shortage of funds became sufficiently acute, I had to do that. "
"John McCarthy","Interviewer","So what do you think AI gained from the ventures into robotics research?"
"John McCarthy","Interviewee","Well, a lot of the specific pieces of research contributed to AI the face recognition, the speech recognition, the driving the cart around the lab, the mechanical assembly and so forth. These things, they established a sort of boundary of what was relatively easy to do. Yeah. I think Earnest is the guy you should definitely interview."
"John McCarthy","Interviewer","Did you have much interaction with the people at SRI, like Nils Nilsson, and their robotic work?"
"John McCarthy","Interviewee","I guess the basic answer is no, and my hesitation is that I am trying to figure out why. Are you going to interview Nils Nilsson?"
"John McCarthy","Interviewer","Yeah, next week."
"John McCarthy","Interviewee","Now, Engelbart said something in which he contrasted his motivations and mine, and I think he misrepresented mine in order to get a contrast. He was interested in man-machine interaction, and I was interested, he said, in what a machine can do all by itself. And of course I was also interested in man-machine interaction. Timesharing was my biggest work in that area, as well as being interested in what a machine could do by itself. I remember being very skeptical of a mouse because it was one more device, having following the light pen and so forth. It took me a while to realize, yes, but the mouse was much better. "
"John McCarthy","Interviewer","Do you have any stories you would like to share about working with Marvin Minsky?"
"John McCarthy","Interviewee","No, basically Minsky and I worked separately."
"John McCarthy","Interviewer","What were Newell and Simon like to interact with as colleagues?"
"John McCarthy","Interviewee","What?"
"John McCarthy","Interviewer","What was it like interacting with Newell and Simon in the early days of AI?"
"John McCarthy","Interviewee","Well, I annoyed them on a specific occasion. And they were justifiably annoyed, though not necessarily with me. In September of 1956, there was a meeting maybe of IEEE or maybe it was called IRE in those days, in Boston, and I was invited to give a talk on the Dartmouth summer project and the state of AI. And I told what I knew, but in terms of actual implement of AI, they were ahead of us. "
"John McCarthy","Interviewer","If there were young people interested in pursuing careers in artificial intelligence or robotics, what would you recommend to them to study to pursue a career? What kind of advice would you give them?"
"John McCarthy","Interviewee","It depends on how good they are. If They are as self-confident as I was, then I would recommend to them do not pay any attention to anybody's advice. Think about it for yourself. I think AI needs new ideas and it is most likely to come from new people. The probability that it will come from someone who is 83 is very unlikely, although I just read in the New York Times an obituary of someone who died at the age of 97 who is most famous for something that he did after the age of 90. "
"John McCarthy","Interviewer","Could you tell us just a little bit about some of the challenges in AI and robotics that you think are the most important ones you have seen solved, and others that are pending?"
"John McCarthy","Interviewee","No. Sometimes I feel or maybe I do feel what Harrison Schmitt said about NASA. Did you read that?"
"John McCarthy","Interviewer","No."
"John McCarthy","Interviewee","Know who he is?"
"John McCarthy","Interviewer","Harrison Schmitt?"
"John McCarthy","Interviewee","The only scientist to ever walk on the moon. He was a geologist. He said NASA should be abolished and restarted with well, now I am forgetting exactly what he said and what I think started with new people. Because it was started with young people, and now they have grown old. "
"John McCarthy","Interviewer","You think robotics is a sort of new way to restart some of what AI was aiming towards in the beginning?"
"John McCarthy","Interviewee","I do not even know how old the leading people in robotics are, so I can not even say that thing, because I do not know. There was just a big conference on monotonic reasoning held in Kentucky, and I should have gone, but I am not very mobile these days and did not go. I got a greeting from it signed by about 100 people. About half of the names I recognized, which worries me it may be too many. "
"John McCarthy","Interviewer","Well, I think that just about does it, unless there is anything you would like to add."
"John McCarthy","Interviewee","No, That is fine."
"John McCarthy","Interviewer","Thank you very much."
"John McCarthy","Interviewee","Uh-huh. Print or publish or include in your program very little of this interview. "
"John McCarthy","Interviewee","there is a guy who said he invented it, the term artificial intelligence. Well, I was quite prepared to believe that, because when I wrote the thing down in this August 31, 1955 proposal, I was not absolutely sure that I had not heard the term somewhere else. And at least in something I wrote later on I said I was not sure of that, would anybody who knew it so he said he'd invented it. But then he said he invented it in the spring of 1956, which was of course quite a long time after the call for the Dartmouth conference had gone out and all sorts of people had accepted the invitation and so forth. And I said, Well, look, maybe you invented it earlier, but he absolutely could not be persuaded in that he might have invented it earlier. So he did not invent it earlier, and but somebody might have. But I did at least as far as anybody knows invent the term artificial intelligence. And I did propose logical AI, the way to do it. And now I would not be certain about , whether I was the first to vision, computer vision, towards description. I was certainly one of the first who did that. "
"John McCarthy","Interviewer","Did the fact that the robots were embodied and can move in space help and manipulate help with the notion of description, or change the notion of description at all?"
"John McCarthy","Interviewee","Well, yeah, because okay, now, here is an unsolved problem. The description of objects with flat surfaces is reasonably understood. Geometry provides us with that. The description of irregular objects is not well understood, and is almost not done, or I do not know anybody who does it because it is anyone who can describe, say, a cat as a solid object, or a person even."
"John McCarthy","Interviewer","Thank you."
"Kazuhiro Kosuge","Interviewer","So if you could start by telling us your name and where and when you were born?"
"Kazuhiro Kosuge","Interviewee","Uh-hum. I am Kazuhiro Kosuge. I was born in Japan in 1955 and yeah, actually I was born in Tsu City which is located in Mie prefecture. This is adjacent to Aichi prefecture. Aichi prefecture the main city is Nagoya City so you may know where it is. That is okay?"
"Kazuhiro Kosuge","Interviewer","Where did you start at school?"
"Kazuhiro Kosuge","Interviewee","Actually I was graduated from Tokyo Institute of Technology and my career is a little bit different from other professors in Japan. After finishing master course there I entered the Nippon Denso, one of the Toyota companies and now it is called DENSO. And Denso means electrical equipment for automobiles. So they are now I think one of the largest companies in the world concerned with the electrical equipment for automobiles. And I worked there for two years and three months and then I graduated from the company. I went back to the again the original previous laboratory at Tokyo Tokyo Tech and Department of Control Engineering and after that I joined a laboratory as a Research Associate and when I became a Research Associate Japanese we have a little bit different Japanese system which means that I could become Research Associate without having PhD degree. And then I was working as a Research Associate and doing some research I got the PhD there. And after that it took about eight years for me because I was working during the day time and so my time for research was a little bit limited, but I learned a lot. And then I became I first I visited the United States for one year. I was with Harry Sutter and he hosted me at the Mechanical Engineering Department and I learned a lot from him. And then I joined Nagoya University Toshio lab as an Associate Professor and stayed there four years and a half, and them I moved to Tohoku University and joined one of the departments relating to Mechanical Engineering and became a professor. So I became a professor at the age of 39 years old and the main reason why I moved is that I like to have do something by myself and that is a kind of a reason why I moved, I changed my job many times. "
"Kazuhiro Kosuge","Interviewer","So your degrees were in Control Engineering?"
"Kazuhiro Kosuge","Interviewee","Control Engineering, yes. And actually my supervisor at the Tokyo Tech was a professor Furuta, Katsuhisa Furuta; he is now serving as the President of our Tokyo Denki University and he is still very active in the field and he is one of the pioneers in the area of control theory in Japan and so I learned a lot in some sense, and the education which I received from his lab is really, really valuable for me. I learned a kind of a basic fundamentals concerned with control theory, how to develop the theoretical work and a very interesting thing, maybe this is a kind of a joke. Furuta means old rice field, okay? And Asada means shallow rice field. Fikuda means fortune rice field. And after having served four years and a half I got fortune and become a professor at the Tohoku University. Yeah, that is my career. "
"Kazuhiro Kosuge","Interviewer","So there is all the rice fields. "
"Kazuhiro Kosuge","Interviewee","Yeah, I have to cultivate it by myself and that is what I am doing now. "
"Kazuhiro Kosuge","Interviewer","What was your thesis project?"
"Kazuhiro Kosuge","Interviewee","For the PhD it is a control theory. I built up in some sense I forgot the name. At the time I was interested in nonlinear control theory and my work is a kind of a generalization for a class of nonlinear systems by utilizing a nonlinear fieldwork. That is my master thesis. Based on that we proposed a kind of a model following controller for the linear system and together with the generalization brought by nonlinear field work we made a kind of a robust controller which could control the manipulator based on the many different types of sensory information. And that is still I mean I am still using the results of my PhD thesis for the kind current work. "
"Kazuhiro Kosuge","Interviewer","Which manipulators were you using at the time?"
"Kazuhiro Kosuge","Interviewee","At the time, actually it was a long time ago. First manipulator which I used is the I tried to remember, yes, it is a kind of a prototype manipulator developed by one company that we had a collaboration with the company and they developed a manipulator and so we designed a controller. Other time still we do not have our first computer system and we used Nova from Data General and it is really, really slow. And memory size was at the beginning 32 kilobytes and then it extended to finally 128 kilobytes. And so the memory is very limited so we made our own assembly language and our own 14 point computation system by ourselves so that we could increase the computational speed. And so I still remember that we tried to increase the computational speed but maximum sampling rate was which we could attain is around I think sampling rate maybe along 30 hertz or something like that. It was very, very slow. And then after that, that is a time when I first direct drive manipulator was introduced invented by Harry Sutter as well as Professor Takyo Kanaday the group at CMU and later in some sense we received several direct drive motors from a company and by utilizing that we did several experiments using 2D or 3D planer manipulator system and we did our first control as well as dual-manipulator coordinated motion control digital manipulators using only on the plane, horizontal manipulators. And then we had another collaboration with an industrial company and we tried, we implemented our control scheme in that industrial robots and we did several experiments. After that we had another collaboration with the industrial robot maker and manufacturer and I think at that time we extended our planar results into real 3D space. So by utilizing two six degrees of freedom manipulator, we developed our single master multiservice systems. Single master means we developed two joysticks. Each have three degrees of freedom so the total six degrees of freedom master manipulator could control the twelve degrees of freedom, two industrial robots. And I think that is one of the hardest work relating to the coordinated motion control dual manipulators using real industry robots. Other time as long as I know only two or three groups are doing this similar work except us. One is Osamakative's work and another one is there is one group in Montpelier, France, Pierre Dorshe is group was doing that and I think by thru the real experiments using real industry robots we learned a lot and we are confident that our system works with the 4D could be applied to 4D real applications. "
"Kazuhiro Kosuge","Interviewer","What year was that and what kind of robots were you using?"
"Kazuhiro Kosuge","Interviewee","Pardon?"
"Kazuhiro Kosuge","Interviewer","What year was that?"
"Kazuhiro Kosuge","Interviewee","Yeah many years ago. It was just before I visit the United States for one year so I think it was 1988 or 1989. Yes, I joined M.I.T. 1989 so I think 1988. And it is many years ago. "
"Kazuhiro Kosuge","Interviewer","What companies' robots?"
"Kazuhiro Kosuge","Interviewee","That was supported by Nachifuji Kogi Company and at the time we had a friend there. Later he moved to another company so I do not want to embarass his name. It is a kind of secret. Now he is actually this is confidential but the guy who supported our research at Nachifuji Kogi company is now a kind of what I say one of our I think I do not know how you call it in one of the managers Fanuk so this part is confidential in some sense. "
"Kazuhiro Kosuge","Interviewer","The whole funded part, we will not. "
"Kazuhiro Kosuge","Interviewee","And also of course I had to implement a control scheme at that time. We need a high speed computational system, okay? We had a very good relation at the time with Sony. We have several friends. One day Sony's guy visited us and he said that they said that they are willing to provide us with a new servo controller system. Servo amplifiers, server controller systems and each controller could control two axis, two motors. But I told them I am not interested in that joined control systems. We are interested in kind of what to say, a total control so We had like to control a 360 axis. It was interesting. At that time Sony looks very, very in some sense very active and they are interested in my idea so they told me that they are going to develop a kind of a customized computer system. it is called a beta slicer system so by putting a lot of chips they can develop kind of their own control C.P.U.s. So they developed the C.P.U. computational system consist of two floating point systems, two F.P.U.s, and one A.L.U. , and several memories or something and the length of the micro-assembler. I forgot the name precisely. The is 128 bits. It was really, really powerful. And after that I was Japanese, I am Japanese, so we could not know how to give a presentation concerned with this special processor. A similar work was presented in the United States. They call it a very long word instruction-something . So I think if we knew how to present it, how to publish the results and maybe it could attract some people. But it is very powerful and it has a capability of a floating point, a computation of maybe at that time 20 megaflops. So now of course now the C.P.s are very, very the performance is very high and 20 megaflops is almost nothing. But at that time it is amazing C.P.U. so by utilizing a C.P.U. and together with the Nachifuji Kogi's robots system we could realize a single master multi-service systems. "
"Kazuhiro Kosuge","Interviewer","You mentioned that you have a lot of friends in industry. How did you meet these friends or how did you make these connections? "
"Kazuhiro Kosuge","Interviewee","Connections? Oh, that is a good question. When I was at the time I was with Tokyo Tech, Tokyo Institute of Technology and of course it is located inside of the Tokyo area and so many people are coming. And actually probably partially they are interested in my research. And partially they would like to support my research. And I have a lot of networks and based on the network I am still doing some collaborative research based on the network which I established I mean when I was at Tokyo Tech. "
"Kazuhiro Kosuge","Interviewer","So people were generally visiting Tokyo Tech and then they would also come see your work?"
"Kazuhiro Kosuge","Interviewee","Yeah, because Tokyo is very convenient so as long as we are doing something interesting they can easily I mean visit us and of course my boss at the time Professor Furuta was a well-known professor in the field of control engineering so actually, they are interested in that. "
"Kazuhiro Kosuge","Interviewer","What was the first robot you worked on? "
"Kazuhiro Kosuge","Interviewee","First robot? First robot is manipulator as I mentioned but developed by a company and it is a kind of collaborate research. And they thought that maybe the application at the time control theory is a kind of is called a modern control theory and so they considered that by applying an advanced control theory they could I mean improve the performance of their own robots. But actually we could not do it because of kind of a computational burden . The computer system was so slow to implement our own controllers. "
"Kazuhiro Kosuge","Interviewer","These were projects that you still did while you were at Tokyo Institute of Technology?"
"Kazuhiro Kosuge","Interviewee","No, no, no, no. Now I have already spent 18 years at the Tohoku University and I have my own network and a part with the network is relating to the network of the kind which I established or created during my yeah. "
"Kazuhiro Kosuge","Interviewer","When did you first engage the international community of robotics? "
"Kazuhiro Kosuge","Interviewee","International community of robotics? When I was young I was a Research Associate, at the beginning of course I have nothing to present. And after that, it is interesting that at that time linear control theory in some sense theoretical work had been saturated at that time so my supervisor, Professor Furuta, recommended me to do something in the robotics field because at that time robotics is kind of emerging field for the control people so first I start yeah, the reason why I started the robotics research. And Furuta itself and they are also doing a lot of research like one is at the time the largest project was is concerned with the to develop our own computer design system for the CAD for the control system design. And so I am the only one guy who is doing robotics in that lab and that was really good for me because everything, I have to do everything by myself. And nobody knows. Nobody has knowledge concerned with robots so I did everything by myself and That is why it took a long time to get the PhD. "
"Kazuhiro Kosuge","Interviewer","When you first got your appointment as an Associate Professor were you working on robots then or were you working on multiple areas? "
"Kazuhiro Kosuge","Interviewee","Okay, Toshiro's field is really, really wide. At that time he when his laboratory he just started micro-machine stuff. Probably at the beginning he was expecting that I was involved in micromechanical system, MEMS, Micro Electrical Mechanical Systems, but unfortunately I had in some sense I had a lot at the time in other fields. So I was involved in both and also so I learned a lot and when I was at Tokyo Tech in some sense I did kind of my research field a little bit limited. And after joining Toshiro's group, he is doing a lot of things of course so I have to take care of students, we have to take care of students and each student has his or her own area. So that helps me a lot to learn a lot of different things and how to in some sense how to develop the kind of supposed that you have to do something different. Also in research as long as you are doing research you have to do something different. And so I learned how to in some sense how to supervise students so that he or she could do something different in that field. And that is a good experience, very, very good experience for me. "
"Kazuhiro Kosuge","Interviewer","What were some of the projects that you remember from that time?"
"Kazuhiro Kosuge","Interviewee","At the time I think that really a lot. And also my previous sponsor at Tokyo Tech gave me two robots with different controllers. And by utilizing the system I continued the research of the dual-run system. And that is one of my field. Another one is that by utilizing the manipulator in some sense we developed a kind of a human augmentation, power augmentation system and it is a kind of human-robot interaction, physical human-robot interaction system and I think that still continues in some sense. My most of well-known robots in Tohoku University is the Dance Partner Robot. It has physical human level interaction and the idea came from my experience at Nagoya University concerned with the human power augmentation system. And we developed a very robust and stable controller for the power augmentation. Supposed to like to amplify human's power by utilizing mechanical system then the system interacts with the environment and the system robot interacts with the human, okay? So in order to assure the stability of the system the stability of the system depends on the human dynamics as well as the environment dynamics. So what we did is that by controlling a dynamics of the mechanical system so that it has a kind of it behaves like a tool, a passive tool then we can make sure that the total system is stable. And the stability does not depend on the human dynamics as well as the environment dynamics. And that is the idea which we developed at the time and it still works very well. "
"Kazuhiro Kosuge","Interviewer","The application would be for exoskeletons?"
"Kazuhiro Kosuge","Interviewee","But unfortunately Japan is a kind of over in some sense too much likes too much regulation concerned with the safetyness [sic] of robots and so we could not bring the technology into the real environment. After that, we are still searching for that in some fields in the future we can apply the technology."
"Kazuhiro Kosuge","Interviewer","But nowadays in Japan for example they have those robot-free zones where you can basically take your robot and send it out and use it in public without a lot of limitations so is that view changing in terms of a lot of safety security?"
"Kazuhiro Kosuge","Interviewee","No still our country in some sense is maybe I should not say that . it is very conservative in some sense in a good word, very conservative. Without regulation we could not do anything different. So it is a kind of a contradiction. We had like to develop something different, get something new. But if it was new we could not do any experiments using that system in the public. And of course in these ways they have a kind of special rule. If local authority approves it then we can do some experiments but experiments are very limited. I think that is one of the reasons why Japanese, we could not produce different robots. In some sense it is over restricted. "
"Kazuhiro Kosuge","Interviewer","Where did you get funding for this project?"
"Kazuhiro Kosuge","Interviewee","Which one?"
"Kazuhiro Kosuge","Interviewer","The augmented."
"Kazuhiro Kosuge","Interviewee","Augmentation? Actually we had no funding at the time because we had manipulators . At this time I was young so we do not have so much research fund and so the only two robots is a very precious system for me and we tried to utilize the robot for any purposes to prove that our system works, our control system works very well. At the time I stick to the design of the new control system which is robust against kind of this disturbance and everything. Originally I was a control guy. "
"Kazuhiro Kosuge","Interviewer","Over the course of your career what have been your primary sources of funding and support for your research? "
"Kazuhiro Kosuge","Interviewee","Actually we have two fundings, three fundings, but in my case of course we have NSF research fund. it is J.S.P.S. Researching Aid, it is called. And another one is N.A.D.O. , NADO Project and it is funding for the collaborated research with industries. And third one is purely from industries. At this moment I have many research funding. I have several research funding associates from industries and the amount is larger than that of the government research fund. And so okay there is a reason why I started a more industrial project is that without being involved in the real issues we do not know what kind of issues exist in the real field. And I notice that many people are trying to do some basic research, fundamental research of robotics, but it is not easy to find that new issues relating to the in the field of robots. But in case of the United States you have a very good system Darpa works very well. You have a lot of interesting initiatives like Grand Challenge and a lot of funding is given for the kind of more the other oriented robotics issues. So in this country researchers I think have some idea concerned with what kind of robotics technology has to be developed for doing for developing new field. But in Japan unfortunately as long as if you said that this research is relating to the kind of application oriented and then we could not get research fund from J.S.P.S. as well as J.S.T. and something. They believe that scientific research only scientific research is fundamental research and which could be applied to many fields which should be applied to many fields and they fund only such research and so they do not know. Usually it is not easy to notice kind of a real issues existing in real applications. So now I put more emphasis on kind of a collaborative research between industries because they usually bring us a kind of real issues which contains a lot of interesting scientific issues maybe based on through the collaborative research we could establish some new field. That is what I am trying to do at this moment. "
"Kazuhiro Kosuge","Interviewer","Have you found it difficult to kind of use that also in the scientific community, the kinds of results that are more application oriented? "
"Kazuhiro Kosuge","Interviewee","Recently when this will be published? I would like to know because depending on when this interview is opened sometimes I could not say something. "
"Kazuhiro Kosuge","Interviewer","It will be at least a year. It will be yeah, not this year. More than a year. "
"Kazuhiro Kosuge","Interviewee","More than a year? Okay. I think for example suppose we are doing some work okay? And then we use both vision and haptic information okay? And I think we found a very good research topic concerned with kind of the fusion of haptic information as well as visual information. And we are now developing a new controller based on different types of information. So I could not say so much at this moment, but I think it is very interesting. The issue came from the industries or through the discussions concerned with some problems which We had like to solve. We found that we have to develop something different. And I think probably we can develop probably we are going to present it maybe next year. I hope. "
"Kazuhiro Kosuge","Interviewer","And is this also for a manipulator?"
"Kazuhiro Kosuge","Interviewee","Oh, it is concerned with the manipulator. "
"Kazuhiro Kosuge","Interviewer","Sensor fusion. "
"Kazuhiro Kosuge","Interviewee","Yes, sensor fusion. Sensor fusion in some sense. "
"Kazuhiro Kosuge","Interviewer","And who have been some of the corporations, industries that have sponsored your work?"
"Kazuhiro Kosuge","Interviewee","it is secret, confidential. I am not allowed to say. "
"Kazuhiro Kosuge","Interviewer","But for your whole career? Have there been others that are not secret?"
"Kazuhiro Kosuge","Interviewee","They do not want to admit it, unfortunately. Very interesting. Of course, if the research was open okay then company people do not want to bring me the real issue. it is all That is very difficult. Companies in Japan has a different culture. I think I do not know whether it is good or not but they have a different culture. So based on the kind of contract, more strict contract we can see the real issues. And what we can do is try to I want to say abstract the issue and so that we can utilize the results to many different fields. "
"Kazuhiro Kosuge","Interviewer","And then you can publish it basically when it is not related exactly to…"
"Kazuhiro Kosuge","Interviewee","That is right."
"Kazuhiro Kosuge","Interviewer","Do you think there is a difference in the patent structures in Japan from the U.S. and Europe that make that…"
"Kazuhiro Kosuge","Interviewee","Patent structure may be the same, I think so. Yes, the same. But the one difference is I do not know whether I can say but this is true. So keep this part secret, in some sense. it is very strange. Okay. Japanese companies they try to get all of the patents which will be produced through the collaborative research. it is not so good. Okay. If our university holds the patents, we can use the patents for different applications. But usually, people say that the company people are trying to keep the patents by themselves. So we are encouraged to sell the rights of the patents to the companies. Actually, we developed several plug to go systems. we have got patents. And unfortunately our university has sold the patent company so I am a little bit shocked. "
"Kazuhiro Kosuge","Interviewer","So you mentioned in 1989 and 1990 that you went to MIT for a year. "
"Kazuhiro Kosuge","Interviewee","Yes. "
"Kazuhiro Kosuge","Interviewer","How did you decided to go there?"
"Kazuhiro Kosuge","Interviewee","Because that is just after Harry Osada went back to the U.S. and when he was staying at the Kyoto University he asked me whether I can join his group or not. And at that time, it as a secret that he was going back. And yes I got the invitation in one sense. And he is supported my living expenses in Boston. And That is why I joined his group. Again, the data was very interesting. MIT is an exciting place. And yes I learned a lot again. And during it was only one year but I really learned a lot. "
"Kazuhiro Kosuge","Interviewer","Who were the people who were there? And the kinds of projects that were happening at the time at MIT?"
"Kazuhiro Kosuge","Interviewee","Well, I do not remember. "
"Kazuhiro Kosuge","Interviewer","Who did you work with basically?"
"Kazuhiro Kosuge","Interviewee","Okay. I was working with the Harry has his own idea concerned with the robot structure. So we have got by each rising the drive motor we developed I do not know the name of the student, but I think probably Kevin. So this part should not be included. He may be disappointed that I forgot their names. By using the drive motors which I received from a company another student developed a planer link manipulator system. So my work was, at the time, is how to implement the I built the control system which could kind of a master service control system but using that data to drive motor. And, of course, I was interested in the how to make it the - how to create different type of intelligent control system but one year was too short for me. "
"Kazuhiro Kosuge","Interviewer","Who were some other people that you have collaborated with over the years?"
"Kazuhiro Kosuge","Interviewee","At MIT over the years?"
"Kazuhiro Kosuge","Interviewer","Everywhere, Japan and the world. "
"Kazuhiro Kosuge","Interviewee","So it is a difficult question. In some sense I am doing everything by myself. . I was doing everything by myself in the past. And so until recently I think in some sense my research is self-contained. And recently I noticed that the collaboration is very important and I tried to invite several professors in our university. And we are doing something different by converging different technologies. I am good at the control part of the manipulator, forced control or impedance control. it is my favorite area. And some guy from vision join that. And some guy from mechanical design part joined us. And, again, robotics is a kind of product based on the technology convergence. And I like the collaboration with other people. "
"Kazuhiro Kosuge","Interviewer","Can you say who the vision and mechanical person were?"
"Kazuhiro Kosuge","Interviewee","I do not know. "
"Kazuhiro Kosuge","Interviewer","you are like James Bond. "
"Kazuhiro Kosuge","Interviewee","No, no. I am not sure, whether I can. Yeah. Because That is related to the kind of confidential projects. At this moment I should not say that. "
"Kazuhiro Kosuge","Interviewer","We will know in a year. "
"Kazuhiro Kosuge","Interviewee","Yeah, hopefully. Yes. "
"Kazuhiro Kosuge","Interviewer","So how did you start working on the dancer project? Because you talked a lot about these realistic applications and things like that. "
"Kazuhiro Kosuge","Interviewee","Okay. At the time, when I started the dancer project we are doing some cooperative robot control system, cooperative control of multiple mobile robots handling a single object in coordination. And at the time I was interested in how to make the robot more intelligent. Of course, the definition of intelligence is not so easy. So I thought that maybe it might be a good idea to develop kind of a pet robot. So I wanted to develop a mobile pet robot. We named it Moped . But unfortunately the student who was involved in the Moped project in my lab, each student has his or her own kind of research topic. he is been hospitalized for two months or something. So we noticed that we did not have enough time for him to do something in the Moped because that is a completely different field from our previous experiences. And so we had a discussion and I noticed that maybe if we created something different, probably I mean that could be appreciated that could be utilized as a master of thesis, at the time of the student, a master course student. And also through the multiple robot coordination we are doing a lot of things. Multiple robot coordination and human/robot coordination. And especially the human/robot coordination through the several experiments over a human/robot coordination it turned out that we needed something different for the robots. Of course, in these days, many people are interested in how to develop a robot assistant, for example. In order to assist a human, for a robot, the robot has to know what the human is doing, what its user is doing, how its user would like to be assisted. Or what kind of a task the guy is doing. And all over the such information is very important. How, he or she is trying to do, in some sense their intentions. Without this information and the robot could not assist the human. Up to the collaborate, I want to say the physical at that time we have a very limited knowledge concern with the human/robot interaction. That is from based on the pure control system design. So we found that something is missing. So we thought it is a good idea to develop a ballroom dance robot. And in case of ballroom dance the male dancer leads the female dancer. So if we could develop a female dancer, we could reproduce the female dancer as a function then probably we could apply the results for the assistant robot for future robots which could assist humans. So this idea combined with the situation of that student and in some sense created the idea of a dance partner robot by utilizing mobile robot. We have several mobile robots. And we decided to use one of the robots. We modify the mobile robot so that it could dance with a human and that is really the starting point. I think it is around 1997. And, of course, after that we had are doing the new students continue the research and fortunately in 2005, IJ Expo provided help in Japan. We gave a proposal for the NATO project and saying that I would like to demonstrate a dance partner robot. And our proposal was accepted. And so we could hire the designer. It turned very interesting. A designer of the well-known dance partner robot PBDR is Tatsio Kanogi who is a real designer, dress designer. And when we found him, we met him, he was one of the key designers of Issey Miyake's group. Issey Miyake is a well-known designer in Japan. And after that he left the group and he is now independent. And so we had a collaboration with the designer, dress designer. And also in order to have a demonstration of our robot during IJ Expo actually it was a two week demonstration. it is not so long but it is not a one-time demonstration. So we thought that it was not easy to give everything by ourselves. So we found a company, a generous company to support us to develop the robot. And so the company and it is called Nomali Nissan. Now, they changed the name. it is called Nomali Nissan and Mr. Okonogi and ourselves set up a group. And Mr. Okonogi has a lot of his own networks. He found a good mannequin company who could produce beautiful outer panel of the robot. And himself a design created a completely different design of a dancer partner robot. And it is really beautiful. And when I saw the first, what I say, we saw the mannequin company which produced the outer panel is located in Kyoto. We are located in Sendai. And Mr. Okonogi is located in Tokyo. And Nomali Nissan is located in Chino City in Nagano Prefecture. So four different entities are involved in the project. And, again, we learned a lot. And we noticed that we do not know so much about how to produce something different. "
"Kazuhiro Kosuge","Interviewer","How did people react to the dancing robot?"
"Kazuhiro Kosuge","Interviewee","The reaction was so nice. Actually, before that our robot actually a third generation robot was in some sense it was broadcasted. And we had some presentation in the ABSJ , Robotics Society of Japan's annual conference. And one media is interested in the robot. And they filmed our robot. And several broadcasting companies broadcasted the robot. Then the other time I was all ready in Sendai and one of the companies were Sendai they broadcasted the dance partner robot and the original version and newscaster said that she does not like her face, the face of the robot. "
"Kazuhiro Kosuge","Interviewer","Was it at that point the turquoise and the pink one?"
"Kazuhiro Kosuge","Interviewee","No, a different design, original one. Actually, That is the third generation. So in some sense we are disappointed to hear the comments and in some sense discouraged. So this ITX plus project was really nice by inviting the real designer, dress designer. Of course, he is a major designer of dress, he has his own idea, how to make the system, the robot is more attractive to the ordinary people. it is very beautiful. And according to him our robot is a kind of combination of a Mickey Mouse and Marilyn Monroe. I do not know how to pronounce it in the precise way and actress, well known actress. And according to him in order to attract make the robot attractive to the ordinary people then he said that design should be kind of a combination of well-known characters. He did not want to make the robot like human. So he include the kind of design, similar to the Mickey Mouse. It has large ears. And Marilyn Monroe is maybe his favorite actress. So by combining them actually it is very beautiful. And also the first part of the demonstration consists of a slow dance. A slow dance was created by my students and together with Mr. Okonogi. And it was, again, very beautiful. So it could attract many people. After that, actually, of course, we did a demonstration of the physical human/robot interaction. Our student, Dr. Takeda, has danced with the robot. And yeah it was successfully done and many people likes the robot. "
"Kazuhiro Kosuge","Interviewer","Do you think That is your most famous robot?"
"Kazuhiro Kosuge","Interviewee","Yes. I think still people know. "
"Kazuhiro Kosuge","Interviewer","What about technically?"
"Kazuhiro Kosuge","Interviewee","Technically it is kind of a I am not sure whether I could say that behavior estimation, estimation of the next step, following step based on the resultant force applied to the upper body from the male dancer. And we designed in some sense a behavior, a step estimator based on the by utilizing model and it works. Of course, we are still doing the research, how to increase the robustness or how to make the system more adaptable, adaptive to the different people. Yeah, we found a lot of issues. And actually, during the CIPRA conference, one student, our student, Mr. Honogone is going to give a presentation concerned with how to realize couple the dynamics of both dancers. it is another issue. "
"Kazuhiro Kosuge","Interviewer","What do you think is the biggest technical challenge to this kind of human/robot physical interaction?"
"Kazuhiro Kosuge","Interviewee","Of this interaction? Of course, the different types of physical human/robot interaction means a lot of different things. So probably they okay, generally speaking most of the difficult issue is how to create safety, safetyness . The robot has to be safe. So it is kind of issues which we have to solve. But in our case, in case of dance robot several issues, one is how to estimate the human's behavior. This is also general. Suppose that we try to develop an assistant robot, the robot has to know the human's intention, in some sense intention estimation or behavior estimation, more precisely. And the next one is in our case, in the case of dance robot it issues kind of a synchronization of motions or a couple dynamics. So suppose that you would like to do something together with the robot, suppose that you like to carry something like a desk, together with a robot. These two dynamics have to be in some sense have to be coordinated. And sometimes you may need some synchronization. Okay. And another one is I am sorry, I am not very organized. And another one is as long as robot is interact with the human the human may expect some characters, some emotions in the robot. So emotional behavior, emotional aspects should be implemented in the robot system. That is kind of our final goal. it is really difficult. We are starting with the physical human/robot interaction means that kind design and control first and then try to move it to the in some sense intelligent part. So we are still trying to climb up the stairs, climb up the mountain and that takes time. "
"Kazuhiro Kosuge","Interviewer","And is this also funded by industry? Or is this funded by the government?"
"Kazuhiro Kosuge","Interviewee","Which one?"
"Kazuhiro Kosuge","Interviewer","The dancer. "
"Kazuhiro Kosuge","Interviewee","Now, of course, concerning dance robot in the past we received research fund from JSPS and also NATO , the IJ Expo and the country that we are doing that by ourselves. "
"Kazuhiro Kosuge","Interviewer","What do you consider the biggest technical accomplishments of your career? "
"Kazuhiro Kosuge","Interviewee","Okay. It might not be theoretical. I would like to say based on this human/robot interaction experiments with dance robots we found several applications in the industries. One is PaDY and it is a robot which is supposed to be utilized for the automobile companies, factories. And at least in Japan there is a lot of workers, human workers still involved in assembling of automobiles. And sometimes they have to go back to the workbench to pick up parts and put the parts to the vehicle. And we found that by developing kind of an assistant robot which assisted these workers to assemble the parts, maybe the workers we can make their work more efficient. So our robot is parts and the tools delivery robot. PaDY stands for, it is a bit strange English, parts tools delivery to you robot, PaDY. And the robot captures some parts necessary for the assembly. So the worker is doing some assembly task and then the robot is going to bring him or her different parts. So the robot has to estimate to which extent the work has been done, which parts is necessary for him or her to do the next assembly task or something like that. So it depends in some sense, the concept is completely comes from the dance partner robot which we expected at the beginning. But some people may be interested in why we did not develop a home use robot. Because in some sense now many people are trying to develop robot for home use. But home is a really, really difficult environment. We have an older user which means that the robot have to be completely safe. We could not educate the user at home. So in case of factories by limiting the kind of first we can educate the user. The user is a worker and usually are educated for that productions system. And we can control the environment. Of course, it is in some sense it is less unstructured than compared to the home. So I think it might be a good idea to bring the robot assistant into the factory first. Then based on the several experiences in the factories, probably that concept could be brought into the real ordinary environment. I think we are still working on it. And it is exciting, very exciting. "
"Kazuhiro Kosuge","Interviewer","Did it help you improve your dancing?"
"Kazuhiro Kosuge","Interviewee","Pardon?"
"Kazuhiro Kosuge","Interviewer","Did it help you improve your dancing, the dance robot?"
"Kazuhiro Kosuge","Interviewee","Yeah. Yeah. "
"Kazuhiro Kosuge","Interviewer","The student did all of the dancing. "
"Kazuhiro Kosuge","Interviewee","Well, unfortunately I could not dance. "
"Kazuhiro Kosuge","Interviewer","So who are some of your more successful students who are still working in robotics?"
"Kazuhiro Kosuge","Interviewee","Still working on robotics and successful students? In our case, since maybe since we are doing a lot of system integration type of research and so many people after having got a Ph.D. and many people would like to join the companies. And many students are working in companies. Some of them are developing next generation robots and some of them are doing something different. And concerned with the academia, yes and my associate professor is old student. This is Professor Hirata . And he is trying to apply the kind of physical human/robot interaction technology to the assistive systems, I mean assistive systems of the walking assisted system or other types, usually mainly mobility assistive system for the elderly or some disabled person. I think he is most successful. "
"Kazuhiro Kosuge","Interviewer","Can you also tell us a little bit about your work for RAS and RSJ?"
"Kazuhiro Kosuge","Interviewee","Yeah, and the JSME. Somehow I have been heavily involved in society activities. In Japan I was kind of there are three societies relating to the robots. One is SICE, Society of Instrument and Control Engineers. When I was member of the board of directors, board of governors, we established a new division in that society, the Society of Instrument and Control Engineers. That division is system integration division. Okay. I was kind of the head of the division and also served as kind of several positions in the board of governors in that organization. And after that I was also concerned with the Robotics Society of Japan. Again, I was a…"
"Ken Salisbury","Interviewer","When, where you were born ."
"Ken Salisbury","Interviewee","Are we rolling?"
"Ken Salisbury","Interviewer","Yeah."
"Ken Salisbury","Interviewee","Oh, okay. So my name's Ken Salisbury. I was born in Schenectady, New York. I was the son of my father, same name, Kenneth Salisbury, who was heading the steam turbines division at General Electric. So at the time I think he kind of wrote the book on how to design steam turbines, but That is in the '30s, 1940s, a long time ago. Spent two years there then moved to California where my dad was a faculty member here for a couple years. Went to grade schools in the middle Atherton, Palo Alto I am sorry. Not Palo Alto, Menlo Park grade school area. Had a lot of fun in school. Liked to hang out with the girls more than the guys. I do not know why. They were more interesting. The guys were into like bashing each other with toys and the girls were kind of like into more fantasy play, which I liked. Did really well in school and kind of skated all the way through high school without a lot of work. A lot of things came easy to me and I got pretty involved in student government and scouts and competitions and a lot of stuff. I was pretty aggressive about those things. Went to college at Stanford, both undergraduate and graduate. Took some years out on and off during that, but I spent about 11 years as a student at Stanford which was really a privilege and really a fun thing for me and now I am back sitting on the other side of the desk, but it is really good to be here. My education at Stanford started in mechanical engineering. I like to build things. I have a pretty good physical intuition about things. Was convinced by a friend of mine, Rob Young, who is a technical guy, a serial entrepreneur who started quite a number of games, built companies. He enjoys them. I was convinced as an undergraduate to switch to Double E so I could learn some things that I did not really know so much about. Mechanisms I kind of knew already. I built lots of stuff as a kid. So I got my BS in electrical engineering then switched back to mechanical engineering because I really wanted to dig deeper into science, the physics behind mechanical things. This kind of cycle of build something intuitively and then go back and go, Well, why did it work? or Why did not it work? So go to the analysis from whatever discipline is appropriate and then build it again based on what I learned in there and then my Ph.D. was with Bernie Roth in mechanical engineering and ultimately resulted in a thesis that looked at the design and utilization of robot hands and that became the three finger. Initially JPL, Stanford Hand, which not by my fault, but people now call it the Stanford sorry, the Salisbury hand. there is the real one . From there I accepted a post-doc at MIT to work in their AI lab. A one-year post-doc turned into a 17-year adventure with a lot of really good folks and then I came back to the Bay area on the invitation of Intuitive Surgical where I became their science advisor and fellow for four years and kind of helped that company get started by making technical contributions, licensing some of my patents, and finding good people to help them out. And then came back to academia ultimately as a research faculty in mechanical sorry, not mechanical, but in divided between computer science and the department of surgery because in the interim four years I had gotten involved in medical robotics and I also have a courtesy appointment with mechanical engineering because I know the department well and I advise quite a few students there. So which brings me here which is my sort of latest lab which is the bio-robotics lab and it is kind of in the Clark Center, but it is kind of jointly supported by my appointment in computer science and the department of surgery, so it is kind of an eclectic group of people."
"Ken Salisbury","Interviewer","Now that we have kind of gone through the whole trajectory, how did you get to building a hand in the first place? Why were you interested in that?"
"Ken Salisbury","Interviewee","The first finger I built probably was when I was six years old. It goes way back. I have always been interested in things having to do with hands ranging from magic tricks to playing musical instruments to knot tying, teaching scouts how to build bridges and stuff and so hands in a variety of ways have always been an interest of mine. I worked with my dad after he had a stroke and tried to help him restore functionality in his hand and was kind of toying with physical therapy versus engineering for quite a while, partly because of the emotion the psychological aspect of supporting a person going through recovery as well as the mechanical sense that I had about how you should be moving things to stimulate different nerve paths or muscles, but I ultimately got seduced by robotics because it had a lot of gadget components to it and entranced very much with motors and sensors and computer control of them and I kind of saw that coming early on, so switching between Double E and ME kind of provided a foundation which I sort of envisioned would be very important for me in the long run and That is certainly been borne out. A lot of our devices in my lab here and previously have motors and sensors and computers connected to them. I think my best contributions have to do with creating interesting mechanisms that have They are controllable, their controllability, so to speak. They are observable or have observability which means you can look at the state through sensors and you can have sufficient control to make them move to a new state and that kind of comes from a controls background, but it exhibits itself in design of mechanisms so that They are designed right. I really firmly believe that a mechanism's got to be really, really good to have mechanically to have good performance. Some controls folks just say, Oh we can write an adaptive control algorithm to deal with it, but if the mechanics am not right, am not going to work . So and that is a theme that has been repeated many times in my work. I forgot what the question was."
"Ken Salisbury","Interviewer","We were just starting to "
"Ken Salisbury","Interviewee","You can cut that part out."
"Ken Salisbury","Interviewer","Oh no, that was great. How you got interested in hands and what kinds of problems you were kind of looking to solve by working on hands and developing a new hand."
"Ken Salisbury","Interviewee","Yeah, good question. I mean ultimately from some prior experiences with NASA and prosthetics and dealing with some handicapped kids, I began to realize that there were some interesting contributions to be made in designing robot hands and there've been many before me. Many of them were anthropomorphic. A lot of them turned out to be one-trick ponies. They could grasp something or they could do something, some manipulation in a limited sense, so I wanted to step back and kind of look at the science behind it. How should a hand be built? What are the tasks that we want it to perform that are interesting and useful and then how do you put a control system around that to allow you to execute those tasks? And to be honest, when I began this thesis work with Bernie Roth, intuitively I kind of knew how the hand should have been built and then I had to kind of backfill and justify what I did, which was a very good learning experience and is kind of a style of research that I do now with my own students. If you have got intuition, go for it and then come back and figure out what you did. In fact, one of my mottos is ignore the prior art for a while so that people think more freely about how they can solve the problem without accepting the constraints that others have assumed and then be duly diligent and look and see what is been done. So what resulted from my Ph.D. work was a three-finger hand that had sufficient mobility to both grasp an object securely and control the quality of grasp. If somebody's trying to push the object out of my hand I kind of describe how to squeeze more tightly to stop that from happening and the hand had mechanical ability to do that and the math told us how to respond to these different disturbances and secondly had the ability to arbitrarily move through small rotations and small orientations objects that it grasped. So this kind of high-level goals which we mostly, partly, I would say succeeded in doing. It kind of became a platform and an icon at that time in dexterous hands. It was not intended to be anthropomorphic, though it had fingers and tendons, but it is schematics were quite a bit different. It kind of looked like a three-finger hand, but it could also curl backwards and do some really bizarre things. It was kind of fun watching people watch the hand manipulate in the demonstrations and then it would kind of warp out and do something non-anthropomorphic and people would get all upset about that because they would be engaged and then be surprised. I formed a small company to sell these hands because people started saying, I want one of them, and we sold about 20 of them, so at that moment for me it became my first platform that went out to the research community and it has a life of its own. People still write papers about it and it was kind of a good idea. I had no idea it would have the impact, whether it was due to deep insights or just being first, but some cool ideas. I do not know, but it is been fun watching its evolution and its influence on the field."
"Ken Salisbury","Interviewer","Who else worked with you on the hand? So Bernie "
"Ken Salisbury","Interviewee","Well, that is a good question and the kind I like to answer. It was an opportunity with NASA and Jet Propulsion Labs to get seed funding for a project and I hooked up with a fellow, one of my several mentors, Carl Ruoff, and together we, if I remember correctly, pitched an idea designing a new generation of robot hands for NASA, but other applications, and then so he and I and with Bernie Roth as my advisor brainstormed and reviewed and went through the ideas. I did a lot of drawing and sketching. The two of Bernie and Carl gave some sort of high-level goals and some low-level details and then I kind of carried the ball from there and came up with this hand, built some prototypes. Now I get a chance to show one of my early prototypes if it does not fall apart. I like in the spirit of some design skills that I was taught at Stanford, the earlier you reduce an idea to a physical embodiment, the sooner you get the insight about what is the appropriate problem to solve. So this is about an afternoon's work with a band saw and a belt sander and it really gave me a physical entity to help me figure out what was the right thing to do. I tried eating my dinner with this. Was not very successful. My housemates laughed, but it definitely helped and ultimately after many iterations and consultations with students and Professor Roth and others, we came up with this device which has a nine degree of freedom. It has nine joints that can be independently controlled and they can go one, two, three degrees of freedom. This turns out to be the right number to controllably grasp something and then make the small orientations that I talked about and it worked. I forgot to put a palm in it. That was a big mistake. It turns out palms are really important. Over time we added sensors to it. The first Ph.D. student to begin with me developed this four-sensing finger so that as the hand grasped things, we could have even more fidelity in the touching of objects to confirm grasp and ultimately to determine material properties. We could stroke across a textured object and determine its spatial frequency, the vibration, the friction, the stick slick behaviors. there is a whole lot of information you could get out of this and this is different from the more classic tactile sensors which would have an array of single points measuring the distribution of force. This measured the net force on an object which to me was more directly useful in grasping and maintaining grasps. I think I said this was developed by David Brock who was my first Ph.D. student. Dave went on to found a couple companies. A lot of my students have gone on to found companies. it is sort of fun. We have a little more entrepreneurial bent here. Though some of my students have gone on to be faculty members, a lot of them more have tended to take their technologies into companies and exploit them in the real world and That is one of my charges with my students. Make something that we can continue to use whether it is here in the lab or via licensing or some other means of transferring it out. Yeah, so it took on a life of its own. There were 20 of these around the world and people started sending me papers about the hand doing pretty interesting things and it was satisfying and sort of inspiring and I continue to be interested in hands. We have a new project looking at a low-cost sort of high-performance hand for a DARPA project. So it is sort of fun for me to revisit something I did 20-25 years ago and curiously the co-investigator on it is a recently graduated student whose name is Curt Salisbury. So I kind of fantasize that this will be the Salisbury Mach 2 or something like that. he is a fabulous designer and we are having a lot of fun designing a new generation of hands. "
"Ken Salisbury","Interviewer","So what are some of the challenges in this new generation of hands? Where are you taking it now?"
"Ken Salisbury","Interviewee","Well it is for a DARPA project where they want to develop hands that can be used to make safe or diffuse IEDs, improvised explosive devices. That is sort of their immediate driver and That is certainly a good practical goal to follow. I like having a concrete goal so we know when we have succeeded rather than abstract make hands more dexterous. What does that mean? But I am also interested in it because it relates very much to my interest in prosthetics, sort of the hopefully low-cost end of these technologies. Instead of being military, it is hands for the rest of the world and so learning about mechanism design, details, finger shapes, frictions, surfaces, kinematics, how many joints, lots of things from DARPA is relevant to my interest in low-cost prosthetics. So That is sort of a happy convergence coming back from my early work in wanting to do physical therapy, now bringing in knowledge from government-funded work into spinouts to underserved populations. Okay, where we going from there?"
"Ken Salisbury","Interviewer","We can go back. I was just curious. Who works with you on that one?"
"Ken Salisbury","Interviewee","Well, on the high-tech end it is Curt Salisbury. he is the principal investigator on that project run through Sandia National Labs and then we have a good subcontract to myself here at Stanford and here I have a couple students working on it, Rob Wilson and Morgan Quigley, covering mechanical and electronic interfacing. Oddly, DARPA specced that this hand should be a retrofit for the Barrett hand. They wanted to kind of divide the task at a certain point. Well, the Barrett hand came out of our work at MIT and so suddenly my arm is now becoming that arm is becoming the standard platform for carrying around the next generation of robot hands. That arm, initially called the WAM, meaning whole arm manipulation, became commercialized by Bill Townsend who was my first to graduate Ph.D. student at MIT. he is formed a company called Barrett Technologies in Massachusetts and now sells the arm called the Barrett arm and the Guinness Book of World Records said it was the world's most dexterous arm at one point. Wonderful or dubious distinction."
"Ken Salisbury","Interviewer","we have used the Barrett arm. We were making robots that play shadow puppets with people, so we were actually using that."
"Ken Salisbury","Interviewee","You saw that with them or "
"Ken Salisbury","Interviewer","Yeah, yeah. We were using it in a project to "
"Ken Salisbury","Interviewee","So let me make a comment on that. it is easy to seduce people with an arm that kind of wiggles and does interesting things, but moving in free space is easy. The thing That is hard and still not well understood is making contact and controlling physical contact and interpreting it. So if you are going to pick up something and you do not want to slip or you want to turn the doorknob, how do you monitor that and cause it to happen? I mean it is very classic in robotics. People make a complicated thing and it wiggles around. it is like, Well That is great, but what are you going to do with it? I do not mean to deprecate the complexities of other people's ideas, but where the rubber hits the road is when you grab something and do it intelligently. "
"Ken Salisbury","Interviewer","So to go from the Stanford, since you just mentioned your Barrett arm and MIT, how did your transition there go and what kinds of projects were you involved there?"
"Ken Salisbury","Interviewee","At MIT?"
"Ken Salisbury","Interviewer","Mm-hmm."
"Ken Salisbury","Interviewee"," read my "
"Ken Salisbury","Interviewer","Yeah, but we want the stories."
"Ken Salisbury","Interviewee","Yeah, yeah. So there were many. I mean this has been true to my life. I had the opportunity or the blessing to work with a lot of really clever people. I tend to take on students who are rather independent, sort of mavericks. I am not a hard-driving Gantt chart oriented guy. I mean I have to satisfy sponsor requirements. A lot of my students who are in fellowships get a little more free reign and That is where things really happen. I think I have kind of a good gut sense of who is going to work out and fit with our lab. So at MIT, what else did we do? I brought my hand in from my Stanford work, began commercializing it and selling them. Worked on the WAM arm with Townsend. Worked on the touch sensing interpretation of the four sensing finger I showed you. Worked on with Brian Averman who used that force information to deduce material properties such as texture and stiffness and other things and then used that to detect events such as collision or starting or stopping of sliding and other things. It was very deep mathematical analysis and very interesting, but really complex and it is at that point I got a little bit frustrated with robots perceiving what is going on. I do not know if we lacked the sensor capability or the processing capability and I decided to flip the problem around and start looking at haptics and that is the idea of using force feedback and something that tracks the motion of your hand to make you feel like you are touching a virtual object. So you might see on the screen a wall when you are moving this device around and when your icon on the screen touches it, you feel the force. So we brought in a second modality for interaction with geometric information and that work was inspired in part by my work with Thomas sorry, by Mandayam Srinivasan, who runs the Touch Lab at MIT. He kind of came at it from a psychophysics point of view and understood what people needed to detect information, touch and material properties of objects and some ideas of the precision quality needed in that. So I sat down with Thomas Massie who was an undergrad at the time and gave him the challenge of building a device that let me feel things that were on the screen and Thomas was a very clever designer and within a week had a one degree of freedom device that could do exactly that. You could make it move and feel a virtual wall and it is like yeah, That is good. A quick prototype, proof of concept. I think we got a good idea here and within a couple more weeks he came back with a wooden model of the phantom haptic interface which ultimately became to me really the first practical force feedback device. It was simple enough and instead of having complexity, many different degrees of freedom, it had only a few degrees of freedom and traded that for fidelity, bandwidth sensitivity to force, and so I often like to trade complexity for fidelity and that worked and that caught on. A lot of people started using the phantom to interact with virtual stuff ranging from people who wanted to sculpt virtual stuff to psychophysicists who wanted to do controlled experiments to understand what people could perceive in various ways. The company he founded, partially I helped with that founding, was SensAble Technologies which continues on now. They are in Woburn, Massachusetts. they have branched out into quite a number of applications ranging from sculpting as I mentioned whether it be for the jewelry industry, sculpting faces, shoes, sort of organic designs, to automobile design. The ability to get people's hands back involved in the shaping of things to learn sensory motor skills so that they could express what it is they wanted to show, plus the advantage of computer tracking modification, mirroring, smoothing, and a lot of other things. So that became pretty interesting. That company has now branched into SensAble Technologies Dental or something close to that and so They are looking very much at the dental market perhaps initially to train people to do procedures, but ultimately to help them sculpt different appliances that go into the mouth, bridges, prostheses of various sorts, and that seems to be catching on. The phantom haptic interface has been used a lot by medical researchers, people who want to enable doctors to feel and train or plan or ultimately rehearse medical procedures with the inclusion of force interactions which is pretty central to a lot of procedures. Learning to discriminate between a cancerous tumor which might feel crunchy versus a benign one which might feel elastic. Sure they can do that with cadavers or with real patients in some circumstances, but to be able to virtualize that just like flood simulation where you can be exposed to a variety of circumstances really is a big win. So in our work here currently we are looking at simulation for rehearsal which I think is the most interesting one because it improves the outcome, if it works, the outcome of a particular patient. So if you can show safety and efficacy for an individual now you can say this is insurance reimbursable just as a scan is which helps diagnosis and procedure performance. So That is one of my current thrusts in surgical simulation, getting the fidelity good enough that it works, and then validating with having some rehearsal time before doing the actual procedure will improve the outcomes. So continuing the history at MIT, we developed some hands, some curling hands that Helen Greiner developed. She was the founder of iRobot, cofounder, which is something I just dug up today. it is not a well-known publication but has a huge number of insights into it. I am guilty of not publishing everything that we do or they end up in obscure places. So I really like pulling out her thesis or some other students' theses and spreading them around to bring people up to speed. And that got me involved in more hand design, more kind of simple grasping hands that could pick up arbitrary objects. Could not manipulate them in some arbitrary ways, but were pretty good at grabbing onto on-size objects. One interesting spinout of the WAM arm which was designed to have good force controllability, was designed to be able to reach through gravel and find big rocks for NASA or to do other open a door that has a constraining motion access. It turned out the same design principles that led us to high force controllability and fidelity also meant that the arm could go really fast. It had very high accelerations. We designed it to have maximum power transfer from motors to endpoint which means maximum acceleration. So this arm could move like a bat. It was great. So working with Professors Lateen and Gutra Needmyer and Jesse Hong , they developed a system that could catch a ball so you could throw a ball at it. We had a couple cameras that tracked it, predicted the trajectory and the arm went up and would reach the ball. It got up to reach and grasp the ball and we got to about an 80 percent reliability level on that. One of the fellows in that project who designed the gripper was Akhil Madhani who is now at Walt Disney Imagineering R&D group designing really cool robots for Disney. We overlapped there in that he wants his robots to have human interaction as do we. So how do we manage touch interactions in a safe and attractive way? Akhil also designed an early prototype of a surgical robot which he called the silver falcon and then the black falcon, two generations, and ultimately those were let me back up. To Akhil's credit, he said from the very outset, Anything that gets invented here, we are going to share equally. So there is sort of no ego problem on the line. And this is always true with students, who gets credit for what? And I am generally pretty generous about that, but to have a student come forward and say, we are going fifty-fifty on this, is really great. And so he did design an early prototype surgical robot that some intellectual property from which was licensed to Intuitive Surgical, became their portfolio. Ultimately, Akhil and I became consultants with Intuitive. And ultimately, it was my relationship with Intuitive that got me to move back to California. I had a four-year sabbatical with them as I rekindled my relationship with Stanford and then ultimately moved from Intuitive to Stanford as research faculty. And ultimately that became joint in computer science and surgery. So, anything else at MIT?"
"Ken Salisbury","Interviewer","You mentioned wanting to work on this problem of the robot and people actually coming into contact. A lot of the things you mentioned have to do with touching getting balls, or grabbing balls, or touching more physical objects. Were there any particular projects that you were working on that had to do with direct contact with people?"
"Ken Salisbury","Interviewee","Yeah, some. Some. I like to explore things to see what really is the interesting problem, so one experiment we did was to develop the ability to shake hands with people. And the experiment was simple. We had somebody shake the hand, and we told them to have one of four different affective states. Be angry. Be anxious. Be inquisitive, or something. I forget what the four were. And they were somewhat thought out to span a range of emotional states. And we recorded some aspects of what they were doing as they shook hands with this robot, which happened to be a PHANTOM with a very simple hand on it, impedance of the motion, spectral components of how fast they moved, duration of that. And then we played those recorded behaviors back to another set of subjects, and had them pick one of the four. What attitude is this thing shaking hands with? And actually it was pretty accurate. I can not give you the numbers, but it was well better than fifty percent. Pretty simple sample, pretty simple paradigm that we were looking at, but it was sort of a hint that there is at least a simple communication that could go on through touch. Since then I have kind of developed a taxonomy, which begins with touching and being touched. So if you might want to play pat-a-cake with a robot, or just simply touch its arm and have it get out of the way, which are both safe things and also emotional. That it is not forcing itself on me, it is sort of accommodating to me. After touching and being touched, there is taking and giving. So if the robot is going to hand me something, how does it know when to let go? What does it sense about our physical interaction that gives it the confidence to let go and know that I am not going to drop my bowl of soup on the ground. And you can imagine all sorts of human customers that might need that ranging from people in a store to handicapped folks to elderly folks. Third level is leading and being lead. And so I might be using the robot to help me carry cinder blocks across a construction site. I am leading it. How do I get it to follow me, appropriately use its extra capabilities, strength, collision avoidance, other things, to follow what leading information I am giving it by pulling on it? Being lead kind of touches on the elderly, or impaired population, helping me find my way down the hallway. If I want to stop and talk to a friend or get a drink of water how does it know? So all of these involve touching and interacting and not just yes, no touching, yes, no force in this direction, but impedance, vibration, frequency content of the motion. That is totally open area. And there is probably more to that taxonomy not yet fleshed out. But that is one of my missions right now is to understand that vocabulary and the syntax of it. Try to sort out what we can so that the robots can be responsive and communicative in a physical sense with people. Okay?"
"Ken Salisbury","Interviewer","Alright. Great. You seemed to be thinking of whether there was something else, so."
"Ken Salisbury","Interviewee","Well, no I get into something and then I forget what the question was. You know I get on a thread That is like, Oh yeah this is cool. And then it is like "
"Ken Salisbury","Interviewer","Yeah, no They are all great. do not worry. So we came from we were going, I think, from MIT to how many well, we can look at that. Never mind that. I was going to say how many students have you had at MIT and that kind of stuff. But That is easy to check out. So when you were going from MIT to Intuitive why did you decide to kind of what were the specific problems that you wanted to deal with at Intuitive that made you want to make that switch?"
"Ken Salisbury","Interviewee","Oh yeah, no, perfect. Well, again saying I have always had an interest in dexterity and hands. And here was an opportunity to enhance a skilled surgeon's ability at a different scale. So technically, that was pretty interesting. Second, I had been working on a lot of moderately abstract aspects of this. How do you control it? How do you build it? Yeah, picking up rocks for now, catching balls, kind of gave us a hint of a concrete application. But here we suddenly had a couple guys, one dear friend from my freshman dormitory, and another very smart experienced medical entrepreneur who said, we are going to do this thing. we are going to take telerobotics and make it practical, FDA approved, and we are going to use it to fix people's lives. And for family reasons I wanted to come back to the West Coast, but I also saw this as an opportunity to kind of get on this train I do not know how to say They had raised 100 million dollars. They had made this commitment. we are going to do this amazing thing. And it was moving like a train going downhill. And I thought, okay this is an interesting and instructive ride. I want to get on board. I was, ultimately, was not a founder of the company. But I feel very happy that I was able steer them in some of their early decisions. And then help them make connections with really capable people and license some technology to them. So yeah, I was intrigued to have an opportunity to apply my fifteen, seventeen years at MIT of sort of developing a theoretical framework for doing these kinds of physical interactions, human-machine activities apply it and get some feedback. And also know when I had succeeded. When I saw surgeons performing heart valve replacements, I felt pretty good. You know it is like, okay, this stuff is relevant. And, of course, they had a huge team at that point who filled in all the stuff that I did not know anything about. I am pretty good a figuring out problems, but I am not always good at answering them. So That is why I work with students and colleagues who are much more deep in their particular disciplines. "
"Ken Salisbury","Interviewer","Did that particular application give you kind of new questions that you needed to answer?"
"Ken Salisbury","Interviewee","Sure. I mean lots of questions about how should I map a human's ability to control and need for receiving information into the activities of a remote, and not necessarily distantly remote, but maybe at a different scale, useful actions? So I work both on the master control end of this, developing the fancy joysticks that are needed to control the remote robot. I had some activity with the designing of the grippers, which are sort fancy laparoscopic tools. And was involved with lots of design reviews of the overall system and the performance. How much bandwidth do we need? How much dynamic range and force? And so it gave me a chance to apply things that I kind of knew how to do from my work at MIT, but did not really have a focus of application. And ultimately over some years that all came together, again with the help of a lot of really smart people and some good support from the VC community and a robot that could really surgery and ultimately improved outcomes. They looked at cardiac bypass procedures early on because that was thought to be a good market. Difficult market. Turns out it is hard to get behind the heart and do some of the other things. But you can at least avoid the sternotomy and get to vessels on the front end of the heart. And since then Intuitive has found other applications. The prostate radical prostatectomies, removing the prostate gland when it is cancerous, and other procedures which really capitalize on this really good human-machine interface where your visual and your haptic coordinates are co-aligned so that forward means forward, rather than the old style laparoscopy where you are pushing on a tool going into a body and over here the image is going that way. So it is difficult mapping between sensory input and motor output. So it is been exciting to watch that company grow. they have distributed a lot of robots that are doing real surgery frequently. So ultimately I wanted to come back to Stanford and sort of begin the next generation of robots, haptic interfaces, human-machine interaction, various combinations of those things. Began working on lower cost robots. I got a little tired of the elitism of the 100 to half a million dollar robots that were being sold to a few labs, and kind of wanted to get the cost of robots down to lower cost without giving up performance. And That is still a mission that I am on. I think we have got some good ways to do that, and I am excited about the next generation of those robots. Another thread that had grown out of my work at MIT was wanting to build multiple arm robots that were on a mobile base. And we started working on that here with Keenan Wyrobek and Eric Berger, two Ph.D. students with me at the time, and built a prototype, which became called the PR1, or Personal Robot 1. and then we started shopping this idea around to try to find support for the next generation. And after about forty pitches giving of the pitch to potential angel funding or sponsors of some sort, they found a really good donor who got the idea and saw the value of building a platform rather than building a three month explicit task oriented something, that we could really change the climate of this research community. And that resulted in Willow Garage. And They are going like a house afire. they have sent out ten or twelve robots to some of the really best labs around the world and have galvanized that community with open source software and a standard platform. And I think That is the tip of the iceberg. They are not sitting on their laurels with just those outputs. they have got more coming. And they have a very generous attitude. The open source component of it allows researchers from all over the world to contribute and have access to colleagues in slightly different disciplines. And instead of each camp developing and hiding its own developments, now we are starting to pull them all together through the ROS, Robot Operation System project. So, in my lab right now, it is a pretty tight group. I think we have eight researchers. One component of our work is in surgical simulation where we take scans, potentially multimodal, such as MRI and CT scan, ultrasound, infuse them into much more rich representation of the human head, in the particular case right now. So that you can see soft tissue and hard tissue and interactively try out different procedures. Like if you are trying to do a sinus surgery or a transsphenoidal resectioning where you need to figure out what is the best approach so that you can see what you want to see. Then they can rehearse that and try it out so that it should be familiar when they actually go into the real patient to do the work. And we are making good progress on that. We have not done clinical experiments with it. That is assuming some funding comes in that we think will, we will start doing some clinical experiments to validate that this is actually helpful. Surgical simulation, or surg-sim, has been around for a long time. And it is sort of been expensive and not very capable. there is not been a lot of success commercially. They have not become self-sustaining except in a few cases. So I am trying to make it good enough, capitalizing on better hardware, better algorithms, and some of our insights about where it should be applied, to really help it become useful. And part of the magic of being supported, computer science and surgery, is that I have access to people in both areas. And I am physically located between those two entities. So I have a number of surgeons, Dr. Nick Blevins whose and ear surgeon, Dr. Sabin Girod who is a cranial facial surgeon, neonatalogist Lou Halamek and a longer list. So we stay in pretty tight connection with people who have real clinical needs in this area, but also have enough of an understanding of technology that we can overlap and they can say, Well, could not we do this? And I can say, Well, technically this is possible, or not. So a lot of what I do is make connections with people who have abilities and people who have needs who can talk on the same wavelength. And so our surgical simulation work has been going on for quite some years now. And haptic rendering, there is some new breakthroughs on that so we can feel with better fidelity more complex interactions. The visual rendering, it looks like we are going to be making some progress on that. Surgeons really like to see how things look, the color, the change when you put pressure on a blood vessel an area with vascular flow through it, and other cues. So we are trying to incorporate these from either real patient scans where we can, or through prototypical models or morphing between the two. So and That is lead to development of next generation haptic interfaces. For the cranial-facial work in particular, we wanted really good fidelity so that the surgeon could feel the texture of one set of bones versus mobility of something else. And fidelity here means being able to sense or detect very small forces versus very large forces. And the wider that range is, the better dynamic range you have. that is a very important metric in these haptic interfaces. There are also spatial dynamic range, and then temporal h what kind of bandwidth. And so sort of finding what is the necessary volume within that three space should we design these things. That is kind of what we explore. And I am very interested in sort of making what I call high fidelity robotics, which means I want to expand that volume of capabilities and sort of make sure it intersects with practical needs as well as technical capabilities. So that is a mission that we are on now. So That is the medical simulation component of our work, covers some of the haptic interface design. And then on the robotic side, we are working on again high fidelity robots, or haptic interfaces. So really taking a fundamental look at that. We have some applications in more practical near term use, such as a telerobot for positioning ultrasound sensors on a patient while They are receiving radiation therapy. If they move and their prostate, for example, gets out of the range of the beam, you want to turn off the beam. So this is to give real time feedback to make sure that that works. And then that problem in spades happens if you are eradiating more mobile tumors, the liver, abdominal. And so you really want to track where it is and either steer the beam or turn it off when you get out of range. So it is a nice application of a clinical need that we had a sufficient technical solution to address. An example of the synergy that comes from mechanical plus computer science overlap, one of my students developed a technique for watching the image of fertilized embryos as they mature from a very primitive state to the more mature and how to say, robust form that . This is relevant to in vitro fertilization, initially. Where you want to implant the growing embryos fertilized embryos, as early as you can so they get into the right environment and mature healthily, but it is very difficult to tell was, previously, which of those would mature into a healthy next stage. And so using some computer vision techniques, he was able to track the maturation of these cells in multiple cases, and ultimately find predictors of survival maturation. That ultimately became a company cofounder looking at IVF. And you know he is the technical lead there. so it is one of many kind of happy stories where something came out of the blue because my students took the initiative to find somebody and realize there is this solution here, and applied in Kevin Milkey's case, applied the math and the mechanical abilities that he had to find a fundable, sustainable technology. Yeah a lot of my students have formed companies. Thomas Massie , going back to the PHANTOM, they whether it is because They are intrinsically that way, or because of my nudging, a lot of my students build devices that become platforms for other people. So the PHANTOM became really a worldwide standard for that. The WAM arm continues to be the arm that people use if they want force control ability. The surgical robotic stuff used by Intuitive Surgical, the personal robot activity now at Willow Garage. So I get a lot vicarious satisfaction out of seeing these things live on, rather than just disappear as the pieces on a shelf some place."
"Ken Salisbury","Interviewer","Do you get feedback from the communities that use them that also feed into your design at all?"
"Ken Salisbury","Interviewee","Two kinds. Yeah some people come back and say, Could you make it so it does this? And you know I try to assess that. Is this a population that really would benefit from this? Or is it a one-person need? it is always useful to hear people's feedback. Sorry there is another dimension to that which has slipped my mind. What was the question?"
"Ken Salisbury","Interviewer","It was how the feedback from people who use since your platforms are so widely used, whether the kinds of uses that they have or things that they say about them end up giving you ideas for more or further development?"
"Ken Salisbury","Interviewee","Yeah, so there are people who come back with very good ideas for further development or potential collaborations. I recently met a faculty member here, Professor Howe , who is developed very high fidelity spatial and temporal resolution tactile sensors. it is the first one that I have seen that makes sense for a robot. And it also has a lot of other applications where you might want to build a glove where you can track people's manipulation of things. And it is an example of the kind of synergy that works for me around Stanford. I sort of find people who are doing interesting things and say, You could apply it over here. I certainly get some category of sort of wacky people who call up and they say, Can we use your robot in a theme park in XYZ location, and make it throw balls in a contest. And I was like, Eh… They probably have a lot more money than NSF, but I do not want to go quite yet to the entertainment industry. I am interested in the human-machine interaction, shaking hands and all of that has sort of technical meat to it that I am interested in, but replicating something we have done for entertainment eh, not quite ready for that. "
"Ken Salisbury","Interviewer","Do you think if something like ROS had been available earlier in the history of robotics that there would have been faster development of it was really a problem over time of trying to transport code that you wrote from one robot to another robot, and reinventing the wheel every time?"
"Ken Salisbury","Interviewee","Yeah, maybe I mean we have certainly seen examples of the value of open source software, and sort of to inspire and cultivate communities to collaborate with each other. I mean eMax is one of them. Visual Toolkits. There are a lot pieces of in other disciplines of this kind of shared resource. In robotics I do not think it could have happened much earlier. I think it works with Willow Garage's work because they simultaneously have a platform so you can if you use ROS on this platform, you can compare apples with apples, and you can each share the developments of other researchers in your field. I mean Microsoft tried to do this. It did not work. It hasn't really caught on. And whether it is because it was improperly structured, or because there was not enough technical capability coupled with a decent platform, somehow we have crossed the threshold of where this can be done. You know some of the problems like speech interpretation, or image segmentation, object identification, grasp planning, there have been lots of little niches of that work. And so by saying look all you guys can share each other's work if you adhere to a certain programming interface applications API, applications programming interface. So it sort of provided a on one end, a common interface so that people could contribute and use and then at some lower level it takes care of some of the more difficult machine specific control needs, safety, stop when this overloads or this force overloads. Ultimately there could be collision detection built into that so that you just can not drive it into the wall. And it allows for incremental improvement. So your vision algorithm can now deal with specular reflection. Put that in and other guys can just update it and They are able to take advantage of it. So I think it really does galvanize and simplify some of this work. And I am not sure it could have happened much earlier. Partly because it was just technically possible, and I do not think the research world had gelled into the multiple disciplines that we talked about. And that it was technically possible to do this. And then the inspiration really of Eric and Keenan and their sponsors that this is worth doing. And it seems to be born out. "
"Ken Salisbury","Interviewer","The PR2, though, is once again one of those platforms that are very expensive and only kind of available to a small group of people, so is there any inkling of potentially making some platforms that are more widely available because then you could get more people in the community involved in development?"
"Ken Salisbury","Interviewee","Sure. And I think that is a great idea. I mean in the same way with the early PC being a platform. It was low cost enough that somebody working in their garage could get involved and develop spreadsheets and word processors and things that others had not imagined. Yeah, right now, I mean at least Willow has given away ten or twelve of these robots. they have seeded the research community and the industry to some extent with the platform. You know if you are making ten or a hundred of such robots, you do not get the economies of scale, but PR3 is going to look at that. I mean we here in my own lab and others are looking at cost reductions there is some interesting ways to do that, as well as performance enhancements, which I think is needed. How do get all the other parts ? it is a twenty-five degree of freedom robot. Yet, if you look at the cost of Townsend's WAM arm, which is a wonderful arm and has changed the face of this kind of research, that goes for slightly under 200 thousand, maybe 175. The Willow robot I do not think I am speaking out of turn, if you ask for a quote now, it is about 400 thousand, but instead of getting six of seven degrees of freedom, you are getting twenty-four, twenty-five, plus a community of people that are really sharing the work. So yeah, it is still not something your high school can buy and build a class around, or even a university and build a graduate research program unless They are lucky enough to receive one. And there are not many graduate programs around the current robots "
"Ken Salisbury","Interviewee"," is a chicken and egg. it is got to show some success to encourage higher quantity production of it, to enable broader community to contribute to it. And I think They are on their way to do that. They certainly want to make it available. And I think we have begun on a good spiral of that chicken and egg cycle to show utility, show desirability, increase quantity, maybe find some clever solutions to making it less expensive. The Willow Garage model, because it is foundation supported, it is not in itself a sustainable industry, except for the generosity "
"Ken Salisbury","Interviewee","So when I was at MIT I worked a lot on kind of basic aspects of robotics, how to use the robot hand to manipulate kind of a generic object, how to make an arm that could have good force control, a variety of other things, haptic devices that let you feel virtual stuff. When I made the transition to working with intuitive surgical, suddenly I was in a situation where they had a real commitment to making something that was clinically relevant and that was intriguing to me to kind of join up with some very experienced company builders who made a commitment and borrowed a lot of money to fulfill it, to build a robot that would really work on people. So it was very gratifying to be in a position to take this stuff that I had been learning and suddenly find it was very relevant and very helpful to this team. And so we have been doing that for four years, I had a lot of chance to see what was going on in the operating room, how the technology could make a difference, where it stumbled and not and also sort of the cycle of prototyping, of assessing your successes and failures and redoing it. That is the thing we do in design all the time but when you have got clinical applications in the loop where there is a cadaver or an animal or a human or other kinds of tasks, you learn something from each one. We had one experience with a I do not know if you want to use this or not."
"Ken Salisbury","Interviewee","So one interesting example for me in the design process in this sort of clinical venture funded environment was we were getting ready for clinical experiments with an early version of the robot and that I was working with the team developing the optic interface, the fancy joystick that controls the robot and the clinical folks said We need 20 of these things because we have got clinical starting in six weeks or something crazy like that and I kept saying We ought to build just one of them and try it out. They said No we need 20, go with your best idea right now. And so we built the 20 of them, within about 10 minutes, the doctor came on out, they were rubbing their wrists and just saying This is horrible, it just does not work. And we could have found that out in about a one week's effort of just building a mock up of the thing and letting them try it out, but the rush for sort of clinical relevance, the venture capital money, waiting at the door to be spent and proven that it was useful work, pushed us in the direction we should not have and so that really is for me has underlined the value of prototyping things and trying them out and especially in a medical environment, so there is just a lot of unknown unknowns that you can not imagine and we have known this in design for a long time but this really emphasized the value of that. There was a lot of money spent building 20 bad, not very good devices. The good news is I inherited all the parts from them, so we have lots of extra motors in my lab, so they got something out of it. When I came to Stanford I was interesting in medical simulation, I had done little bits of that mainly haptically as we began to discover that we could discriminate between many different feelings of objects and Doctors saw it and said Oh you could teach the difference between a tumor and a benign more elastic structure in the body. And so I got interested in developing surgical simulation, initially for training and at the time and even now it is kind of preaching to the choir when you talk to some doctors. To some it is like That is crazy, we want to do it the old way. And so I got more involved here, my appointment became with Dr. in the Department of Surgery as sort of half my time and the other half is in computer science, which is a perfect blend because I had the clinical coaching from the Surgery Department and a community to try out my ideas on and had the resources of the Computer Science Department. Even though I am a mechanical engineer, I can build gadgets but I guess I have enough sense to find other people to come in and really do the work that I think ought to be done and so that was a four or five year NIH project to develop simulations which worked pretty well. The visual rendering was good; the haptic rendering was good, not ready to turn into a company or a self sustaining technology. As much because the technology was not fast enough to do complex scenarios and visually and physically and partly because we are still learning what to simulate. One of our colleagues simulated knot tying, that is an intellectually interesting problem, but I can simulate that by getting a piece chicken meat from the grocery store and just doing it. So it is not a cost effective thing to do. So rolling ahead in time we began working with Dr. Blevins who is an Otologist, an ear surgeon and he walked in one day with a laptop full of gorgeous CAD drawings of the middle ear and other parts of the hearing system and it just really excited me that an MD was thinking that concretely about the shapes of things and how they look in different patients and that he had a good physical sense of what he wanted to do. He knew I was doing simulations so roll ahead five years later, we are still working together, he is actually done that procedure on my own son three times so I knew ahead of time he was pretty good at doing it because I had seen him running the simulation. It was a mastoidectomy which is a very difficult procedure to teach. You have to drill through the bone behind the ear, avoid some delicate structures and then go inside and do various things with a little tiny ossicles little tiny one millimeter bones and it is hard to train you can not do it on an animal model, cadaver bones are hard to get, you do not do it on a live person because it is so delicate. So it is very hard to do training in that demand. So we have been up and we have done some pilot studies with that, it is having some success. we are now I think on the verge of doing patient specific simulation for rehearsal and That is something the doctors are pretty excited about and I am too, I have an entrepreneurial head that says it is got to be self sustaining in some way and if the technology can improve the outcome of a specific patient, improve their efficacy and safety of it, then potentially FDA will go for it and in particular if it improves an individual's outcome, then you can start thinking about your insurance reimbursement, just like you would get reimbursed for a scan. So I think there may be a business model there. So we are embarking on "
"Ken Salisbury","Interviewee","So where was I, working with Dr. Blevins developing So with Dr. Blevins now we are starting to. With Dr. Blevins now and some of his colleagues, we are starting to take very high resolution scans of the head, both in CAT scan and MRI and then fuse those together so you could see different structures. The bony structures so we know it is there and them some of the softer structures so we can begin merging these two modalities to get a quite interesting, quite good fidelity scans and then one of my grad students has been working on the rendering algorithms to allow the bone to be removed, to allow much higher visual fidelity so the doctor can go in and practice the procedure and They are doing some interesting things to enhance their understanding of where They are going. They can dial up the transparency so they can start seeing structures outside of what is visible at the surface so they kind of get this superman view through the material. They can see what is inside, which sort of I think enhances their situational awareness for when they go in and do the actual surgery. So technically we are getting there, we are not ready to do human experiments although we are gearing up to do some cadaver experiments on that to see if it actually enhances the person's ability to perform the procedure if they have the rehearsal to try out."
"Ken Salisbury","Interviewer","One was working on these and how does for example working on a domain like medicine change how you think of designing devices for example or change your work, how does it influence what you do in a sense?"
"Ken Salisbury","Interviewee","I like to see things used and I like to find a niche where they will make sense to somebody so working with NASA was really fun, because I believe in it and I support them, but it is a 20 year project before something flies and I am a little more impatient than that. In a two to five year cycle you can develop a medical instrument that will go out the door and start doing real practical work. So medicine has been a good application area for me, also I think surgeons in particular I think very spatially, physically, they use different vocabularies so there is great communication between them and me, because I do think that way too, just use different words and use different instruments. So I mean there is this wonderful interplay we have the clinical pull, doctors want to do something and if They are technically savvy enough they can begin to say Oh can not you do this and there is the technical push where I know about lots of gadgets which may or may not be relevant to what They are doing but then there is this overlap and if you call it the low hanging fruit where we can actually merge their needs with our capabilities and outcomes, it is an interesting robot. We have one robot, students working on which will draw blood from a patient or do an IV insertion. The first he'd mentioned this I thought this is crazy, who is going to want a robot doing this, but it turns out that about 25% of IV insertions are failures and so you can do a lot of damage, a lot of pain and that there is a need for doing it more accurately. So he is combined a bunch of sensors, imaging below the surface of the hand, various touch and pulse sensors and developed a very interesting instrument that may well have some commercial applications, I am pretty intrigued to see how it goes. it is a fabulous instrument anyway. It kind of gives some of my more mechanically minded folks a better defined design criteria. If I just say build a better arm, some interesting things happen, That is where the WAM arm came from but we did not think exactly that we are going to do this task. But Rueben who is working on this IV insertion robot had a very clear goal, he researched it extensively, talked to lots of doctors, he drew blood from probably 20 of my students and colleagues, meaning using a needle to draw blood, not in some other way and took measurements of the motions of the forces exerted. So really got a nice understanding of what is happening clinically there and then use that information to like guide the design of the system. Sometimes opportunistic things happen and it is partly the way I work, I get good people in; earn a certain amount of trust and latitude. I have a certain amount of trust in, I give them a fair amount of latitude and a good example was Kevin Lokey he came in, mechanical engineer, worked on some different devices for us, eventually got interested in he got hooked up with the in vitro fertilization group here. I do not know how he met them or how they found him, but he started looking at the maturation of cells in fertilized embryos to see how they grew and how they might mature into something viable. I have already talked about this. I talk to so many people during the day. Did it sound the same though? Another one of my students got hooked up with a oh, I told you this one of the radiologist? I will go back to the beginning. Using ultrasound to track tumors?"
"Ken Salisbury","Interviewer","Yeah."
"Ken Salisbury","Interviewee","I did talk about that, okay."
"Ken Salisbury","Interviewer","How do they make these connections, I mean do the students, do you have any clue?"
"Ken Salisbury","Interviewee","They go to parties with doctors. No it is an interesting question, I mean we have a lot of casual interactions with doctors, I mean right adjacent to our lab is the bio design group and there are a lot of MDs who come through there evaluating the student's projects and we talk with them, occasionally my department chair, the surgery or other medical colleagues will introduce me to other ones. there is a lot of word of mouth connections that are going on here. we have sort of got a reputation for being able to do some interesting things, software/hardware wise and clinically relevant. So we do not hold problem finding seminars yet, I mean I could imagine doing that with a little more resources, setting up monthly lunches where people come and present a problem, we present the potential solutions and kind of a more mix of medical engineering mixers, I guess you would call it. Yeah I mean some problems; I guess I find them on my own. There is a company nearby that makes a robotic catheter for going inside the body and finding its way to different structures, less invasively and my students have done internships with that company and other medical companies, so they often come back with problems and one David came back with a problem of how do we improve the accuracy of a robotic catheter, a little snake that can move and twist and find its way through vessels in the body. So we sat down and started looking at what engineering analysis could we do that would contribute to improving the accuracy of that and that ultimately became his thesis work. it is kind of something I knew could be done but it needed some real attentions and analytical work and some experimentation, all of which he did, sort of like made it happen. I have been interested in improved haptics, today's haptics in the sense of good force feedback is generally three degrees of freedom, you can feel the force in three different directions on the tip of an instrument and that has been pretty exciting and pretty astonishing when you first feel it but we have gotten to the point now where we are interested in the six degree of freedom interactions. So if I touch a rigid object against a rigid object that the contacts are not just point contacts but They are line contacts, potentially surface contacts and so the interactions between these different geometries feel quite different. In particular if you are drilling into the head and you have a hole that you are going through, if you wedge like this, it should stop, it should just pass through and so this next generation of six degree of freedom haptic interfaces is starting to emerge with a very high fidelity one that we prototyped and again it was designed around doctor's needs. we are doing in this case we are doing craniofacial surgery so the student in that case Kurt Salisbury measured the doctor's movements and kind of figured out the workspace, measured some of the forces and kind of came up with the design specs that again were relevant to a specific task. So designing in a vacuum is kind of frustrating at a time because you do not know when you are done. Here when you have got sufficient quality out of it, you kind of have a sense, okay this is good, now we should go get using it and try it out to see if it really does the right thing and this for interacting with simulations of the skull for a craniofacial surgeon, on working when she deals with repairing trauma or congenital defects and sort of needs to interact with a 3D model that needs the fidelity of being able to feel the textures and fitting parts together and feeling the fit to be correct."
"Ken Salisbury","Interviewer","Have you done any interdisciplinary projects outside of medical work?"
"Ken Salisbury","Interviewee","Nothing really formal, but as I spoke about earlier, I am very much interested in communication through touch. For the medical bit here, we have been talking more about enhancing capability of humans and I always think in terms of human in the move, I think autonomy will come in some of these areas. But working with touch communication for example with the Communications Department, they have a perspective on how people feel about interacting with machines. If the door too quickly opens and it is an automatic door, people kind of feel weird about that and there is going to come a time when We will be physically interacting with robots and not just silly it is not silly but simple things like shaking hands or leading it along but cooperative working together if it is in a construction environment and it is helping me put up some wall board, will it sense my pull, my kind of leading the task or is it going to be kind of yanking it around. If the robot is moving through my building delivering things, food, medicine, tools, maybe just Googling for my missing screwdriver, I do not know. How should it react to me, I mean one thing is should it just look at me and acknowledge my existence so that I know that it knows that I am here that I am not afraid it is going to drive over my foot. Or if we really are in each other's way can it kind of gently move to the side if I nudge it, It will kind of react appropriately to that. So understanding those, like I said effective aspects of physical interaction is quite interesting to me. we are working with some folks at Disney, one of my former students again, developed a physical version of Wall-e from the movie Wall-e and it is a 300 pound, pretty powerful thing, it looks kind of fun, it is just like the real character, the movie character. But they want it to be able to have touch interactions with people, so again hand a child a bunny or take something from somebody and so beyond safety which is critical, making that an interesting and pleasant interaction. Could the robot act nervous when it first meets somebody, could it be really welcoming and say Oh come with me, I want to show you something. Those are sort of more character simulation ideas, physical interactions. Other fields, well I want to build a robot that can do magic tricks. If you look at dexterity there is a wonderful range from well I can imagine picking a lock which is something I like to do is totally by feel, there is no robot that can do that. There are some hardcore instruments that will just break the lock but so a human can pick a lock, they can also put a key in the lock, which is a little easier, they can grab the doorknob and turn it which is a little easier, they can open the door, which is a little easier. But in those four tasks we span quite a range of force control and position control and That is what I would call the dynamic range of the robot. So kind of a general goal I have is increasing the dynamic range of robots so they can do not just one category of tasks but a very broad range of tasks. In the robots industry and even some of the ones we have now tend to be kind of one trick ponies that can do something in a fairly narrow domain and this is what I am beginning to call high fidelity robotics. Finding what task requirements, what bigger, more important, more diverse tasks require and then technically how do we get there, how do we build a robot that has variable compliance or more sensors or finer quality motors or whatever and I do not want to build another gold plated robot, I want to do this inexpensively. We do not quite have the benefit of Moore's Law on the motor side, although sensing and computation is just exquisitely growing and helping us. But building mechanical system, motors and batteries are only increasing linearly rather than exponentially. So I am sort of jealous of my circuit is friends. But there are new motors and the MEMS folks and other electronic component designers are starting to come up with some pretty interesting devices that we can capitalize on. For example you can put an accelerometer, a little 3x accelerometer like what is in some of our cell phones and tell if the robot is scraping across a textured surface or impacting, it is a compliant surface. So there are some interesting components; in this case enabled by the air bag industry which made accelerometers really cheap. Those a couple of bucks and you can get a really high quality, high bandwidth accelerometer or you could put several of them on the robot and it can detect not only contact and quality of contact of material properties but also just the condition of the robot as if it is gears are getting dirty or something's start to wear and it is getting backlash, you can see all that in the spectrum of what is coming out or at least what I have hypothesized. there is some interesting new tactile sensors that are coming out of one of the labs here at Stanford which look to me to be the first practical tactile sensor. it is high resolution which is okay for certain tasks but more than that it is physically durable so that it does not fall apart as soon as you pick up something and have any excessive forces on it. I am actually with Professor Bao and I am trying to push her to make a surgical glove that has tactile sensors all over it. what is the point of doing that, well at the moment it is just to tell what people are really doing, how hard is a person pushing, how far did they slip, what is the distribution of forces between their fingers and I think we are on the verge of having that kind of technology available for monitoring the activity of persons, I think yet to emerge is the feedback side of it. If you want to have a totally high quality touch hand, you need to display something to the hand and how to do that is I think maybe a bigger challenge or at least it is an equally large task. And what is the point of doing this, well if you wanted to scale somebody's ability to deal with little tiny nerves that They are repairing, where the ossicles in the ear and you do not want to squeeze them excessively or you want to feel for diagnostic reasons the texture and the shape, could you do the kind of Fantastic Voyage image where you have scaled way down. we have done some experiments with just sort of simple one degree of freedom force scaling. I think we have about a hundred to one running at one point and you could touch a little piece of tissue and it felt like a giant piece of cardboard, so it was very interesting to kind of transform my physical sensations down to a domain that I normally would not be able to distinguish much in."
"Ken Salisbury","Interviewer","What about artificial tendons, artificial lumps, muscles, technologies that allow the kind of manipulation, movement of these systems, do you see changes in that field?"
"Ken Salisbury","Interviewee","Yeah, I am not a real fan of the term artificial muscles because it is sort of giving it more anthropomorphism than I think is right. I mean it is an actuator, or maybe it is just my engineering background but the question really you are touching on is Are actuators getting better, what is becoming available? And there have been some pretty interesting improvements in the quality of magnets, the strength of a magnet and a very small space you can get a very powerful magnet now and that has been driven by the motor industry and driven by other ones, it shows up in all sorts of places. But it means you can get more torque per unit volume or more energy through put in a motor per unit volume and the costs are coming down because there is commercial demand outside of this, our needs. Batteries, the power density or energy intensity in batteries is getting much, much better. You put little Lithium or Polymer-ion batteries that have huge energy entities compared to the old lead acid batteries. So that begins to offer well maybe a prosthesis with enough energy in it that I can do multiple degree of freedom grasping for a whole day without having to recharge it or just have one degree of freedom in gripping. And as we start building autonomous robots that are going roam the building doing useful things or patrolling or retrieving things, gives them some longevity. Materials are getting better, lighter weight, high strength to weight ratio materials and carbon fiber, other metals, other forming processes. So there is a lot of technology driven by higher quantity needs outside of robotics that we are trying to capitalize on. A great example is the cameras in our cell phones, you have got these little 2mm squares of good quality camera, why not stick that on your hand or in your fingertips so that you can what you are doing before you land on it. So That is why I kind of like it, I keep scanning technology and encourage my students to do that because we may find little bits out there that come into support our needs. Tendons, there are increasingly better quality synthetic materials if you are going to use tendons and They are a pretty good way to transmit force over a distance. If you think of high quality hydraulics, you can get up to maybe five or even ten thousand pounds per square inch in like a super fired aircraft. But the piece of steel you can get up to a couple of hundred thousand pounds per square inch. So in a very small area you can transmit a huge amount of force or power as in through put if you want. And there are materials better than steel now, some of the synthetics, Kevlar and Kapton and several others that again are driven by the sports industry, the high performance aircraft industry, lots of other places where they want good quality materials but we can again skim off the top components that help us a lot. I am going to go off on a tangent. there is a lot of interest in Japan especially but also in this country in building anthropomorphic robots and I am not sure That is the way to get to highly functional robots as quick as we want. I mean number one, the walking problem is the whole research problem in its own right. When we built the PR1, the first personal robot that we developed, we quickly said we are going to put this thing on wheels; we are going to let it go or enable it to go where wheelchairs could go. Because the world around us here has been engineered pretty much to accommodate to that modality of moving around. So mobility problem solved and then we could focus on putting enough sensors on it, putting the right kind of arms and creating a functional robot that could move and manipulate and use dual arm capabilities and have a good sense of platform all over it. So and the same thing with hands that we built hands with fingers, you could make them double jointed or you could do lots of different things that make them not anthropomorphic, you do not have to have tendons going back to the forearm, you can put very small high reduction motors in the fingers and make them work pretty well too. But I am known as a tendon guy or the cable guy because a lot of things I build tend to use mechanical tendons in them. The next arm/hand I would like to build is probably a forearm where you allocate the motor volume into the forearm and then have it actuate the wrist and the fingers and again I am not trying to be particularly anthropomorphic but just taking advantage of emerging materials and motor capabilities. we are working on a hand for DARPA right now, to help them with their need to diffuse or make safe IEDs and they put out a solicitation to build a low cost moderately high dexterity hand and I with one of my students who has the same last name, Kurt Salisbury won one of the contracts and so I am sort of back to what I did when I was an undergrad, when I was a PhD student, building another hand. we are trying to keep it really low cost and make it very durable and as a research project it is interesting in and of itself, but they have a clear set tasks, picking up certain kinds of objects, picking up a screwdriver, pliers, actuating a drill, digging around in a bag for objects."
"Ken Salisbury","Interviewee","So one of the side benefits that I enjoy about working on this new hand design for DARPA is it has the same goals, has durability, capability, low cost that we want for prosthetic applications and I am quite interested in developing upper limb prostheses for underserved populations. As a counterpoint, DARPA's investing three billion dollars in building a very high-tech upper limb prosthesis. And it is going to be an expensive arm. The population that can use it is going to be folks with military insurance and got a lot of money. Well, there are a lot more people who are farmers and machinists and other folks who have lost a limb who could really use something like that. So That is kind of getting dual use out of this DARPA work. And it is fun for me just to get back into thinking about hands again with some fresh ideas. I have got some new students working on it and They are challenging my assumptions, which is perfect. So that is a good project. we are also working on a low-cost arm. Low cost, high fidelity is where I am hoping We will get to. I do not know how to solve all the problems around doing that, but I think it would be a real contribution. I keep wanting to get robotics away from being the elite, corporate or university group that has millions of dollars or hundreds of thousands of dollars to spend on their hardware. I would like to get it down to like the PCs where in the early days, where people could run them in their home and invent new things."
"Ken Salisbury","Interviewer","What do you think are some of the obstacles to that beyond just maybe price, but in terms of getting the kind of non-experts perhaps involved in the development of robotics and in the development of what they actually want the robots to do?"
"Ken Salisbury","Interviewee","Yeah. So I could give you a parallel example. Computers did not really take off until somebody built a platform that people could interact with at a higher level. They could just write software. They did not have to go and wire wrap all the chips and make sure the power supplies were working. They could just write code. And if it did not work, reboot it and recompile and run again. So it got away from the technical people had to design it and let people who had sort of a application or product concept to work at a manageable level. Same thing in robotics. The long history of computer scientists trying to build mechanical robots and mechanical folk trying to program the things. And there is sort of this disconnect. That is not to say neither one is good in a cross-disciplinary work, but lot of my work has been in building platforms that then other people write code for. And once we get a good mechanical platform built, then there is the next level of writing a code layer that makes it accessible to a more average or not mechanical person. So the Phantom haptic interface is a good example of that. There was a code and now many layers of code that makes it accessible to completely non-mechanical folks. A very, very good example is the personal robot now from Willow Garage. they have developed a whole suite of open-source code which again allows people whose skills may be in image processing or physical planning or dynamic simulation and it allows them to share the work and also focus on doing their work rather than fixing the broken wires on the robot. I can not tell you how much time my grad students spent fixing broken wires. And so That is why I am kind of shy of complexity. Tactile sensors in the old days had gazillions of wires and they never worked for very long, if they worked at all. Always repairing wires. And so I am not trying to build commercial quality things that sell in Kmart yet, but I want them to be good enough that people can do the research that they want to do or even product development and not have to worry about the thing falling apart. So That is part of the answer of how you make it accessible to different populations. Reliability, low cost, software interfaces or API's that let people talk to it and not have to worry about the details. And then making their accomplishments portable. If I can run this bread-making algorithm on a PR2, I would like to be able to take the top level parts of that that do the planning and perception and move it over to the next generation or somebody else's robot, and so that the robot becomes an abstracted element and if it has the capabilities to execute the higher level code it can. And I think that kind of ferment of ideas and the support of the hardware, I think it is going to revolutionize robotics. it is really interesting to see what is happening with Willow Garage. Already you are seeing people do things with robots that you have never seen done before and it is caught the eye of a lot of people. it is not the only robot in town, but I think it is been a well planned program of creating a durable, rich or robust platform, coupled with a really aggressive software development environment. So you are going to see kids programming those PR2s in time. Just like the Lego robot's got that going. Got young folks and not so young folks accustomed to controlling electromechanical devices, sensors and motors and reacting to changing environments. that is a good start, but it is not rich enough to really do real tasks. A typical robot will wiggle its hands and everybody goes, Yeah, yeah, it is great. you are picking up something and putting it together, and if it drops it and recover, it has to be much more robust in its behavior than what you see in a Roomba or a Lego robot. I do not mean to deprecate those. They are good examples, but we need to move up to a level where the robots can start having physical interactions with the world. A lot of roboticists worry about the path planning problem. They do not want to touch anything by definition almost. They do not want to collide with anything. Where what we want to do is intentionally interact with objects, whether it is putting things together, opening doors to get through places or shaking hands. And that is an even more difficult task, to build a platform that other people can use, because physical contact implies energetic exchange, which implies you can do damage to the robot or to the person or both. So we need to be very careful in doing that. So things like covering the robot with a soft exterior greatly reduces the impact forces if you get hit with it. Just a little bit of rubber or soft material on the outside really reduces the injury potential. Making the arm compliant so that if you push on it, it gets out of the way is very important. And our WAM arm that Townsend worked on is very much an example of that. I got hit by it one time and it is low mass and was compliant and got out of the way and it was not a big deal. If you look at the PUMA robot, which is a very stiff, very non-backdriveable robot, if you get hit with one of those things it is not good. It has sharp edges on everything. Course, it was designed for industrial applications and I do not want to put it down. it is everybody's favorite robot to complain about and that it is everywhere. People have gotten a lot of good work out of it, but it is sort of an old style. And I think there are some new styles emerging that have controllable compliance. You can make your arm very stiff or you could make it very compliant depending on the task that you are doing. So being able to modulate that is a challenge that many of us have recognized as worth doing. How to do it is a good challenge. we have been able to do it in software by changing the gain so it is sort of soft or stiff and then you can put a peg in a hole by making it soft and stiff in different ways. But if we can do it mechanically by modulating the spring stiffnesses, and there are turning out to be some clever ways to do that, then we do not rely so much on the calibration of all the servo elements, all the potential failure modes of that, and it is intrinsically backdriveable. I do not have to wait for the computer to respond to the fact that I am pushing on the fourth sensor and having it get out of the way or having it not even notice that I am hitting it over here because it does not have a sensor downstream of where I am touching. Again, I am not trying to be anthropomorphic. There are a lot of qualities that humans have that we admire and are part of us functioning properly in our world, but there are going to be different ways to put those into robots. And robots will do very different things. The analogy of getting flight by flapping wings, that was tried and did not work. They had to deal with the physics in a different way and with the resources they had, jet engines and carbon fiber wings, and we can mock three or more and it is way different from a bird. Same thing with a robot. I can imagine fingers that have little conveyor belts on them, so to grab something and just runs into the hand, and rotating it means turning the conveyor belts the other way. Or I do not know. I do not know what it is going to be, but I think we really need to be open to those alternate solutions, because we have a different tool kit of things with which to build these new robots."
"Ken Salisbury","Interviewer","Do you think people are often kind of I do not want to say blinded, but in a sense limited because of this vision of, let us make it more human-like, let us make it more animal-like, let us make it like something that is already out there, or…"
"Ken Salisbury","Interviewee","that is a good question. there is certain subcultures within robotics that are very focused on anthropomorphism and the sort of simple but almost trite arguments are, Well, they should be able to accommodate to the environment that humans have designed around themselves. I think that could be accomplished without legs and without heads that look like heads. I do not know if you want to quote me on this one or not but…"
"Ken Salisbury","Interviewee","In Japan there is this great passion for anthropomorphic robots. it is huge. And I sometimes wonder if it was influenced by a lot of the folks were doing the work when they were children watching Astro Boy movies, a sort of Pinocchio-like character that was very strong in that culture and so they grew up and did this. I do not know what the American equivalent is. There are less of us interested in anthropomorphism, but R2-D2 was not very anthropomorphic but C-3PO was. If you are trying to have a interaction with a person where They are sort of immediately comfortable with you, should they even look like a robot or is that going to be scary? You look at what Pixar can do with just a little Luxo lamp. It had to be friendly and cute and there is a lot you can do just thinking about the motion and the color and the texture of it to make it welcoming, just like a car. I like to sit down in my car because it is got leather seat and it feels nice. It does not look like a horse I am not running, but it accommodates to what I like. I think there is going to be a time here when we work to make robots appealing and welcoming, just as we have done with many products. Chairs. it is not just the shape, it is the color, it is the texture, it is the motion that it has. Or lots of things in our lives. And so how to build them to be welcoming and also useful. it is got to be useful. Can we go to another thread here? there is some examples of products becoming acceptable to people when they were not acceptable. My favorite one is just simply putting color on braces. Kids used to hate to get braces and they'd be hiding their faces. Now it is like, Look. I got green ones."
"Ken Salisbury","Interviewee","So it is become a fashion trend. And They are anxious to get their braces at times. The Baby Boomer generation starting to need hearing aids. there is some that look like Bluetooth connections, so they look like cool guy with, his or her, cell phone. But in fact it is an amplifier so they can actually hear the person across the room. I do not know if this is going to be possible, but it is a direction I want to go. With prostheses, somebody who is missing an arm, they will tend to wear a cosmetic hand when They are in a social environment and they will tend to wear a more functional, a very old hook, the Dorrance hook or something like that. And it is very awkward sort of body image issue and acceptability. A lot of times people just do not want to use these appliances because it is better just to have your arm below to remain above the sleeve. Could we make those attractive? Could we allow individuals who need a prosthesis to be involved in the design of it, custom design? Get on your CAD system and tweak the shape, tweak the color, design it to be a tool that is useful for your particular hobby or interest, and then hit the print button and it comes out Kinko's down the street which has a 3D printer and you can get exactly what you want the way you want. So get people involved in the design of these things. But the bigger, the higher level thing, is making the sort of supplementary devices attractive and personalized. And I think robots are going to become personalized. And I do not mean just the cute little seal that they have in Japan that kind of is a companion. That is kind of interesting, but if something's roaming around my house, just fixing up things and I do not know if That is the killer app or not. I would like it to be sort of friendly towards me. A really funny example is my cat discovered how to turn on my Roomba and…"
"Ken Salisbury","Interviewee","So she would run over and whack the button and then watch it go around. She never rode on top of it but it was really funny. And she tired after some months of that game, but SmartCat toys is a growing industry by the way. "
"Ken Salisbury","Interviewer","Yeah."
"Ken Salisbury","Interviewee","That inadvertently was one."
"Ken Salisbury","Interviewer","We tried attaching a cat toy onto the Roomba. You know the ones that—"
"Ken Salisbury","Interviewee","Oh, yeah."
"Ken Salisbury","Interviewer"," flop like this."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","But yeah."
"Ken Salisbury","Interviewee","Did it work for a while or…"
"Ken Salisbury","Interviewer","They were not that crazy about it."
"Ken Salisbury","Interviewee","Oh. "
"Ken Salisbury","Interviewer","They are too old or something. I do not know."
"Ken Salisbury","Interviewee","This one was a young kitten almost."
"Ken Salisbury","Interviewer","There you go."
"Ken Salisbury","Interviewee","It was novel."
"Ken Salisbury","Interviewer","My cat likes to turn on the printer, because it goes through that cycle, it sends the thing back and forth."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","it is really exciting."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewee","it."
"Ken Salisbury","Interviewer","Yeah."
"Ken Salisbury","Interviewee","So I do not know what the human equivalent of that is. Yeah. Little kids sit in their parents' cars and they go, vroom, vroom, vroom, they pretend They are doing something."
"Ken Salisbury","Interviewer","But people are I think amazed by the Roomba as well. there is been some work where they have well, one they give them clothing and stuff, but they have also, yeah, they make clothing for Roombas. But people give them names and they have after a while of living with them, sometimes they found that they start kind of referring to them in social ways because they really change the way that even people go about cleaning or you have to do certain things for them, like move stuff around and kind of save them when they get stuck and all this."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","This kind of thing."
"Ken Salisbury","Interviewee","I think this is where we come to the communications folks who really study that. And others. Anthropological folks. There are others who are quite interested in those relationships. Even my GPS in my car, I tried to get it to have a voice that was sort of little more human, and that was okay. Now, I wish it would get kind of sassy, like if I missed my turnoff it would go, You missed that turn again. Make a U-turn very carefully this time. And That is going to happen. there is going to be a personality in these things. I hope it is more than Dave."
"Ken Salisbury","Interviewer","Well, Cliff is working on those, those kinds of things, right?"
"Ken Salisbury","Interviewee","Yeah. Yeah, yeah. And I think that could be good. It might be creepy to some people at first, but when it starts being responsive and novel. We see some of that on our computers. it is mostly annoying, but where they pop up some information now and then. They try to kind of be proactive in providing something. I think They are better versions of that. And also adapting to the way that we act. When I use my computer, there is certain websites I go to frequently and I wish it would sort of realize that, sort of prompt me in an intelligent way, fragments of that. Same thing with the robot. I do not know he is going to show up at the door with my newspaper or things that our animals do for us. As robots get smarter and more sensitive to our needs they may well be able to do that."
"Ken Salisbury","Interviewer","you have already talked I think a bit about the different challenges just now of what you think is coming and what kinds of stuff that you want to look at as well. When you look back at your career, what strikes you as a few of the most important contributions you have made or the things that you are most proud of or…"
"Ken Salisbury","Interviewee","That is good question. Well, in fact, I would not be where I am without my students. And in the end, They are the real product. They I think pick up some ideas with me, get some experience and then run off into the world and create companies and really make some interesting things happen. There are lots of example of my students that have just gone and done amazing things. And we have licensed quite a bit of our technology, some of which has gone to surgical applications. Some of it is gone to NASA applications. they have gone different places. So life after thesis is important to me, both for the people and for the concepts and the devices that they develop. If we look at particular devices, my robot hand, which was just kind of a fun, exciting project for me, has become an icon. I still get people call me up and ask me can I sell them one of them. I was like, No. we have gotten all we can out of it. Wait for the next generation. And yet that hand took on a life of its own. People would send me videos from all over the world and it is like, You can do that with that? And it sort of reinforced that, well, I had some pretty good ideas at the mechanical level, what functionality it should have, but I did not quite note what to do with all of that. I did write some programs. It could wiggle objects, but people went well beyond that. Same thing with the WAM arm. Had kind of a central idea of behavior and intrinsic mechanical capability and Townsend took that to be commercial and has done lots of wonderful things with it, his customers. And what else? The Phantom haptic interface apparently seems to have changed haptics. I am sometimes too humble about these things. I am sort of surprised maybe when I should not be that it is going to make a difference. Because you never know. You hatch an idea. it is like, Well, is this going to make a difference or not? I do not know. let us just build it and see how people react. And I have some amazing pictures of people feeling virtual objects for the first time with the Phantom. And it is like maybe showing a mirror to somebody who is never seen their own face. And like, Wow. there is something really different here. And people get bug-eyed and there is such whimsy in some of what we do here. it is sort of playful and yet it has real value to it. it is different. Makes it sort of seem novel, but it is different in a good way. The work I did with Akhil Madhani on developing early versions of surgical robots, which eventually got licensed to Intuitive Surgical, was very interesting. He came from a family of doctors and yet was very good at machining and making things and it just turned out to be another pivotal kind of design that helped hatch a new industry. Intuitive brought a lot of, certainly lot of, their own ideas to the table, but it was nice being part of that flow and feeling like I helped make things happen there. What else have I built? You probably know more than I do. Some of the robots my students are building now, the one for tracking tumors while radiation therapy is happening, it is sort of at the moment a narrow application, but it has a human in the loop and it allows them to enhance the quality of care that a person is getting. And that hasn't been productized yet, but I can see it eventually working its way into a real clinical use. I do not know. it is more on the software side, but at one point I got very interested in using these four sensing fingers and using them to detect textures, the presence of objects, the orientation of objects. And it is began getting me interested in the temporal quality of contact information rather than the spatial quality. And so even this simple little fourth sensing finger which was developed by Dave Brock, it did not become a long-term product but it was very pivotal in my understanding of what robots were doing. I saw that if you had high quality force sensing and controllability you could do a lot broader range of tasks. Oh, lost my thread. Yeah, okay. One of the funnest parts when we began using the Phantom haptic interface was developing algorithms for rendering the way things feel. And I sort of liken it to the early days of graphics. First graphics, what did you see? Well, after dots on the screen you saw lines on the screen. So you would see a wire framed cube moving around. That was pretty exciting at that time. we are just a little bit beyond that stage in haptics now. We can feel the shape of something, some texture, some compliance, but when you start getting fingers involved so you can pick up something and feel the size of it or the compliance of it you have added an order of magnitude, more capability. you have put two hands on it, so now I can pick up something and feel it this way. you have added another 10-time increase in the richness of what you can do. And couple of the algorithms that were developed early on, one of them that I liked was for rendering implicit surfaces. Very mathematically clean way of representing a class of objects and the rendering, deciding how much force to exert when I push this object, worked pretty well. And it was clean. I am not much of a complex algorithm person. I like a more simple insight That is consistent with my mechanical way of doing things. And that was pretty exciting for me, and that algorithm has shown up in lots of other people's work. Recently one of my students figured out how to run it with six degrees of freedom rather than just singe-point contacts. And That is kind of satisfying to see something That is 15 or 20 years old, a mathematical concept come back into helping him get his thesis and ultimately do some of the really complex medical rendering we are trying to do. Another example of early haptic rendering algorithms was some work done by "
"Ken Salisbury","Interviewee","Another example of an early haptic rendering algorithm that one of my students, Zillus , came up with, enabled us to render polygonal objects. So he just grabbed off the internet a geometric model of the space shuttle and then he came up with a method for determining what forces should be applied when you are touching this kind of faceted surface. And out of that came the idea of a reference point that lived on the surface of the object that you were rendering. And That is used throughout haptics rendering, yeah, and just a way of keeping track so you do not push through the object. You keep track of where you touched it and you have a reference point to bring it back to the surface. Two very simple concepts that have really broad application. And whether we get credit because we just did it first and happened to be lucky enough, in the right place, or whether we really had great insight, I do not know sometimes."
"Ken Salisbury","Interviewee","Sometimes it is like if you get there first, it is sort of obvious what to do. And these are sort of obvious things that we did, but we got to do them first and we got a lot of excitement out of it and fair amount of credit, which makes it kind of fun. Yeah. it is funny, because I have a list of people. Well, in some ways it is the people too that have come out of our group. Helen Greiner who was one of the founders of iRobot, just charged into that company and made it really go very well. And I recently pulled her thesis out. it is a little-known Master's thesis from MIT and it is got wonderful things in it, which I am handing to my students now. How to understand a curling finger so that it grabs onto an object in a mechanically smart way. Another woman who worked with me who has done many, several, astonishing things. Catherine Mohr, started out as a mechanical engineering student with me, one of the finest machinists I knew at MIT at the time, and she developed some interesting mechanical hands, little more theoretical than some of the other medically applied ones. But she spent 10 years in industry and then decided to become a doctor. She was good with her hands in the machine shop. Turns out she is a really good surgeon as well, so same skill kind of maps over to this new domain. She is now director of Intuitive Surgical's medical research program. And so it is sort of fun to have been with somebody when they were sort of coming out and figuring out what They are going to do and now she is changing the world. I should probably give more credit to the admissions department than to myself because they bring these wonderful people in the door and then I try to figure out who is going to be compatible and work with our group. Bill Townsend who is just had this great passion for building the WAM arm."
"Ken Salisbury","Interviewee","I spoke about the Phantom haptic interface. Well, the fellow who really got that off the ground was Thomas Massie. he is one of those guys that I worked with from early on freshman year probably. He came in with a stack of pictures of some amazing things he'd done in high school. I kind of worked with him for couple years. I had some interesting problem that I wanted to give him but sometimes you need to build trust before you hand over a good problem to somebody. And so I told Thomas I wanted to build a device that would let me feel objects on the screen, and he this is while he was still working on his Bachelor's degree and within six weeks he had a working model of the Phantom haptic interface and we were feeling virtual objects. And it is kind of a nice teamwork. I had kind of nudge him away in a certain direction and he'd come back and that kind of interchange or exchange with students is one of the really fun parts of this job. These days I do not go into the shop and make many things, but I like hanging out in this lab. I can walk over there, see 10 different gadgets, and these guys have gotten so good at building robots fast. I tease the world and say we build a robot a week, which we almost do. If you walk around the lab you will see all kinds of things with motors and computers connected to them. And That is kind of the spirit I like to have of having this intense culture here where everybody's kind of helping each other. we are not competing with each other. Although They are individual projects, each of the students is helping the other ones, so it is a really nice synergy that comes out here. Another one of my students who is had an interesting career, John Morrell, did some very nice controls work understanding, explaining, the fidelity of robots. And this will come back into my work on high fidelity robots, but after that he went to work for Dean Kamen's corporation, DEKA Corporation, and he would not tell me for five years what he was doing. And then out came Dean Kamen's what is it called?"
"Ken Salisbury","Interviewer","The Segway?"
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewee","So he worked with Dean Kamen for about five years and then came out with the Segway. Turned out John had been doing the control system on that, which is a really exciting and I think actually pretty practical. it is novel certainly, but it is making a lot of changes in some people's lives. And it is not just Joe Average wheeling down the street. it is folks who have some mobility difficulty or people, I have seen policemen, using them to cruise around. And They are really fun to ride. I do not know if you have ever ridden one, but it is a gas. it is just so well designed, and if the batteries get weak it kind of has a lot of human safety capabilities in it. it is very hard to do something wrong with it. that is another kind of nice success story. And then, course, there is the personal robot work. At times people say, Well, you are the grandfather of some really interesting things. I do not know what it is, but certainly I am proud to see the PR2 and how it is changing the world. It has some interesting mechanical concepts in it that I helped with. Eric and Keenan really did the lion's share of the really hard work and they continue to do that. But it had been a dream of mine for a long time to build a platform that was functionally quite good, and distribute it, give it away. Which they actually did give them away. And That is inspired a lot of people. So that is another device that ultimately did come from our lab here and has now taken on a life of its own."
"Ken Salisbury","Interviewer","Why is it a personal robot?"
"Ken Salisbury","Interviewee","Well, it is a counterpoint to the hydraulic 500-pound brute that can pick up car engines and has flashing red lights and cages around it. That is not a personal robot. you are not going to go shake hands with that puppy. it is perhaps a little bit of a bow to the word personal computer. Something you can have in your space and work with. it is not a card-munching UNIVAC with thousands of switches on it and you got to wear a white coat to operate it. it is something I can sit down at my desk or even carry around my hand now. So to make it a little more intimate with your daily life. The father of a friend of mine who is one of the early pioneers in computers spec'ed out one of the first personal computers. This was Wesley Clark. Not the military fellow, but a different fellow, who was at Lincoln Labs. And he spec'ed the first personal computer and one of the things he said that I love is it should not be taller than a human being. He sort of had a sense that it should not be imposing or threatening in any way. It should be kind of down at a human level. And I think That is true about robots. If you look at the PR2 it can kind of shrink down and be relatively un-intimidating. It can also stand up and be quite tall, it is function useful, but little things like that make a difference. And so it is trying to be personal. And you look at it, it is got a certain amount of whimsy. it is not a scary, sharp-edged thing. it is got nice, rounded corners. there is a nice bit of industrial design in it that makes it not scary. And it is designed to work in human environments. it is not something with tank treads That is going out to explore caves with explosives in them. there is great value to that too, but it is designed to be in our environment and there is great interest in that. I do not really think we know what the real application is going to be. Is it elder care? Is it factory box stacking? Is it finding things that I lose in my house? I think Eric Berger came up with this idea of a Googlebot, which would just spend its idle time going around the house and looking at stuff and then whenever you say, Where'd I put my glasses? it is like, Oh, it is over there. it is not entirely crazy. One of my dreams is to have a personal robot drive across campus and get me a cup of coffee and come back, primarily to watch people's reactions to it and kind of learn from that. Partly because it is technically challenging to do that. Let me say a little bit about what I think the future of robotics development is going to be. On one end of the spectrum we have got fully autonomous robots, and the Roomba is that, but its functionality is not really huge. Does good job at what it does. On the other hand, you have the fully human controlled robots, which tend to be like a telemanipulator, going into a nuclear environment, changing out fuel or fixing broken things. But in between there is this huge bit of territory, which is semi-autonomous or supervisory controlled robots. And just like airplanes, the first time they flew with a autopilot you did not have a 747 full of 400 people. They tried those things out over time, developed them. As trust and capability developed they finally got to a crossover point where they were willing to accept having people on the planes with them. So robots, we are not going to turn an autonomous robot loose in a factory and have it stack all the boxes, unless it is a highly structured system, like a factory automation. it is going to take time to trust the robot. So people are going to be in the loop. You look at the intuitive surgical robot. That robot is not stitching up the person all by itself and yet it is in some ways augmenting the person. it is scaling their motion, it is taking jitter out of it. it is bringing visual and haptic frames of reference to be coincidence, so it enables the person to be more effective. And so it is these little bit of inroads on autonomy, first for safety, next for maybe usability and then what is next? Well, if I am going to drive a robot through my interface to it, but I do not want to have to think about running over things, well, the robot can scan an avoid obstacles and can tell me I can not go there because the door is locked. Or next higher level might be, Go to these coordinates and if you need help, dial back to me and I will help you open the door or help you find the key. So there is going to be this synergistic relationship that I think is going to go on for a long time. I think it makes business sense in that we can get these machines doing something useful early on. And technical sense in that we kind of learn what is worth doing, what is possible. there is so many emerging technologies, I can not predict what sensors and what algorithms are going to be available to make this autonomous Roomba. And I am also impatient. I want to see my robot doing something soon. Yeah, it is great, but it is taken time to really understand how to do high level planning or to make judgment. Getting to Asimov's three laws. am not going to get there for a long time. But being able to disarm a mine with a human in the loop but enough machine capability to do it right. That is happening and that can happen better. Helping folks get out, people who can not get out of the house for whatever reason. But have them enabling them to have a remote presence so they can be back in society in some way. I think That is going to become attractive. People, what is it called, Taxi , from the mobile TV screen? And microphones and camera. People are beginning to dress them up. They put hats on them, they draw mustaches on them. They become sort of personal extensions of themself. I think more and more people are going to identify with these things and personalize them, and That is somewhere along the spectrum. I am not going to tell this robot to behave like me and go to a party. I am going to be there. Maybe I can not be there in all respects, so it is going to take care of not running over people's feet or getting itself there without my having to drive it there. So I love that future view of how robots and people will cooperate and We will each learn about each. Robots are not learning. Well, they are learning actually. In our own ways, we will learn to cooperate, and that'll drive the designs of them. I do not know if We will ever get to autonomous robots, C-3PO will make me dinner. that is a little far out there of me to predict if they will within our lifetimes. they will be doing very amazing things, and they already are, in surgery and a lot of other places. So maybe that is a good place to stop."
"Ken Salisbury","Interviewer","I think so."
"Ken Salisbury","Interviewee","I can do some card tricks for you."
"Ken Salisbury","Interviewee","I forgot my cards."
"Ken Salisbury","Interviewer","Collaborating with the robot hands. That would be something."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","Yeah."
"Ken Salisbury","Interviewee","I was reading a book on a fellow who only had one hand and he does these amazing card tricks. One of the reasons I read more than do about magic is it is talking about dexterity. Completely unconsciously, but They are just talking about, How do you make this thing disappear? How do you not make it show? How do you make it flashy? And so it is great fun, and I do practice in front of the mirror quite a bit."
"Ken Salisbury","Interviewee","The other thing I like, I do lots of things with my hands. I do pick locks. I am very interested in knot-tying. I have certainly learned some knots that are not very well-known. And I play the flute. And if we come back to the tactile sensors, the fine array tactile sensors I mentioned, my teacher and I have been just wanting to put touch sensors on people's hands so you could track the growth of a person's skill. If you are wrong, you squeeze too hard or you put sheer forces on it, and would make a very interesting Ph.D. project for somebody to sort of track the accumulation of talent in that touch domain. Because sometimes she looks at my hands and she can not tell why it is not working, so it has to kind of feel my finger or whatever. But anyway."
"Ken Salisbury","Interviewer","So I think in Waseda they have the flattest robot and They are really interested in doing this kind of more human-like, more individual feeling of playing rather than just the mechanics of playing?"
"Ken Salisbury","Interviewee","Okay. Where is this?"
"Ken Salisbury","Interviewer","Do you know?"
"Ken Salisbury","Interviewee","I have seen some of this but where?"
"Ken Salisbury","Interviewer","In Waseda University. They call it consay "
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer"," engineering and I know that there so I think, I do not, maybe it would be fun for them to hear that idea. Because I think one of the things that they seem to be really interested in is, How can we actually make something where it is not just playing these flat notes, that there is a feeling or a personality or the kind of specific individual playmanship that a actual human has when They are playing an instrument? My brother's a professional piano player."
"Ken Salisbury","Interviewee","Okay."
"Ken Salisbury","Interviewer","And sometime's he is forced to use an electric sort of thing and they used to be really terrible. They are a little bit better."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","They have weighted keys and they have gotten much better at the sensitivity of "
"Ken Salisbury","Interviewee","Yeah. Velocity and force sensing."
"Ken Salisbury","Interviewer"," the velocity and things."
"Ken Salisbury","Interviewee","Yeah."
"Ken Salisbury","Interviewer","But it is still like he does not, there is not that haptic feedback that you get from a real piano and the kind of vibration and the sense you get when you are actually playing the piano."
"Ken Salisbury","Interviewee","So the dual of that is these folks who want to build a robotic flute player. To me that sort of comes from the same place of people who want to make a legged robot. it is a really interesting technical challenge and it is impressive when they succeed, but it is sort of putting the cart before the horse in my mind. If They are developing better flute mechanics, which is a different research domain to get better quality sound on it, that makes sense. The electrical piano getting better and better so it can be truly expressive and a person can really think about the movement of the music rather than the mechanics of the keys, where with a flute, it is more an interesting study of biomechanics, I think, getting the ambature right, getting the air flow right, sort of understanding the physics of what is going on. That is the first thing they had to do, and I have seen that version of the robot. I have not seen the version That is trying to be expressive. And that seems like the long way around. If I wanted to make a robot that could jump really high, I would not necessarily put legs on it. I would use gas-powered pogo sticks or something like that. And if I wanted to make an instrument that was expressive, I would skip the difficulties of mechanical interactions and I had do just electronic production of it and work on the higher level issues of how do I make it sound interesting? If I am trilling on a song That is going slowly, it is very different from trilling on a song That is going fast. it is not just a mechanical transformation. So to get that to be aesthetically pleasing, you can look at all those problems without building an anthropomorphic finger pushing, mouth-twitching flute. Again, I do not want to deprecate the work. there is a lot of great engineering That is going on in that area and it is years since I have seen what They are doing. But if I were trying to understand expressiveness and presentation, those things, I would not impede that process by requiring fingers and robot mouths to do it."
"Ken Salisbury","Interviewee","There was a piano-playing robot around the time that I was working on my hand. I think it was from Waseda or one of the Japanese universities, and it could play and it could even scan with a camera the music and transcribe that into finger motions. And it was sort of interesting, When should I shift my hand? When should I just reach with my fingers? and it solved a lot of classic problems more in the mechanical sense that, What algorithms? Looking ahead in the music, what is the optimal shifting of my hands that I could do? But do you have to go so far as building a machine that actually has fingers to do that? Again, it is interesting and it is entertaining, but I do not think it is solving a deep scientific problem to build a hand like that, at least not directly. Maybe along the way you learn something about it. I have programmed my hand to play the National Geographic theme for a film that they were doing. It was really pretty easy. I just put it on each key and said, Play the sequence over and over, and it did it. was not very expressive."
"Ken Salisbury","Interviewee","But it worked. Yeah. The expressiveness that I am interested in, it comes back to the touching of the robot. That is meaningful if it is helping me walk or if it is helping me do a task or if it is serving me noodles or whatever. There is a reason to study that quality of interaction so that I am comfortable with it. Same way as designing a car. How should I design the steering mechanism with variable ratios so that I feel comfortable driving fast and slow and turning? So accommodating to humans' capabilities and enhancing them I think is a really good thing to do. But just trying to replicate them for replication's sake, yeah, I am not quite ready for that."
"Ken Salisbury","Interviewer","Unless you think there is something that we have not touched on that you would like to mention."
"Ken Salisbury","Interviewee","Appreciate that question. No. I have made the point about the students are really the real output. I think That is pretty important. And I am not the first one to say that. But it is something that makes me very proud. As I was going through my list of students and I go, Wow. He did this, she did that. Yeah. it is good stuff. we are all kind of on the same family tree now. Bernie was such a huge inspiration to me. I have had lots of good mentors. he is probably been the most significant one after my father though in just attitude about, You can do it, and you do not have to go in a linear path. You can kind of wander around in your thinking and let it stir in your head until something good comes out. And his just kind of gentle manner. he is not putting everybody on the Gantt chart saying, This is what you are going to do and I do not want you to think about it. Just be a soldier. He was very encouraging of some independent thinking and so certainly learned a lot from him. We go to Burning Man together too."
"Ken Salisbury","Interviewer","Right. Going to ask about Burning Man."
"Ken Salisbury","Interviewee","You want to get "
"Ken Salisbury","Interviewer","How long have you been going?"
"Ken Salisbury","Interviewer","Yeah, yeah. Was like, I know we had something that we did not have."
"Ken Salisbury","Interviewee","How much time you got for this one?"
"Ken Salisbury","Interviewee","Okay. For quite some years Bernie Roth was trying to talk me into going to Burning Man and he said, it is going to change your life. And I used to camp a lot and I am sort of up for kind of crazy things. So I went when my daughter graduated from high school. She and I went and camped out with Bernie and his clan of friends and it was life-changing. It was huge for my relationship with my daughter just to be in this crazy environment and we have a sign now that I have put up in the camp that says, Recess all day. And the other sign I put up says, Mistakes are okay. That is relevant to my flute playing. I get pretty anxious when I play in a formal recital, but in front of this crowd, I just, I played for half an hour and maybe everybody was drinking or half of them were."
"Ken Salisbury","Interviewee","Maybe I was. I do not know. But it was the first recital that I really, really enjoyed, just because it was this whimsical, free environment. I have been getting interested in making chimes. In the orchestra you call them tubular bells. They are not wind chimes but They are chimes. And I wanted to make an interactive musical instrument for people to play with, so I made these huge eight-foot long chimes and tuned them. My geek self went in high drive on this and tuned them really, really exquisitely and then bought an old swing set to hang them on and took it to Burning Man and hundreds of people came by and played these chimes. Some of them were really good musicians, there were gamelan players and there were percussionists and there were blind folks who came by and just kind of figured them out and lots of folks in between. I have lots of pictures of people with smiles just playing away on this. And next to my hand, That is probably the most satisfying thing that I have done. That is because I got lots of good feedback. People like it. They played with it. I made a toy that people played with, but it was sort of aesthetically pleasing and I put a lot of science into it and suddenly it worked. One funny anecdote. I had these chimes as I am tuning them hanging in the hallway in my house, in the stairwell of my house. And my son would come by and he goes, Dad, why do you have a stripper pole hanging in the stairway?"
"Ken Salisbury","Interviewee","How come you know about stripper poles? was my question."
"Ken Salisbury","Interviewee","And then I have three of them hanging there and he said, Well, Dad, now you got three of them. What goes? I said, Well, when you are at Mom's house you do not know what goes on here. Crazy stuff. But it was really fun. And I will probably do that again next year."
"Ken Salisbury","Interviewer","So have you been once or "
"Ken Salisbury","Interviewee","Four "
"Ken Salisbury","Interviewer","Four times."
"Ken Salisbury","Interviewee","Four times."
"Ken Salisbury","Interviewee","It changes."
"Ken Salisbury","Interviewee","And I love going with my daughter. it is just a time when we get away from our normal interaction modality. School is not there, the phone's not ringing and all this other stuff, and we really had a lot of fun. We get really close about this. And we still talk about it constantly. What are you going to wear next year? What are you going to make? Or Who can we invite? My son who is 16 is just dying to go. I will wait until he is 18. You need a certain level of maturity or experience to go there. And it is such a rugged place and you got sand and wind and dirt and it is crazy. But the adversity almost makes it good. You survive it and you are all in it together. you are all wearing your goggles and your dust masks at times. But it is a really good experience. I used to be in the Scouts and used to love camping and taking care of myself and being prepared and all of that. Well, you got to do that in spades when you go to this place. And so I feel pretty helpful. I love going around with my tools and helping people fix things that are broken. Their sculpture That is falling down or something that needs to be welded. So the gifting attitude is interesting too. it is not just, I will pay you this for that. it is, here is something I want you to have, and I am not expecting something in return. So it is sort of an artificial culture but it really works well. And it does echo over rest of your life. Just kind of questioning the way we do things and maybe being more generous, whether it is in spirit or materially. I do not know. it is really been a good experience. I have Bernie to thank for that as well, yeah."
"Ken Salisbury","Interviewer","Burning Bernie."
"Ken Salisbury","Interviewer","Weekend with Bernie."
"Ken Salisbury","Interviewee","Yeah. We were going to call it, yeah, Bernie Man we were going to call our camp. That did not stick. It became called Nice Nice for some other reasons. But yeah, it is a good group. And it is really eclectic. People do not their identity is not what they do. You rarely hear somebody say, what is your job? it is like, What did you see today? or Your costume's cool. What do you like to do? or I found this noodle bar. will not you come with me? And we get away from the normal social exchanges in a really nice way. I have no idea what some of the people I camped with do. I know what exhibits they like and the funny costumes that they like to wear in some cases and what music and stuff, so yeah, it is good in a very different way."
"Ken Salisbury","Interviewer","Okay. we are good. Great. Thank you."
"Ken Waldron","Interviewer","Okay. So if we could start by having you say your name and where you were born."
"Ken Waldron","Interviewee","My name is Ken Waldron. I was born in Sydney, Australia and most of my education was at the University of Sydney. I have a bachelor of engineering degree and a master of engineering science from there and I got my Ph.D. here at Stanford with Bernie Roth and I subsequently did receive a doctor of engineering degree from the University of Sydney in 1999."
"Ken Waldron","Interviewer","So how did you get interested in engineering to begin with?"
"Ken Waldron","Interviewee","I have often wondered about that. It seemed like a good idea at the time, I guess. I had a grandfather who worked as a draftsman at the Water Board in Sydney and he kind of fed me stuff when I was a teenager which I guess got me interested and then I got a traineeship from the Australian Steel Industry, which meant that I went to work for them on vacations and I got some salary and stuff like that so that seemed like a very good idea at the time."
"Ken Waldron","Interviewer","What made you decide to come to the States to continue your education?"
"Ken Waldron","Interviewee","Well, when I came to consider doing a doctoral degree, most advanced students in Australia at the time went to England. I was interested in things that people here in the States were better at than anybody in England and I did not want to do what everybody else did, anyway, so I wound up coming here."
"Ken Waldron","Interviewer","What were some of the things that the U.S. was better at?"
"Ken Waldron","Interviewee","Hm?"
"Ken Waldron","Interviewer","What were the things?"
"Ken Waldron","Interviewee","Well, at the time, it was mechanism and machine theory, kinematics and dynamics of mechanisms. There was hardly anybody in England working in that area at the time so it was much easier to find people here or in Germany or some place like that."
"Ken Waldron","Interviewer","When did you first meet Bernie Roth?"
"Ken Waldron","Interviewee","When I came here as a graduate student in 1965, June, 1965."
"Ken Waldron","Interviewer","How did you meet him?"
"Ken Waldron","Interviewee","How did I meet him? I think I had just arrived and I climbed up the big flight of stairs in engineering corner to his office on the top floor and walked in and said, Here I am. "
"Ken Waldron","Interviewer","Did you know him before you came?"
"Ken Waldron","Interviewee","We had corresponded in."
"Ken Waldron","Interviewee",".the area of research of system ships, yeah. He knew I was coming."
"Ken Waldron","Interviewer","So you came to be his student?"
"Ken Waldron","Interviewee","Yes."
"Ken Waldron","Interviewer","What were some of the projects that you worked on with Bernie in those early years?"
"Ken Waldron","Interviewee","Oh, well, my doctoral thesis was actually a topic I brought with me that I had been tinkering around with in Australia, which was in the area of mobility of linkages, just counting links and identifying how many degrees of freedom the whole assemblage would have based on its geometry. But, at the time, the really early work in robotics was going on, too, so I sort of got involved in that by osmosis. "
"Ken Waldron","Interviewer","So what kind of work in robotics did you see or get involved in?"
"Ken Waldron","Interviewee","Well, the last year I was here, Bernie went on sabbatical and I was put on as an acting assistant professor to teach his courses. At the time, Vic Shineman was designing the Stanford Arm and so I wound up being his advisor of record so I was involved in that project. Also, I was sharing an office with Don Piper and Mike Kahn at the time when Don was doing one of the first versions of inverse reg kinematics and I happened to know a good deal about the algebraic geometry involved so we talked about that quite a bit. So, you know, it was not my work but I got to contribute some ideas maybe."
"Ken Waldron","Interviewer","Who were some of the other people here who you might have worked with or exchanged ideas with?"
"Ken Waldron","Interviewee","Oh, Lou Pole was up in the AI lab at the time and I used the computer up there for my doctoral work so I spent quite a bit of time up there. let us see, who else? Oh, Vic Shineman I have already mentioned. There was a guy by the name of Spalding who I wound up essentially advising him for the year, too. I do not know where he wound up. that is about the lot. Salisbury was a bit later. I do not think we overlapped. Yeah, I think that is about it."
"Ken Waldron","Interviewer","Was there much robotics going on within the AI lab?"
"Ken Waldron","Interviewee","Oh, yeah. Yeah. There was shaky- not shaky but the old Rancho arm that shivered and shook while it was stacking blocks and stuff like that. That was really a lot of the motivation for the Stanford arm. Then there was the hydraulic arm that Bernie's students put together, which was a fearsome beast and terrified everybody. I remember one day, the guys who were working on that, and I do not remember their names now, one of the hydraulic valves stripped out its mounting screws and flew off and sprayed everybody with hydraulic oil, which, of course, was a very exciting event. There was up in that AI lab, which was a wood frame building, and this machine was quite heavy and very fast. The computer scientists thought computers are fast so it is got to be fast, which was absolutely wrong, actually, but, anyway. They had not got the interface between the mechanical system and the computer right so, every so often, the thing would just take off on its own and swing round. That lightweight building would kind of jump off its foundations. So one of the jobs Vic got was to cut a hole in the floor and pour a great big block of concrete to bolt this thing down to and they put an enclosure around it so nobody could get in there. But then they thought, well, most of the time, it just sits there waiting for the computer to make its mind up so why do not we build something that is a bit more user friendly. That is what turned into the Stanford arm project. Are you talking to Vic, by the way?"
"Ken Waldron","Interviewer","We talked to Vic."
"Ken Waldron","Interviewee","All right. So you have got all the story on that."
"Ken Waldron","Interviewer","What were some of the discussions at the time here about robotics and some of the possibilities that you can remember?"
"Ken Waldron","Interviewee","I think, at the time, we were kind of preoccupied with sort of the basic of computer controlled manipulation, how to get the machine to the position you wanted in some kind of reasonably controlled manner and how to perform basic manipulation tasks, you know? Things that, these ays, people hardly think twice about them. Back then, it was a big deal."
"Ken Waldron","Interviewer","Why the choice of manipulation?"
"Ken Waldron","Interviewee","Hm?"
"Ken Waldron","Interviewer","Why the choice of manipulation?"
"Ken Waldron","Interviewee","Well, the industry seemed to want that, okay? You know, this was the same period of time when Engelberger was building the first Unimate or had recently built it. That was doing simple industrial tasks like removing molds from die casting machines and stuff like that. Basically, it was just an arm that did simple tasks. Well, That is manipulation so that was the initial focus. As you, I am sure, know, Vic went on to design the Puma and some other kinds of manipulators in industry. So, at the time, that was the focus."
"Ken Waldron","Interviewer","What kind of mechanisms were you, yourself, interested in?"
"Ken Waldron","Interviewee","Well, back then, I was, you know, I suppose I did some theory on these manipulation tasks. Somewhat later, I went to Ohio State University and hooked up with Bob McGee and we started- he had already been doing leg machines and I got involved in that. That machine on the wall behind you was one of the things we did."
"Ken Waldron","Interviewer","So how did you end up in Ohio State?"
"Ken Waldron","Interviewee","Oh, well, that is a long story. After I graduated from here, I went back to Australia. I was in a faculty position at the University of New South Wales. My wife was, also. She is not Australian, she is Indian. I think she was a little uncomfortable there. We also have a child, our eldest child is deaf and he needed some special education opportunities. So we made the decision to come back to the States. In the meantime, We had done a sabbatical, part of which was spent at the University of Maryland. While there, I went and visited one of my old roommates from here at the University of Houston and discovered I was being interviewed. So I wound up accepting a faculty position at the University of Houston. After five years there, that was not working so well. Looked around some and what was available was Ohio State so That is where I went."
"Ken Waldron","Interviewer","What was the kind of work that you did at Houston?"
"Ken Waldron","Interviewee","I did not do any robotics there, I do not think. I did mechanism theory work there. That was one of the frustrations there, there was not the opportunity."
"Ken Waldron","Interviewer","So when you came to Ohio State, Bob McGee was already working in robotics?"
"Ken Waldron","Interviewee","Yes. He'd been doing that while he was working on leg locomotion. He'd been doing that since the late 1960s so that was about ten years before I got there."
"Ken Waldron","Interviewer","How did you get involved with Bob McGee?"
"Ken Waldron","Interviewee","I already knew him because I had met him at robotics conferences overseas, actually. I thought the stuff that he was doing was interesting so, when I got there, I made a point of going to meet him and one thing led to another from there."
"Ken Waldron","Interviewer","What was the first project you worked on together?"
"Ken Waldron","Interviewee","Well, I worked some on the old OSU Hexapod. I do not think I was ever formally a part of that project but, you know, tried to contribute well, I remember working out, for example, the final inertia ratio on the thing which had Black and Decker drill motors and a pretty large ratio gear box between the motor and the joint. So the reflected inertia was huge and I then did an estimate of how much energy the thing was wasting just coming to a halt and reversing direction every step. It was about six kilowatts or something. It was pretty impressive. And then, when DARPA came to talk to him about doing the big machine, which turned into that thing up there, and he needed somebody to look after the mechanical design, it was an easy step to put together a team."
"Ken Waldron","Interviewer","So what was the DARPA project?"
"Ken Waldron","Interviewee","Basically the fundamental idea was to build a vehicle for transportation in very rough terrain and, because of the limitations of wheels and tracks in those circumstances, they were interested in looking at a legged solution. And we were interested in that so That is what we did."
"Ken Waldron","Interviewer","What year was this?"
"Ken Waldron","Interviewee","That project started in 1981 and it finished up in, I think, 1990."
"Ken Waldron","Interviewer","What were some of the interesting questions for you?"
"Ken Waldron","Interviewee","Well, we worked, I think I could say, we reworked all the theory of statically stable locomotion. One of my students, Simon Song, and myself, particularly, did that. This book was basically Simon's doctoral dissertation with an additional chapter added that I wrote myself to provide a general description of the machine. I better get that out; otherwise, it will disappear forever."
"Ken Waldron","Interviewer","So what was the next big robotics project that you took up?"
"Ken Waldron","Interviewee","Well, after that finished, I am having a hard time remembering. I did some smaller projects. I did come here on sabbatical and was involved with Bernie and Ursula Katib in what he called the Artisan Project, which was a redundant robot that had both series and parallel elements and, in fact, I did a design for a parallel wrist for that robot. And Bernie and I and Monty Regevan wrote a couple of papers on the kinematics of mixed serial parallel robot configurations, which I think were fairly influential. And so that actually came into the same timeframe as the ASV work. And sometime, it was not all that long after that, that well, I continued to do mobile robot work, not only legs but also wheels and tracks. I had become involved in that and produced several student dissertations out of all that. And then I became department chairman and my research kind of slid for awhile. After that, I came here and did some more mobile robot work on joint DARPA and SAR I/C sponsorship. Did some more leg robot work, part of it was a project that I had brought from Ohio State on a dynamically stable quadruped, which is still over in my lab there. And subsequently I also did some dynamically stable biped work. Those are the major things that I have been involved in."
"Ken Waldron","Interviewer","How did you get back to Stanford?"
"Ken Waldron","Interviewee","I had a lot of friends here and I kind of asked Bernie if he could fix up a basically, a soft bunny position. I am called, well, I was until I retired, called a professor brackets research here, which was similar to what we called a senior research scientist at Ohio State. Well, as department chairman at Ohio State, I could have fixed a position like that in two weeks. It took 18 months here but it happened in the end. And I decided that That is what I wanted to do so I came out."
"Ken Waldron","Interviewer","Were there other people while you were at Ohio State that you worked with?"
"Ken Waldron","Interviewee","Yes. David Aran I worked with. Chuck Cline I worked with there. Gary Kinsel in my own department and Neger Bermais also in my own department. I think- oh, and then there were a couple of people in computer science we worked with occasionally, Bruce Whitey, who is the most active of those."
"Ken Waldron","Interviewer","What are some of the major contributions that you feel you have made through?"
"Ken Waldron","Interviewee","That takes some thought. Well, you know, obviously, the whole thing of statically stable walking machines, I did a lot of stuff on that. Earlier on, I did some work which kind of followed on from my doctoral work here on synthesis of planar mechanisms, which had nothing to do with robotics but I think was fairly important. Less important, but it still impresses people, there is several versions of the Hartenberg and Denavit notation that are used but the one that is most used was the one that I used in my doctoral dissertation. Again, it was before anything to do with robotics. I think, in terms of understanding the mechanics of dynamic quadrupedal locomotion, I think we are ahead of anybody else, including Marc Raibert. He has had great success in the walking and trotting gaits, which are symmetric and less baffling than a gallop. We have focused on galloping and we still I would say do not have a complete understanding but I think we know more about it than anybody else. Still writing papers on that. And I am sure there was a bunch of other things in between but well, did do some of the early work in parallel robotic architectures and I know That is still cited fairly frequently. And with Vijay Kumar, who was my student at the time at Ohio State, we did some very basic work on the coordination of multi-limbed systems which was very widely cited. Of course, he is had a very successful career of his own."
"Ken Waldron","Interviewer","How would you categorize some of the approaches that you have used to mobility?"
"Ken Waldron","Interviewee","I beg your pardon?"
"Ken Waldron","Interviewer","How would you categorize some of the approaches that you used over the years? So are you inspired more kind of mathematically or by actual biological mechanisms, a combination?"
"Ken Waldron","Interviewee","Well, I think, you know, my sort of roots go back to kinematic theory. That is what I first learned about in Australia and which I continued to study when I was here as a doctoral student. But I subsequently became involved in hardware design and I think I was successful at that and what is now called mechatronics. Did a lot of that with the ASV, a lot of it with other systems, even going back to the days of the Stanford arm long before it was called mechatronics."
"Ken Waldron","Interviewer","How would you say mechatronics relates to robotics?"
"Ken Waldron","Interviewee","I regard robotics as a subset of mechatronics. Mechatronics is integrating computers with mechanical systems of whatever description. A robot, of course, is such a system but there are other systems that we probably would not call robots which are certainly mechatronics systems like that thing there."
"Ken Waldron","Interviewer","So are there also, through your work, have you considered your work specifically on particular applications of mechanisms that you have designed?"
"Ken Waldron","Interviewee","Well, I have to say that, you know, my orientation has always been basic science. So I have not well, you know, I have gotten involved in some applications. But I would say that was fairly peripheral to what I do. I have used biomimetic inspiration, of course, at various times, certainly, with the locomotion work. But, you know, you use that to provide inspiration. You do not try to copy nature because we are not good enough to do that."
"Ken Waldron","Interviewer","And what are some of the organisms that you might have been inspired by for different projects?"
"Ken Waldron","Interviewee","Well, when we were doing the ASV, we had a collaborator who took high speed photographs of grasshoppers crawling over obstacles and stuff like that. So we studied that a lot. Then we had another collaborator who did experiments with goats, figuring out how they managed their legs and how they dealt with obstacles and how they those were the main things. And so, we and then more recently, of course, Mark Kokovski works with Bob Full up at Berkeley and uses a whole variety of animals from cockroaches to geckos to whatever. And, you know, we interacted a little on that, so a whole variety of beasties at various times."
"Ken Waldron","Interviewer","Who are some other people that you have collaborated with over the years ?"
"Ken Waldron","Interviewee","Former students or international? Well, I was the president of IFToMM for eight years. IFToMM is the International Federation for Promotion of Mechanist and Machine Science. And, you know, I have a whole bunch of people overseas that I have interacted with fairly intensively, people like Jorge Angeles who is maybe on your list of interviewees even though he is in Canada not the U.S. And people like Adam Morecki, who is no longer with us, John Vetou , who much earlier passed away, who was a very innovative person in the robotics area, did some very important work in France and Giovanni Bianchi in Italy, and several of Morecki's students, including Teresa Syolenska and a bunch of people in France, Phillipe Nadeau , Jean-Pierre Merlan . And some of my buddies in Australia are Jim Trevelyan is one, Hugh Durrant-Whyte and Gamini Dissanayake. And he is still a colleague. I spend time each year at the University of Technology in Sydney with him. So it is a whole variety of people."
"Ken Waldron","Interviewer","And who are some of the students of yours who have gone on to work in robotics?"
"Ken Waldron","Interviewee","I mentioned Vijay Kumar who of course has been extremely successful. Svay Swenovasim at the University of Texas has been enormously successful in building things like machines to replicate integrated circuits and stuff like that. So I guess he is not really doing robotics per se anymore. Who else? Samuel Aguele who was with me for a Master's degree and then switched to for his doctorate. he is been highly successful. And there is others, a number who have been very successful in the industry. And yeah, I am sure if I went down the list, I could find some more."
"Ken Waldron","Interviewer","Have you done any work with industries?"
"Ken Waldron","Interviewee","Oh, I have done dozens of industry sponsored projects, yes. I still got a little sponsorship from General Motors, for example, which, again, is not robotics. it is hybrid drive trains basically, the mechatronics fundamentally."
"Ken Waldron","Interviewer","Could you talk a little bit about some of those and what kinds of things the industry has been interested in over the years?"
"Ken Waldron","Interviewee","Yeah. Well, some of the industry work was the stuff I did with SAIC, which was basically mobile robots mostly not legged, mostly, you know, wheels and tracks. Then earlier than that, I worked with Martin Marietta Aerospace, as they called themselves at the time, in Denver. And we built a legged robot there, which was a for the potential Mars Rover Project before NASA changed direction and changed direction again. But back in the days when they were thinking of a fairly ambitious Rover project the large sized rover, we proposed a huge six or seven legged machine for that. And I did most of the mechanical design of that. They actually built a core to scale prototype and drove it around the box up there. And let us see, I have done some actuation work for industry. That was General Motors again. And that was polymer actuators, again a mechtronics project not a robotics project."
"Ken Waldron","Interviewer","And what other places have you received funding from? You mentioned DARPA?"
"Ken Waldron","Interviewee","Most of my funding has actually been NSF. I got more or less continuous funding from them for many years. And I have also I have not mentioned any of the Australian stuff. I got some funding from the Australian Research Council there with a colleague at UTS to build a robot to do inspection on steel bridges. And we still argue over whether that is a legged machine or a wheeled machine or what geometry it is. But, you know, basically climbing around truss work, It will have legs of some sort. And it will have some adhesion mechanism whether it is electromagnets or something, permanent magnets or something else. Again, it is something we are still arguing over."
"Ken Waldron","Interviewer","You mentioned that you did a second PhD in Australia. "
"Ken Waldron","Interviewee","Well, now it was not a second PhD. It was a doctor of engineering degree, which is one where you submit a compilation of your published work as a thesis. And it is examined by a bunch of people around the world. And that is kind of my ultimate degree."
"Ken Waldron","Interviewer","And you have been to obviously Stanford multiple times, so how has it changed do you think over the years, the kinds of directions people are taking there?"
"Ken Waldron","Interviewee","Well, back when I was here as a student, you know, the design division was very new and unstable, shall we say. A lot of the early faculty that either did not get tenure or did not stay for other reasons and Bernie was one of those young junior professors at that time who did stick. And as I say, back then, sort of robotics was a very new thing. The AI Lab did exist. And we have talked a bit about that. And I know you have talked to John McCarthy and he was directing that at the time. There was a whole sort of bunch of semi temporary buildings over there. My wife had an office in one of those. She was a PhD student in electrical engineering. And all of that has been bulldozed and replaced by the flashy new buildings and things like that. So the campus has changed a lot. The design division has gone from being new and unstable to being very well established in a central part of the chemical engineering department here. So That is different."
"Ken Waldron","Interviewer","What was Bernie Roth like to work with as a student?"
"Ken Waldron","Interviewee","Oh, I enjoyed working with him. At the time, he was a lousy lecturer. he is since become an excellent lecturer but at the time he was not. But he was I enjoyed working with him. And I have to give him credit. You know, he let me do basically a project that I brought with me from Australia on his funding. So that was kind of a unique situation. And actually, it was quite a long time after I finished and went my own way that we finally published a paper together. He is not an author on any of my early papers. Yeah, we are still good friends."
"Ken Waldron","Interviewer","And what were some of the challenges of working on mechanical design that happened over the years? And how have they changed from, you know, the accumulation of knowledge or from, you know, technological capabilities that perhaps were lacking?"
"Ken Waldron","Interviewee","Well, the whole set of technologies is usually called rapid prototyping happened relatively recently. And that makes an enormous difference. You know, a student can now sit down at a computer and do a solid model and put the model to a laser cam or something and build parts in a very short period of time. So it is so much easier to build prototype hardware. So we can think about, you know, building lots of prototypes to try out ideas and things, which you simply did not do back when building a prototype was enormously expensive and required lots of time. So all of That is different. And it has you know, you have to change the way you think because sort of back when I was a student, you would not think of building anything unless you had a really big grant to pay for all the costs. And now, you kind of do not do anything without thinking of building hardware."
"Ken Waldron","Interviewer","What were some of the challenges of like the parallel risks? You described sort of the hybrids systems."
"Ken Waldron","Interviewee","Well, at the time, nobody had really thought about the kinematic equations for those things and how you would control them because, you see the way you the mathematics works for parallel systems is fundamentally different from the way the mathematics works for a serial system. And what is easy in a serial system is difficult in a parallel system and vice versa. So putting them together in trying to run a system that had both features at the time was something that nobody had explored. So we had to roll up our sleeves and I think do some pretty fundamental stuff to just work out how you would indeed do that."
"Ken Waldron","Interviewer","What do you think are some of the outstanding challenges or things that people are still kind of questions that are important to ask in the next, I do not know, five, 10 years?"
"Ken Waldron","Interviewee","Oh, where to start? there is so many of them really. You know, the one that always frustrates me is actuation. And I have done quite a few projects myself trying to improve that. But, you know, fundamentally, things like electric motors are rotten. If you compare them to what we can do, you know, biologically, They are pathetic. And yeah, hydraulic actuators are much stronger and very quick and all that. But they have a whole bunch of problems themselves including being very wasteful of energy. And when you think about it, a muscle fiber converts chemical to mechanical energy in a micro mechanical package. And we can not even remotely approach that. Our usual way of converting chemical to mechanical energy after all is a heat engine. And so, there is enormous scope for things that we can not yet do. The whole thing of human interactive robotics, which I know is a very hot area right now. But yeah, we are not very good at that. That is some very fine stuff over there. Essentially, making the mechanical system so the different it whaps you. It will not kill you. It will hurt but, you know, maybe you do not have to fence the robot off. But really, the what is missing is the massive paralleled sensing that we have and the ability to process all that information. If you have that, you probably would not need to make the you know, the robot soft. It would be smart enough not to do things that would damage people. But we are light years away from that life. And I know there is going to be a lot of government funding and a lot of research effort going to that. And We will see what happens. But I think we have got a long, long way to go."
"Ken Waldron","Interviewer","What are some of the big breakthroughs that you have witnessed over the years?"
"Ken Waldron","Interviewee","Well, the first and biggest was simply the integration of computers with mechanical systems, which changed the landscape enormously. And before that, you thought in terms of building a machine with a single big motor, turning it and coordinating everything mechanically. And nowadays, the game is you individually actuate joints and coordinate them in software. that is a totally different way of doing things. So that was important. I have already mentioned the rapid prototyping development and of course computer aided design or computer aided engineering of all sorts. It all happened during my career. So that was a vast change also. Back when I was doing my doctorate, you know, you did a lot of graphical computation. That was very rapidly taken over by computer aided design type software. And it was, in fact, a very interesting problem, learning to use that because the best ways to do things in the computer are not the same as the best ways to do them with a pencil and paper."
"Ken Waldron","Interviewer","Did you ever run into Regina when you were here?"
"Ken Waldron","Interviewee","Oh yeah, I knew Regina quite well. Not here. I knew her at UPENN and of course, subsequently at Berkeley."
"Ken Waldron","Interviewer","Did you ever collaborate on anything with her?"
"Ken Waldron","Interviewee","Not really. We did talk a lot for a while on and of course she hired Vijay. And yeah, there was a vivid of conversation but I do not think any formal collaboration."
"Ken Waldron","Interviewer","What was the conversation about?"
"Ken Waldron","Interviewee","Well, of course, she is more of a perception person. I am a mechanical systems guy. And she was, at the time, interested in bolstering the ability of her lab to do mechanical things. And Vijay was one person who early on helped with that. Lou Pole , of course, was there at the time but he had gone to the dean's office and is no doubt busy with other things. Zho Ping , who is now at the Naval post graduate at the School at Monterey, was there early on and working with her. So, you know, I knew all those people and talked to them. But that is about as far as it went."
"Ken Waldron","Interviewer","Okay and if you had some advice for young people who might be interested in robotics, particularly, perhaps in the design, what would it be?"
"Ken Waldron","Interviewee","Well, I think, you know, robotics has always been kind of a difficult animal to deal with because it does involve so many different technologies in an integrated way. What I advise my own students to do here is to take all the mechatronics courses they can get hold of, and there is a good series here, and then to do the, you know, basic robotics course sequence to get the fundamental mathematics and stuff. And there is also we have good computer vision courses, which I advise them to do. But, you know, the world's changing. I am not sure I can tell them what to expect beyond a year or two after they graduate."
"Ken Waldron","Interviewer","And what was Vijay like as a student?"
"Ken Waldron","Interviewee","Oh, Vijay. was wonderful. You know, I did not work with him like a student. I worked with him like a colleague. And, you know, I suppose I put the problems before him. But he'd go away and come back with a solution kind of thing, you know. He was fun."
"Ken Waldron","Interviewer","And are there any other stories you would like to share?"
"Ken Waldron","Interviewee","There have been other very good students too. Jim Schmiedeler who is now at Notre Dame, was another student like that who was great fun to work with. More recently, Alex Perkins who is now at Boston Dynamics and Paul Csonka who is about to graduate, have all been very fun people to work with."
"Ken Waldron","Interviewer","This is all we have unless you have something you would like to add."
"Ken Waldron","Interviewee","No, I think I am about bled dry."
"Ken Waldron","Interviewer","I hope you will revive very quickly . Thank you. Thank you very much."
"Ken Waldron","Interviewee","So this will be in the"
"Larry Matthies","Interviewee","Okay, I was born in Saskatchewan, in the town of North Battleford in Canada. I was the oldest of five boys, so I did my education up through Bachelor's degree in Saskatchewan. Then I went to the University of Waterloo for a Master's in computer science and then Carnegie Mellon for a PhD in computer science."
"Larry Matthies","Interviewer","And how did you get interested in computer science?"
"Larry Matthies","Interviewee","Actually, when I was in grade 12, I took the grade 11 level computer science class and up until that time I was interested in chemistry. And I just enjoyed programming, I found it a fun challenge, decided to try that in the university and never looked back."
"Larry Matthies","Interviewer","Who did you work with at Carnegie Mellon?"
"Larry Matthies","Interviewee","I started with Hans Moravec but he was not in the computer science department per se, he was in the robotics institute. So I needed to have a computer science professor as a co-advisor which was Takeo Kanade and then along the way I switched from Hans Moravec to Steve Schaffer but still with Takeo as a co-advisor. So in fact, Takeo was really my main mentor all the way through."
"Larry Matthies","Interviewer","What was your first sort of project with. as a graduate student?"
"Larry Matthies","Interviewee","I was working in Hans Moravec's mobile robot lab on stereovision for autonomous navigation of ground robots. So there was a problem of trying to estimate the motion of the robot as it droves the environment by using the imagery to track features in the scene and so I made improvements to that algorithm. And at the time I did not actually believe that that was the most important thing to be doing but it is turned out 30 years later that That is now called visual odometry and it is actually very valuable and very widely used and many people have worked on the problem since. "
"Larry Matthies","Interviewer","How did you get interested in vision?"
"Larry Matthies","Interviewee","Actually as an undergrad, I got interested in artificial intelligence and then for my Master's degree I ended up studying computer graphics. I still wanted to do artificial intelligence and I thought the best places to do that were the big schools in the US that were doing that, so That is how I ended up at Carnegie Mellon. In my first year at CMU, I got a little disillusioned with artificial intelligence but computer vision still had some of the same appeal but it had also some of the appeal that I had found in computer graphics. So I tried that and in particular, Hans was working on computer vision for robots, so that was exciting and I enjoyed it. So that appealed to me because it had some of the same visual gratification you get from computer graphics but it had a strong theoretical foundation which I was looking for as well."
"Larry Matthies","Interviewer","about AI?"
"Larry Matthies","Interviewee","Pardon me?"
"Larry Matthies","Interviewer","What about AI disillusioned you?"
"Larry Matthies","Interviewee","Well, at the time, you know, I do not wanna be unfair to the field but at the time AI was kind of a collection of problems that we did not know how to solve yet and once we knew how to solve them they were no longer considered AI. And the very fact that we did not know how to solve them meant we did not have a good theoretical foundation in some cases, at least not a strong mathematical foundation. And so at least the particular things I had been looking at at the time I was not happy with the degree of theoretical basis to them. So in computer vision, it is really founded in strongly in physics and mathematics and you know, much of the curriculum you would find in electrical engineering for example. it is pretty cross-disciplinary in that respect but it draws on engineering and applied math disciplines quite a bit."
"Larry Matthies","Interviewer","So what year did you get to Carnegie Mellon and what kind of systems were you working with as far as the vision of computers?"
"Larry Matthies","Interviewee","I got there in the fall of 1981 and I started working on vision in the fall of 1982. When you say what kind of systems?"
"Larry Matthies","Interviewer","Like what was the technology like that you were working with?"
"Larry Matthies","Interviewee","Well, as a robot to do the vision work with, we had something that looked like a little tricycle, about the size of a tricycle. And we were working with computers that. I do not remember exactly what we had then but I think the VAX 1170 might've been about the right timeframe. And they did not have a lot of memory so they'd been a lot of work, you know. And years just before then in writing vision software packages that could swap images in and out of memory so that you could actually process something in reasonable amounts of time. So things were a lot slower. There were central mainframes. The PDP 10 that the department had that, I do not think we did much of the research on but you know, everybody had terminals. We did not have, you know, your own desktop computer in those days. The kinds of cameras that we used, this was before solid state cameras really. So, I think Vitacom's, basically a much lower quality imaging device than we have now. You know, I work on vision for robotics, so it is multi-sensory problem so you are combining the vision sensors with inertial sensors. In those days, inertial sensors were big and heavy and very expensive. So you basically did not use anything but the cameras. That is kind of a quick overview I guess."
"Larry Matthies","Interviewer","And where did you go then after Carnegie Mellon?"
"Larry Matthies","Interviewee","After Carnegie Mellon, I came here. So I came here in 1989, I have been here ever since. And I did a lot of interviews when I graduated, 12-14, including universities, federal labs and companies and what I was enjoying at CMU was robotics for outdoor applications. So I was looking for a place to do that and this was basically the best opportunity to do that. I was not necessarily interested in space per se, but once you get here, it is nice to have a ringside seat on the space program and it is certainly exciting to work on space applications. It so happened that I dropped into a perfect niche for me. The research I had been doing was exactly what was needed for Mars rovers at the time and it is gone to Mars since, so it is really panned out well in that respect."
"Larry Matthies","Interviewer","I am curious, since you mentioned you were in field robotics, at the time at CMU did they have a field robotics lab or what kinds of labs do they have, in particular, the ones you worked in?"
"Larry Matthies","Interviewee","So I was in the computer science department. I think the robotics institute was founded a year or two before I got there, 1979 or 1980. There were some smaller labs so Hans Moravec was running the mobile robot lab. This was before the field robotics center, before the term field robotics had been popularized and Red Whittaker who started the Field Robotics Center and I think there is two institutions there but anyway, he was still a professor of civil engineering and I think while I was there was when the Three Mile Island incident happened and that was a big thing that propelled him along in robotics and the DARPA Autonomous Land Vehicle Program happened while I was there and I think Red was involved in building up testbed vehicles for that. So basically Red grew in mobile robotics while I was there and I think FRC got set up while I was there, toward the end of my time there or maybe just after, I can not remember now."
"Larry Matthies","Interviewer","And is that when the term started to become popular?"
"Larry Matthies","Interviewee","It probably started then. I think it grew probably through the 1990s, as, you know, Red and others were addressing field-type applications in space, military and mining and agriculture. "
"Larry Matthies","Interviewer","What were the big challenges for field robotics as opposed to just mobile robotics?"
"Larry Matthies","Interviewee","Well, there is basically a contrast of people working indoors on level floors where there is only two types of terrain. there is smooth level floor and then there is discrete obstacles. You can represent the world in two dimensions and do all the path planning in two dimensions. Weather's always good, the lighting's always good, whereas in field applications, you have got uneven terrain, you have got ground cover, you have got different soil types that some of them are drivable, some of them are not. you have got a variety of lighting conditions, you have got a variety of weather conditions, you have got dust that can foul the sensors or you can not see through. You have to represent the world at least in 2-1/2D if not in 3D. You have to make inferences about physical properties of the world that you do not have to bother with indoors. it is a more complex problem. it is more expensive to work in that domain. You know, typically, you need a bigger robot, you need just a lot more logistics and infrastructure to do field applications. So, it is not studied as much or fewer places have the wherewithal to do that."
"Larry Matthies","Interviewer","And how did those play out in your first projects at JPL?"
"Larry Matthies","Interviewee","When I got here, NASA and JPL were working on a program called Mars Rover Sample Return. So the acronym was MRSR, the vision was to do a sample return from Mars. They had a fair bit of money. Actually, CMU and JPL were funded under that program so JPL was working on wheeled robots with stereovision. We had quite a big robot that was. I am not exactly sure of the size but it was probably 15-20 feet long and to the top of its camera mast it was probably 10 feet high. And Carnegie Mellon was working on alternatives, basically a legged vehicle using laser range finders. So we had quite a bit of money and a big team to do field work and the field work that we did was. there is a dry river wash next to JPL called the Royal Seiko so we would load up the vehicle on the trailer and go out there and do test runs. So. I do not know what the budgets were but that takes a lot of financing to run that kind of experiment. Compared to working indoors, you know, you buy a little robot two-feet in diameter and you know, work with one or two grad students and that is all you need. So, you know, very much a difference in scale between what you could do in a university or at least most universities and what you could do at a federal lab or, you know one or two companies like Martin Marietta that were working on that at the time."
"Larry Matthies","Interviewer","What were the challenges of the vision system for the sample return mission?"
"Larry Matthies","Interviewee","The algorithms were very, very slow. So, you have to have 3D perception since That is how you could, you know, determine the. where the terrain was smooth enough to drive and where the obstacles were and so we were working on that with stereovision and was working on that with laser range finders. The stereo algorithms were very slow so one of my first big breakthroughs was designing a new stereovision algorithm that had much better computational complexity and basically reduce the runtime from half an hour per image to six seconds per image. So that was a huge breakthrough at the time and feasibility of outdoor robot navigation."
"Larry Matthies","Interviewer","Did you work a lot with CMU still at the time or?"
"Larry Matthies","Interviewee","Not directly. You know, we were funded by the same sponsor, working on the same kind of mission but we were working independently. Since then I have had collaborations, you know, in the 22 years I have been here, had collaborations with CMU people a number of times but when I first got here, it was not directly collaborative."
"Larry Matthies","Interviewer","What were some of the later collaborations?"
"Larry Matthies","Interviewee","I may not get these in the right order, or at least chronological order but CMU managed to get funded by NASA to set up an organization they called at the time the, I think it was the NASA Robotics Engineering Consortium. it is now called the National Robotics Engineering Consortium and so that was a vehicle to try to channel NASA-funded research into commercial applications and there was a mechanism where while you could propose joint projects, you know, between say us, CMU and the company that would try to take a piece of NASA technology and spin it into personalization. So, I worked with Sanjiv Singh on a few things on that and then along the way the Army Research Lab has funded a program called the Robotics Collaborative Technology Alliance and so I have collaborated a little bit with Marshall Abert along the way on that. Al Kelly was a grad student. let me think. DARPA had a program called Demo II. So, we and CMU were part of the Demo II program working on different parts of the problem and so we collaborated a little bit there and I hired Al Kelly for one or two summers as a student to bring his path planning capabilities and merge it with our vision capabilities here. And after that, that was taken to. I do not remember if it was still Martin Marietta then or Lockheed Martin but taken to Denver to put on the robots for Demo II. We worked some with Tony Stentz who does a lot of path planning work as well. I am probably forgetting people but those for me personally have been the most direct and the most substantial collaborations. "
"Larry Matthies","Interviewer","So we heard a little bit of history about the sample return sort of getting cancelled and then evolving into the other Mars builders . So, were you working on those and were any of those systems that you worked on supportive to that?"
"Larry Matthies","Interviewee","Well so the Mars Rover Sample Return program, I was working on when I first got here and I do not remember exactly when that got cancelled but it was fairly shortly after I got here. You know, within the first two or three years. It was simply unaffordable. And then the pendulum swung to the other extreme of looking at micro robots and that was far, far less capable but also far, far cheaper. And so we managed to sell this mission called Mars Pathfinder which was the first lander that NASA-JPL did with airbags and it was. you know, every mission has to have some science but it was as much I think a technology test and demonstration mission as it was a science mission and the same was true with the rover. So, the rover was a technology test and demonstration. It had to have some science. You know, it was fairly minimal science and it was cheap. I think it was 25 million dollars just to do the rover. So, I was involved in that a little bit. I did not work directly as part of the mission team but it had a sensor called a Light Striper for detecting obstacles that was having some performance problems. And just coincidentally in parallel I was working on a next generation Light Striper and so I got involved in essentially debugging what was wrong with the one that was headed for Mars and so there turned out to be a problem with the optical design that I was able to isolate and then we got an optical engineer to come in and redesign it, so."
"Larry Matthies","Interviewer","Could you tell us a little bit about what a micro robot is like compared to the previous idea?"
"Larry Matthies","Interviewee","Well, it is behind me, I suppose we do not wanna turn the camera, but. So the Mars pathfinder rover which was named Sojourner, weighed about 11 kilograms. I am not sure if That is the exact number. The Rovers that had been looked at for Mars Rover Sample Return were probably, you know, close to a ton. I do not know the exact number but you know, we are talking two orders of magnitude different in weight and whereas the Sojourner rover never went more than six or eight or ten meters from the lander. The original concept for the sample return rover was to go, I do not even know, you know, hundreds of kilometers and be a self-contained mission, whereas Sojourner was dependent on the lander and the cameras on the lander and the communication system on the lander to be told what to do and to communicate with Earth. But nevertheless, that mission did firmly convince the whole Mars science community of the importance of mobility. So, essentially, the vision of how to explore Mars was never the same after pathfinder because now everybody realized you have gotta have mobility because there can be stuff just out of reach from the lander that is where the big discoveries are and what we found in the Mars exploration rover mission which those two rovers have covered, I do not remember off the cuff but you know, it is an order of 20 kilometers in seven years. You know, we are several kilometers away from where they landed and That is where the big discoveries happened, so. I guess I am straying from the original question but you know, the difference between the micro rovers at 10-11 kilograms and staying with inside of the lander versus sample return at, let us say. well, the Mars science lab mission that we are working on now, the next rover, I think it weighs 900 kilograms and it is supposed to drive an order of 20 kilometers. That is the difference."
"Larry Matthies","Interviewer","And were you involved on the Mars Explorer Program?"
"Larry Matthies","Interviewee","The Mars Exploration Rovers? Yeah, so my whole career, I have been in research, so I have never worked on the flight software or been formally part of the mission team but key elements of, you know, the capabilities in that mission came from either me personally or my group. So, those rovers use stereovision to detect obstacles, that basically is the outcome of work I did in my first year here. They use visual odometry to help keep track of where they are and more importantly to detect right when They are slipping. That basically grew out of my PhD thesis research. The path planning software That is on there, I did not have any personal hand in developing but that was done by somebody in my group and I basically convinced him that he should as a career move, get involved in the mission. Later on there were some things that were added after they already landed as kind of the mission software uploads. So, there is software on board that does basic image processing to detect when a dust devil goes by. That software was developed by somebody in my group. That mission halfway through developing the spacecraft, you know, like two years before launch, they realized that they had underestimated what the wind velocities might be and there was a concern that the horizontal velocity of the lander might be so large that the airbags might rip on impact. So, you know, some people came to us. it turned out that there were retrorockets on board that could be used to reduce the horizontal velocity if you knew what that velocity was. So then the problem became can we get a velocity sensor. And the traditional way to do that is with a Doppler radar but there was not time or money to put that into the mission at that point but coincidentally, they had designed in a camera that they were not using and so the question was could they put that camera back in and aim it down. It was originally designed to be on the rover looking up to trap the sun but could we aim it down instead of up. Track features on the surface during the sand and estimate horizontal velocity. So, we mounted a. you know, a crash effort, pun intended, to try to develop that capability and that was successful. And that was used for both landings and for the sphere of rover, from the. after the fact reconstruction, it may well have saved that mission because it did lead to the retrorockets being fired, kind of reduced the velocity by about a factor of two. So for the MER mission. I also had a hand in helping keep track of where it is. besides this visual odometry thing that operates kind of over short distances. I work with a photogrammetrist named Ron Lee at Ohio State University on mapping and so there is bundle adjustment software that Ron's group has developed that is used to keep track of the multi-kilometer traverse and is part of the whole mapping package that Ron's group has developed to generate terrain maps as the rover goes along. I think That is pretty much what I did in that mission. Basically, most of the autonomous navigation capabilities in that mission came out of my group. "
"Larry Matthies","Interviewer","What were some of the most important breakthroughs that you feel you have had?"
"Larry Matthies","Interviewee","Well, realtime stereovision. So, in the 1980s, the dominant paradigm was to try to do stereovision by matching edges because that was thought to be much faster and when I got here I could see that for off-road navigation, you know, in desert-like terrains, edges was just the wrong way to do it, so you really needed to use what was the alternative paradigm which was area-based cross correlation. So finding an algorithm that was fast enough for real time was something I did and that was a key breakthrough. This whole visual odometry business was something actually I did at CMU before I left there. I think that was not. not at the time, so I developed the first accurate visual odometry algorithm, even though we were not calling it visual odometry then and you know, at the time, you know, that was a good advance over what had been done previously but it was not that important. I think, you know, over the years since then we have recognized it is a very important capability. Along with some collaborators, some I advised with Takeo and Rick Szeliski, we did a well-known paper that was one of the first to show how to process images in an incremental fashion to build 3D models, so, you know, much better techniques of course have emerged but that was one of the first to show that you could incrementally build 3D models from image sequences. I have been. well the thing I just mentioned about vision systems for Mars landers, so trying to rule out a velocity estimation during landing. when I got here in the mid 1990s, I managed to get funding to work on landing hazard detection. So, essentially I built a team that has been working on various approaches to landing hazard detection with imagery and LADARs. None of that has gone to Mars yet but over the years we have built up quite a bit of capability to be able to do that and I believe that some day that will go to Mars. Precision landing has been another important thing, especially for Mars and so more or less the same team that I built up here has been working on how do you recognize landmarks during descent, so that you can reduce the positional uncertainty from say, plus or minus 20 kilometers, to plus or minus 100 meters. And that would make, you know, far more of the planet accessible and if we could land, you know, 100 meters from interesting terrain instead of, you know, 20 meters from interesting terrain or 20 kilometers from interesting terrain. You know, now you can get there in a day instead of getting there in months. Other things that I have worked on for space application include two explorer asteroids that have a lot of craters. we have developed algorithms that can use the craters to navigate a space craft around asteroids. JPL has been working on balloon missions for Titan which is the big moon of Saturn that has a thick atmosphere. there is a question of, how do you know where the balloon is? So we have been working on, you know, taking algorithms. the fundamental algorithms that were developed by others and applying them in this domain so that you could take imagery from an ordinary camera on board and register that to radar data taken from an orbiter. So that kind of cross registration of different sensor modalities can tell us where the balloon is. And then. so That is the NASA side. I have been working on defense robotics for, you know, more than 20 years and that grad school most of my work was funded by the defense department. So, you know, as a funding strategy, I have tried to find things to work on that had relevance to both NASA and other agencies. So, off-road navigation fits, so the focus on terrain understanding. So even while I was at grad school I collaborated with Hans Moravec and Alberto Elfes on. they had a fundamental breakthrough in an algorithm called occupancy grids for world model representation and Alberto and I wrote the first paper on combining data from multiple sensors in occupancy grids, so that was sonar and stereo. And then with funding from DARPA and the Army Research Lab, I was the first person to use near-infrared imagery for terrain classification of vegetation for off-road navigation. The first person to recognize that you could use LADAR to classify tall vegetation which can be difficult to discriminate, you know, you can drive through it but it can be difficult to discriminate that from a real obstacle that you have to go around. there is something that we call negative obstacles in this business, so basically, any hole in the ground. They are very hard to see. They are still very hard to see. You know, the only good way That is ever been discovered to find those is from the air. But you can not always send an aircraft ahead of you. So, along the way, I discovered that there is just kind of a physical property in the way heat transfer works. that the interior of a negative obstacle tends to keep itself warm. That has not completely solved the problem but it was an interesting advance that makes it somewhat easier to detect those than it would be otherwise. In looking for things that I could work on that other people were not doing. water bodies in off-road navigation that are hazards to navigation. we have. myself and collaborators here have put a lot of effort into how do you detect water bodies from a ground robot and, you know, we have made a lot of progress towards solving that problem. So That is. you know, it does not have wide impact but it is something fairly distinctive that we have done. I think that is a fair selection of highlights."
"Larry Matthies","Interviewer","Has optic flow been a concept that you have used in some of your visual odometry? "
"Larry Matthies","Interviewee","Certainly have used it. So, what we do in visual odometry, tracking features through the image sequence is, you know, there are many different flavors of optical flow, so that is a flavor of optical flow. The collaboration I had with Takeo Kanade and Rick Szeliski was essentially using a flavor of optical flow. In my work on ground robotics, I focused on stereovision for 3D perception and motion estimation, whereas there have been other people in the community that have tried to use a single camera and so the problem with a single camera when you are driving forward is, you do not have depth perception directly in front of you because you have no visual parallax. So, optical flow per se, has not been as important part of my work because of that but in the last few years I have started to work on micro air vehicles under funding from the Army. Which have very important applications in military reconnaissance and, you know, applications I the civil arena and inspecting bridges and so forth but is also very relevant to things for NASA. So if you are trying to explore a comet or an asteroid, or even fly a balloon in the atmosphere of Titan or Venus, you know, there a are very different scale of machine. But the vision problems have a lot in common. Or if you wanna have a micro-inspector like a little ball, you know, a foot or two in diameter, on a human spacecraft like the space station or if in Apollo 13 we had a micro-inspector that could've gone outside and had a look, that is a lot has a lot in common with the microware vehicle for earth applications. So, there, you can not really fit a stereo system and expect to see very far. So optical flow is quite important in those domains. So we are using it. We have not developed new approaches to optical flow, but we are using it for perception for those kinds of systems."
"Larry Matthies","Interviewer","So for these various, like, new infrared and mydar and vegetation detection, what were the robots that you put these systems on demonstrations ?"
"Larry Matthies","Interviewee","Some of that work was done under the Darpa Demo II program, which was using Humvees that were turned into robots. Then there was the Darpa Tactical Mobile Robotics program which essentially that was before iRobot became successful. And they developed a little tract vehicle, which initially was called the Urban Robot and later became the Packbot. So that program was the genesis of their Packbot product line and, as you probably know, those are now used in the middle-east for bomb disposal. So we put censors, including the well-known SICK Ladar single access scanner as a range finder on a Packbot and used that to classify vegetation. The new infrared was on the Humvee. The thermal infrared, that came out of another program called Preceptor where we were basically using all-terrain vehicles that were outfitted as robots. You know, the quad-altering vehicles. And General Dynamics Robotic Systems has been a big player in army robotics. They built some custom vehicles that are, I think, around 3,000 pounds. They call them experimental unvan vehicles. So my work has been integrated on those vehicles. You know, sort of Volkswagen-size vehicle. What else? I think those are the highlights of that."
"Larry Matthies","Interviewer","Can you tell us a little bit about the organization of the groups that you have worked in and how they have changed through time, how different groups interact with each other within NASA, and what it looked like when you got here."
"Larry Matthies","Interviewee","Okay. Well, I was originally in a robotic vehicles group run by Brian Wilcox. Somewhere along the way, the organization decided it was time to have a vision group and I became the leader of the vision group. And when that was first created, actually, there were a small number of us working in vision, which they merged with a slightly larger number of people working on star trackers. So star trackers are used in interplanetary crews to keep track of the orientation of the spacecraft. So I really was not interested in star trackers and felt that spending a lotta time on them was gonna be detrimental to the stuff that I was interested in. So I did not really take care of it very well and eventually management recognized that and moved that off somewhere else and left me with just the vision part. And that grew from, you know, originally a half dozen people to as many as 18 and then we, you know, had the succession of reorganizations and the group would get smaller and then it would get bigger again. And along the way, we recognized that from a, you know, a strictly, a funding strategy perspective there is actually a lot more money in visual surveillance than there is in robotics, or at least vision for robotics. So we thought we should participate in that somewhat. So we started to get a toehold in airborne surveillance work. And then there was another reorganization where we formed a separate group that is carrying on that work and I am focusing, again, on vision for autonomous navigation. I have avoided moving further up in management cause I did not wanna be purely managerial. So if the question is, you know, How has the organization evolved within JPL?, That is it. And then just within the last year/year and a half, you know, I felt that it was important to try to get more visibility with top management here and more appreciation by top management of the importance of unmanned systems outside of NASA. And therefore, it should be important to address those applications within JPL. So I have taken sort of a day a week level of responsibility to try to provide some strategic coordination of robotics for non-NASA applications across JPL."
"Larry Matthies","Interviewer","You mentioned earlier that with some of these missions, the idea that mobility is important became clear. What has been the status of robotics or of unmanned vehicles within NASA? Has it changed through time?"
"Larry Matthies","Interviewee","Well, I think NASA has been interested in surface mobility since the 1960s with the Lunar Surveyor program. So there is always been the interest there but I think it was not until the Mars Pathfinder Mission that it was really appreciated as essential, and also that it was recognized that it was feasible. So I think there was a watershed there around 1997. And then with the Mars Exploration Rover Mission, we have shown that it is not only feasible for short-range motion, it is feasible for long-range motion and that it is crucial to find rock outcrops that are many kilometers away from where you landed. But, you know, as the ebb and flow of research funding goes, it is been a little bit of a hand to mouth existence because NASA there is been swings of the pendulum within NASA where for periods of time there is very little research funding, per se. You know, there is very focused money or specific things needed for the next mission. But that is another reason why it is been essential to be, you know, having other sponsors at the same time, in order to manage the ebbs and flows of research dollars within NASA. So to maintain, you know, a steady cadre of people working on these problems so that when the opportunities came back within NASA we were still here and still equip to address them."
"Larry Matthies","Interviewer","So how does the funding work exactly? How much of it does the group have to create for itself?"
"Larry Matthies","Interviewee","Most of the funding that we get, we have to raise ourselves. So there is some funding that comes through what is called Focused Technology Programs That is, you know, assigned to JPL to solve specific problems for specific missions that will kind of trickle down through management to us. But at the, you know, more basic and applied research level, almost all the funding that we get is competitively ordered. So I liken it to you know, in universities there is a concept of a soft money position, which is non-tenure track funded by research contracts. it is very analogous to that."
"Larry Matthies","Interviewer","So, in a sense, the size of the group also depends on the ability to find that kind of."
"Larry Matthies","Interviewee","To raise money."
"Larry Matthies","Interviewer","Okay. "
"Larry Matthies","Interviewee","Right. Yes."
"Larry Matthies","Interviewer","And how much does the funding shape what you decide to do research on versus how much is driven by your interest?"
"Larry Matthies","Interviewee","Well, they go hand-in-hand. And, you know, you have to be pragmatic and realize that if you have to have a charge number, you know, and a contract behind that charge number, you have to work on things that people will fund. But that is a bit of a chicken and egg thing. If you bring an interesting new idea to a sponsor then sometimes they will apply some funding to it. So you need to sorta be working under the radar on things that you believe in even if, you know, the country is not ready to apply funding to them. And there are ways to get funding for that at, you know, a small level. So JPL has some internal seed funding pots you can apply to. You can collaborate with people elsewhere. So there could be different agencies like the National Science Foundation that fund basic research that maybe NASA or the Defense Department are not ready to fund; but if you collaborate with those people, you can kinda get the ball rolling and then move those ideas into other agencies."
"Larry Matthies","Interviewer","And have you had much interaction with companies as well ?"
"Larry Matthies","Interviewee","Yeah. So the Robotics Collaborate Technology Alliance that the army's been funding, we have always been part of a team, led by companies. So General Dynamics. The Darpa Demo II program was led by Martin Marietta. We were I do not remember if our money came through then. I think our money, then, came directly from Darpa but we were basically working on a team with Martin Marietta. When we were working with CMU and the NASA Robotics Engineering Consortium we worked a little bit with some companies. So Toro was interested in automation for some of there, you know, lawnmower products. we have had some of our vision software licensed by small businesses. So no small businesses that've made it big yet, but we have had some of our software licensed. I actually collaborated with people here a little bit who pioneered the development of Sea Moss Imagers . So the cameras that are in all the cell phones these days, some of the pioneering work on that technology was done here. So I was part of a patent for on-chip block averaging for multi-resolution readout, which was part of the package of patents were licensed. That particular capability hasn't had much impact in the market yet but you can buy it. Let me think. we have collaborated with other companies in other DOD funded programs. So we are doing work for the navy now where we are a subcontractor to other companies doing on-man boats for the navy. there is probably others that I am not remembering. So iRobot, you know, we collaborated with iRobot in some programs. we are collaborating a little bit with iRobot's competitor, Kinetic . In the robotics technology lines these days, Kinetic's part of that team. We work for Boston Dynamics on some of the Darpa programs for legged squad support system, basically for legged robots. We provide vision systems for legged robots for Boston Dynamics."
"Larry Matthies","Interviewer","So what do you see as the big outstanding problems facing field robotics over the next few years?"
"Larry Matthies","Interviewee","Well, one of the things that we have been working on, which there is been progress I do not think it is done but for many years, all of robotics research was done in static environments. So the problem was hard enough when nothing else was moving that you did not wanna have anything moving in the environment. Cause we just did not have the perception capability to understand that yet, or the path planning capability to reason about things moving in the environment. And a lot of that was just driven by limitations in computational power. So we have been working on the perception and representational and planning capabilities to operate in dynamic environments. For Mars there is still an issue of understanding the difference between hard soil and soft soil. So the robots have gotten stuck in soft soil. And there are problems yet to be solved in detecting that before it happens and making sure we get out of it. Back on earth, you know, in the mainstream computer vision community, there is been a lot of work on object recognition. You know, that is a dominant theme in computer vision these days. That will play into mobile robotics. It hasn't been as significant yet but it is going to become important. As we get the more basic problems of safe mobility solved then you need to do more purpose of mobility and that means you have gotta understand things around you as more than just 3D structures. you have gotta understand what they are and what They are for. So even just, you know, going through a door, helps to understand what doors are in a semantic sense not just in a geometric sense. And there is a growing trend to work on mobile manipulations, so robots with arms. So now you are combining all of the problems that come with manipulation, including object recognition, with the problems of mobility. So you know, if you have arms on a mobile base, now you have to reason about the degrees of freedom of the arms and the mobile base. let us see. I think That is fairly good."
"Larry Matthies","Interviewer","What do you think is the future of robotics in NASA?"
"Larry Matthies","Interviewee","In NASA?"
"Larry Matthies","Interviewer","Hmm. hmm."
"Larry Matthies","Interviewee","Well, the holy grail for Mars is sample return so rovers would be part of that. Right now for Mars we are limited to terrain that you can go to with a wheeled vehicle. But some of the more interesting science may be in terrain that you cannot access that way. So we are looking at robot systems that can, say, repel down cliffs. NASA would like to enable sample return from comets because comets may, you know, be where some of the chemistry arose that gave rise to life. And, you know, an unmanned space craft is not the same as robots that you see, you know, roaming around on earth but they have many of the same requirements for autonomy. So free flying spacecraft that can operate in close proximity to other objects, whether those objects are planetary bodies, like comets, asteroids, or moons, or other spacecraft. So like a micro-inspector. And then long-term for NASA, I believe that there will be value to robots for satellite servicing. So this has been a debate, you know, in the commercial world, Is that really economically viable? And just within the last six months, I think, there was announcement that for the first time a big satellite operator has awarded a contract, in this case, to a Canadian company to do satellite servicing. But what is made that economically viable is that this is for communications and Intelsat has many satellites, essentially in geostationary orbits, on the equator. And so you can go and refuel those with one mission that just kind of drifts along the equator, servicing many in one mission. So that becomes an economically viable business model. But for NASA so NASA spent, you know, $5 billion or more on a mission called the James Web Space Telescope, which is going to be on the far side of the moon. And it is not designed to be serviceable. And I really know very little about the mission but I have to wonder, if we could do robot servicing, could we do a better job of great observatories in space and perhaps make them more affordable because they do not have to be so failsafe upfront. You know, servicing missions are not cheap but, you know, if you can spend $500 million on a servicing mission as opposed to, you know, throw another one and a half billion in to greater reliability so you do not have to service, maybe it is a good idea. And we have seen that with the Hubble. Right ? We extended the life of the Hubble many times through servicing missions."
"Larry Matthies","Interviewer","There are, of course, autonomous robots and then there is also a lot of telerobotics at NASA. Have you worked on any of the telerobotics and how do you see those two working together or against each other or whatever you would call it?"
"Larry Matthies","Interviewee","I have not had much involvement in telerobotics. You know, there was a lotta work on that when I first got here but I chose to work on rovers. I do not see that as competition. it is a matter of an evolution and so you do telerobotics where it is feasible and where autonomy is not yet feasible. And you do autonomy where That is the only possible way to do it and, therefore, you have invented a way to do it. So you can do telerobotics in Earth orbit or potentially on the moon because communi basically what makes telerobotics possible is relatively low communication delays. And where it must be autonomous is where the communication delays are too long, so essentially Mars and anything beyond the moon has to be autonomous. And then, you know, there are analogies on earth. The same thing goes. So, you know, applications that you would do telerobotically on earth you could think of surgery as a telerobotic kind of application, where you would not dream of not having a surgeon involved with today's technology. But, at the same time, you would much rather send the robot in to Fukushima than have to send a person. And it is sort of unfortunate that we are not ready as a society to have robots that could be sent in there to do that job. But I think, you know, that is a rare occurrences that disasters like that happen, and therefore the even though technically I think it is feasible, the investment had not been made, you know, prior to that incident to have the robots ready to do more. So they have certainly taken robots in there but we could do a lot more. The capability exists to do more. it is just matured to the point it is quite deployable yet."
"Larry Matthies","Interviewer","And I noticed that you were also on the editorial board of Field Robotics, the journal."
"Larry Matthies","Interviewee","The journal of Field Robotics, yeah."
"Larry Matthies","Interviewer","And Autonomous Robots. So I was wondering how long you have been on those boards and how you have seen the field change while you were there, or emerge ."
"Larry Matthies","Interviewee","I have been on the editorial board for Autonomous Robo I can not remember how long I have been on either of those editorial boards. I have been on Autonomous Robots longer. I have not been the most active editorial board member . You know, for Autonomous Robots I review papers occasionally. For JFR I have been a guest editor for special issues occasionally, particularly in space robotics. So how has the field evolved? Since I can not remember exactly when I started those roles, I do not really have a good answer for that."
"Larry Matthies","Interviewer","It can be more broad than just from the journal itself."
"Larry Matthies","Interviewee","Well, we have examples of things that have actually been fielded. So, you know, we have been talking a lot about space. You know, prior to 1997 there had never been an autonomous planetary rover mission. And so, since then, we have had substantial missions for that. On earth, things like the Packbot and the Talon from Kinetic are the first deployed military robotic systems. Since I really have not been that involved in commercial applications I can not say as much about that side but I think there are applications in agriculture and mining and material movement in shipping ports and things like that where we are seeing autonomous vehicles. You know, we have been seeing a lotta work in the last decade or more. So the whole robot road following thing, which, you know, got a big start in the Darpa ALD program in the mid to late 1980s you know, That is gone from something that was just barely possible in a very big, very expensive research vehicle to something that actually works pretty well and is, you know, doable in an automobile now. And now we have cars that can part themselves. And so this has been driven by advances in sensing and especially by advances in computing and by reducing the cost of those things. A big driver that I believe we are gonna see in the future is cell phones. So, you know, small cameras for cell phones, which lead to now you have got images in cell phones, you need to be able to process those images. So now we are getting very substantial image processing capabilities in cell phones. The next thing That is gonna happen is now you have got two cameras in cell phones so you can do have a camera and do, you know, Skype on the cell phone. But there are also things coming out so you can have two cameras facing the same direction to aid with teleconferencing. So that is a stereo system that you can use for a robot. And because it is a cell phone it is not only gonna have a lot of processing power, it is gotta be very low power dissipation. So I think we are gonna see processes develop for cell phones eventually go into small in fact, not eventually, it is already happening go into small mobile robots, both on the ground and in microware vehicles. So robots, robotics by itself, is too small a market to drive substantial innovation in sensors and computers. But commercial electronics is a huge market that is driving those and robotics will basically ride that wave in sensors and computers."
"Larry Matthies","Interviewer",". I have a curiosity question. I was curious, since you worked with both Hans Moravec and Takeo Kanade, what was it like working with them?"
"Larry Matthies","Interviewee","They are polar opposite personalities. You know, Hans was a very creative guy, you know, I had have to say somewhat eccentric, and did not like to manage. And, you know, he was fine in communicating one-on-one but he did not like to give talks in front of big groups. So he was a pioneer in his day and did some radically new things. But Takeo you know, meaning in a positive way, Takeo is an empire builder, and he is a great communicator, and he is a great educator, and he does not mind management. And he goes out and he builds large organizations. And so he is had, because of those differences in personalities, far more impact. So."
"Larry Matthies","Interviewer","How were their labs different?"
"Larry Matthies","Interviewee","Well, when I got to CMU, I think, was probably not that long after Hans had got there; he as a faculty, of course, and me as a student. And I think he had a $700,000 dollar a year grant from the navy, at the time, which for, at the time, for a university was very large grant. So he had half a dozen or more people and was probably the biggest robotics lab at CMU at the time. But because he was not really a manager it sort of it carried on for several years but eventually it kinda wound down. Whereas Takeo started as CMU really as a vision researcher and he got involved in robotics I guess I do not really know. But, in mobile robotics, he got involved through the Darpa ALD program. And he was involved in robot manipulation as well but I do not really know when he started that. And he ultimately became the director of the Robotics Institute. And, you know, he was very adept in raising money from many different sources and, you know, given his ties to Japan, he was able to get you know, he was always getting, you know, new equipment somehow. Which, as a student, you never understood really how this happened that We had have the best state of the art printer, which he somehow got as a gift from some company in Japan. And I think he would get other, you know, fairly unrestricted funds through sources like that. So and we would have very nice group retreats for his whole lab. So now we are talking, you know, 60 people as opposed to 6 people. Once a year, We had all go off to a local ski resort. And it was not just skiing. It was, you know, you would spend two or three days where you would spend half the day meeting and half the day skiing, talking about Where do we go next? And giving the students a chance to present, you know, what have they done. So it both helped the students to, you know, polish their presentation skills and it helped the whole group to crystalize their thinking about Where are we now and where do we need to be going? And, you know, part of the ability to do that was his ability to raise unrestricted money that could be spent that way. So I owe a lot to Takeo ."
"Larry Matthies","Interviewer","Our final question. Generally, if you could give some advice to young people who are interested in robotics what would it be?"
"Larry Matthies","Interviewee","Get a solid grounding in mathematics but not just that. You need to be hands-on so you need to get a solid grounding in computing and the ability to program. It, given the multi-disciplinary nature of the field, it might actually be useful to start with an undergraduate degree in an engineering discipline and then possibly do, you know, with some computing options, and then possibly move to a computer science department in grad school. You know, I have talked to students recently who are grooming themselves for grad school who are getting a very diverse background in computer science and controls and elements of electrical engineering. And I am very impressed with, you know, the level of maturity and forward thinking I see in people like that because it is a very diverse field. And when you get to grad school, you know, you can not be completely sure in advance which direction your interests are gonna go and which direction your opportunities are gonna go. So if you come in with that breadth of background as an undergrad, not only are you more likely to get accepted to a good place but you are more prepared for whatever opportunities arise. You know, if possible, at the high school level. So, you know, through the first program it is good to get hands-on experience with projects at the high school level. You know, if you can manage to attach yourself as an undergrad to the faculty doing research, you know, get summer jobs or, you know, part-time winter internships not internships really but, you know, work with faculty who are doing research, as an undergrad on whatever they need to do, to get that experience and exposure. But also remember that it is, at least today, it is still a fairly small field. So while it is growing, there are more jobs in other fields than there are in robotics. And, yes, it is exciting but it is still a small field, although I believe, is gonna grow, so."
"Larry Matthies","Interviewer","Okay. Thank you."
"Larry Matthies","Interviewee","you are welcome."
"Larry Matthies","Interviewer","Was there anything we missed that you wanted to tell us about?"
"Larry Matthies","Interviewee","there is nothing burning in my mind."
"Larry Matthies","Interviewer","Okay ."
"Larry Matthies","Interviewee","I think that was pretty good, so."
"Larry Matthies","Interviewer","Great. Thank you."
"Larry Matthies","Interviewee","All right. Thank you."
"Larry Matthies","Interviewer","Yeah, that was it ."
"Matt Mason","Interviewer","we are just going to start by asking you where you were born and where you grew up."
"Matt Mason","Interviewee","I was born in, and grew up, in Oklahoma City. Born in 1952. Grew up there. Went to MIT in 1970, just a few days before my eighteenth birthday."
"Matt Mason","Interviewer","What did you study as an undergrad?"
"Matt Mason","Interviewee","I started majoring in physics and math, and shortly thereafter switched to computer science."
"Matt Mason","Interviewer","And what motivated you to switch?"
"Matt Mason","Interviewee","Well, I had taken a class at Stanford. So when I was still in high school, I did a summer session at Stanford, and discovered computers there. There was a very nice class in computer programming that I took that summer. I had to sneak in. I kind of crashed the course, you might say, with my brother, who was attending Stanford. So I knew computer science was cool. This was 1968 or 1969. So everybody else did not know it was cool. Some people would say, Well, you know, a computer is just a tool. Kind of like you would not study calculators. Telling somebody you are studying computer science in those days might have sounded to some people kind of like you are going to study calculator science or something. But I think, just from hanging out and studying physics, and seeing some of the things that are going on, it just confirmed what I already knew in my heart, which was that computers really were cool and it was fun."
"Matt Mason","Interviewer","When did you first become interested in robotics?"
"Matt Mason","Interviewee","Yeah, that is an interesting question. When did that happen? When I was at MIT, I came into contact with the people in the artificial intelligence laboratory. And at that time they had just done something called a copy demo, which was the idea that you could set up a bunch of blocks and then the robot would look at it and build a copy of it. And so I was hearing some research talks from that, and That is what got me into the lab initially. I did not really start working myself on robotics until a few years later, and that came about mostly because I just happened to be sharing an office with Marc Raibert and John Hollerbach, and Shimon Ullman, all of whom were doing robotics of one form or another. And they were just having too much fun."
"Matt Mason","Interviewer","Who were some of those first people who did the copy of blocks?"
"Matt Mason","Interviewee","Yeah, the copy demo yeah, as I say, it was a little bit before my time, and I am trying to recover the names now. Some of them were graduate students or young faculty that were there, and then left before I really got to know the people in the lab. I think one of them was Eugene Charniak, but it seems like he was doing linguistics. Yeah. Well, I do not know. You should ask Jerry Sussman. You should ask Berthold Horn. Certainly Berthold Horn was involved. Tom Binford, who later went to Stanford, I think was involved. And kind of along related I mean, there was related work going on by sorry, I should have done some mental exercises to work through all the names. there is a very famous guy, another guy who is well known for linguistics at Stanford, who might have been involved. "
"Matt Mason","Interviewer","What was the first robotic project that you worked on?"
"Matt Mason","Interviewee","I guess the first thing I did was a project in compliant motion and force control. This was my Master's thesis. So I started working on that, oh, a few months after I started grad school. So, I started as an undergrad in 1970, but I started graduate school in 1976, so it would have been right around 1976 or 1977. And compliant motion and force control, that means if you have got a hand and you are trying to interact with things in the real world, you have to do it gracefully. You want to be able to touch hard surfaces, interact with them without hurting yourself or the surface. So it makes sense to try and control force rather than just controlling position."
"Matt Mason","Interviewer","What kind of machine were you using? Was it a robotic arm?"
"Matt Mason","Interviewee","You know what? That is funny. We did have machines and I was messing around with them. My Master's thesis was theoretical. I do not think I did any actual force control until after I finished the thesis. Immediately after finding out it, I did do a visit, an internship, at IBM Yorktown Heights and worked with Russ Taylor there. Worked for my I think my the boss of the group was Peter Will, and another manager was Dave Grossman. Russ Taylor was the one who I was working directly with. And I did implement a force control system for their arm that was called their experimental system was called the RS1, and they released a product a couple years later called I think the 7565 arm. The arm we had in the lab maybe that gets back to the original question. Yeah, what did we have in the lab? We had a at that time we had the MIT Arm, it was called. So this had been designed by Victor Scheinman, I think, at the request of Minsky. I think the original one had aluminum gears. There would be a little pile of aluminum dust under it if you worked it too hard. Raibert did his PhD thesis on that. And then we had an arm that we were developing in the lab ourselves called the Purbrick Arm. John Purbrick who was a guy who was designing an arm. And I actually did the sort of the programming and control system for that arm. And then there was a third system called the Silver Arm. There had been a visitor at MIT named Hiroshi Inoue, who went on to be a very famous guy in Japan, and he had worked on assembly and worked with Tomas Lozano-Perez, and that was on the Silver Arm, which was it is another arm that was developed at MIT. Any more hardware questions? "
"Matt Mason","Interviewer","What was your PhD thesis and how did that research progress?"
"Matt Mason","Interviewee","Yeah, so the PhD was on basically how to push things around. let us see. I think maybe the right way what is the right perspective for all of this? So there is a few things going on. So my advisor was Berthold Horn. Horn was very well known for using sort of careful I will say mathematical or engineering models of the image formation process and inverting them in order to develop really hard-nosed approaches to constructing the shape the three-dimensional shape from an image. So there were a lot of us that were interested in assembly and using arms, which may seem very distant from vision, but I think I was probably inspired by Horn's work to try and do something similar that is, can you, from a very careful engineering model of how things move when you touch them, can you invert that then to come up with the plans and the controls for a robot? So in the abstract, that seems pretty simple. Then you start looking at real cases. So I mean, usually you think of things at a rather abstract level: I want to put Block A on Block B. I am going to pick up Block A. Where is the subtlety in that? Where is the engineering model in that? But when you look at very carefully what happens when you go to pick up an object, usually there is some error often there is some error and because of that error, you make contact not exactly as you planned. Things move a little bit, or maybe your fingers deform a little bit. there is all kinds of little things like that going on. And from looking at this and sort of thinking about some problems I had seen over the years, I realized that those little motions can actually be very important. Maybe the best example I have several examples. The best example was that I had seen a movie that had been made at Stanford called I think it is Programmable Assembly: Three Short Examples. Maybe this is going to show up in some of your other interviews. I believe Lou Paul, Richard Paul, was one of the others, and Bob Bowles. I do not know if he is on your list at SRI and a guy who I never met name Pingle, I think, was part of it. And they pick up a hinge They are going to put hinges together They are going to assemble a hinge. And when they go to pick up the hinge, instead of the two fingers coming down like this and grabbing, like you sometimes see, instead of the fingers sort of start over here, and they came along and pushed the hinge like so, as they squeezed. And it was like, Wow, why'd you have to do that? Well, that pushing process eliminated the uncertainty, and if you continue to push as you squeeze, you end up with those fingertips right in the corners of the hinge with, I guess I will say, perfect precision. Right? I mean, you are in absolutely mechanical contact with both features of this corner. So it is a precision that you can not get just by raw positioning. And you realize when you watch people program arms, you see them doing these kind of things all the time. Russ Taylor's PhD thesis had a great example, which was that if you squeeze a box and a lid at the same time I think he might have squeezed it twice, one in the X direction and one in the Y direction then you have perfectly aligned the box and the lid, and then it makes the assembly easier. So you this stuff all the time. You watch people work, and if you have got an eye for it, you see people doing similar things, right? When you shuffle a deck of cards, you do not get the precision with which the card deck is stacked by open-loop positioning. Actually, if you watch an infant messing with cards, you will see that right? they will pick up the cards one at a time and put them in a stack, and it is a mess. But somebody with a few years of experience will squeeze it and tap it on the right? or tapping chopsticks. You just see these tricks over and over again and you begin to realize it is actually an important part of manipulation. So, I guess that is a pretty long answer. The question was what did I do for my PhD thesis. So I decided to work on these pushing motions, and That is what I did."
"Matt Mason","Interviewer","When did you start applying them to robotic systems?"
"Matt Mason","Interviewee","Well, that was from the beginning. I do not think it is not as easy to you do not see these things. I mean, the beauty of robotics is that you are trying to make something happen and you can not appreciate the problems until you are trying to make it happen yourself, right? So if somebody's out there and They are doing something and you think, Wow, that looks easy, then you go try and do it, then That is when you discover it is hard, right? So if you are trying to build a machine to do something, you are trying to program a computer to do something, you really have to understand the something. And so That is one of the very interesting things. there is all kinds of problems of a very fundamental nature just in geometry or in dynamics or in simple mechanics that could have been of interest even a hundred years ago, which really never got that much attention, perhaps were not noticed at all, until they became relevant in the context of robotics. So I certainly never worried about pushing until I was worrying about how to get a PhD. "
"Matt Mason","Interviewer","What did you do after your PhD?"
"Matt Mason","Interviewee","Well, there was a few things. So, there was one project that started before I finished my PhD. The guys at MIT had this great idea they had something called the Year of the Robot I think That is what they called it. And they invited a bunch of people up. I think John Liu was there. Mike Brady had been there for some time. In fact, who knows, maybe the other robot was his idea. But Russ Taylor came, and so Russ Taylor and Tomas Lozano-Perez and I had a project to try to it was on fine motion planning. There was an idea that had been around a long time, which was that you can sort of divide manipulation into fine and coarse. So if you are just moving your hand from here to there, That is one thing, but then when you are trying to pick things up, there are these little fine motions that happen that are perhaps more sensor-mediated and more involving compliance and pushing and things like that. So we were sort of trying to have a very develop a geometrical perspective on how this fine motion planning happened. How do you the errors and uncertainty in the task can be greater than the precision with which you can control things. So then you want to use the compliant motion and maybe force feedback to help you guide the system into the desired goal. So anyway, that was a project which we called fine motion planning, and later on I think it was Lozano-Perez's graduate students who coined the turned it into LMT Lozano-Perez, Mason, Taylor. So a lot of times people called this LMT. Sometimes they call it pre-image backchaining. So there was that project. I put a lot of time into that, some before and a lot after, working with Tomas and Russ. I do not know. it is a lot of time after a PhD, so the answer to that could go on for a long time."
"Matt Mason","Interviewer","When did you come to Carnegie Mellon?"
"Matt Mason","Interviewee","I came straight to CMU from MIT. So my first year in graduate school, I mentioned I was in an office with Marc Raibert. When he graduated, which was just at the end of that first year, he went to JPL at Caltech. Ultimately he came to CMU around 1980 or so, and then in 1982 he convinced me I should come here."
"Matt Mason","Interviewer","What was CMU like in 1982?"
"Matt Mason","Interviewee","Well, let us see. It was an exciting place. I was firmly convinced it was the best place in the world to do research. The money situation was good. did not have to spend a lot of time writing proposals, and the main reason for that was Allen Newell and Raj Reddy and people like that were doing a lot of that work for us. And so and there was and the teaching load was light. There was no undergraduate program well, we kind of shared responsibility for an undergraduate program with the math department. So the teaching load was rather light, and the students were awesome, and the faculty that were around were great, and it was just a terrific place. "
"Matt Mason","Interviewer","Was it a full-fledged robotics program at that point, or were you still part of "
"Matt Mason","Interviewee","Well, it was the Robotics Institute was had been going for just a year or two. I identified much more at that time with the computer science department than I do now, and I think I can admit to some prejudices that I arrived with from MIT. There were people, as I was leaving MIT to come to Carnegie Mellon, telling me to watch out for this guy and that guy, and, Maybe you should be careful about that Robotics Institute. But in any case, I mean, it was kind of people refer to those as wild and wooly days. In some ways I guess they were. There was no robotics PhD program. The Robotics Institute was just a research institute. Anybody that had a tenure track appointment was joint with another department. So I was joint between computer science and robotics. So, it was interesting. It brought some great people here. Hans Moravec was here because of it. And Marc and I would not have been here without it, I do not think."
"Matt Mason","Interviewer","Who else was here at that time?"
"Matt Mason","Interviewee","Well, it was a really interesting thing going on. Ivan Sutherland was here. So Sutherland was one of these people that had been part of MIT many years before I had been there, and then Raibert got to know him in California, and then Sutherland is an alum of the ECE department here, and he was back here, and he was building a walking machine. And so he had attracted a really interesting group of people, including Marc, and their walking machine was pretty interesting. And he produced a book, which I still pull out once in a while. it is a very unusual book in that it kind of covers everything from how do you create the little fillets in the metal castings, all the way up to how do you design gate patterns for walking machines. it is very it is interesting."
"Matt Mason","Interviewer","What kinds of projects did you start when you came here?"
"Matt Mason","Interviewee","Well, let us see. So I told you about the fine motion planning project. What else was going on here at the beginning? What was I doing? More pushing. I kind of started well, I guess probably the most interesting thing was a thing called tray tilting, and that was work with Mike Erdmann. So he was still he was a graduate student at MIT and he came here one summer. And we were just trying to figure out how far could you go understanding certainty, or eliminating uncertainty in the world, but not by using sensors. And maybe this just started as a sort of contrarian thing, but I think almost anytime you pick up a paper on robotics research, it might have said, Well, there is uncertainty in the world and therefore you got to use sensors. You need force sensing and tactile sensing, visual sensing, etcetera, etcetera. It all seems perfectly obvious that there is uncertainty in the world; you need sensors to get more information. And then but we knew some examples where people were getting really interesting information without using sensors. And I will cite an example from the IBM group. Peter Will had told me some stories that were pretty interesting about these things, and then Grossman and Blasgen had a paper where if you want to know where a part is in a tray, well you just or I will say it this way: If you want to know where a part is and let us say it is kind of an irregular-shaped part. You have this tilted tray, you throw the part in the tray, and if there are no symmetries or anything, and maybe you even shake the tray to eliminate friction it is going to settle into one of some finite number of poses, and you can disambiguate that by just having a sort of a cat's whisker. And so you go in and kind of do a binary search. You say, Is there stuff there? No. Well, is there stuff there? No. Well, then it must be configuration number three. So that seemed kind of interesting, and Mike and I started thinking, Gee, I wonder if we could even get rid of the cat's whisker. Can we actually figure out where something is with zero sensory information? So the first idea was to use actually to kind of use pushing. So you could imagine imagine you have a part That is like in the center of a table, and let us say you push it like that, and then you push it like that. And you are not looking at or anything you just know if it was somewhere in the center of the table, you do a couple pushes like that, you are going to know approximately where it is. But maybe you want to do some other things. Maybe you kind of come in with a needle and do this, or push it this way or that way. Can you actually get all of the information about its orientation and position this way? Well, that turned out to be too hard, but there is a kind of simpler version of that, which is you go back to the tray, toss the object in the tray, and now you tilt the tray this way, and then you tilt it that way, you tilt it that way. The thing's sliding around. You make it slide from this corner to that corner, back and forth a few times, and at the end of that process you know its position and its orientation. So, I do not know. that is a long answer. Are these should I be "
"Matt Mason","Interviewer","No, those are great. No, the detail is great. "
"Matt Mason","Interviewee","Okay. Well anyway, yeah. So that was one project. That was with Erdmann and, I do not know, that one, actually we still pull it out and show it to people a lot. Erdmann had just done some work where he could automatically predict the behavior of rigid bodies under frictional contact. And so he had a system more or less lined up ready to go, and so he could basically simulate all the actions that you might contemplate in order to give you the information that you need in order to do automatic planning of that. But I think maybe the most interesting bit was that you could identify a finite set of actions. So, subject to some these things are always full of assumptions to try and narrow things down but subject to these assumptions you could show that there was a finite set of actions that covered everything that you could possibly do, and so that made an exhaustive search actually feasible for that tray-tilting problem."
"Matt Mason","Interviewer","What other kinds of main questions were you interested in solving?"
"Matt Mason","Interviewee","You know, that is a good question. You know, a lot of it was I mean, it gets back to that original inspiration from Horn. I guess I have always said sort of that maybe the main thing I am interested in is the mechanics of manipulation. I think the work on how things move when you push on them got enough traction or I got enough sort of positive encouragement from people, and you could see there is a lot of interesting things kind of along those lines. So that was something that and of course I am working with graduate students who are doing most of the work by that time. So, Randy Brost, Ken Goldberg. Probably Ken's thesis was the one that was the most noticed out of that whole body of work that was going on shortly after I will say shortly after my PhD, within the first ten years or so. So yeah, mechanics of manipulation, that was one element. Uncertainty how to plan for uncertainty and how to eliminate uncertainty with I do not want to say without sensors. it is not that it did get to be a joke for a while that I hated sensors, but on the positive side, the truth of it was that we were interested in getting rid of uncertainty by knowing how the world behaves and what you have done with the world. And then there was a time when I started working on learning. So at some point Raibert left and Tom Mitchell showed up and it is not exactly a coincidence I got interested in machine learning. And Alan Christiansen, another graduate student, did some work there, and just recently coming back to that. The original idea was that we have been doing this work in mechanics as if we were oh, what is the right word? as if we were 19th century philosophers trying to prove everything from first axioms. And it became an interesting question instead of trying to create a model of the world that was based on Newtonian mechanics, could you do similar things with a more empirically derived model of the world. So could you just watch how things proceed and abstract from that, and develop models of how the world works with which you could then construct plans automatically?"
"Matt Mason","Interviewer","What were some of the important projects that you worked on?"
"Matt Mason","Interviewee","I do not know, let me think. Maybe there are not any. The important ones? that is a tough question."
"Matt Mason","Interviewer","I mean, maybe important. Since there are so many often people work on so many so some that you think were particularly interesting. You mentioned Ken's."
"Matt Mason","Interviewee","I do not know. I think the more important, the more on the periphery. I mean, most recently the Urban Grand Challenge. And I was just on the periphery of that. I probably would not have been involved in that if I was not the director of the Robotics Institute. But certainly that was I think one of the biggest days in the history of robotics. And I got to be there, but it was mostly just kind of supporting in an administrative way, the work of Red and his gang. Gee, I do not know. I mean, some of this stuff is it is hard to say how the technology gets into place. I mean, when I started, it seemed like there were a hundred different companies that were talking about doing manufacturing building manufacturing equipment. I remember we went out and consulted once with Bridgeport, who were working on building a robotic arm for manufacturing. And some of the things we were doing but I will say kind of what seemed like mundane things, like, Gee, why do not we have robots whose control computers include the ability to have subroutine calls, or functions with parameters? Very, very mundane things. Some of that stuff you never know how it got to where it got in most cases."
"Matt Mason","Interviewer","Who are some of your PhD students?"
"Matt Mason","Interviewee","let us see. This is going to be really bad if you put this online and I forget anybody. So, Yu Wang, who was actually the first person I ever met from mainland China. So. They were pretty rare in those days. He sometimes goes by Michael Wong. Randy Brost. Ken Goldberg. Alan Christiansen. Kevin Lynch. Wes Huang. Garth Zeglin. Devin Balkcom. Amir Degani graduated he got his PhD like two days ago. And so now, let us see. Who have I forgotten? I am really sorry. Do you have a list? "
"Matt Mason","Interviewer","We will find one."
"Matt Mason","Interviewee","Was it a test?"
"Matt Mason","Interviewer","No, no. No right answer."
"Matt Mason","Interviewee","Yeah, I know I have forgotten somebody. "
"Matt Mason","Interviewer","Where have they gone on to work?"
"Matt Mason","Interviewee","Well, Devin right now is at Dartmouth, and Kevin Lynch is at Northwestern. Ken Goldberg is at USC. Alan Christiansen is at MITRE. Randy Brost I have forgotten the name of the company. They are working on solar mirror technology. He worked for quite a while at Sandia National Labs, and then worked for Kodak. Yeah, see I am forgetting even more people now."
"Matt Mason","Interviewer","You spent some time at Sandia as well?"
"Matt Mason","Interviewee","I did a couple of summers. I went there for a couple summers, yeah."
"Matt Mason","Interviewer","What kind of work did you do there?"
"Matt Mason","Interviewee","I was trying to help Randy Brost and his group. One summer I added some simulation of pushing to a system that they were working on. And what did I do the other summer? I do not remember. Must have been wasted."
"Matt Mason","Interviewer","What are your projects right now that you are interested in?"
"Matt Mason","Interviewee","Well, simple hands. there is our whole plan and all kinds of crazy ideas, most of which are not going anywhere, but maybe a few will. When is this going online? I got to publish everything. Got a new deadline."
"Matt Mason","Interviewer","At least a year."
"Matt Mason","Interviewee","Oh, great. I am planning to do this the rest of my life. Yeah, the simple hand idea is that well, it is interesting. If you look at how people design hands, there is a few ideas that dominate. So one idea is that if this hand works pretty well, let us build something That is kind of like that so the anthropomorphic idea. And I do not want to make it sound superficial I mean, obviously people know a lot about the human hands and everything we learn about it can inform the design and the people that are designing those things have done some really amazing things. there is another idea, which is that maybe we should be able to manipulate something just using the freedoms of the hand. So if you are going to do that, you sort of need to have at least nine motors, because if you just grip something at two points, you can not very well control that rotation, whereas if you have three fingers you can. Well, if you want to give arbitrary motions and do this thing with three fingers, then you need to be able to give X, Y and Z motions to each of the fingertips, and so three times three gives you nine motors. So both of those stories give a very tidy approach to the question of how do you do manipulation in general. If you can grab an arbitrary shape by having an anthropomorphic hand, and even have some general I will say fine motions again, using the fingers and then if you have got a general purpose arm, meaning it is got like six degrees of freedom or more, then that seems like you have got a general purpose manipulation system. And That is pretty tidy, right? I did not give you a lot of assumptions or anything. But there are a lot of hidden assumptions in there. Like for example, the world is not composed of rigid objects. there is lots of soft things. In fact, maybe most of the things we want to work with are soft. And there is liquids. there is bulk things. there is just multiple manipulations. there is all kinds of stuff like that. But then I mean, the other thing is that these hands are really complicated, and we really have not mastered them. I mean, I have mastered that one, and you have mastered yours, but we roboticists have not mastered the robotic copies of these hands. And why is that? it is a funny thing, which is that if you look at practical systems, if you ask what is the most sophisticated autonomous manipulation system that has been developed it is a pretty hard question to answer but I will just say I think one of the most impressive ones is a system that Mike Erdmann did one time, which involves two arms. Each arm has just a palm, and by varying the angles and pushing this way, and it is automatically reasoning about lines of force and where the gravity is and how much friction there is and what the shape of the object is, and it is able to do manipulation of objects, all reasoning, and just using palms. And you can look at some other systems a system done a long time ago by Lozano-Perez called HANDY; a system done at called FREDDY at Edinburgh University many years ago. Both of those had relatively simple hands. Well, HANDY actually I guess HANDY might have had . Well, I do not remember about HANDY. But anyway, and then if you look at what people do, you think, Well, people have these kind of hands. But look at somebody That is lost their hand that has a prosthetic hook, right? they have got a very simple hand and They are still doing all kinds of stuff not as well, but They are doing pretty well. Or you can look at a human being using a tool, a simple gripper, pair of chopsticks. Or one of the most interesting things to look at is if you look at a surgeon using a da Vinci surgical robot. Those grippers are very simple. there is almost no haptic feedback; I think for all practical purposes there is no haptic feedback. That is what people have been telling me. There is visual feedback. They do really interesting things. They are folding you should YouTube Robotic Origami, and you will see somebody folding a paper crane with two simple little grippers as simple as alligator clamps, really. And so what we are trying to do is to say, Well, let us look at devices that are so simple that They are very affordable, They are very light, They are rugged, we can use them, but maybe more to the point, They are so simple that we can understand them. And then try to build up the autonomy from that understanding arising from the fact that we are using such simple devices. Now, it makes a lot of things a lot harder. I mean, the tidiness you have with saying, Well, I am going to have a device That is so complicated that I can conform to the shape of the thing no matter what shape it is and no matter where it is right? We do not get that tidiness anymore. So if I have a very simple gripper That is going to go pick up, let us say, a bottle of apple juice by just squeezing it good and then picking it up, That is something a human being would do like that <snaps>. But our theories of what constitutes a stable grasp do not work for that, because the pose from which that grasp would be stable may not be available with a very simple device. And what you see the human doing is to grab the thing even though it is not exactly stable where it is right now but you just squeeze it anyway, and when you pick up it adjusts, and you have got it, and it is not a problem. So That is what we want. We want something that I guess in a way has to be smarter, but can use simpler devices and develop an autonomous manipulation ability that way."
"Matt Mason","Interviewer","So you have a book with Ken Salisbury on manipulation?"
"Matt Mason","Interviewee","Yes. "
"Matt Mason","Interviewer","Have you done collaborated on other things apart from that book?"
"Matt Mason","Interviewee","With Ken, That is interesting. Ken and I have been such good friends, and we really worked together. I mean, even that book was not much of a collaboration, it was kind of a staple job. It was Ken's PhD thesis and mine, and then Ken tossed in some of his papers as well. I do not even remember if we wrote a forward for it or not. That book has been very good. there is lots of great things that Ken did in his PhD thesis, and sometimes when people cite it, it is cited as Mason and Salisbury, because M comes before S, so thanks, Ken, that was very nice. You can see some people who absolutely do not want to cite me for Ken's work, and they will cite Ken's TR or something else instead, just to make sure That is understood. But I am sorry, to your question about working with Ken, you know, I had an opportunity and when he first did the whole arm, the WAM Arm, you know, because I had kind of been working on related things. We talked about it, and I could not really figure out any way to help. Let me think about other things."
"Matt Mason","Interviewee","Yeah, but with Ken, we were talking about collaborations with Ken Salisbury. That is funny, I do not remember I do not remember ever actually doing something professionally with him, but I remember always visiting him at MIT when he was there, and we used to we did used to hang out together, so there was, I think there was a group that was a bit more fun and I do not know if this was a Stanford thing, or was it a west coast thing, or something, but all of a sudden I fell in with a gang at conferences that were going bar hopping, so I think I can tell you at least that much."
"Matt Mason","Interviewer","Yeah, who else was in that group?"
"Matt Mason","Interviewee","Well Salisbury was in that group, Mike McCarthy was maybe I should not be telling these things, huh? Mike McCarthy, I met him at a workshop in Minnesota, and I had no idea that, in those days, there was this really awesome music scene in Minneapolis, and Mike knew about it, and I think I met him and then five minutes later, we were headed down there to check out some of these bands. So it was a lot of fun. So I do not know if Mike is on your list or not, but he was a student of Bernie Roth's I think, and it was a lot of interesting history around, you know, mathematical kinematics, you know, which, I assume Bernie gave you all of that. Let me think, what is the question, other collaborators?"
"Matt Mason","Interviewer","Yeah, and other people, the kind of social network as you were a student, and then that is also very interesting. "
"Matt Mason","Interviewee","Yeah. Yeah, there was this group of people at MIT, so when I got there, Marc Raibert and John Hollerbach, and then Tomaso Lozano-Perez was doing one year at Yorktown Heights, and I believe he came back after halfway through my first year in graduate school. And between them and Eric Grimson, Ellen Hildreth, it was quite an interesting group. There was also Robinstant that showed up from Australia, visited for a while, and a Japanese visitor, Koji Fukumori and I am going to be forgetting a few people. There was something going on, I guess, not that you would know it necessarily at the time. I mean, who knows, maybe you suspect it, but you would not really know, or maybe the people that are kind of the more arrogant or, you know, or visionary, you know, actually believe it, but it did seem like maybe there should be a field of robotics, and maybe there was something new going on. There was, you know, in the way of publications, there were not many, so my Masters thesis was published in the IEEE Transactions on System, Man and Cybernetics. There were not any robotics journals, there was not really a conference, there was the there was an industrial conference. Mainly we were trading technical reports, we were reading the technical reports from Stanford, and we were reading our own technical reports and PhD theses. We actually put a book together that was a bunch of reprints. We kind of thought, well, you know, we are just trading these things among ourselves, if you do not have the good fortune to be to have landed in that group or a similar group at Stanford, how would you ever hit on this stuff. So we created a collection. Now I should say at that point, Mike Brady had showed up, and he is a real doer, I mean, he is somebody, when a lot of people are thinking, maybe we should do this, maybe we should do that, he is, you know, he is like, okay, I am doing it. And you better jump on the bandwagon if you want to be part of it, because he did not waste any time. But man, I mean, that combination really worked. I mean, Mike, and I was not really privy to the inner dealings of this, but Mike, together with Lou Paul, put together the International Journal of Robotics Research within a few years, and the International Symposium on Robotics Research, which was certainly at that time, the premier conference in robotics. And then I do not know exactly how it came about, but then it was not that much longer afterwards, that the IEEE International Conference on Robotics and Automation came along, and you know, so things kind of did evolve in the way that you kind of I guess you sort of imagine that we had an idea that maybe something like that was in the offing. But I do not think of it as the birth of robotics. You know, it is a certain step in the maturation of robotics, where it becomes, maybe more academically conventional and people can have, you know, conventional tenure track positions, and succeed. And before that, you know, an awful lot of the work that was being done was things that you heard about. Yeah, this guy had an AMF Versitran arm, and, you know, and all the things that they did with it. it is not written down anywhere, or if it was, it was hard to find. An awful lot of those guys were just these, you know, were people without PhDs, without academic positions, kind of, you might say kind of, you know, moving around from one group to another and so That is I mean, that was a real change, it was a change."
"Matt Mason","Interviewer","And concurrent with that, how did the Robotics Institute at Carnegie Mellon evolve? "
"Matt Mason","Interviewee","Well, let us see, so I got here in 1982, so it had started in 1979. When I got here, Raj told me that, you know, I mean the question is, I think, you know, everybody recognized at that time, that MIT and Stanford were, at least as far as academic institutions, sort of the two that were doing robotics in a big way. There were some other places, the Draper Labs in Boston, close to MIT, SRI, JPL, and then in the academic circles, there was some stuff going on at Illinois and Purdue, but you know, it seemed like Stanford and MIT, well, okay, I was at MIT, what do I know? I had my, you know, my maybe not the best vantage point, but That is the way I understood it at the time. And when I got here, Raj was saying, well, CMU is a more systems oriented place, a more less theoretically oriented, and you know, we are going to make things that work, focused primarily on manufacturing systems. That is kind of what I heard, and I you know, that may not be accurate. I do not know if you are going to interview Raj or not. You should get the original vision from him, I think. But it really changed, if it really did start that way, it changed quickly. When Moravec came, and when Red Whittaker, joined up, and when Marc Raibert showed up, I would say within a few years, we are already the number one place in mobile robotic systems. And with Takeo Kanade coming here, we are, you know, one of the top places in computer vision. And these guys were doing work, not just with industry, not just manufacturing applications, but also doing work with DARPA, and so with the Defense Department, and with the National Science Foundation, and then very strong sponsorship from NASA over the years, and the Office of Naval Research. So our kind of manufacturing orientation was a very strong element of the Robotics Institute for a long time, but it started broadening out right away."
"Matt Mason","Interviewer","And how did you decide to have a robotics PhD as part of the institute?"
"Matt Mason","Interviewee","You know, that is a good question. And you know what, I do not really know the answer. I can only speculate. There are a few reasons. I guess, you know, things have to come together. All the reasons have to be right. So I mean, it is got to be intellectually right, and it has to be and you have to be able to solve kind of the kind of logistical, financial, structural issues as well, and in this case, everything was just right. I think people saw robotics maturing and were excited about it as a field, and that goes back to the origins of the Robotics Institute. There was a very strong support for it from our most valued leaders, Allen Newell in particular, and then the president of the university and so forth. So intellectually, it just kind of worked. I think we have always had people who were interested in new things, you know, in creating new enterprises, and so that certainly fits, and then on the structural and financial side, it just kind of works better worked better for us to have our own PhD students, rather than to be borrowing, so to speak, PhD students from other departments. So so but I do not know the details. Raj would know."
"Matt Mason","Interviewer","When did you become director, and then "
"Matt Mason","Interviewee","About six years ago. How did that happen?"
"Matt Mason","Interviewer","How did that happen, yeah."
"Matt Mason","Interviewee","Yeah, well That is interesting. Most of my I think people would I have not been in close touch with year by year, may be shocked to discover that I was doing this, because in the old days, I always kept my head down. I thought you had to be insane to want to be a department head and so I was always the guy who would try to duck out of every administrative job, you know, committee work and so forth. I really wanted to focus 100 percent on research and well, you know, you want to do a good job teaching, so I would try and do all right with teaching as well, but I had no interest in management. And so what happened? Well part of the problem is that Pradeep Khosla I used to hang around a lot with Pradeep, and he was always talking to me about this. Obviously he saw things in a different way, as you might imagine, from his rise in the academic administration, so actually he did have an influence on me. Takeo tricked me into running the robotics PhD program, and you know, and that has its rewards, so I guess I fell in, over to the dark side, bit by bit, influence of former friends, good friends, and then, I do not know, as far as the actual event, you know, it is funny, because Chuck Thorpe was the director just before me, and I imagined that Chuck would be the director for ten years, so I was not really thinking about it at that time. I mean, I had, when Takeo first stepped down, I thought, well maybe I do want to do this. But when Chuck, after Chuck had been director for a year or two, he announced he was going to step down and go be the dean of the Qatar campus of Carnegie Mellon, and then at that point, well you know, it is more or less the faculty voting on who is least likely to give them trouble, so That is not an actual vote."
"Matt Mason","Interviewer","what is your vision for the future of the institute?"
"Matt Mason","Interviewee","Oh boy, I should have prepared for this question, huh?"
"Matt Mason","Interviewer","Where do you see robotics going? "
"Matt Mason","Interviewee","Well robotics is let me try that one. That one's easier. Okay, so here is my view of robotics. Robotics is about the idea that a machine can do the kind of things that people do. And you might extend that and say, well people and animals, depends on, I guess, what you think animals are doing. You know, can a machine have purpose? Can it be perceptive, can it be aware of what is going on around it? Can it actually interact meaningfully, purposefully with the physical world? it is a question that has actually been on everybody's minds for centuries, right? This is not a new question. There are stories about the Gollum being made from mud, and you know, machines that have been built through the ages that have mimicked living things, one way or another, somewhat superficially I would say, but now we are trying to do it in a much deeper way, right, and maybe the most, kind of profound way. Can we do the things that people and animals do? And robotics, what makes robotics different, and this is I guess this is the 50 year thing that brings this up. I mean, I think what happened 50 years ago, was that the final pieces were in place, where you could see that this might really be possible. The final pieces being, well computers, electronic cameras and intellectual elements, feedback, control theory, and so about 50 years, I think, about 50 years ago is when there comes the first plausible idea that we might actually have the kind of technologies we need. And I think that is actually been proven now. So if you watch a RoboCup soccer, you know, if you watch a bunch of little Sony Ibo robot dogs or cats, whatever they are, playing soccer, They are they know where their players are, they know where the ball is, they know where they are, they pass, they shoot, they play defense. I do not think it is possible in ordinary in an ordinary sense, in a common sense way, to watch that and without getting the sense that machines can be aware of their surroundings, right, and it is easy to forget that, you know, it was not at all clear that a machine was that a machine could do those things. And now I think it is clear. it is not that They are as good as humans, you know, humans are still way ahead of them, and cats and dogs are still way ahead of them, but I think they have crossed that boundary where you could say, yeah, you know, you have got to admit, machines can be where they do perceive, they do have purpose, they do act purposefully. So That is where I think we have gotten to. Where is it going, well one thing "
"Matt Mason","Interviewee","Well let us see, yeah, I was onto the spiel about robot about Ibo and RoboCup and "
"Matt Mason","Interviewer","You were going to say where it is going."
"Matt Mason","Interviewee","Yeah, well so one of the things That is happened is that our sense of what use this technology can be, has also changed. it is a strange thing, when you start out, you start with, well we want to build, you know, we want to build a dog. Well you have got to be able to see, you have got to be able to run around, you know, so let us work on seeing, let us just take seeing for an example. We need a vision system, right? You build a vision system, and well, in the process, first off, you discover that it is very, very it is a rich problem, there is numerous different technologies that can come together or be used independently, and then you start looking at all the applications of them. So right now, we have machine vision systems, but mostly They are not in robots, right, mostly They are out doing other things. Probably the most common thing for a machines vision system to be doing is the systems that recognize faces in your digital cameras, to do the auto focus, to help with auto focus, right? People look at that, and say, hey, they do not think of a robot, right, there is nothing in there That is necessarily a robotics technology, it is a technology that might have been inspired by trying to emulate what animals and people do. And it has this other use. Well, I mean, That is just the beginning. The most some of the most interesting ones or mind bending ones that I am aware of is for example, teaching kids to read. So there is a project here called, Project Listen, that Jack Mostow is involved in. And it is simple, They are using voice recognition software, to build reading tutors. They are using the kind of cognitive models that our psychology department has come up with over the years, there is an algebra tutor program. Well they developed a reading tutor program. The program knows what the text is, and it has models of how humans, you know, of how kids learn, and what kind of issues They are dealing with as they develop. And so with that, you can have an informed interaction with the student to teach them to read. I do not think, you know, I do not think people ever really thought that much about how profound that kind of thing could be, a long time ago. I mean, when you start having the technology available, you see these things. The excitement in it is not that you are doing within that was not being done before, I mean, a human teacher, at least a skilled human teacher is still better than the computer, but the computer does not have to compete with a human being, right, most of the kids, if They are learning to read at all, They are reading in classrooms where generally, They are reading alone, to themselves, right, and the teacher is maybe going from student to student, and They are interact individual interaction with the teacher is rather rare. The computer is competing, not with humans, but it is competing with inattention, right, and computers are very cheap, They are getting cheaper all the time. Microphones that you can do speech recognition is very cheap, so it is an opportunity to provide a service, namely, I mean, a really important on, namely education, in ways it could not be and to people where it could not be delivered before. So you know, another example of that would be another, I will say kind of unexpected application, would be watching mice. The there is a company in Manhattan, called, PsychoGenics. They test drugs by giving them to mice, and watching to see how the mice behave, right? So ordinarily a human being would be doing this with a clipboard and watching what the mouse does, and writing it all down and so forth, and it is very expensive, not because of the expense of the mouse, but of the human being. Well, they came to us, we built some instrumented cages for them that can measure, I think there is a force plate on the floor, I believe there is a puffer that can blow air at the mouse, there are cameras so that it can see where the mouse is in the cage, and behavior recognition software that classifies the mouse's behavior tick by tick, and then machine learning software That is classifying the behavior of the mouse and running the drug testing protocols. And all of that can happen now autonomously. The point of this is, again, it is not that it is doing something that you could not do before, but it is it can do it it transforms the economics of these experiments, which in turn, has the potential to transform the economics of drug discovery. So these things were not on the list. Right, what was on the list before, home butlers, right? This seems I do not want to say irrelevant, I had love to have a home butler, you know, but compared with delivering education across the digital divide, or dramatically changing the cost of lab experimentation, right, those things seem very small. So That is one answer. It still does not say where it is going. "
"Matt Mason","Interviewer","Well how do you see the Robotics Institute's role in the future of robotics? "
"Matt Mason","Interviewee","Well, let us see. So let me give you my excuse, first, my non-answer. The Robotics Institute, you know, we are a university department. We have, depending on how you count, somewhere between 40 and 100 faculty, and none of them are looking to me for direction, so the title, director, is more of a courtesy title. So They are all doing their own thing, They are all visionaries. A lot of times, strategic planning is more a sense of looking to see what They are doing, and maybe trying to extrapolate a little bit, connect the dots, and then run out in front, you know, grab the flag and run right back out in front of the mob, and then pretend like you are leading. So you know, five years ago, we went through one of these exercises and we discovered there had been a big transformation, which is what we call Robotics and Life. So in the old days, when the Robotics Institute started, we were focused on motivating robotics by looking at things that people would not want to do, or could not do. So space exploration, you know, hard vacuum, long distance, cosmic radiation etcetera, etcetera, right? It makes a lot of sense that we should send machines to space. Mines, mining, even manufacturing a lot of times, is very tedious and dull, and people would rather not do it. it is hard to sometimes fill some of these jobs. Agriculture would be another example of that, right? So this is what people called the three Ds, dull, dirty and dangerous jobs, right, and That is how we used to motivate robotics. But you know, implicit in that is the idea that we are replacing, you know, we are trying to figure out how to get machines to do things that otherwise people would have to do, replacing humans with robots. And what we have figured out within the last five or ten years or so, is that the most exciting applications in robotics are working with people. So medical robotics, socially assistive robotics, quality of life stuff, helping elderly stay out of the nursing homes, live independently in their own homes longer and longer, rehabilitation, education that I was talking about. So there is a long, long list of these things, and that is, I think, where the most rewarding applications are, and where some of the most exciting work is. So this is what we figured out about five years ago. The advisory board came, there was an interesting faculty meeting one year, where this was when Chuck was director, and he said, well oh yeah, and the president of the university was visiting, and Chuck, without having prepared, just said, well let us have a show of hands, how many of you are doing right now, some application that involves human interaction or human robotics, or something like that, and we were all stunned, because more than half of the hands in the room went up. So this is an interesting change, and not just at CMU, all over the world of robotics, very interesting stuff. Now did you ask me about five years ago, or about now? "
"Matt Mason","Interviewer","The future."
"Matt Mason","Interviewee","The future. Yeah, I do not know, it is interesting. I do not know, is Maja Mataric on your list? I heard her saying that socially assistive robotics might end up being the most significant application. That, I think, is a really interesting idea. Where is it going? I guess what I have maybe my conclusion from all of this, kind of the proliferation of applications, you see the appearance of applications that are completely outside of what anybody imagined. I have a pretty humble attitude, I think, about trying to project what is going to happen in the future. If you ask yourself, what are the applications of robotics, well let us see. So if you just think back a few years, in fact, maybe this hasn't really changed. I mean, if you just look at a computer, and you ask, you know, what are the applications of a computer? Well it is a lot, but you know, still, you look at it, and how does it get sensory information? Well, it is not that much, you know, it is getting stuff over the internet, but other than that, it is keystrokes. You know, what kind of actions can it take? Well it can not do much. You know, if you imagine that you, yourself, are in that situation, you are locked inside of this box, you know, interacting by putting pictures up on a screen and getting keystrokes, well you would not really be able to do much, right? So comparing an animal or a human being with that, is, I think, really mind blowing. What are the applications of a human being? is not, you know, if That is what we are doing, if we are finding machines that can do the things that human beings do, it is like asking, what are the applications of a human being? But without all of the constraints, right? So I mean the reason that the reading tutor works is because They are so cheap. I mean, They are just impossibly cheap, right, you can not train the human beings and get the human beings in place that can do that. it is the same thing with the mice, right? Why are they successful in space? Red I think I have heard Red say, every space mission, every robotic space mission is a suicide mission. You know, you can do things in space, obviously, you can not do with human beings. They can be small, They are not all soft and squishy, right? So well, okay, so That is just another excuse for why I do not have an answer, but immediate future is great. One of the best arguments I have for the future of robotics is just to show people the level of activity in the Robotics Institute, which started at a million dollars a year, in 1979, and it is running at 63 million dollars a year right now, and almost without exception, it is been exponential growth through its whole history, despite the so-called failure or disappointment of robotics in the 1980s, despite ups and downs, the trend seems very obvious. And it is an interesting phenomenon, it depends on several things working right, but one of them is that there is just no limit in sight, to the applications. "
"Matt Mason","Interviewer","Do you see any limitations to where robotics can go? "
"Matt Mason","Interviewee","I mean, not fundamental, no. No. Everything looks good. People are excited about it, That is the main thing. The excitement is justified."
"Matt Mason","Interviewer","What would be your advice to young people who are excited about robots and are thinking about a career in robotics?"
"Matt Mason","Interviewee","You should do it. "
"Matt Mason","Interviewer","How would they go about it?"
"Matt Mason","Interviewee","Sometimes They are slowed down. So you know, we do have people that come in and say, well, I do not know, is the robotics industry really going to take off? Are there going to be jobs? And That is too narrow a way to look at it, right? If you say the robotics industry, well there is a robotics industry, and it is doing great, but That is just the tip of the iceberg, right, the real payoff is in how it permeates all industries, and so if you look at where the robotics PhD students have gone over the years, and most of them have not gone to places that you think of as a robotics place. A lot of them are at Microsoft Research, they go to Microsoft, Google and Intel, financial companies, all over the place, NASA, of course. And you asked, how do they get started? Well, we are again having we are going to have a problem, because it is so broad, right, there is many, many different thing to do in robotics. If it is your aim to do a PhD in robotics, then you should study hard, you should get good grades, you should study math, and you should go home and build stuff. And what stuff, you know, in my day, people were working on their cars. That is not as easy as it once was. I started building radio controlled cars about ten years ago. That is pretty great. Radio controlled model airplanes, some people I know used to build helicopters, and then these days, the really amazing thing is, suddenly, robotics as a hobby has developed into something really interesting. Subscribe to Make Magazine, learn to build flame cannons in your back yard. do not tell the CMU lawyers I said that. "
"Matt Mason","Interviewer","You mentioned the failure of robotics in the 1980s, or the discord of the "
"Matt Mason","Interviewee","The so-called. The so-called."
"Matt Mason","Interviewer","Yeah, yeah. Could you just tell us a little bit about that, and how actually people managed to kind of, in a sense get out of it? "
"Matt Mason","Interviewee","Yeah, I do not know, you know, it surprised me when I was looking at our charts and I realized that you did not see a dip in the funding because of that. I mean, what happened was that in the 1980s, or late 1970s, the hype about robot the robotics revolution, about it revolutionizing manufacturing, was really over the top, and a lot of venture capitalists and others, got excited about it, and there were many, many companies building, basically arms and hands for manufacturing. And at some point, the floor fell out and almost all those companies went belly up or a lot of them were companies that were trying it, and had other things to do. They just stopped. Why why did that not have a serious impact at CMU? I think the reason is because well there is two reasons. I mean, one reason is because the technology is so fundamental, I do not know if That is the right word or not, so basic to so many different applications. I mean, the ability to perceive your environment, you know, if you put it that way, it is like, does that have anything in particular to do with manufacturing? No, That is just everything, right, it has to do with everything. So there is that. And then there is the fact that the faculty here are extremely agile, adept, even proactive at anticipating downturns. I will cite another example, which is that we were we did have an enormous run up in funding from the defense department for unmanned ground vehicles. And when there was a downturn, the faculty had basically anticipated it, and have replaced that with funding from other sources, mining, agriculture and other things. So you know, I guess one way of looking at it, I mean, I look at this as evidence that there is an untapped reserve, that there is, you know, we have not seen the bottom of the resources that are available for developing the technology. "
"Matt Mason","Interviewer","Is there anything that you would like to add, that you think we missed, or "
"Matt Mason","Interviewee","No, history of robotics and 50 years ago and stuff like that. Oh, I do not know. I will say this. Yeah, I will say something, which is that I think the most important thing robotics can tell us is about ourselves, and this gets back to a question that was asked earlier, you know, did I had I pondered the mechanics of pushing, or trying to do it with a robot, and the answer was no. I do not think we have a sense of how hard it is, what we do, or even in detail, what it is that we are doing, until we try to do it ourselves. And you know, when people ask, well what is the number one lesson that we have learned from robotics, maybe it is, we have learned just how hard it is to do these things. So you know, was not so long ago, everybody was impressed with how difficult chess was, and then you know, computers started competing at grand master level in chess. Well, we are still not competing with humans in what we generally regard as the most trivial of physical tasks, and as you ponder that, and you start asking questions like, gee, how hard is it to, let us say, figure out what is the best way to jump, you know, how high could a human being jump, what would be the best strategy to jump? These are really hard questions, right? I mean, the world of jumping was transformed several years ago, you know, with the Fosbury Flop. You think, wow, you know, after being in these bodies for, I do not know, somewhere 500,000 years or five million years, we are still discovering how to operate them, you know, in fundamentally different ways. That kind of fits in with robotic experience, which is that motion planning and control and so forth, that these problems are fundamentally very difficult. So our progress, you know, with robotics, I think, not just at such an overall level, but, I think, in detail, can help us to understand what we are doing. "
"Matt Mason","Interviewer","Do you think, once we build a RoboCup team that can beat the world cup team, that will diminish our appreciation for soccer? "
"Matt Mason","Interviewee","Diminish appreciation for, no, I do not think so. I do not think I mean, if it turned out that somebody said, oh my gosh, you know, there is this we just did not think of it, we should have been using left handed screws instead of right handed screws and then everything is simple, you know, unless it is something really stupid like that, or like, you know, oh, Frankenstein, he hit the dead body with electricity, That is the secret of life, right? If it turns out to be something that simple, then I guess that diminishes our appreciation, but like most people, I do not think knowing the nature of stars actually diminishes our appreciation of stars, and I think human beings are going to be way more interesting than stars, already are. "
"Matt Mason","Interviewer","Great. Thank you. I think there is somebody—"
"Michael Arbib","Interviewer","You can start by just telling us where you were born and where you grew up and where you started school."
"Michael Arbib","Interviewee","Well, I was born in England and at the age of seven moved to New Zealand and at the age of nine moved to Sydney in Australia, which is where I went to high school and my undergraduate work."
"Michael Arbib","Interviewer","Okay."
"Michael Arbib","Interviewee","Do you want to keep speaking?"
"Michael Arbib","Interviewer","Sure, yeah."
"Michael Arbib","Interviewee","Okay, well, I should first clarify that I do not really consider myself as a roboticist. My career has overlapped robotics from time to time and I think perhaps influenced it from time to time, but I would not consider myself one of the robotics people, as it were. So I really got started in moving away from pure mathematics, which was my first love in college in this direction by reading Norbert Wiener's Cybernetics, which showed me that mathematics could be applied in a different way from classical Newtonian stuff but thinking about parallels between brains and machines. And about the same time I came upon Grey Walter's book, which introduced me to his tortoises, and so that was probably the first real robot I knew outside reading science fiction like I, Robot, by Asimov. But as a mathematician I was very interested in automata theory and mathematical theory of neural networks and things of that kind. And then in my final year there was a neurophysiologist working at Sydney University on the visual cortex of a cat named Bill Levick, and he wanted to learn more mathematics, and so he taught me about the brain and let me see what they did to cats and I helped him with his mathematics. And it was he who introduced me to a paper called, What the Frog's Eye Tells the Frog's Brain, which had come out only a little bit earlier in which it built on some of what I had been reading on the basics of the cybernetics book, for example, the Formal Theory of Neural Networks by McCulloch and Pitts, and it turned out that Ledford and Maturana had worked with McCulloch and Pitts and had taken not the classic '43 paper but the '47 paper on how we know universals, which showed how patent recognition might operate over a layered neural network, and they tried to test that in the frog. And in the end they did find an interesting layered network, although it was not the one predicted by the theory. And so that got me interested in the frog as a place in which one could bridge between the actual biological data an the more formal theory that my mathematics had gotten me to. It also taught me that McCulloch and Pitts were at MIT until that time. Since I had been reading their classic papers I thought they were still in Chicago. And also as part of my automata theory I read a book called, Automata Studies, which was edited by Shannon and McCarthy who were on the faculty at MIT and had a very interesting paper by Marvin Minsky before he became virulently anti-neural networks. And so all these people, Wiener, McCulloch and Pitts, Shannon, McCarthy, Minsky and so on were at MIT, so that became the natural place to go for my Ph.D. work. I started working with Wiener because I wanted to know about cybernetics, but I also had a research assistantship with McCulloch, and so I was involved with that group. But then it turned out that Wiener was not really into cybernetics anymore. His big thing was statistical mechanics, so I was his Ph.D. student for a while, but when he left for his sabbatical and we did not get much correspondence I switched to another mathematician working on statistical mechanics, and in the end I decided that was not a very interesting type of mathematics. So I ended up with a Ph.D. in probability theory, stochastic processes that has nothing to do with robots or brain in terms of my own career. But midway through the Ph.D. I went back to Australia and gave a series of lectures at the University of New South Wales, and that became my first book, Brains, Machines, and Mathematics. So that really set me up for my future. And the one other thing I would add about MIT was that and it just shows how much serendipity affects one's career. A friend from Sydney wrote and said he'd read this book on control theory, and the authors Newton, Gould, and Kaiser were at MIT. Would I go and talk to them? And until that time I had known nothing about control theory beyond what was in Wiener's cybernetics book. So I went in and talked to them and they said, Well, since you are a mathematician you will be interested in these two people working out at Lincoln Labs, Michael Ethanessiotis and Peter Falb. And so I went to see them and it turned out they were developing the theory of Rudolph Kalman who invented the Kalman filter. And so after my Ph.D. I spent four months driving all the way around the United States visiting people and national parks and so on confusing the hell out of them because they all assumed if I was visiting them I was looking for a job, and then they'd start talking about a job and I would say, No, I just wanted to see what you were up to. Anyway, one of the people I visited was Kalman, who was at Maryland at a research center, but he was just then moving to Stanford so he asked me to go there as a postdoc, which I agreed to do. So after about six months traveling around Europe no, actually six months in London working on neural and then about four months traveling around Europe and the Soviet Union I went back to Australia and then finally got to Stanford. And so during that time I probably had my first real contact with robotics research because just down the road from Stanford was SRI at that time, still called Stanford Research International before Stanford disassociated itself and then Neals Nealson and his group were working on Shaky the Robot and the strip system for robot planning. So I think That is where I got first involved with real work on robotics. But my own research was divided between automata theory and mathematical theory of neural networks and then getting more involved with real brains in real animals, and in particular building on the work with What the Frog's Eye Tells the Frogs Brain I worked with a student named Rich Duday and we asked, What does the frog's eye tell the frog, so the idea is, okay. Here are some signals in the brain the original paper said that might be correlated with prey and might be correlated with predator, but how does the animal decide if there are several prey, for example, which one to snap at? So we came up with a model, which I think might've been the first winner-take-all network. You can check with everybody else and find out whether there were earlier dates than the late sixties. And then with other students we modeled mammalian systems with , looked at cortical networks for depth perception with Curt Boyles , looked at the cerebellum and its relation to that. That is when we started interacting with David Marr. And then I developed something called schema theory where the idea was that just as in computer science doing everything in machine code is death. You need higher level procedures, so I felt that the brain needed not just a structural account in terms of networks and neural columns and so on but a more functional level of parallel interaction distributed in corrections. Those were the schemas, and the focus there was to really think about vision, not in terms of just recognizing what was going on in the world but in terms of how that recognition could extract the parameters needed to guide action. So what I was doing then has been characterized as computational neural ethology, ethology, the study of animal behavior, computer models of the brain, mechanisms underlying that. So in a sense I was learning about robotics, not contributing to it but developing a framework that was very much relevant to robotics as, if you will, embodied computers, which had both sensors and effectors. So that gets me through Stanford. Are there any questions you want to raise before I jump into the next phase?"
"Michael Arbib","Interviewer","Well, so you were conscious of the applications to robotics. How much of your work was driven by an interest in being able to translate these neural models to an artificial system, and how much was just trying to model it ?"
"Michael Arbib","Interviewee","I think that the robotics people I was interacting with at that time were either looking at the visual front end, what computer vision algorithms might influence the thing, or in terms of extracting a model of the environment, or they were looking at the high level planning in a very abstract space. So I think that my work was probably more complementary than tightly geared to it at the time. I wanted to know really how you have a system that is extracting the information it needs to control its behavior inspired by the brain talking to the roboticist but not looking for a platform on which to actually implement it."
"Michael Arbib","Interviewer","And in terms of the cybernetics scene at MIT when you were there was there a growing interest in trying to develop robotic systems there or to continue Grey Walters' work in any sense, or were they sort of working on different "
"Michael Arbib","Interviewee","I left MIT a long time ago, 1963, so at that time under Minsky's leadership there was quite a lot of stuff in what you might call symbolic AI. Minsky and Papert were writing their book on perceptrons, which many people took as the death nail of neural networks, but I think just introduced complexity theory into the study of neural networks. We had some early work on computer vision, but I do not think there was what you might call live robots at that time. I mean I have always claimed since that I was a robot created by Marvin Minsky, but "
"Michael Arbib","Interviewee"," whether That is true or not I do not know. I do not know whether you would know this but a few years ago a group in England published a paper on unfortunately a very simple robot, but it was called ARBIB, and the good thing about it was not the robot itself but the acronym because it turns out that I am an autonomous robot based on information from biology, so what you are looking at now is not actually a human, but an artifact that Marvin Minsky created in the early 1960s. "
"Michael Arbib","Interviewer","But based on biology."
"Michael Arbib","Interviewee","Definitely inspired by biology, yeah."
"Michael Arbib","Interviewer","Did you ever encounter Shannon's rats or any of the other cybernetic robots of the early days? You saw the tortoise as ?"
"Michael Arbib","Interviewee","No, I never saw them. Yeah, I knew Shannon moderately well. I once went rowing in the pond behind his house and capsized, and he cycled out to rescue me because he had a bicycle on pontoons that he could take out onto the pond. But I talked to him more in terms of his mathematical theory of communication, so I knew about the rat study in relation to as you say Grey Walters' robot and other efforts, but I do not remember that as something that we were actively engaged in discussing, sorry."
"Michael Arbib","Interviewer","Was it just at that point the mathematical models and the neural models were more interesting? It seems that cybernetics had that sort of moment when they built a lot of robots and then they stopped for a decade or so, and then they started rebuilding them with the more symbolic AI except for maybe the Hawkins Beast, which was another cybernetic one."
"Michael Arbib","Interviewee","Yeah. No, I am just saying that there were obviously a lot going on at MIT so I can not claim to be giving you an accurate picture of the whole spectrum but certainly in terms of the people I interacted with there were the formal theory of neural networks and reliability theory over in McCulloch's group. There was the move into symbolic AI by the interest in perceptrons in Minsky's group and then a lot of control theory, communication theory, mathematics, so I was not actively engaged in robotics as such at that time. So as I say I think the first serious conversations I had on robotics were with Neals Nealson when I went to Stanford where it was at the level of planning, so in some sense it was complementary to my interest in what are the neural networks whereby a computer model of the brain can recognize objects in terms of interacting with them, navigating around them and things of that kind. "
"Michael Arbib","Interviewer","And what was the extent of your interaction with the roboticists there? Did you mostly have conversations or did you work with them on any of the projects at SRI?"
"Michael Arbib","Interviewee","Conversations."
"Michael Arbib","Interviewer","What was the first project that you worked on that involved a robotic component?"
"Michael Arbib","Interviewee","That is the next stage, the University of Massachusetts. So in 1970 I left Stanford. I was recruited to start the Ph.D. program and chair the new department of computer and information science, and so in setting that up I explicitly added cybernetics to systems and theory as the three tenants, as it were, of the department. And so I think the turning point came at a 1979 conference on the brain, which was arranged by amongst others David Ingold , who was one of the people I had been interacting with who did frog experiments. And at this meeting there were two very influential papers about human and monkey brains. Mark Genereaux from France had been studying hand movements in humans and looking at the way that the pre-shaping of the hand is coordinated with the movement of the arm. And so that led me to think through the issue of how to take the schema theory that had been developed more in relation to my visual control of frog behavior and think about how it could be applied to the visual control of hand movements. And so I put out a review paper that included my initial thoughts about that and fortunately or unfortunately it gave the impression that I knew about hand control, and so I got invited to an international meeting in Australia and then I had to produce, so I had two very good Ph.D. students, Thea Iberall and Damian Lyons, who worked with me to develop a theory of hand control. And that work finally led into robotics in two directions. One is that it raised the question of, well, can we apply this to control of a robot hand? So we got hold of what was then one of the first dexterous hands produced, the Salisbury Hand, and started applying our algorithms to that. And Damian in addition to working with me on modeling the human hand took schema theory and developed a programming language called RS for robot schemas, and That is seen modest application in the robotics community, I would say, not massive but some. And then we established something called the Laboratory for Perceptual Robotics, and I think this was somewhat novel at that time in that a lot of concentration had gone into the things of path planning for robots, and then of course in industry by that time there were already a lot of robots, but they were doing stereotyped operation. So the notion of really thinking through on the basis of my animal studies how to close the loop of perception and action, I think that was still relatively novel. And so some of the things that came out of that, I had a couple of students, John Prager and Daryl Lawton who worked on optic flow so that as you moved here I had been influenced by the work of a guy named Dave Lee from Edinburgh University who had been looking at the role of optic flow in animal behavior, so we said, okay. Can we go from his observations to actually thinking about algorithms for extracting optic flow in a way that could be useful whether it is a brain doing it or a robot doing it? And then a fellow named Ken Overton, who unfortunately left academia to work at General Electric and has never been heard from since, but he was quite the operator, and so he developed tactile senses that we applied to the Salisbury Hand, so we spent time picking up eggs with the Salisbury Hand and things of this kind. And then there was one other student, Steve Begich , I think, who continued the work on tactile senses. So I would say that was my main phase of being as it were within robotics rather than having ideas that interacted with robotics. The Lab for Perceptual Robotics is still going strong. The current director is a guy named Rod Grupen, and in addition to having a lot more robots than we ever had he has developed these ideas of perceptual and motor schemas that were part of the schema theory. Another way we developed schemas at UMass, University of Massachusetts Amherst was that we had two people, Ed Riseman and Al Hanson, who had a computer vision group, and they developed some of my ideas in schema theory and I interacted with them to think about how to recognize complex scenes so that you would have different schemas specialized in recognizing different objects in the scene but passing messages to each other so that the different schema instances could compete and cooperate to come up with the interpretation of that scheme, and that architecture was related to the hearsay architecture for speech understanding that had been developed in the early to mid-seventies at CMU, and we hired Victor Lesser who had been one of the members of that group to join us, so that got cooperative computation, distributed artificial intelligence, call it what you will, up and running at UMass. And then the other thing, which has had an influence both in neural networks and in robotics and also in machine learning is that I met a guy named Harry Klopf who was working at the air force research center outside Cambridge, Bedford, Massachusetts, and he put out a little book called The Hedonistic Neuron, and his idea was to think about brain learning by asking, what is in it for the neuron? So his idea was how could you have the neuron was in some sense adapting, changing its synapses, to satisfy its own needs. And so I got some money from him to do research on seeing if we could come up with a real theory of that. And I had two colleagues working on brain modeling at the time, Nico Spinelli, Bill Kilmer, and while I was on sabbatical after I had got the money they hired a postdoc to come in and work on the project. His name was Andy Barto, and when Harry Klopf gave us the money one condition was that, I know this very bright student at Stanford just getting his bachelors degree. You have to hire him as a research assistant on- on this grant, and that guy was Rick Sutton, and as they say the rest is history. Barto and Sutton came up with the mathematical theory of reinforcement learning that has been incredibly successful and influential. Oh, and then the one other person I should mention from my UMass days is Ron Arkin, who became very intrigued not with the hand work but with the frog work in terms of the models We had devised on how the frog recognizes its prey, how it avoids its predators, how it can detour around obstacles and so on, and so he took that and implemented that as a controller for a robot and that became the basis for his very successful career in robotics that he is pursued for many years at Georgia Tech. So, yeah, I would say my peak involvement with the history of robotics is during that period at UMass. And then I moved here in 1986 and I was recruited in part by George Bekey, who was then chair of computer science here, and he had a dexterous hand as well, perhaps not quite as beautiful as the Salisbury Hand in that it had less independent finger control, but it was the USC/Belgrade Hand. And we brought over Thea Iberall as a postdoc to work with us on that collaboration, and so there was quite a bit of work between the three of us then on dexterous hand control in relation to studies of human hand control. And then we had several Ph.D. students work with us. Tony Lewis did a thesis work, which we jointly supervised on evolutionary algorithms for locomoting robots, hexapod robots and so on. But I think it became clear after a while that most of the students we were getting oh, and just one other student in relation to this. Andy Fagg did his Ph.D. with me on what is going on in the monkey brain in relating parietal and frontal cortex and sort of taking visual information and converting it into hand control, but he was also actively involved with Bekey's group so that there was a bridge there from the brain modeling we were doing at the time into the robot control, and then Tony Lewis was looking at the evolution of neural networks. And that actually lay in some sense a basis for a later thesis at the University of Edinburgh by Alkie Icepert on how to evolve a fish as a lamprey's spinal generator for swimming into a salamander's spinal network that could do both swimming and locomotion on land, and he later came here with his then wife to do a postdoc, but that is a different thing. So there were some successes, I would say, from that collaboration, but it also became clear that we were not making as much progress as we should, in part because both of us were doing a lot of different things, in part because the students tended to be perhaps too purely computer science students, so we had a few lucky students like Lewis and Fagg who did enjoy tinkering, but we had others who did not really know what to do if the robot stopped. And so at that stage we were successful in recruiting a couple of very bright then young people to come in as assistant professors and basically handed over robotics to them. So Stefan Schaal in terms of the hand control, and now That is moved on to a lot of other issues where you are really thinking about how various learning algorithms can be applied to really look at the dynamic control of complex manipulators, skeletal systems and so on. And then Maya Matarich who came to us from Rodney Brooks at MIT who came in more to look at the social robots where you do not really need to know much about the guts of the robot. it is got a simple control. It will scoot around, but how do you work on those controllers to make them interact? And then there was a good Ph.D. student of George Bekey's named Guarav Sukhatme, so around 1999, 2000 we promoted him from Ph.D. to postdoc to assistant professor, and he has become very dynamic since. So with Matarich, Schaal, Sukhatme and some interaction with Laurent Itti, who I hired to work on the bridge between computer vision and brain vision, we really have a very strong robotics group here. But I would say by now I am just a brain guy and leaving the working with the real machines to them. My own interests were captured, I would say, in the late 1990s. We got some money to collaborate with an international group of people in Japan, France, and Italy on the neural mechanisms controlling hand movements on the basis of visual input, and Andy Fagg's thesis was a part of that. And then this group discovered something called mirror neurons, Giacomo Rizzolatti and his colleagues in Parma, which bridged between firing both to code the action the monkey is doing and to code an action the monkey is seeing someone else do. And then we here at USC with a brain imaging expert called Scott Grafton imaged the human brain, so we went there looking at individual neurons coding the action two ways because at least other chunks of brain that light up more for interacting with objects and seeing someone else interact with objects rather than just looking at the object alone. And we found that that seemed to be in Broca's area, which is traditionally thought of as a language area. So ever since I have been continuing modeling the mechanic brain but also developing a theory of language evolution that suggests that the mirror neurons might be at the heart of an increasingly elaborate set of circuitry that allows the human to learn and use language, and that is my life."
"Michael Arbib","Interviewer","Have you seen the mirror neuron model being used in robotic learning systems?"
"Michael Arbib","Interviewee","Erhan Oztop, who was the first student to model mirror neurons with me after his Ph.D. went to ATR in Japan to work with Mitsuo Kawato, who is probably the leading person on the brain robot interface in Japan, and so they have done some work. I would say their mirror neurons in the robotic case are not as interesting as the brain mirror neurons. But there was also a collaboration between them and Daniel Wolpert in London on mental state inference where they would look at how you would have internal models for different actions and how you could deploy them in different combinations on the basis of the mirror neurons. We will be running a workshop here at the end of July where we are bridging between models of action and action recognition, neural linguistic models and the neuron for that can support that. And one of the people We will be inviting is Yiannis Demiris from London Imperial College, who is working on imitation in robots because in fact some of the modeling he has been doing overlaps with what Oztop and I did in thinking about the relevance of mirror neurons for larger systems that could do imitation. The mirror neurons by themselves just say, I will recognize an action I already know, so you need a bigger system to say, Oh, there is something I would like to do but I do not know how to do it. How can I add it to my repertoire?"
"Michael Arbib","Interviewer","Who are some of the other partners in this international collaboration? You mentioned Parma and ATR."
"Michael Arbib","Interviewee","Yes. Okay, so I mentioned that my interest in hands started back in 1979 with the work of Mark Genereaux, so he was the French anchor for this effort, Rizzolatti in Parma, Hideo Sakata who looked at the parietal cortex. He was basically recording from the monkey brain to look at how vision was coded in a way that was relevant to action, and Rizzolatti's group was more looking at the frontal cortex to say, Okay. If I get that visual input what do I do with it? And then, Gennaro was more in terms of, Okay, those ideas are great. let us see how I can apply them in analyzing human behavior. And then we had another modeler at that, who is since gone on to do other things, but Michael Jordan, who did his PhD with Rumelhart [ph] in UCSD, where I met him because I was on sabbatical there while he was finishing his PhD. And then he, for a while, was very much engaged in motor control. And then he basically handed over to two of his PhD students, Dan Walpert [ph] I have already mentioned, and Gara Murney [ph]. And then he went into graphical models and machine learning, and is now at Berkley, I think, where he is done very well. So that was the- the initial group. And then we brought in other people to do some brain imaging in later years. "
"Michael Arbib","Interviewer","And so Kawato became involved with all this just later on when "
"Michael Arbib","Interviewee","Now Ka- Kawato is a different path. "
"Michael Arbib","Interviewer","Okay. "
"Michael Arbib","Interviewee","So back at UMass, I had something I had founded something called the Center for Systems Neuroscience with funding from the Sloan Foundation. And in the first year of that, one of the fellows who came to spend a year with us was Shun-ichi Amari, who has gone on to become the most influential person in the mathematical theory of neural networks in Japan. I mean, that was many years ago, so He came in 1977, I think. So Amari and I organized a meeting in Kyoto in 1982 on Competition and Cooperation in Neural Nets that, in part, built on the work We had done together in Amers [ph], but also introduced a lot of other people. And one of the bright young things at that meeting was Mitsuo Kawato, who would just finished his PhD. So as a result of that, I got to know Mitsuo quite well, and visited him in ATR quite a few times. And so, that led to the fact that Stefan Schall, who had been doing a postdoc for several years with Kawato when he was looking for a university position. It sort of was on the basis of that longstanding arrangement with Kawato that I came to be able to rec help recruit him here to- to USC. But also on that basis, several of my PhD students went on to do postdocs with Kawato, so the N- Nicolas Schweighofer, who did a PhD with me on the cerebellum worked with Kawato for several years, and he is actually now on the USC faculty, but over in biokinesiology and physical therapy, looking at how to apply his modeling to rehabilitation. How does the- the neural net how do the neural networks of the brain change after a stroke? How can we help the patient recover their functionality? Erhan Oztop then followed in those same footsteps, and then the third person, I think, from my group who went after his PhD was Jacob Spoelstra, another person who would worked on modelling the cerebellum. So That is- that is a longstanding relationship. And so, it is included discussions of the work he does on robotics, but I would say the- the serious interaction has probably been more on general modeling of control of hand movements, without worrying too much whether it is a- a monkey brain, a human brain, or a- a robot brain That is- That is doing the controlling, whereas- as you know, Stefan Schall really got involved in the- the detailed algorithms for control of the Sarcos, a robot very beautiful humanoid robot. "
"Michael Arbib","Interviewer","What do you think are some of the most significant neural models, or mathematical models, that have been influential in the evolution of robotics? So, common filters, specific forms of neural networks, what is your personal impression of what is been some of the breakthroughs? "
"Michael Arbib","Interviewee","Well, modeling the cerebellum has certainly had quite an impact. There was the- the Cam model, which was directly influenced by that. Jim Albus, who did a PhD thesis, published in 1970 on the cerebellum, not only came up with that model, but was very influential at the National Institute of Standards, whatever the it is NIST these days, I forget the acronym. So, thinking about the cerebellum, and then Michael Paulin, a New Zealander, was the one who really pushed using the Kalman filter as a model of the cerebellum, so that ties in with that brain influence work. But on the other hand, the Kalman filter is such a general mechanism that it is certainly been well applied. I mean, clearly, I would think optic flow algorithms, in terms of robot navigation, depth algorithms, more generally, whether They are static, stereo, or dynamic, optic flow has certainly been important. The work of Schall is typical of those people who are using complex, non-linear learning models to- to really get at the problem of, If I have a robot that is very flexible, I can not afford to use a- a sloppy algorithm the way I can with a- a robot with a few degrees of freedom and- and very rigid joints, and so on. So I think that is a another area. And then, where people have continued work on planning, and That is probably an area where neural networks, to date, have not been as important as more traditional AI models. From my point of view, another thing That is very important is thinking about distributive control, so you are not just looking at the a serial flow, in this case, you are really thinking about how to distribute control to different parts of the system. And it is interesting, there, that if we look at today's motor cars, they already have vast networks of- of computers on board, doing everything from optic flow to avoid collisions, to self-parking of the car, at the other end. So the interesting point there, I suppose, is that the field of robotics has moved, perhaps, out of its specialized niche into computer science, more generally, as we think about embedding computers in systems which have sophisticated sensors, and so on. So that the- the skills that go into robotics are not just for animaloid or humanoid systems, but for very diverse vehicles, as it were, which- which can be platforms for integrating sensation and action. "
"Michael Arbib","Interviewer","In terms of optic flow, do you find the work of JJ Gibson to be informative or influential?"
"Michael Arbib","Interviewee","Well, JJ Gibson is where we started. Well, JJ Gibson, in terms of the general concept of optic flow, and then part of our work has been influenced by the general notion of affordances. David Li, in terms of looking at actual use of optic flow in controlling the- the dive of the gannet towards the water to catch the fish, and the- the judgment of pace length by people doing the long jump, and things of that kind. So those- those two set the stage on which our particular quest for, How do we come up with brain-like parallel algorithms for extracting optic flow? took place. The debate with that man and there actually was a debate when I was at U- UMass. We invited Gibson to come and debate me, because he had this idea of direct perception, the notion that, somehow, the brain just picked up affordances, including optic flow. A- and so where the debate was drawn was, basically, I was saying, Yes, I agree with everything you are saying about we pick up this information, but look, it is not direct. And- and we have to understand the neural networks that- that carry out these performances. So- so, conceptually, Gibson was tremendously important. Computationally, he was not in the running, and so we- we built on his work in that way. "
"Michael Arbib","Interviewer","What was his reaction to you? "
"Michael Arbib","Interviewee","He was a nice guy. "
"Michael Arbib","Interviewee","No, no. I mean it was just what we- we had a- a debate, it was very well attended by the- the psychologists, as well as the computer scientists, and I think we- we both enjoyed the interaction, and I do not think either of us budged an inch, but I think the audience benefited from getting a- a deeper understanding of what Gibson was about by seeing how he responded to my questions. But perhaps getting, also, a fuller understanding of- of what neural networks were about, if- if they were pure Gibsonians, who had just looked at what information is being picked up. "
"Michael Arbib","Interviewer","Was it your sense that the people interested in robotics were less concerned about the symbolic AI-versus-neural-network paradigm struggle, and were more willing to engage with neural networks than the more traditional CS people that might have been more interested in the debate between neural nets and AI? "
"Michael Arbib","Interviewee","I think one has to be careful, because my sample is completely biased. So, in other words, I interacted with people who were interested interacting with me. And if they wanted to interact with me, then they wanted to see what they could learn in the way of biologically inspired robotics. So I would not claim any typicality there. I think other people were and if you look at the people doing mobile robots, there they- they probably put on some laser range finders and did not worry too much about the- the details of the visual processing. The- the controllers were very simple for steering the robots, and so a lot of their work would be more at the planning stage. An exception to that would be Ron Arkin's work, where he really was interposing a more potential field approach, based on the frog stuff, and other people did pick up on that. And then, of course, or in the early 80's Rodney Brooks came up with, what I thought was a reduced form of my schema theory, and what, unfortunately, most people thought was something brand new I am sure you get a lot of this in these interviews where he had a layered hierarchy, but- but, to my mind, the- the whole point was that you had to have representations to close the loop, in general, if you- if you were looking, for example, at navigation, where you had to know the layout of a- of a complex environment. So but a but the point is, that- that work of Rodney Brooks neatly complimented what Ron Arkin had taken from a more biological point of view, and sort of created sort of field of behavior-based robotics, and so on. But probably, if one writes the history of it, Rodney's strict hierarchy of representation-free schemas was more influential, at the beginning, at least. I think, in the end, everybody realized, as- as Ron himself pushed, that you had to see how to integrate the delegation of many functions to perceptual and motor schemas. But still, that had to interact with long term knowledge about the world, and in the end, I- I think it is a moot debate. You just say, Well, in some cases, the robot does not need much of a representation of its world, in other case, it does. And so, to be good at robotics, you really have to integrate the- the stuff which is more easy to relate to neural networks of the perceptual and the motor ends to networks that may tend to be more abstract interacting schemas, or even high-level programming languages that can bridge into- into representations. And we have done some modeling in the years since of rat navigation, and looking at models of the hippocampus, and those models actually go all the way back to the same year that Shun-Ichi Amari was a visitor. We had a- an Israeli visitor named Israel Lieblich, and we were looking at mice, finding behavior in rats, which had gone out of fashion. So we went back to the classic literature, and came up with something called the World Graph, the idea that the rat was, on the one hand, worrying about the affordances, it will not go through if there was not space to go through, but it had to know where it had got food, where it had got other things, and that, coincidentally, came out a year before a classic book called The Hippocampus as a Cognitive Map. So, in fact, we had a model of The Hippocampus as a Cognitive Map before the book which declared this as a major theme. But we were already influenced a little bit by the early finding on place cells in the hippocampus. I think that is another way in which I would not say that study has been very influential outside a relatively small circle, but for me, it- it gave a way of thinking about a hybrid system where we had certain parts of the system were developed as neural networks for the as it were, the immediate, if you will, the Brooksian [ph] interactions with the environment to avoid collisions, find a place to go, things of that kind, and a representation this World Graph of knowing about your world, knowing where food is, and so on. And another thing interesting about it is that I mean, just trivial personal history, but this, in some sense, was reinforcement learning before reinforcement learning existed, because we had if the animal was hungry, then the reinforcement of food was what mattered. If the animal was thirsty, the reinforcement of water was what mattered. In any case, avoiding a painful electric shock was important. And so, in fact, much later, after the theory of reinforcement learning had been well established on the basis of- of the Barto/Sutton work, then we were able to improve our original model by formally using some of the theory of- of reinforcement learning to fit things that had been done in an ad hoc fashion on the first- on the first pass. "
"Michael Arbib","Interviewer","So that was mostly sort of perceptual side, but do you see this also in the motor side, in terms of central pattern generators being controlled by representations, or grasping and trajectories of the "
"Michael Arbib","Interviewee","Okay. So the central pattern generators were always interesting. We had some interaction, and I think the- the UCSD sabbatical, where I met actually no, it goes- goes way back. Okay. So way, way, way back at Stanford, there were two people working on central pattern generators in insects. Don Wilson who- who died rather young in a boating accident on the Snake River, I think, and Don Kennedy, who went on to be chairman of the FDA and president of Stanford. And so, the study of central pattern generators was always an interesting theme for us, but apart from Tony Lewis' thesis and Auke Ijspeert's postdoc, that hasn't been something that we have really developed, as to seen from being part of just the general culture that I share with my students. And then with the- the hands, the whole point was that it was not a central pattern generator, in the sense of Ron going with them to be modulated, it really was a discreet movement. And, in fact, one of Stefan Schall's papers is where he claims to have differential brain imaging for discreet movements versus rhythmic movements. So the you have got a target, and then you are coordinating two controllers, one to get the arm to the right place to carry the hand, the other to get the hand in the right shape to grasp the particular object. That has been a research issue that we have looked at, both in terms of neural networks and, in one PhD thesis with a guy named Bruce Hoff, in terms of adaptive control theory, where we, again, interacted with the Gennaro group, in terms of data on what happens when you perturb the position of an object, or perturb the size of an object. How can the controller adapt to that? And we came up with a- a very interesting model that explains some rather strange anomalies so that, if the hand is coming out like this, and you suddenly switch the size of the object, it may, in some case, not stay like this and go into the new size of the object, but it may actually sort of shrink down and open up again. And sorry, That is if you displace the distance to the object. So we came up with an optimality criterion for the coupling, to say, basically, it cost you to hold the hand open. So if you- if you are suddenly told, I have got further to go before I grasp, then it may be worth your while to close the hand for a while, in terms of that optimality criterion. So that allowed us to explain, what, at first, looked like some very strange behavior that Gennaro and his colleagues had observed in their work in France. "
"Michael Arbib","Interviewer","You discussed a lot of different ways about how your work on different biological systems influenced things in robotics, and I was curious if your interaction about your work in robotics, what kind of effect it had on the rest of your work. "
"Michael Arbib","Interviewee","Well, as I say, there was a specific period at UMass, with the lab for perceptual robotics, and then, when I came here, interacting with Becky, where we were actually looking at robots, as well as continuing the brain modeling. And there, there was a real conversation, thinking about the optic flow, in terms of how the robot could use it, fed into our thought about the- the other system. And then thinking about hapsis, of- of the sense of touch, was influence by the robotics. But- but I would say that, in my personal history, it is more trying to understand the brain, and the robotics as a source of stimulation and occasional application, rather than many other people you will talk to, for whom They are roboticists, and they learn a little bit from the biology occasionally, rather than centrally. "
"Michael Arbib","Interviewer","And now there seems to be quite a push for cognitive robotics as a new area of research and expansion. Do you have any comments on that, or is that something That is interesting at all? "
"Michael Arbib","Interviewee","Well, That is what I have done for 40 years, and "
"Michael Arbib","Interviewee","If they want to say it is new, good on them, but oh, it is the same with embodiment, and so on. I mean, this is what we have been doing ever since we started work on the- on the frogs. And suddenly people in AI and cognitive science are talking about embodied AI, embodied robotics, but I mean, not embodied robotics. Embodied cognition. But really, this has been a central theme ever since the late 60's in my work. "
"Michael Arbib","Interviewer","So what year did you create the lab for perceptual robotics? "
"Michael Arbib","Interviewee","1980-ish. Yeah, probably. Might have been a couple of years earlier, but 1980-ish would be right. "
"Michael Arbib","Interviewer","And what year did you come to USC? "
"Michael Arbib","Interviewee","1986. "
"Michael Arbib","Interviewer","And the perceptual lab is still going? "
"Michael Arbib","Interviewee","Yeah. Well, it when I was last at UMass, about three years ago, it was. And a guy name Rod Grupen was, at that time, leading it. And not only, as I said before, with a much wider range of robots than we had when I left, but nonetheless, building on the schema theory that I had initiated. So it was nice to see that those ideas that I had developed, that Ron Arkin developed, that Damian Lyons, who came up with our RS schema language, that that work that had been from the early 80's, basically, at- at UMass, that the person who had taken over the lab for perceptual robotics was, in some sense, building on that tradition, rather than just doing any old robotics, as it were. "
"Michael Arbib","Interviewer","And did you actually collaborate with Ken Salisbury at all, or you just worked with his hand? "
"Michael Arbib","Interviewee","Well, in terms of getting the hand and learning how to use it, we interacted with him. But we did not, I think, feed back into the design of a new generation of Salisbury hands, or anything like that. It was more that we were customers and he was pleased to be informed of what we were doing with it. And I am sure we showed him the touch sensors, but I cannot remember, at this stage, whether he said, Oh, great. I am going to add those touch sensors to my hand, or whether he said, That is nice, thank you. That- that is gone from my synapses. "
"Michael Arbib","Interviewer","What do you think are some of the future challenges in the field of brain robotics? What do you think are some of the things that people are coming across now as big issues that they might want to deal with, or some of the things that are going to be coming up in the next five to ten years? "
"Michael Arbib","Interviewee","Just about everything. I mean, in terms of visual perception when I worked with Hansen and Riseman and this work peaked probably about 1980 on the visions system for seeing and perception I thought that, in the next few years, we would have a general system for analyzing objects in the scene, and how they move. it is not happened. The- the funding has all gone into, Build me a very special purpose vision system that does a particular thing. So I think general scene perception is still remote. we have seen a lot of progress lately in object perception, picking out a particular object in the scene. Mirror system stuff is, How do you recognize what a hand is going to do to an object? More generally, How do you recognize actions? I think we- we have very little guidance, and especially if we are concerned with robotics for social assistance of- of patients and children, and others. Being able to flexibly recognize what is going on around you, not just what objects are there, but what humans are doing, so that you can either get out of the way, or protect them from harm, or assist them in some way. I- I think That is going to be so I had just say, on the- on the vision side, just that general thing of- of dynamic what we might call dynamic scene perception, to be able to recognize agents, objects, and the actions that link them. On the motor control side, I would suspect that the sort of work that I associated before, with Stefan Schall, on humanoid control, and so on, will continue. A lot of work in mechanical engineering of different systems. As I mentioned before, the question of how much of the robotics of the future will be so strictly humanoid, and how much will be able to, as it were, exploit different mechanical systems, I do not know. So that is a the mechanical engineering end and the control theory end is tremendously important, but That is probably rather separate. Everything in between, you know? Planning is still pretty primitive. it is fine if you have got a very constrained environment, but going beyond that and then language. I mean, That is not really robotics, but if we are going to have robots that are built, as some of them will be, for human interaction, then a decent language interface that can pick up on ambiguities, and use the current context to- to remove some of those ambiguities, are going to be very important. So I think the general point is, I- I see robotics as blurring. it is not really a separate subject anymore. Just as computer science has blurred. When I- when I set up the department at UMass, when I persuaded some skeptics to allow Becky to hire me here, the view of computer science was pretty narrow. When we do operating systems, we do a little bit of theory of curing machines. And beyond that, it is not computer science. And now, we- we have one of the things I initiated here was a seminar for our PhD students, just each week, to have one of our faculty come in and talk about their research. And I for the first year or two of that, I would sit in on the lectures. And I do not know. The barriers have gone. We- we have got Paul Debevec, who, as his computer science work, came up with a system for facial motion capture that powered the success of the Avatar movie, in part. we have got people doing senso-networks, so Gar- Gaurav Sukhatme is both looking at mobile robots, but he is also looking at what happens if you scatter a few thousand sensors in a bay to monitor the ecosystem. there is no line between those two- two projects. So the idea that computer science is no longer symbolic manipulation in a box, but- but embodies all these techniques of perception, all these diverse forms of effector control, and so on, means, I think, that- that, although there will still be a certain class of computerized devices that people will recognize as robots, probably the more humanoid ones, but the expertise that is in robotics will not be segregated from this very dynamic network of- of computer science research areas That is emerged in the last 20 years, oh, I would say. "
"Michael Arbib","Interviewer","And you yourself have had a very trans-disciplinary career in belonging to different parts of the institution. How did you kind of navigate that? Because if it makes sense. Makes it challenging. "
"Michael Arbib","Interviewee","Talk very fast. "
"Michael Arbib","Interviewee","No, I- I mean I think there is always a danger that, if you do too many things, you end up not being good at any of them. So I think the answer has been not to try everything all at once. I mean, in fact, I know when I came here 25 years ago, I dropped my work in- in algebraic theory of computation, for example, which was a sad thing to do. But I just could not establish the program here. And then, as we said, later on, it became prudent to hire these great younger people like Schall and Mataridge [ph], and then Sukhatme and Iti [ph] to take over the robotics. So I think that and now I am obsessed with the evolution of language. I have always worked on linguistics, off and on, since I knew Chomsky as a graduate student when I was a graduate student, not him. But I- I think That is probably that- that in any particular year, there have been real foci, grounded by having very PhD students, and but at the same time, the base of knowledge is increasing, so that opportunities come up later. So, for example, I had a group of four PhD students at UMass working on schema theory approaches to language, that came to an end when I left there in 1986. But then when about 11 years later, we did the brain imaging that said, Oh, look. These mirror neurons in the human appear to be in Broca's area, language area. I was then ready to be able to- to land on my feet running in returning to language, but now, tying it into an evolutionary scenario, as well as trying to think through whether the scenario gave us a new approach for thinking about the human brain, and neurolinguistics, which it has done. "
"Minoru Asada","Interviewer"," and go kind of through your education, talk about your projects, people you have worked with, places you got funding from those kinds of things."
"Minoru Asada","Interviewee","So were was that your question, or ?"
"Minoru Asada","Interviewer","Yeah, We will ask you questions and then you can talk as "
"Minoru Asada","Interviewee","it is much easier for me. Please ask any questions. "
"Minoru Asada","Interviewer","No problem. So can we start with just having you state your name and where and when you were born?"
"Minoru Asada","Interviewee","Okay. I am Minoru Asada. I have to see here, or ?"
"Minoru Asada","Interviewer","No, no, no. You can look at us."
"Minoru Asada","Interviewee","Yeah. I am Minoru Asada, and I was born in the Shiga Prefecture in Japan, October 1, 1953. Therefore now I am 58. Almost 60. Yeah, okay."
"Minoru Asada","Interviewer","And can you tell us a little bit about your early education and how you got to undergraduate how you decided what to study."
"Minoru Asada","Interviewee","So, this is a typical story about my education, is just I was born in Shiga Prefecture. More correctly, it is Nagahama City. And I went to the elementary school six year there, and junior high school just one year, because my father was employee of the JR. Well, at that time JNR, Japan National Railroad and his area was from a little bit of Nagahama City to the north part of Japan. And he got he moved okay, I finally moved to Toyama Prefecture. There I spent two years junior high school there. And when I entered high school, again, my father moved to another place. But at that time my brother older brother, senior brother had six year three years difference. And when I entered high school, also he entered university. And at that time in Japan, it is a very famous one, it is examination of University of Tokyo, due to a student movement against the university. This affect everything, many, many student. So my brother entered Toyama University, the local university, so he stayed in still Toyama. I was very near, and then I proposed to stay with him, because I entered the very famous high school for the very, very high rank to go to the very famous university in Japan. Then I decided to stay with him, apart from my father and my family, and spent three year there. So when I was a high school student, I just imagined, Okay, maybe I work as engineer or scientific or engineering science, not . And I spent three years, and my high school decided the direction which university you can go or something, something. And I decided to enter the Osaka University when I was 18, and control engineering. At that time, I just to the control engineering or information engineering. The control engineering just mainly control the object or something, including robots. So information engineering is a computer science and so on and so on. So I entered control engineering and spent four years as undergraduate. And when I choose which laboratory. So usually consists of at that time maybe five or six laboratories. So each laboratory consist of full professor, the associate professor, and at that time a research assistant two research assistance. And one more thing I have to say, that I got married when I was undergraduate, somehow. And or, more correctly, in Japan many high school students spend much time to training, of enter the university. Therefore once I entered the university, that is all my freedom or something. So I spent I did not go to the university. I did not attend classes, but maybe something. So I spent one more year in undergraduate. So I spent five years, when I got married. So, okay, I to go to the industry, because I got married, and also the baby, and so on. But my wife told me that, Okay, if you go to the industry, not for yourself but me that is, my wife and my baby please do not do that. Please choose your way as you like. Otherwise my wife says I do not like to be how do you say? Or if I enter the industry without my with not my will, so maybe I regret myself or something. So she does not like such a situation. Therefore, Please choose your way. And then I decided, Okay, I go to the laboratory, and I like to be the researcher, to do something. And when I decided the laboratory, I just decided the laboratory of computer vision . At that time, pattern recognition. So , I lack maybe my way is just engineering or science and something. And not simply engineering, but more deeply, I like to know what . Therefore, I am just very interested in the pattern recognition. How does the machine recognize the object, or something. And then I enter the laboratory. The professor, , he was famous in Japan in the computer vision, or the pattern recognition area. And I spent totally five years in the vision, computer vision, robot division. And my work, my PhD thesis, is how to reconstruct from the image sequence to the image sequence. And at that time some guy proposed some very simple idea of the 3D reconstruction from 2D image. I just followed, and my main focus, or thesis, was how to represent the 3D movement of the object, mainly maybe the robots and so on. That was my PhD thesis. And at that time so, I spent five years the master course two years, and doctor course, the PhD course, three years. That first two years, just mainly focusing on this image processing so, image tracking of the fish, fish swimming, and then tracking the object, and so on. And then the three years in the PhD course, I shifted more robotics, so the mobile robot, so the captured image of a sequence of the indoor and so on, and then we reconstruct the map disruption of something, something. And That is related to the robot vision and the computer vision, and so on. After I finished the PhD course, I continued my work with my students and my professor. The professor, the supervisor I was student. So we have, between the mobile robot with vision, and so on. And when I was I forget exactly, maybe 33 yes 1986. I was born in 1952 yeah, so 32 or 33 or something. Okay. When I was 32, I was asked to going abroad, because at that time it is kind of , maybe one year or something. And I tried to visit the state, the United States, somewhere, MIT or Stanford or CMU, and so on. And finally I decided to visit University of Maryland, Washington, D.C., and stay one year, two months, ten days. That is how many days of my research work. "
"Minoru Asada","Interviewer","Could you tell us you mentioned that somebody was already doing when you just started doing your computer vision work, you mentioned that a guy do you remember who the guy was?"
"Minoru Asada","Interviewee","Simon I forget yeah. Ooh, ooh, ooh, ooh. Very famous guy. He published a book."
"Minoru Asada","Interviewer","David Marr?"
"Minoru Asada","Interviewee","No, no, David Marr is so famous. Of course I did speak to him. And after him, Simon sorry, I can not tell you."
"Minoru Asada","Interviewer","We can "
"Minoru Asada","Interviewee","Sorry, I forget the title, exact title, but I just say the 3D structure for motion. Structure for motion, or something like that. that is a very simple idea of how many points to reconstruct how many points and how many images are necessary to reconstruct a 3D structure of the three points or four points, and so on."
"Minoru Asada","Interviewer","And you mentioned then you started working with the mobile robots. What were some of the reasons that people were using mobile robots in your lab?"
"Minoru Asada","Interviewee","So idea that at that time so very poor about the memory and the CPU and everything. So we are just image processing for the still image is one of the big topic, and image sequence is another one. For example, at that time, I suppose maybe the image consist of 128, 128 or something. Every 30 frames per second, something like that. So it is kind of a challenge. So when I was the master course student, I just fish tracking. That is very, very simple image processing, the tracking of something. So the more challenge is analyze some image sequence, like humans working, and so on. Therefore the movement purpose is another big challenge at that time. And then, okay, so take a picture of the first, and then analyze the image, or the image sequence. That is kind of a big challenge at that time. Still very poor memory, poor processing power, and so on. "
"Minoru Asada","Interviewer","So the robot would basically take a sequence of pictures that you would be ?"
"Minoru Asada","Interviewee","Yeah. Yeah. So there are separate ways to analyze image the sequence, and our case is just the camera is moving along, like this, therefore pick up some image vertical lines, how these lines and the image, and then reconstruct the 3D points or the structure of the corridor, and so on. Did I answer to the questions?"
"Minoru Asada","Interviewer","Yes, yes, yes. He was going to ask something though."
"Minoru Asada","Interviewer","So, who were you working with in Maryland and what kind of research were you doing there?"
"Minoru Asada","Interviewee","Azriel Rosenfeld and oh, I forget. I remember his face, but I forgot his name. Rosenfeld and another very famous guy of image processing. Rosenfeld, Azriel Rosenfeld, is very famous as god of image processing. He published the image processing book, the book and so on. Sorry, I will tell you later."
"Minoru Asada","Interviewer","No problem."
"Minoru Asada","Interviewer","What kind of research were you doing?"
"Minoru Asada","Interviewee","Oh yeah. At that time so before I was there, I did some work with the mobile robots. So in the United States and the University of Maryland, Center for Automation Research . So, ALV project, autonomous land vehicle, that is automatically controlled by the computer, and so on. So I continued the image processing, and other outdoor and also the large image. So at that time, also University of Maryland and also CMU, the Carnegie Mellon, and some very famous university or institute, they have started the similar work, ALV. And also one of the laser scanner laser finder started to be used. So we suppose then image, and video image together and analyze the structure of environment. So That is the main topic of in the University of Maryland."
"Minoru Asada","Interviewer","And what was some of the other work that people were doing there?"
"Minoru Asada","Interviewee","Oh, it is mainly the image processing. There are many, many, many image processing issues. For example, some image resolution, the database, or 3D structure or motion. One was a guy, at that time very young researcher, was Yiannis Aloimonos. he is a Greek guy. He also same conference. He proposed active vision. Yeah. And he has published many papers about active vision, mainly from the fabricator viewpoint, reconstructions or or something, something. Anyhow, the point is active that is, the observer moving intentionally. I suppose maybe that idea is very close to the robotics the robots. It actively captures image, and if the robot has some disambiguity, so the robot try to observe more, or different viewpoint, well, maybe we can attach or something. Therefore the concept of active vision, or active perception, is a very close idea of robotics itself."
"Minoru Asada","Interviewer","Did that have any influence on your work?"
"Minoru Asada","Interviewee","Yiannis's work?"
"Minoru Asada","Interviewer","Mm-hmm."
"Minoru Asada","Interviewee","Yeah, yeah. Yes. I think so, yeah. Yeah, we have discussed many times, and his starting point is he is a kind of a theoreticist. So all the time he claims theory, theory, theory. My position is much more not solely practical, but real sensors, image, and so on. So what we discussed and we actually, we did not have any papers we have coauthored, but discussed all the time. Therefore maybe I acknowledged his name in acknowledgement of my paper."
"Minoru Asada","Interviewer","Were there some other people that you spoke to often there, or had an influence on the way you thought about vision problems for robotics?"
"Minoru Asada","Interviewee","I just remembered Larry Davis. Azriel Rosenfeld, the head, and the subhead is Larry Davis. So, of course we discussed or, at that time, my English skill was poor. Therefore all the time they checked the English. And Yiannis Aloimonos, all the time we discussed. Any other guy? Yeah, there are many, many researcher from around the world, and we discussed many, many issues. But mainly I think I thought by myself and then exchanged the opinions and so on. So, yeah. Azriel Rosenfeld is a god of image processing. Larry Davis all the time check my English. Yiannis Aloimonos, all the time discussions, and so on. Yeah. When I was in the United States, these three guys impression for my work."
"Minoru Asada","Interviewer","And was Rosenfeld basically the reason that you decided to go to Maryland rather than some of these other places you visited?"
"Minoru Asada","Interviewee","At that time, one of my friend in Kyoto University he was at Kyoto University he visited there two years before my visit, and he recommend the apartment and any kind of thing. So for me, it is much easier to move. And so, more correctly, Takashi Matsuyama, the professor at Kyoto University, he before me, two years ago. When he go, just the professor Kanatani at the Goma University, he also successor of this guy. So the furniture or something, something the same apartment. And then also I am same apartment. So very smooth. So therefore when I visited the United States, he already set up my apartment. So my family at that time I took my wife and two of my sons, for whole family. It . Yeah, of course I traveled to MIT and stuff, maybe I forgot the detail, but maybe I could not I was not accepted by them."
"Minoru Asada","Interviewer","Do you have anything you want to ask about Maryland?"
"Minoru Asada","Interviewer","Not about Maryland. I was just going to ask, what do you consider your first real robotic project to be?"
"Minoru Asada","Interviewee","it is difficult to define what robotics. So when I was PhD course student, I already started some kind of image processing of the robot vision system. So this is part of the robotics. But much more robotics for me is much, much later. So when I was in the United States, my wife and two of my kids really enjoyed the U.S. life. So they ask me is there a possibility to continue more or to stay in the United States. So at that time I got a job interview inside the University of Maryland in the electrical engineering department, before I leave. So it was very, very close. So I got the interview with three or four professors, and after I left, I got some message of the interview. But when I returned to Osaka University, my supervisor when I was student, he decided my position to move, promote. Same university, but different campus and different department more correctly, mechanical engineering. So I hesitated. Go to the United States, or stay, or something? And my intention was that, okay, if I have a chance in the United States okay, I will have more times to go to the United States okay, then I stay one or two years here first, and then decide. But actually I could not do that. Anyhow, so when I returned to United States, I was the research assistant, and I was promoted to the lecturer first, and then one year later the associate professor, with professor Shirai Yoshioaki Shirai. he is a very, very famous guy of the computer vision too. So I started continuing the vision work with him 1988, 1989, 1991 yes, I think so. Three years. And I was telling him that I like to be promoted to in five years, in five years. So after three years, I just started to my promotion, and I told him okay, I tried to start. So something happened that so the professors of the department of mechanical engineering there are many professors, total 18 actually the group of the three departments of the mechanical engineering. So these professors liked me to stay. That means there is one empty space, one professor to be filled. So these professors asked me to stay and then be the professor over here when I was, at that time, 38 or something. Is that correct? Okay. I think so. Eight-sex, thirty-four 1990 is 37. Yes. Yeah, That is right 37 or 38 the age 37 or 38 is too early in Japan to be professor. Therefore, still associate professor. But I have one space for the full professor, associate professor, and two research associates. So that is a new stage for me. So at that time I started to a new idea of the robotics. At that time I really very, very confident about at that time. At that time myself to start robotics. So that was 37 or 38, yes."
"Minoru Asada","Interviewer","Who were the professors that wanted you to stay?"
"Minoru Asada","Interviewee","Professors?"
"Minoru Asada","Interviewer","The professors that you said that there were a few professors that really wanted you to stay. Who were they?"
"Minoru Asada","Interviewee","Oh, the professors of the department of mechanical engineering. So not my own area, but the fluid dynamics, thermodynamics, the material science, and so on, so and so. Complete different, but somehow, very complicated reasons, . At that time I did not realize that my achievement is so excellent. I have no actually I did not have any idea about my own, but just research, publish a paper, and so on. But these guys suppose that, Okay, this guy is very excellent. So we decide to stay ask him to stay here, or something. Another reason is I was okay, I graduated Osaka University the master course and also PhD course. They liked another reason is they like to be the professor of the graduate the same university, because actually there is some five professors in one department that come from the other universities. So That is kind of all the politics of the university. But I did not care anything of such things nothing. I can be anywhere, if I can do my research. So I stayed at this same university, and one laboratory. I can control everything. That is most the hardest time for me, because once you are promoted full professor, so many meetings and other issues. So I could not spend I can not spend much time for the research. Can I wear the ? Because this room is so cold."
"Minoru Asada","Interviewer","Oh yes, it is really cold. you are right. "
"Minoru Asada","Interviewer","So you were mentioning in your new position you could really start focusing and working on robotics."
"Minoru Asada","Interviewer","And what made you decide to turn to robotics at that time?"
"Minoru Asada","Interviewee","So that is a point. that is a point. So, Japan we had many Japanese robotics researchers, and many of them were doing the very in some sense very classical, the standard, the very popular robotics researchers. One of the idea, the machine learning. So let me start to try okay. When I moved but associate professor, but moved to the new laboratory, I am thinking about new ideas. Therefore we had many, many meetings with not my own laboratory but also with other people. So at that time, Professor , he was my supervisor. He collected many members of my own and others, and so on. And we started some kind of how do you say? introduction of the book to the machine learning, or the robot learning, and so on. One topic is reinforcement learning, and especially focused on the many theoretical issues and so on. I got idea, Okay, we should utilize this the reinforcement learning, and we studied about the reinforcement learning again, and again, and again. Okay, so the new topic, or new idea, is because before myself, many people study about not so many, but some guys studied all they studied about reinforcement learning, and so on, but not so real application to the robots. Because reinforcement learning is very, very interactive, but so many trials, it is kind of almost exhaustive search. They are not suitable for the robots because many trials means program and something, something. So we study about what kind of area is suitable to the reinforcement learning. At that time, my students at the new laboratory, newcomers so I spent much time with them, and we discussed what one of the guy, one of the students, proposed tennis robots, some kind of sports, or tennis so difficult. Okay, okay, okay. Okay, please keep him in mind. So another guy says, How about soccer? Soccer robot. Okay. Also soccer is also very, very complicated; very, very hard. But very simple gesture, chasing the ball and shooting the ball to the goal. just one mobile robot. That is kind of soccer. So we started about applying the reinforcement learning to the soccer robot. And also this is a same period of starting the idea of the RoboCup. That is one of the biggest, my life work. So at that time, 1992 or yeah, 1992 or 1993 there are two things, two big things for me. We have already started about started the work of the reinforcement learning, applying to the soccer robots. Another thing that Hiroaki Kitano Dr. Hiroaki Kitano he is a guy, cofounder of the RoboCup and at that time he collected the researchers to start a new project from Japan. Because he is a guy of AI, and in the AI field, there are many Japanese researchers just follow the AI work in the United States. So he likes to promote some original idea of AI or something. So he held some workshops, several workshops, about a new challenge, the grant challenge. So one of the grant challenge we discussed is idea of the RoboCup at that time. So That is the big idea, and he promoted he collected the young guys and discussed how to promote the RoboCup idea, and also he collected his connection of the people outside of Japan, and then we started something, something. So that is a big issue one. Another one is that 1993, ICRA conference. Twenty years ago? Almost."
"Minoru Asada","Interviewer","Next year."
"Minoru Asada","Interviewee","Yeah, yeah. We submit the first paper from my lab about the application of the reinforcement learning to the soccer robot. We submitted ? Yes, we started research and finished in 1993 and submit the paper for yeah, sorry, 1994 ICRA conference. Paper was rejected. So That is so the reviewer says, it is very interesting, but something, something, something. So my paper was rejected. So I disappointed so disappointed because this is a very new area, it is a very nice one. So I was confident that this paper should be accepted and I have a chance to give my talk or something. But that is a big conference. Even at this time it was a big conference. And the conference is kind of a gamble. So it depends on the reviewer, so it is kind of gamble. So I decided I disappointed. This is kind of a huge conference, and then I sent the paper to a very small workshop. So I sent the paper to the workshop where ICML the Internet Commerce of learning there are a series of workshops the robot learning or something. I submitted the paper, it accepted, I gave my talk. So researchers earlier or robotics earlier and they were so impressed by my work and also I was rated okay so my work was rated by many people. that is a very, very strong motivation, okay, I can do that thing, yeah. The next year I sent the same paper, exactly the same paper to the ICA conference, next year, 1995. So my paper was elected one of the best papers. Unfortunately I could not get the best paper, just one but nomination is okay. So at that time almost 1,000 paper submissions. The finalists is ten papers, That is one percent so my paper was elected so that is another evidence of the gamble, exactly the same paper, nothing changed. The paper is here, next year the finalist so big difference. So I said okay, That is confidence a gamble or something, so then I started the series of the and learning and also I started RoboCup activities. So we discussed started the RoboCup idea and we set up the first RoboCup in 1997. The ICGI Conference ICGI Conference in conjunction with ICGI Conference 1997 because it was held in Nagoya in Japan so we set up 1997. And then at that time we have four years because we started decide to hold the first RoboCup in 1997 four years before 1993. And we started a discussion and so on. So Hiroki mentioned that because 1993 is the first year in Japan professional soccer league. So we say Jleague Japanese league or something. So Hiroki mentioned Okay, Robot Jleague. That members outside Japan Why J ? Why J? Okay I have idea RoboCup is a little bit too large cup is a RoboCup. it is done naming. Actually I forgot to say I invented this name or not but anyhow myself yeah. So I started RoboCup activities and there was and so the and so on. So the early days my work of learning is directly ready to bring the RoboCup so my students do some work on the research and then at the same time do the RoboCup and so on. At that time the middle-size league the mobile robots are going around something. "
"Minoru Asada","Interviewer","Was Manuela involved then?"
"Minoru Asada","Interviewee","Yeah."
"Minoru Asada","Interviewer","Okay. "
"Minoru Asada","Interviewee","Yeah let me continue. So as I mentioned Hiroki collected that outside Japan. One was a researcher is Manuela Veloso and I forgot exactly the other guys but most invention was Manuela Veloso. And there was Peter Stone, her student. So before for us the RoboCup 1997 we held Political Cup 1996 and 1996 I was the General Chair of the not the but Conference. And I have any right to everything therefore I said that play RoboCup 1996 and at that time Manuela Veloso and maybe Peter Stone maybe came to us and they participated okay in the Political Cup we had some competition of the league, just competition and we have some demonstration of the middle-size league just demonstration of my team, my students I think. So there is Manuela Veloso came to us and then her team participated competition game competition yeah that and we discussed then how to organize the next year and so on, so on. Therefore Manuela Veloso is one of the founders of RoboCup."
"Minoru Asada","Interviewer","Were there any other people that you worked with on the RoboCup?"
"Minoru Asada","Interviewee","At that time?"
"Minoru Asada","Interviewer","Uh-huh. "
"Minoru Asada","Interviewee","So French guy, Dominique Touheur and I forgot his name, University of Southern California there was another group of middle-size league robot team. Now he is doing robotics, our modular robots. "
"Minoru Asada","Interviewer","it is not Triche or who was at U.S.C.?"
"Minoru Asada","Interviewee","U.S.C. I forgot his name. "
"Minoru Asada","Interviewer","Shawl ? No. "
"Minoru Asada","Interviewee","He is a Chinese guy. "
"Minoru Asada","Interviewer","At U.S.C.?"
"Minoru Asada","Interviewee","At University of Southern California. "
"Minoru Asada","Interviewer","Well we will look for it and if I can not find it I will just email you and We will figure it out. "
"Minoru Asada","Interviewee","I forgot his name. So anyhow, and also U.S.C. there were two guys. One guy is in the middle-size league. Another guy is competition relations . His name was I forgot. Wow. I have so long memory."
"Minoru Asada","Interviewer","Who won the first competition?"
"Minoru Asada","Interviewee","In 1997? Yeah, that is a story I would like to tell you. At the 1997 the first RoboCup with three leauges, one is competition relation game so 11 versus 11 games. The second one is the small-size league. That is Mauela Veloso participated the small. And middle-size league, not life size yet, no humanity yet. So the competition relation is much, much easier than the real robot therefore we got almost 20 teams or something or more 25? And the small-size league just four teams. And the middle-size the five teams. Small size league I suppose Manuela's C.M.U. gotta be if my memory was correct. And the middle-size league the five teams my team from Japan, another Japanese team from . is in the , University. Three more that one is from U.S.C. and one from I forgot the name but also United States, Australia the five teams. So also other teams. Nothing. The brought their robots but also random movement . U.S.C. and my team by accident the same pick Japanese toy , it is a Japanese radio control car, yeah. So I forgot his name, anyhow so this surprised because two teams the same vehicle and we put on the TV cameras and so on and so on. So sometimes difficult to discriminate the two teams together. Anyhow, so these two teams the final these two teams. In the first game they draw so we proposed the second game but somehow the U.S.C. teams went out of the battery so no battery anymore but we had but okay so we do not have any game. Therefore the core champions . At that time it is very, very nowadays very, very competitive the first year because we are shuffling we are sharing some difficulty of the challenge of moving robots because you know it is very, very difficult to control your five robots at the same time. So some robots it just stay, some robots it is random movements and so on so that is very, very difficult like a big challenge. So anyhow so the two teams core champion and we started it was together to do some research on this one. Yes and that was the first one and not so many European things yet that the RoboCup was held in 1997 and other people from European team, European people, okay. So they observed the game and they decided okay we can do it because you know the performance is so poor so we are very ashamed that the audience the spectators the potential the teams Okay we can do it. So the next year 1998 in Paris the in condition with the RoboCup okay so many European teams and also teams and so on many started, so That is the beginning of the RoboCup and at that time so is Sony therefore we got sponsors from Sony that the RoboCup is really in the early days and many professors not business guys so therefore the banner or some poster made by ourselves and also put everything by ourselves. So the very, very early days of the RoboCup, yeah. "
"Minoru Asada","Interviewer","And did become involved in the RoboCup because of Sony? "
"Minoru Asada","Interviewee","Sony, yes. So the idea was that was yes, in Paris, 1998 it is the most recent exhibition, and start from 1999 in Stockholm the first offshore game in 1999 yeah. So the idea of course you know Hiroki is in Sony therefore easy to discuss how to involve that I go to the RoboCup so the idea was that okay so two ideas, why that? Okay we should have the league with a common platform. Nowadays it is just standard platform. The hardware is fixed, and some competition of this That is one reason. Another reason is that because many people suffering from building the Robots because at that time since RoboCup started from the conference, there are many computer scientists, not mechanical engineering. They are not therefore they like to have such platforms. Therefore we love to have the RoboCup . So the backside reason from the company is that it is a big promotion, a big advertisement. On the other hand so the RoboCup teams they are very, very hard users so all the time using the . And then so we are also my team and other teams also it is easy to broken and then to the company that they fixed again and again and again many times. And then the company found one thing. One part systematically broken easily for many teams. They found some mistakes in the design of some parts. That is a good reason for the company side the user found something that something is wrong. That is the key idea of RoboCup. it is open to public, there are many people just try to use and then found some . This is some origin though, origin idea of the my proposal of the RoboCity CoRE. The RoboCity is a town but some experiment all kinds of robot experiment. And I proposed the city of Osaka ten years ago and we started to work almost ten years. But sad news that last year election of the new mayor and the new mayor changed everything. Because Japan as a nation huge amount of deficit all the time and also the local government similar situations so the city of Osaka spent much money to the not useful in the past therefore the new mayor change everything so cut, cut, cut everything and the reviews all kind of events and everything. So one of the events is my proposal because actually is a new town we can next year 2013 March, and we try to set up the RoboCity CoRE to deploy the experiments but no way to . So now I am thinking about different way to realize the RoboCity CoRE or something but first one was rejected. "
"Minoru Asada","Interviewer","So you were never able to-"
"Minoru Asada","Interviewee","Never. "
"Minoru Asada","Interviewer","But in Fukuoka, I think they have the free zone like there are some areas where you can do that right?"
"Minoru Asada","Interviewee","Yeah, yeah, yeah, you know every well yeah That is right, okay. "
"Minoru Asada","Interviewer","What were some of the elements that you were going to incorporate into RoboCity? What sort of things did you want to incorporate into the RoboCity? Like self-driving cars or-"
"Minoru Asada","Interviewee","Okay so nowdays, Honda, they are trying to utilize the to serve tea or coffee or something so in the restaurant situations or ATL it is Hiroshi Ishiguro he is the researcher there and also ATL of Honda and Osaka University has an experiment of the robot experiment on the street. But still there are some not entered on paper. So the idea that the RoboCity CoRE some experiment with robots the idea is not simply some individual robots but the environment itself a kind of robot, big robots, the town itself. So that is some people say it is invisible robots so there are many Sensors and so on so watch the behavior of the humans and to have to provide information and so on. So there a strong connection with a kind of a cloud idea so therefore we say just cloud robotics. So the environment is kind of the brain the information collection storage and then individual robots are kind of interface with people. So this is invisible. So the corporation with between the visible robots and invisible robots so the invisible robots not only have the people, not only to help the supporters individual robots but also help the people like the case or the senior people and now Japan is super aging society right? In a couple of years maybe one-third of the population is over 65. So we are so serious so the robots should support the senior life of the people therefore . So the idea of the RoboCity CoRE is also involved in this kind of situation some experiments how the people accept the robots or some artifacts or something. So all the time I mentioned this idea as many people agree oh, that is a good idea nice idea or something. So therefore the Korean people they said RobotLand or something near to Incheon Airport. That guy can see me and then I had interview similar idea they try to realize. So and also Singapore, not exactly same but some similar idea I would say the corporation the business side companies and the university that kind of incubation centers and so on. So it is a very pity to not to be in Osaka because actually I proposed that RoboCup in the next year that after the quake and also new mayor changes and Japanese big companies recession like this one we forgot, we throw out the proposal so next year it is not in Osaka. "
"Minoru Asada","Interviewer","Maybe after the other this mayor changes again. "
"Minoru Asada","Interviewee","Yeah, yeah because previous mayors send a letter to hold a RoboCup night in 2013 but this is the previous mayor and this mayor was worst. "
"Minoru Asada","Interviewer","The politics in robotics. "
"Minoru Asada","Interviewee","Yep. So I am continuing the work of applying to RoboCup and so on so on. And also where the final Cup of the RoboCup where is to build a team of 11 humanoids by 2050. Not my own statement but Hiroki's statement. He got the interview with the Scientific Generalist [p?] or commentators and they asked and this guy asked Hirioki How many years do you need to realize this kind of thing? And this guy said that Okay 100 years or something. This guy said that usually in general 50 years is kind of the time for example gene, 1953 that when I was born it is again at the gene and then 2003 all human genomes are analyzed. Or airplane, Wright brothers I forget the exact date and then 40 years later the jumbo airplane and rocket and so on. So with the things should they be achieved in 50 years, That is his comment. Okay, mentioned Okay, by 2050. That is his statement. But the statements as you know not the goal itself is a goal, but the process is much more important. So just as we say the project like U.S. space project to send a man to the moon or something and during this process, Teflon fabrication or something the spinoff. So we set and toward this process have that many spinoffs. For example if we can build that, then the is a very is a very closed one where the humans can do everything, humanoid can do everything. So if we have the humanoid that can play soccer with humans, that means they are very, very flexible and very movement movement and also the skin because if the human player damaged by the robot player many people claim something. So the robot should be easy broken against the humans, the very soft skin and this kind of material should be applied to the house for the senior people to protect them or something. So That is the idea. So the humanoid. So mentions that we have a chance because robot does not the human they do not feel any pressure. My statements are completely against. Without feeling the pressure we can not continue to get a win or something. So the motivation, our consciousness, there are many issues I remembered because I was integrated student. I chose a laboratory of the because I am interested in what humans are. Therefore the idea of course you mention running but much more interesting is motivations, emotion, consciousness, it is a very, very big issues. So of course I am joined I was keeping in order such as the RoboCup and the but at the same time I started some kind of new research issues of the cognition of the emotion, intuition and so on and so on so that is much more human oriented research started. I said maybe yes around early 2000, 2001 or '02 or '03 so one side is RoboCup research. Another side is study the learning the learning but still another other research issues the human cell. "
"Minoru Asada","Interviewer","And so is that your J.S.T. Erupt project? "
"Minoru Asada","Interviewee","Yes, yes, yes, that is actually with I studied Yashi Kinyoushi University of Tokyo and also , these three guys because we had some research meeting in the near the A.T.R. and the young guys, myself and Yashi Kinyoushi the key persons and Hideo Kanokishima He is a very famous guy in Japan, A.I. and he is now President of Hakota University and with other guys and also one of the members is Kenjiro Mogi He is a brain scientist that somehow he is a kind of generalist or the commentator and so on so also he published many books and so much media coverage therefore many other brain scientists they do not like evaluate his work. Because this guy Kenjiro Mogi, is so media coverage and not only the scientific problem but also some other entertainment, make comments so this kind of behavior not so good for these other guys so the man in Japan is they do not evaluate Kenjiro Mogi's work but for us it is different field so we exchange discuss also he keep out is feeding the color or any kind of things so he cares about and how to humanize something, something. So anyhow this research meeting so stimulus and the first meeting I introduce my robots of learning. And that so stimulating. So we how to apply learning to the other areas or the other learning method of other like humans and so on. So it is one of the guests was Mitsuo Kawato or the other guys and also all the time we invited the researchers not robotics but there is a medical doctor or biologist or sometimes another brain scientist and so on. So it is very, very stimulus and we land about what humans what the biology systems is or something, something. So we think about such kind of issue the 2003 or '04, something like that and 2005 the start the year of my project and also interview during the RoboCup in Osaka. That is so busy time so 2005 in the summer I have interview with a lot of project. The more I have JST has a lot it is a very top one, very famous one and much more funding. Other one the Klost that I have two interviews, Klost and at the same time of the same member. So a kind of backup okay. The first one is Klost and the second one is and my approach was elected and then I started from September and therefore the Klost project okay your rejected of course. So we started September, 2005 and 5.5 years project. That second time of my life so much better . First one was I mentioned my paper was rejected and so on. That is okay so the idea is okay we can start the research of the human robotic research so the group consist of Yaso Kinyoushi , Hiroshi Shigiro , and another guy is he was my colleague . So pneumatic actuator's robots. So the baby robots of the newborn P.N.E.W."
"Minoru Asada","Interviewer","The crawling. "
"Minoru Asada","Interviewee","Yeah the crawling and the walking. Yeah, both. So his group is developing this in different kind of robots the baby robots and so on. And Hiroshi Shigiro's group of course you know he start already the Android research so he ask I asked him Okay the humanoid is okay, but do not make Android. The humanoid but please humanoid but very close with humans because at that time my impression Android is so impressed so much by us so it is sometimes difficult to focus on the research issues. Therefore I ask him to design not the Android type but somehow the humanoid but close to the humans. So his group they designed, discussed with companies and CB squared was the first robots we introduced from our project."
"Minoru Asada","Interviewer","So it is kind of like a newborn but it is much larger in a sense, CB squared."
"Minoru Asada","Interviewee","Yeah. "
"Minoru Asada","Interviewer","It has the bigger head. "
"Minoru Asada","Interviewee","So at that time still it is very difficult downsize it. "
"Minoru Asada","Interviewee","-three meters and the size is three kilograms but the proportion is a baby so the big head year right. Have you-"
"Minoru Asada","Interviewer","Uh-hum, I visited. I was at H.R.I. when it was in Osaka. "
"Minoru Asada","Interviewee","You came to my-"
"Minoru Asada","Interviewer","In 2010 so yes, I saw the-"
"Minoru Asada","Interviewee","Really?"
"Minoru Asada","Interviewer","I saw CB-"
"Minoru Asada","Interviewee","Okay so anyhow CB squared at the time the Hiroshi named the robot M3 so manmade man. it is so strong . So he changed the name CB squared, tried the robot with biometric body and CB squared that but Hiroshi like to insist M3 so after the CB squared his group developed three kinds of robots, , , and three types but all the time M3 , M3 . yeah, he likes to put M3. "
"Minoru Asada","Interviewer","What other sorts of collaborations have you had over the years and who have you been collaborating with?"
"Minoru Asada","Interviewee","Collaborating with-"
"Minoru Asada","Interviewer","Different researchers in the U.S.? Or around Japan?"
"Minoru Asada","Interviewee","Oh okay, okay after we started a lot of projects of my own, so yes, Hiroshi, and Hiroshi Shigiro, and the okay, I forgot, another guy is Toshiro Inui He is cognitive neuro scientist. So he has been doing some imaging study of the function MRI and also joined research with medical doctors who cares autistic children and Williams Syndrome. So the both A.D.S. and Williams Syndrome two extreme of the language development so one of the big challenges of my project was how the language development. So therefore we focused on the very, very early days of the human That is infant or the baby so with the group they have already started about simulation the very, very interesting on and that is a strong connection to the medical doctors who cares the babies and also were developmental psychologists and also they making studies brain scientists so at the beginning the brain scientist, the developmental psychologist, the cognitive scientist, the medical doctors and so on are not exactly in my project but there is a connection and discussion and so on so on. So therefore my idea was okay each group focused on their own research issues but my idea is unified, integrate everything together after 5.5 years, but actually I could not do that because of course the integration itself is very difficult but in each group they once they started their own research they found a new one, new one, new one, new one that is more closely related to some biologists who are the real one therefore I give up, okay, please do that. And then in my brain, tried to connect, and then, so the whole picture is everything, but the just the part is over here, so we achieved this one. Someone, guys did, I think, this one. This is missing, okay, this is something. So in my brain, I have a whole picture but I cannot integrate everything together, but I just put something, something here, and something So there are many simple research issues, as I mentioned it is a strong connection with the brain. it is an actuator, Toshio Inui, he is a cognitive neuroscientist. Therefore is very close to the brain scientists, and also he has joint research with a brain scientist who cares monkey, monkey brain, so the probe, now of course it is very, very different, bad cell and has the monkey think about the maze or some predictions, or so his group mainly focuses on the brain activities and That is dependent to the patient of the different disorders, so this is a very extent the connection to the it also involves many people, like this one. Did that answer the question, these kind of things, the more concretely some examples of research?"
"Minoru Asada","Interviewer","Or just other people whose work has influenced you, and you have interacted with in terms of sharing robotic "
"Minoru Asada","Interviewee","Yeah, yeah, yeah, so also I have to tell one other thing that, my background in the academic society. Not exactly the robotics itself, but in Japan, the baby science, it is "
"Nils Nilsson","Interviewee","As a matter of fact, he served mainly his tour of duty at ARPA and he was an assistant to Larry Roberts who was the head of an ARPA office of information processing techniques office. And it was Cordell Green who was assigned by Larry Roberts to look into whether or not it would be a good idea for ARPA to support research in speech understanding. Turned out it was a good idea and they did. And that is all mentioned in my book also. So, then Green started a company that is still in existence as far as I know, what is the name of the company, it may come to me. But, it is a company in Palo Alto that did work on software engineering. "
"Nils Nilsson","Interviewer","Cordell."
"Nils Nilsson","Interviewee","We had lots of students come from Stanford to SRI. And I learned a lot from the students because my background, I did not know what a compiler was. I mean, I did not have any background in computer science, and so these students would read stuff and tell me how to go learn it and I did. "
"Nils Nilsson","Interviewer","Did you have my much interaction with the people who were working on manipulation and grasping?"
"Nils Nilsson","Interviewee","Well, I knew about Vic Scheinman, I knew about his arm that he developed and designed at Stanford. But, I did not personally have any interaction with him. I was not so interested in arms at the time, Shakey did not have arms. Although we designed a system that we had proposed to ARPA that would have arms. But, they ended up not funding it. "
"Nils Nilsson","Interviewer","When did you make that proposal?"
"Nils Nilsson","Interviewee","Oh, I do not know, probably in the early seventies. "
"Nils Nilsson","Interviewer","And did you have much interaction with Bernie Roth?"
"Nils Nilsson","Interviewee","I knew who he was, but no professional interaction. I mean, we did not work together on anything. "
"Nils Nilsson","Interviewer","Okay. And then, at what point did your work ever come back to robotics?"
"Nils Nilsson","Interviewee","Well, so I go over to Stanford and first thing is well, I had to learn about how you become a chairman. The atmosphere was a good deal different than it was at SRI in a number of ways. First of all, the people in the department do not actually work for you. I think their idea is look, you are in charge. we are passengers on your ship, We will tell you where you want to go. Your job is to keep the engine running and do all the things that you need to do. And so, that was a bit of a change, but one that I did not mind, had a lot of smart people at Stanford. There were occasional things we had to solve problems as any manager does. Sometimes there are things that happen on the tail of the distribution that you got to go deal with. The other thing is whereas at SRI you could work at night if you wanted, but largely you would get there in the morning and you might leave at six o'clock at night and that was the working day. But, at Stanford really your work is never done. People are emailing you, they got problems some of them in the middle of the night. And they need things done plus the fact that there is this level above the department chair, the deanery, and deans have various demands. I mean, they want a vision statement every now and again. Where is the department going? We have to have tenure cases. So and so is up for tenure, you have to make sure we get all kinds of letters written. And you have to present the case for this particular person's tenure in front of a committee. We need your budget and oh, by the way we are going to have a special committee in the university to look into how we can better use computer science in civil engineering. Would you be on that committee? And so, there is all that kind of thing that happens more at a university, I think, than a place like SRI. So, it was a lot of work and the first thing I discovered there was quite a bit of work. But, it was all very exciting and challenging so I liked it. I did get involved right away with a bunch of students and I had four or five of them, Ph.D. students. One of the difficulties was that they all came in at the same time so in our little group we had weekly meetings. They did not have anybody, any kind of mentors, people who had gone on before them. People they might work with, so They are all starting from scratch and that made it kind of difficult probably for them and for me, but they had some very good students. One of whom, by the way, did end up at SRI."
"Nils Nilsson","Interviewer","Some of your Ph.D. students and one in particular."
"Nils Nilsson","Interviewee","Yeah. One of them named Karen Myers went to SRI and played a leading role in the project at SRI called CALO which stands for cognitive assistant that learns and organizes. It was a multimillion dollar project. And it actually led to a start up company called Siri, S-I-R-I, Siri, which has an application, free app I think, you can get on your iPhone that will give you advice about where to go to dinner and making reservations for you, things like that. "
"Nils Nilsson","Interviewer","So, I mean, did you do any specifically robotic work after?"
"Nils Nilsson","Interviewee","Well, let us see. In terms of robots after finishing being chair I took a sabbatical and went to, had half a year at MIT and Harvard, some combination, and I was in Rod Brooks' lab and I would teach a class or two at Harvard once in a while, not a class, but I had lecture for someone who was teaching a class. And half a year at Santa Fe Institute in Santa Fe, New Mexico and during that time one reason I wanted to go to Rod Brooks' lab is I began to be interested again in these intermediate level style programs which were very robust. And I was developing a formalism, a style of programming that I called teleo-reactive programs. And these teleo-reactive programs, I called them teleo-reactive because first of all the teleo part was they had a purpose. And the reactive part was how they worked toward that purpose depended upon their particular reaction to the current situation. So, however they decided to achieve the goal depended upon where they were at the moment. And if where they were at the moment suffered a setback as on their way to the goal something untoward would happen, well they would react to that and carry on. So, I had some students at that time who were developing in software simulated robots which we called bots. Well, I did have one student who actually programmed a little NOMAD robot using this teleo-reactive formalism. Tom Willicke, yeah, I think his name was Tom Willicke. And another student named Scott Benson who used this particular formalism to program simulated devices that would learn the effects of their actions. So, he was able to develop a system that could learn to fly a simulated airplane, they have these flight simulating programs. And so, his program could learn by watching and instructor how to take off and how to land. And it would learn that by noticing all the conditions that preceded a particular instructor's action, all the readings and all the dials and everything, and the conditions afterwards and then it would deduce or adduce that that particular action that the instructor performed would, in fact, take the situation from the before to the after. So, it would develop a whole set of these operators which were very much like the strips operators that I talked about earlier, the strips rules. So, he was able to do that. We never made a movie of it, but he wrote a dissertation and I think has had some impact. "
"Nils Nilsson","Interviewer","That is Ben?"
"Nils Nilsson","Interviewee","I would not close that window again. We will not tell Grace. "
"Nils Nilsson","Interviewer","And what year was the sabbatical?"
"Nils Nilsson","Interviewee","You set, all your wires? "
"Nils Nilsson","Interviewer","it is just the headphones."
"Nils Nilsson","Interviewee","That was in 1990. I went off in the fall, summer of 1990 and ended up in the summer of 1991. And so, I had another student who programmed little tiny robots that would wander around on a screen, these were simulated robots, using teleo-reactive programs that would accomplish various tasks. Another student who I am still in touch with quite a bit was able to program some simulated soccer players using teleo-reactive programs. So, soccer player, although might make a plan for doing something, the plans do not always develop the way you think They are going to because there are other players, other things happen. And so, but you always got confronted with a certain situation and there is always some best thing to do in that situation. And so, these particular teleo-reactive programs would try to do that."
"Nils Nilsson","Interviewer","Do you know if that strategy has ever been used for the Robo Cup competition?"
"Nils Nilsson","Interviewee","Not that I know of. However, I think that the idea of these kinds of reactive agents, I mean, I certainly was not the only one pursuing them. As I mentioned Rod Brooks was doing similar things. There was a man at JPL, Aaron Gat, G-A-T, who had some programming ideas that were quite similar. There was a man named Firby, F-I-R-B-Y, at University of Illinois, I think, was he? And I think he had something called reactive action packages. "
"Nils Nilsson","Interviewer","And would you say there is more similarity or more difference between say the subsumption approach of Brooks or some of these others to your own? "
"Nils Nilsson","Interviewee","Well, the subsumption architecture, I think, was quite a moving target. I was not too sure exactly what it was. It was anything Rod Brooks was thinking up at the time. I think the main thing that motivated Rod Brooks was that you could use the real world itself instead of a model. One did not have to make models and work plans out in models. Let the world store itself. And so, most of his ideas on subsumption capitalized on that notion. To a certain extent we did also with the teleo-reactive programs although you could also make plans stringing together these teleo-reactive programs and then proceed from there. So, I think my idea was that yes, the world can store itself, but you people do use models. You have to remember where you parked your car if you are going to let the world store itself you will eventually find it, but you got to look at a lot of places. "
"Nils Nilsson","Interviewer","So you have used both statistical and logical methods, models and representations as well as reactive systems. But these have often been very contentious debates within the AI community. How do you see that? "
"Nils Nilsson","Interviewee","Well, I think it is kind of working itself out now. I think that if one knows something for sure, I mean, statistical techniques, well, one way in which their used in these so called belief networks in which more or less you have propositions and propositions sometimes can be the cause of other propositions. And each one might not be known with certainty, you have various probabilities. And there are techniques for propagating probabilities throughout the network. So, if you learn something new that affects the probabilities not only of the new thing you have learned, but all kinds of other things that might be related. However, it is the case that sometimes you absolutely know pretty much with certainty or at least if it is 95 percent certainty you may as well take it as certain and then in that case, probably ordinary logical reasoning might be more appropriate say than trying to do things with probabilities. After all, when you have the probabilities if you are going to do everything exactly with probabilities there is a good deal of computational burden that not having certainty adds. But, if you do have certainty you ought to be able to capitalize on that extra knowledge. So, I think that there is a role for both techniques. "
"Nils Nilsson","Interviewer","Looking back what would you say were the most challenging problems in pattern recognition and what were some of the biggest breakthroughs that you had? "
"Nils Nilsson","Interviewee","Well, in pattern recognition one of the problems that was recognized from the very earliest days was separating the figure from ground. So, if you are looking at something well even today in face recognition you have to be able to isolate what the face is first and where it is before you can decide to apply the various techniques that you might be able to apply to decide whose face it is. So, picking out a face from a crowd, I think That is largely been pretty well solved. I mean, everybody's personal computer if it has Picasa has a way to recognize various faces and isolate them. Cameras have face isolating mechanisms in them. But, I think it was thought to be a big problem in the past. Otherwise, in pattern recognition I think it is still the case that we are not very good at dealing with cursive script. Connected speech, well, there are various statistical techniques that do a pretty good job with it now. You can buy commercial products but being able to deal with connected speech and connected writing was an intermediate term problem that I think has largely been solved. You talk to people nowadays who are prone to use the various statistical methods and I think they say most of these problems that we thought were really difficult can be solved just by having lots and lots of data. The more data you have the easier it is to solve it and so many of the natural language understanding systems and the, for example, translation programs basically use just lots and lots of examples to help them. "
"Nils Nilsson","Interviewer","And what do you see as the big problems in the near future for AI?"
"Nils Nilsson","Interviewee","For AI? For AI in general. Well, dealing with common sense I think is still the big problem. The expert systems are pretty good in their special domains. You might say Well, let us take a look at one of the milestones achievements. there is been several milestone achievements in AI. Chess playing was one, the autonomous car is another. More recently I think the Jeopardy Watson, the Watson program of IBM that competed on Jeopardy is pretty much a milestone achievement. However, I think even its designers will admit that when it came to dealing with common sense there were difficulties. It could get around that for certain classes of questions it was asked. The more circumscribed the question and the more likely it was that that question was explicitly in its huge database the better off it would be. However, it made several mistakes and even though it won and I think that a lot of the mistakes would have been solved if it had a better, more encyclopedic, common sense knowledge. There have been various attempts to try to solve that problem. Doug Lenat at Cyc is one who thought that Well, the way to deal with it is to hand code all the different elements of common sense you might ever need, the hundreds of millions of little bits of common sense information. Well, good luck. that is a never ending task because common sense changes and culture changes and so you are going to have to have something that can keep track of it and how do you keep track of it? Well, the internet's a good source. there is just an awful lot of stuff on the internet. it is all in English. So, you have a sort of a chicken and egg problem to recognize something in English you have to have common sense, but in order to have common sense you have to be able to recognize all the things that are there. But, I think gradually we are making progress on that. "
"Nils Nilsson","Interviewer","And what about more specifically in the area of planning? So, historically would have been the big problems that have been solved and then looking to the future what are the big problems ahead."
"Nils Nilsson","Interviewee","I think planning is pretty well under control now. And I have not been keeping track of that literature, frankly. But, there are various programs that win so called ARPA planning contests. And they put together plans that seem to be quite beyond what humans would ordinarily do. Planning movement of supplies, doing things like per charts and for a long time I think the problem of dealing with plans which had a big aspect of time involved in them. Certain things would take a certain amount of time, these things could be done in parallel, these other things could not be done, how do certain time dependent processes interact? But, I think they have made a lot of progress in that although I have not been keeping up with it. "
"Nils Nilsson","Interviewer","And in terms of so this project you did right after Shakey which was a sort of a coaching. "
"Nils Nilsson","Interviewee","Coaching, computer based consultant as we called it."
"Nils Nilsson","Interviewer","This was sort of a form of human robot interaction, do you see areas in which AI will advance the ability of robots to interact directly with people?"
"Nils Nilsson","Interviewee","Well, there are a lot of people focusing on interaction between humans and robots particularly the social interaction amongst them. I think some people are, Cynthia Brazil at MIT and some others, have not kept up with that either. But, yeah, I mean, humans are going to have to, well, we hope we do not put too much of the burden on humans, that they have to be specially trained to be able to interact with robots, but robots are going to have to understand humans and so, there is the need for, I believe, robots to have models of what humans believe, what humans' goals are, what it is people are trying to do. And so, for a long time there was work on what the psychologists might call theories of mind. How is it that one agent can understand what another agent believes and what another agent might conclude? And there were special logics designed for dealing with that. I am not sure where That is going nowadays, but I think it is an important area for work. And robots will have to have some idea of what it is that the people around them are wanting to do, what their goals are, how the robots can either get out of the way or help achieve those goals. "
"Nils Nilsson","Interviewer","And you mentioned before that a lot of the methods that are successful are the ones that need lots and lots of examples. Do you think That is going to be a problem for robots that have to interact with the world, that some of their examples might be crashing into things and things like that?"
"Nils Nilsson","Interviewee","Well, there is no reason why you can not give them lots of examples. I mean, they do not have to in their life have experienced all those examples. You can just put them in which you can not do with humans. So, with humans you actually have to learn by living. But, with robots you can put the life of previous robots right into them. "
"Nils Nilsson","Interviewer","So, in the case of Watson were there specific things you noticed in the kinds of errors that it made that made you sort of think about how it was structuring common sense? "
"Nils Nilsson","Interviewee","I recorded all of that and I looked at it. I have forgotten some of the questions that were asked. Well, for example, on this Toronto thing. Remember the example in which it was asked, well the clue was World War II aviators or naval battles for which airports were named. And the answer would be Midway and Chicago and O'Hare. And it mentioned something in Toronto, I think, even though it was supposed to be a US city. And I think the people who designed it explained that well, oftentimes the category US city does not really mean exactly US city, it is sort of general. And so, Watson did not count that as heavily as it should have. But, maybe it had some inaccurate common sense that allowed it to answer Toronto. But, anyway it was a failure of some sort of common sense reasoning. "
"Nils Nilsson","Interviewer","And do you think the increased power of computing is going to really advance artificial intelligence and robotics at a much faster rate?"
"Nils Nilsson","Interviewee","Well, if you had asked me that a few years ago I might have said No, because I think that whatever the power of computing was at the time it was fully able to handle any of the ideas that we had at the time. I mean, we were idea short, we were not hardware short mainly. Now, I am not so sure because the new idea That is come up, the use of lots and lots of data, well, lots and lots of data requires lots and lots of computing. And so, the more computing, the faster it can go the better. I do not know that That is the bottleneck at the moment. After all if you talk to the Watson people which I have not, but if you did talk to them and you asked them Gee, how could Watson have been better? If you had a computer, this IBM 7000 series or whatever it was, if it were 10 times as fast, 100 times as fast, 100 times as much memory would you have done better? I think they'd still answer Well, not necessarily. We would need more ideas about how to program all that."
"Nils Nilsson","Interviewer","So, it is also about the structuring of the knowledge. Do you think there is specific problems in AI that are not going to be susceptible to large corpuses of data or that require new understandings?"
"Nils Nilsson","Interviewee","Well, large corpuses of data are going to be useful in lots of them. I do not know that It will solve all the problems in AI. I mean, right now we can not do all the things that humans can do. Look around you and you can see. I mean, we have office buildings full of people. And many of them are not using their hand eye coordination. It is not mechanical engineering which is a problem. You might ask why are they there? What are the doing? Well, They are having meetings, They are filling out paperwork, They are doing studies, They are communicating with other humans, They are making plans. And those are things, why can not computers do all that? Why is there anybody in those buildings except the janitors and maybe a few top bosses? Well, and computers would be cheap if we could do it, cheaper than those people. And so, why are they there? Well, because computers can not do it yet. And will lots and lots of data solve that problem? I do not think so. Might help, might be part of the solution, but the reason we do not have what you might call human level intelligence yet is that we just do not have the ideas needed in order to write the programs that would allow us to achieve human level AI. But, we have a lot of smart people and I think we are making some progress. It will be a problem in the end, I think, for society what happens, what do we do with all the people that computers replace? And eventually, I mean, right now you need more and more skills in order to have jobs. But, there is this guy Robin Hansen, you know about Robin Hansen? Robin Hansen is an economist and he has got this interesting metaphor of sea level rising. Sea level is what computers can do. And land and the land That is inhabited, the jobs that require humans to do. And sea level's been rising. And on the shore a lot of people are displaced. Well, they have had to move to higher levels. But, to move to higher levels they have to have more training. Now, the fact that sea level's rising itself makes some higher levels. it is a funny thing. At sea level build some mountains so people can climb those mountains, but sea level will keep rising. And the question is will it rise above even those mountains? And so, what do we end up having people do? Well, there is certain jobs that only people can do. You can not have a machine make sweaters made by hand. And there is kinds of things which involve social interaction which only people can do. Some of the social interaction maybe machines can do. But, if you really want a human you got to have a human. And so, I am not saying that all jobs will be replaced, but we are already seeing a trend of many and I think that trend will continue and you read people who talk about the current slow recovery, the economic situation, and many people say Well, we have laid off a lot of people because of the recession, but in the meantime we have found out we could do some of those jobs that those people did with machines and by the way, we are not going to hire those people back. And so, I think That is going to be a continuing difficulty."
"Nils Nilsson","Interviewer","what is your advice for young people who are interested in a career in robotics or AI?"
"Nils Nilsson","Interviewee","Right now, I do not know, I think I had try to get involved in the bridge between AI and neurophysiology. let us take neural science in particular because I think there is still a lot of secrets about how the brain works that we do not understand that'll be helpful in engineering. The reason we do not understand them, I think, is we have not invented the concepts needed to understand them. I have this analogy with computers. If you had a Martian coming down looking at computers, measuring all the currents flowing back and forth from the transistors, no amount of all that measuring, no amount of understanding how a transistor works is going to tell you how say an online banking system works or how an airline reservation system works. You have to have concepts that got invented in computer science to even understand them. You have to have concepts like lists, programs, data structures, compilers and there are probably a whole set of analogous concepts in helping us understand the brain. So, yes it is important to understand how a neuron works and a lot of neurophysiologists might complain that models of the neurons that the AI people are cooking up are not accurate enough. Well, that might be, but no amount of detailed understanding of an individual neuron or even how neurons get interconnected I think will be sufficient to have a good explanation of how it is that we do what we do. We have to have some higher level things and there are people working on that. But, some of it, I think, will get developed by those very people who have one foot in artificial intelligence and one foot in neuroscience to say Ah, the analogy to these high level programs is such and such to the way the brain does this. And they will invent concepts that will then help us understand the brain better. "
"Nils Nilsson","Interviewer","Okay. Is there anything you would like to add?"
"Nils Nilsson","Interviewee","I think you have got everything. Well, I think of things after you leave. "
"Nils Nilsson","Interviewer","Oh, well, on the wiki page is said that Charlie Rosen started a winery."
"Nils Nilsson","Interviewee","Yes, he did. Ridge Wines, do you know about Ridge Wines? "
"Nils Nilsson","Interviewer","Yeah. I bought a bottle on my trip, but I did not drink it yet."
"Nils Nilsson","Interviewee","Uh-huh. Good wines, I have been up there helping him pick grapes."
"Nils Nilsson","Interviewer","In Santa Cruz, yeah. "
"Nils Nilsson","Interviewee","Well, in Santa Cruz Mountains. it is actually in the foothills behind Cupertino."
"Nils Nilsson","Interviewer","Okay. "
"Nils Nilsson","Interviewee","You can get to it, Ridge Winery, it probably has a website. It was bought, I think, by a Japanese company, but I think they kept the same winemaker and he and three other people at SRI started that winery. I think they have all passed away now. Well, everybody has, Charlie did too. "
"Nils Nilsson","Interviewer","Yeah, I saw that. Is Bertrand still around?"
"Nils Nilsson","Interviewee","Ravel?"
"Nils Nilsson","Interviewer","Yeah."
"Nils Nilsson","Interviewee","Yeah. "
"Nils Nilsson","Interviewer","Where?"
"Nils Nilsson","Interviewee","I have his email address. "
"Nils Nilsson","Interviewer","Oh, that would be great. "
"Nils Nilsson","Interviewee","Do you want it right now?"
"Nils Nilsson","Interviewer","Yeah, sure. "
"Nils Nilsson","Interviewee","Can I take this off?"
"Nils Nilsson","Interviewer","Yeah. "
"Nils Nilsson","Interviewee","we are done? "
"Nils Nilsson","Interviewer","Yeah. "
"Paolo Dario","Interviewee","institution, I owe very much to it, the Institute of Clinical Physiology or the CNR. The CNR is the National Research Council of Italy where I learned really a lot working with biomedical engineers, physicists, mathematicians and many, many doctors. And it was a very nice community where I learned the interdisciplinary research very much and international opening to new ideas, to new inputs. I have always been prone to have a very open mind, not too sectorial. So I am curious, very open to good ideas, hints coming from everywhere rather than from my own specific field. And then at that time, I learned a lot. So I learned working with sensors because from the artificial heart I was likely moved towards sensors. Sensor technology so sensor to measure pressure, to measure flow, to measure vibrations, accelerations, noise, any kind, mostly physical parameters because I am still a mechanical engineer as a background so I like physics. And sensor technology is a very, very good gym for education of engineers because it is very, very interdisciplinary. In order to design, a sensor you need to have good understanding of many different phenomena and using different things so modeling, materials science, microelectronics, single processing, measurement technologies. So you become aware of many different problems and you are able to integrate them because the sensor, today, we are no longer talking about sensor. We are more and more talking about MAMs and microsystems and, in fact, they are sort of micro machines, if you will, micro system integrating, mechanical parts, actuators, sometimes, sensor themselves, electronics, then control communications. Sensor technology is very, very good for training. And I learned a lot by working on sensors for a few years in many different areas. The problem of sensors is that the sensor experts are they depend on the needs of different people. So they had their own technology, their own abilities. There is a community. I am part of it, also a big part, and still I am part of it. But they are either discoverers, inventors in search of an application. Or I would say they implement people who can implement problems that are created by others. But through the sensor pathway I moved from the core of the medical engineering into robotics. So I enter the field of robotics through the door of the sensors because why developing a physical sensors like pressure, temperature, vibration, sensor, acceleration sensors I learned about robotics. I was not really aware about robotics before 1982. I met many, many bright colleagues, and masters, let us say who really advised me that this could be a good area for research, of course, for application. And that is also for science. So robotics gradually became my main field of interest because robotics is extremely wide. And so it was a very appropriate field for my own attitude so looking at problems with a large extension. For example, if you look at these robot here there is everything here, from sensors, to the actuators, electronics control, intelligence, sensing, in fact, a vision and communication and usefulness. And there is a mechanical structure that I like something like my motorcycle. Or those are just capabilities amongst other things. So sensors were the gateway for robotics. And my first research in robotics was on tactile sensing because these colleagues that I met at that time advised me that robots needed tactile sensors, artificial skin. They did not have artificial skin. And it is easy to understand that the sense of touch is very strong in biological systems. I would say all living beings need and have contact or more sophisticated contact sensor like tactile sensors or skin, able to detect different kinds of contact possibly, but more frequently, actively. So the sense of touch is an active sense. it is not relatively passive as hearing, for example. You have to search for information. So the sensors use similar technologies as pressure, sensors, in biomedical engineering, and this was where I came from. But they have many different functions related to manipulation and to active search so essentially, perception and intelligence, if you will. So gradually, I became interested, not only in the sensor, but also in the fingertip, in the finger, in the hand, then in the arm and finally, in the full body of the robot. And this was what I gradually developed and became the core of my research interest in the late eighties and in the nineties. I should also say in the eighties I was able together with a colleague of mine in Pisa, who is now a professor, Danilo De Rossi and people in the CNR and the university this is when I said that even if I always studied in Pisa, Pisa was a place where I could meet virtually everybody from every part of the world. I was all ready very international. So I met two people who really changed my life. One is the late professor Pierre Galleti , and professor Peter Richardson , both from Brown University. And through them finally, I took a plane and I visited my dream country that was the U.S. So in 1980, I was finally able to fly to the U.S. And then I flew maybe more than a pilot, sometimes. So now frequent flyer. I just say reconsider all of my previous . And now I am a very frequent traveler. And we started the collaboration with a very big company, Johnson & Johnson at that time. So we even create a partnership. So Pisa, Providence because Brown University is in Providence, Rhode Island. And I spent a lot of time also with my family. By the way 1977 I married my wife, still my wife, only one wife, Laura. And I got two daughters in those years. And so we went together to spend time in Providence from 1983 to 1986 or 1987 I was an assistant professor in research at Brown University. And we worked together with a group of biomedical engineers there and medical doctors in the development of a variety of applications of electric polymers. You still remember my background in sensor technology for medical application but also for robotics application. And that peer, exactly, in those years, I moved from biomedical engineer more and more towards robotics. And then in 1985 and 1986 and 1987, I was one of the first participants in ICRA. ICRA is now the International Conference of Robotics Research. The first conference was in 1984. It was at that time, it was the council and not an IEEE society. Immediately afterwards it became an IEEE society and the first ICRA conference was in 1985 in St. Louis. And I had always attended ICRA from that time on. And I met and I became familiar with many, many nice colleagues who are still good friends from Osama Katib , Ken Salsbury , Tomas Lozano Perez , Tony Vecci , Regina Biachu , Mike Ready , George Hirolt , Ira Chicanoweb , Tashi Facuda . And I cannot, of course, list of all of them but all of them are very good friends, colleagues, still. We enjoy meeting, collaborating. At that time, I would say really we created the community of robotics. We were all young, more or less, some really young, some mature. But the community was very young, very enthusiastic willing to open a new frontier, a new field. In this sense, we really were the pioneers of robotics, even if it is difficult. At that time, we did not realize entirely this but there was a lot of enthusiasm. Everything was to be discovered. Mark Raybert made this hopping robot. And all of us worked in different fields. I would say at that, my specialization was essentially tactile sensing. Regina Biachu was very good in vision. And Ken Salsbury designed his hand and Sam McTee was an excellent controller and so on. Again, I do not want to forget distinguished colleagues, but just to name a few. So the community was growing and we were achieving very good results. And every conference, actually every six months new things were implemented or discovered sometimes and invented and implemented and demonstrated. And it was so nice. At that time, we used the VHS video thing and we could see that for the first time the implementation. And so I also became a close collaborator of Regina Biachu at the GRASP Lab. And we worked together on hands, on perception, tactile sensing. I spent years collaborating with her, the University of Pennsylvania, and Philadelphia. She came, actually, we hosted many, many courses. All of the members of the robotics community, more or less, came as visiting professors in Pisa. I should also say that in 1983 I became formally an assistant professor at the University of Pisa with tenure. And then in 1986 I became an associate professor with tenure of biomedical engineering at the Scuola Superiore Sant'Anna. And then in 2000 it took a lot of time because in Italy those things are quite unpredictable I became a full professor at Scuola Superiore Sant'Anna. And meanwhile, I was a visiting professor in many different places, visiting, meeting, organizing conferences; I think it is interesting and a very good suggestion also for young researchers. There was one person who also probably changed my life. So one I think was Tony Vecci. Tony Vecci I met him in 1982 in one of my early trips in the U.S. and with the robotics mostly robotics community. At the time I met Lupold it was in Purdue University. And then there is the Pennsylvania. But I also met Tony Vecci at that time. He was at JPL. And he was really very, very nice in advising me, again, to continue on tactile, the development investigating of touch and development of tactile sensors. At that time I also wrote very fundamental papers on tactile sensing including one Spectrum, IEEE Spectrum. It was really very often cited. It was one of the most cited early papers on tactile sensing in robotics on active touch, active tactile sensing. So the concept of active touch was introduced by me and colleagues at that time. And so after this meeting with Tony Vecci actually he invited me in next conferences. For many years, I was the only Italian participating in robotics conferences and also working with IEEE because IEEE was the main society, of course, organized. We were the founders of the robotics and automation society. And Regina Biachu was another person who really advised me. And another person that few of us remember was Jean Vertu . Jean Vertu was a French scientist, who was a pioneer in tele-operation . He worked at CEA, that is the nuclear agency or energy agency in France, Paris. And he essentially invited me. He proposed me to organize a NATO workshop in robotics. In that period of time, 1982, 1983, 1984 it was the flourishing of many organizations in robotics. And one of them was IRP, International Advanced Robotic Program, of course, RAS, IEEE RAS. Also ISRR, the International Conference of Robotics Research that was very strongly for only invitation and I was honored to be invited. I am now a permanent member of the board there. And at that time, Jean Vertu advised me to organize this workshop promoted by NATO, NATO scientific workshop, of course. And I organized two such workshops in 1986 and 1989. And I edited the books that came out of these workshops. And if you read and I am glad to show to my students, the names of the people who attended those workshops, especially the second one. And you can see, all of the roboticists, all of those who are famous in robotics now were there. So these were funding events. And I owe to Jean Vertu, I was hesitating because I was very young, and I thought I was inadequate for organizing these workshops. He encouraged me very, very much. We had a meeting in Paris. He said, you will never say you will always remember positively these efforts or do this. And just the one week after we had this meeting in Paris unfortunately he died of a heart attack. But I want to remember him as one visionary who had really this attitude of encouraging young person to dream and to be part of this growing area personally. And so in those years I also developed my own laboratory I should say this because my group, of course, I was alone. I was traveling. I was studying. I was doing research alone, but I was also educating young collaborators. And I was in that peer toward the end of the eighties. In parallel with this international networking with this increasing responsibility in organizing events, I mentioned these workshops, but in 1991 I organized or accepted in 1989 to organize one of the first ICAR conferences. ICAR stood for International Conference of Advanced Robotics. I organized this conference in Pisa in 1991. And we had 501 participants, which, you know, is huge. And, again, if you look sometimes I do old pictures, slides, again, you can find literally all robotics community there. And my own group grew very much in those years. In 1989, I created the ARTS Lab. ARTS stands for advanced robotics technology and systems. So also pointing out the work advanced because we did not work very much in automation or in industrial robotics. It was mostly nonindustrial robotics. Technology because we like to build real stuff and to have our own technology, very advanced technology and system because we like to integrate different components into systems. And then in 1991, I established the second laboratory at Scuola Superiore Sant'Anna called the first lab which stays for laboratory for micro technologies and micro robotics. Both of these laboratories have been fused this year in the new Institute of BioRobotics that I have the privilege to coordinate. And we are now about 160 people working on a variety of topics, with about 80 Ph.D. students on board, which is a huge number and doing different things. "
"Paolo Dario","Interviewer","Okay. I just want to go back a little bit. So in terms of the social connections, so when did you meet, say, Regina Biachu for the first time? Was it when you were all ready at Brown? Or had you met her at these IEEE conferences?"
"Paolo Dario","Interviewee","I think I met her first in 1984 at this first robotics, international robotics conference. It was nice because I remember, I was introduced by Tony Vecci. Tony Vecci from Hungary. Regina Biachu from Slovak Republic at that time. And there was another colleague who was a very good mathematician expert in algorithms. I do not remember the name but we sat together and the three of them were from formerly, let us say from Eastern Europe. And they were in the U.S. as refugees, I would say, very high quality refugees. Yes, I met her at that time 1984. And then we became good friends and also really colleagues in the working together. She came to Pisa many times. I went to Philadelphia many times. "
"Paolo Dario","Interviewer","Were you a participant at all in the Romansi conferences? "
"Paolo Dario","Interviewee","Not so often I must say but a couple of times. Also on that there is an interesting story. I think it was exactly 1984 also or 1983 or 1985, and I met many, many very nice, very good people, Benny Roth from Stanford. Also Selma Katib was there. Bruno Siciliano was a young student at that time and also Hatso Takaneshi . Professor Kato was there. I became very good colleague of Professor Kato and his student Hato Takanishi and also Professor Sugano at that time were just students. And they sang the Waseda song and quite impressively at Romansi. And now, of course, they are additional. Mark Graybert who was there. So yes, David Orin is now president elect of the Robotics and the Automation Society. So yeah, talking about people who were and at that time, by the way 1983, I went for the first time in my life in China I spent one month in China at the Academia Cinica and then JiJong University . You can not imagine what was China in 1983. And then immediately from China I went to Japan also for the first time in my life. And I became a very, very good friend of Japan. So in the following years most cases I was living outside my lab mostly in the U.S. I would say predominantly at Brown, Providence, and Philadelphia and also visiting and meeting MIT, Stanford, also Salt Lake City. Jacobson team, he is a fantastic implementation in artificial arms and limbs and robots and CMU and Japan. So Japan I became very familiar with Tokyo, Waseda, Nagoya, all of Japan. I really became acquainted and very good friends and high estimator of Japanese, Professor Inoue and all of the people there at the University of Tokyo. And a great admirer or Japanese abilities. Professor Irose . Really great names, great people, great scientists. Fantastic implementers of very complex systems, very creative. Sometimes even doing very strange things. So the very same idea of the human eye that was born at that time, more or less. And I was fascinated. Please remember that my background is biomedical engineer. It is coming back. Because I should say my main I will say revolutionary idea at that time was medical robotics. At that time, people did not believe in the possibility of using robots in the medicine. Well, of course, it was an idea, circulating, but many people were very skeptical. At that time, the PUMA robot, the PUMA arm was there. I had the first PUMA arm in Italy. I was able to buy with my research funds and bring and use in the lab at that time, the first PUMA arm in Italy. So we were part of these efforts. But this was, I say, just on control, on very basic skills. But I thought that it was possible to integrate my competencies, not because of my competence because I thought for some application robotic could have been a fantastic solution. So merging and keeping into account my skills and my say knowledge of the medical problems with the new technology of robotics. So I began exploring. And this happened all ready in 1986, 1987, I published a paper with a student of mine who is now a professor, Professor Massimo Bergamasco. At that time, we published the first paper on the IEEE transaction on biomedical engineering. It was a special issue on robotics. And we presented a finger to be used as a palpation device, you know, active sensing. Actually, the idea was to detect breast tumors or other pathologies essentially based on the ability to discriminate, embed features with the different mechanical properties than the contiguous material. And also at that time, I was the tutor of another brilliant student who became then also a specialist on hands and manipulation that is Antonio Bicchi. He is now a professor. I would say many of my students Giorgio Buttazzo was another student of mine. We worked together. He spent a long training period at GRASP Lab, is now also a full professor. So during my career I have educated now maybe about 15 students who are full professors, in some cases associate professors in most of them full professors in Italy and many abroad, including the U.S., one of them in Japan and one in Korea. So in Europe, different places. "
"Paolo Dario","Interviewer","Are there any other ones you want to name specifically that come to mind?"
"Paolo Dario","Interviewee","I would hesitate otherwise I forget a few names. Well, in a way, my latest student is now director of our university. So Maria Chiara Carrozza she is also extremely good. She is an expert now on prosthetic hands, is a world expert in prosthetic hands and she is the director of my own university. And she was my Ph.D. student. So I think that it has been fun and also exciting to work together to create such a community. "
"Paolo Dario","Interviewer","Have you had a lot of students that go into industry as well?"
"Paolo Dario","Interviewee","Yes, many of them. I am very proud that this is another from let us say academic policy point of view, let us put this way. It was my vision. traditionally, labs in the U.S. so in Japan, and in Europe are formed by one professor plus a few graduate students. This is a typical model. In Japan, there is almost a rule that each laboratory that is named after a professor has twelve, thirteen people maximum. So a professor, maybe one associate professor, maybe one assistant or a post doc and then graduate and under graduate students. I thought that this was that I could explore a different frontier. And a different frontier is attracting, educating large number of students. I am talking about graduate students. And this was very risky and also very controversial for some people. But I think this is, in fact, a very good model because one, you have a critical mass. You can do a big project. You can explore many different frontiers rather than being a specialist. I must say that many, many colleagues are now coming after this model and also increasing their laboratories. I was one of the first. I sure could not say the first, but certainly one of the pioneers of this new model in robotics that is large groups but not in research institutes but really in a university setting. And so it is a sort of pyramidal"
"Paolo Dario","Interviewer","You were talking about the large labs. "
"Paolo Dario","Interviewee","Yes. So I was able to create this it was an adventure. It was a big risk. I like risk by the way. I like to take risk. I like to have visions and to go beyond the conventions in science, let us say here in engineering. I make mistakes sometimes but, in general, I am able to adapt to circumstances and to find in any case a good solution for a problem. So this one having large laboratory was a risk. But I said, I believe that robotics needs a larger number of researchers, you know, to have an impact and my research activity is a demonstration of this. Essentially, I started I mentioned this from one sensor to an array to the fingertip, then the finger, then the hand, then the entire limb, the shoulder, and more and complete systems. And in parallel, the number of people also grew. And the number of projects also grew. We were able to raise funds and when you raise large funds that were risky at the beginning. And we were ambitious. We were most of the first to investigate the European area. So I said that I spent my eighties and also the beginning of nineties in Japan and in the U.S. mostly. And then I started to stay in Europe rather because of the growing of the European research program that I explored this since the very beginning. So large funds, we are talking about million euros, a $1 million, allowed to pay, to support many students, many graduate students and many post docs. So it was a sort of, I would say, you know the more you take a risk and then you have resources and then you find the risks. And so I explored this model of many, many Ph.D. students. Not one professor, one student, but one professor maybe ten students. And in the meantime a few post docs that could work as sort of quote trainees and trainers of this. And I would say this model works very nicely. "
"Paolo Dario","Interviewer","So it was mostly your funding then from the European Commission. "
"Paolo Dario","Interviewee","At that time, yes. "
"Paolo Dario","Interviewer","How has the changed over the years?"
"Paolo Dario","Interviewee","Still the large majority, with some exceptions, of course, there were peer for example, still as I told you we had this big startup funding from Johnson & Johnson and Brown University. Then there was a period we were able to get quite substantial funds from the National Research Council of Italy. And this was the final big national program launched by Italy. And at that time I created a very strong and still lasting partnership with Giulio Sandini who also is a professor and director on one of the big groups at the Italian Institute of Technology working now on human eye robot, robotics the eye-cup and so on. And we have many joint projects. We also playing the current venture for the new European flagship on robot companions that I am coordinating and Giulio Sandini is a part of. And he is also a biomedical engineer as a professor. And so we share this attention to the Yuma model , to the biological models. So in that time, in the late eighties, early nineties, really I was quite young I was invited to be a member of the board of the Italian program, a big one on robotics. And in that framework we started two big projects. One on a robot, a system for hospitals. And the other one, as a robot for agriculture. I coordinated the project on the medical robot and Giulio Sandini the one on agriculture robotics. And we had a quite substantial amount of money. And we were able to test I tested this model of coordinated project, how to work in a project and this, in my opinion, is a very, very interesting model that is not common in the U.S. it is not common in Japan. I strongly believe in it value. Of course, there are inefficiencies because when you have ten different groups of working on singles, subsystems and components, sometimes the efficiency is not the highest. But at the same time, you get the contributions from some of the leading groups in a country or in a continent. And it is really extremely I would say educational for all of us. And we were able to build at that time we built a mobile robot, a big one with an arm. And the arm, by the way became, I am also very proud to say the first product of the first startup company that I created in our laboratory. In 1991, we created the first startup company of the Scuola Superiore Sant'Anna, probably one of the first in Italy. They have now 50 employees, still alive and successful and building nice robots and nice mechanism. This company, they have a number of Ph.D. graduates. "
"Paolo Dario","Interviewer","what is the company?"
"Paolo Dario","Interviewee","it is interesting. The name is SM. That means Scienza Meccanile . Scienza Meccanile is an old Italian it is not really Latin. it is an old Italian term to indicate mechanical science. It was proposed by Leonardo DaVinci. So we wanted to have and the original signature, let us say brand, of Scienza Meccanile was written from right to left, as Leonardo wrote. So I think a very nice combination of say history, attention to our past and look for the future. This is typically Italian, I would say. And it is also our tradition, try to blend culture, interdisciplinary knowledge and what we hope is advanced engineering. So in 1991, this arm became the first product and all together, they represented one of the first robot in the world devoted to medical applications. "
"Paolo Dario","Interviewer","Have you been involved in other startups, subsequently?"
"Paolo Dario","Interviewee","Yes. Right now, I am the president of two startup companies, small but ready to grow. And our team has created more than 20 startup companies. So you asked me about our Ph.D. students if they work in industry, and my answer is yes, they work everywhere. They work in university in Italy and abroad. They work in research institutes. Some of them work in patent offices. Many of them work in industries. And many of them create or work in startup companies. So even if we produce many Ph.D. students, I must say that so far I do not have major complaints about finding jobs. I would say it is a virtuous process, you know. Our institution has a high reputation. So just being here and being educated here like in the best university in the world it is a good passport. it is a good background for getting positions. And I would say in addition there are, obviously the capabilities of those graduates. So I am pretty happy about this model. So large number. So the ability to have an impact, not to miniaturize laboratory to do miniature things. But a large lab to do visible things or to miniaturize. But complex, I like this idea of adding an impact, okay, doing things that are visible and perceived at the frontier of science, but at the same time at the frontier of application. And we create jobs. We create people who have who are successful, essentially. I am very glad that I am not the only one, of course, but I am glad that our students are highly appreciated worldwide. They go everywhere. They travel not like me. They travel not like me when I was their age, I mean. They are traveling all times. They have huge network of knowledge. So it is an interesting system that I am quite proud of. "
"Paolo Dario","Interviewer","Just to go back to some of the actual projects that you worked on, so your early work on the tactile sensors, what were some of the technical issues you were addressing at that time, and the real challenges you overcome? And what kind of materials and technology did you develop over time?"
"Paolo Dario","Interviewee","Yeah, well at that time, I would say the most challenging issues were, first of all, the understanding of the nature of touch in neurophysiology. This is really a challenge because while vision and motion so motor control and diseases related to motor control have been investigated quite a lot in neuroscience. So mapping of different areas of the brain for vision or for locomotion are quite well known like other reasoning, logic, language. Tactile sensing, touch, the sense of touch has been investigated at a much lower level of depth, I would say. So there was some knowledge about the main structure of skin and the different receptors and how they relate to critical areas and then to other areas. But they were and still are not totally elucidated. So this one was one of the main challenges, and modeling the sense of touch in humans. And that was really fascinating. And this opened to me on the one hand a connection with the world, again, of biology, I was familiar with and very interested in, but also relation with neuroscientists. So we still are working very much with neuroscientists. So in the last decade I was also one of the pioneer, I hope not to be too ambitious to say that, of neurobotics, neurorobotics. It is really the fusion or the integration of knowledge in neuroscience and neurobotics, okay? Also, this was very controversial. In the beginning people said, Well, what is the relation? or the robot is just a machine. So this idea of using robot to understand how biological systems work or using robots to or robotic solution to substitute, for example, limbs, you know, prosthetic, artificial. So the hand or the arm or a leg it was, in my opinion, it was very, very important. So first point, neuro-scientific knowledge. Then the second issue was the technology for building tactile sensor. So at that time we are talking about twenty-five or more years ago the technology was growing. It was still quite immature also. So together with my colleagues and my students I was able explore, also combine solutions. You know, working with piezoelectric materials, especially polymers that could adapt to and to conform different shapes, but also other solutions, like optical sensor for example, optical fibers or or so temperature sensors, and solid-state pressure sensors and the combination of. You know, so the idea was to combine all these sensors, essentially into a layered structure. So this was probably one of the main innovation I was able to introduce. These are all the multilayered tactile sensor, not just one type, that is similar to what we have in our fingertip. So each sensor able to detect something. So high frequency vibrations oh, sorry. I even used a nail, an artificial nail. So it was a combination of static or quasi-static sensing, dynamic sensing, temperature sensing. So at the end, one of the most I will say this was really a pioneer work. Again, it was really cited by lot of people, some of them are now famous professor. At that time they were graduate students and they met me at that time. I already made many seminars and conferences on this. So it was a really quite pioneer work, was the idea of using a fingertip to detect texture or also the distribution of local stresses to detect sharp features, the ability to sense thermal flow from a heated finger to the object, to detect, to have a sense of the material what the materials do not know. For example, when you touch wood or touch iron or steel, plastic, you have a different feeling even if the temperature is the same. And the reason is that heat is drawn at different speed by different materials for the same contact, more or less. And so you have different sensations on what you touch. So this kind of thing that mix technology with processing. So how this could be processed. And then, of course, also the activity so how will you explore different surfaces? What is the strategy? Still now, we have project on that. So we made a lot of work on, for example, micro-technologies for increasing the resolution of the sensors or also silicon technologies and now hybrid technologies. So different kind of polymers. So we are collaborating with industry on this for detecting, for example, the hardness, softness, or, I would say, smoothness of the skin. So there is an interesting evolution of this."
"Paolo Dario","Interviewer","But in terms of the more signal processing and software side, what are the big challenges of integrating these different kinds of signals of the heat flow and of the touch ?"
"Paolo Dario","Interviewee","Yeah, well, of course, there are different levels of integration of these. One level is the, let us say, the peripheral one. And this information can be either kept different, like in different sensory channels, okay, towards the brain, or this can be integrated at different levels because we have different levels of reactivity. Okay? So, for example, some of this information should be processed very quickly. In fact, some of these sensory information when we touch something that is really hot, so we need to react quickly. Sometimes this does not happen. In fact, when we touch something that is very hot, sometimes it takes time to remove the finger because it goes up to, let us say, deeper and more complex processing units. But maybe when you expect something, this, you are ready. You can close the loop much faster. And this is an example of some . Then there are higher level, when you take maybe a decision or you define a strategy, and they go up to the, let us say, the cortical level when you have a strategy, when you take a decisions. So the sense of touch has, like other senses, of course, at many different levels of processing, some of them unconscious, some of them conscious, and the goal that we pursue is to try to integrate these different levels into an architecture that a robot can properly use. And I would say we are exploring all of these issues also, gradually. At this time our we still have the finger as a basic unit, you know, for exploring the sense of, for example, roughness. And my students, actually, my colleagues have now obtained very nice results published in top journals, including top neuroscience journal, because we are collaborating with neuroscientists now. We found finally some very good partners in neuroscience and these things. But then the next unit, let us say, some systems we are working on is the hand. So using this capability in order to control the grasping of the hand in robotics also in prosthesis. And then, finally, also we are using sense of touch for the foot now. we are also working on locomotion, this robot that actually has been developed after Waseda University. here is an example of collaboration with Waseda University has walking capabilities. And walking is a very, very complex ability that, of course, humans have but we take quite a lot to learn it. And then the sense of touch, you can find the sense of touch in many other applications from exoskeletons, for helping people, fragile elderly, but also disabled people to walk and we use counter-sensors everywhere there is contact between, say, robotic devices and exoskeleton with the limbs. We use more and more robots for rehabilitation. We use we have a new program That is very fascinating and very promising in using sensorized [sic] toys to detect pathologies of neurodevelopment in babies, actually, and children. We have developed a sort of gym, a sort of PlayStation, if you will, but for children, which children can play with their friends toys and while they play, the toys sense what the child is doing, if manipulation is physiological or has some pathological tract. And we can find touch even in micro-robots, small robots. So we are working on a new generation of robots for diagnostics or for therapy in which locomotion and vision and touch are also very important. "
"Paolo Dario","Interviewer","Could you talk a little bit more about the significance of active and active sensing, how that changes the problem and where you came up with that?"
"Paolo Dario","Interviewee","Yeah, we started you know, my very first development together with a student of counter-sensing was a fixed platform on which we put objects, okay? And then the platform had many tactiles, many tactile units, and they could detect the presence or absence of these objects. This was a very preliminary and very primitive, if you will, technology for detecting an object using contact. But it was very, very clear very soon that this is not the solution that we need activity to, how we say, to increase the information you can get. it is like when we observe something from different positions, essentially we increase the information that we get from an image. And for touch this is even more important. So by touching different object so by the hand we increase the information we can get and we can further increase this information by moving our cameras, let us say. Because the fingertip is a sort of camera, is a tactile camera. So it is like getting different kinds of information on an object from different points of view, actually. So active touch is fundamental, during desperation. Then when you have learned what an object is, you just move with a very simple grasping. But it is very fascinating to explore this kind of active behavior and an ideal robot should be able to do that in the learning phase. The learning phase is probably the most fascinating phase in the development of a person, okay? Children always learn, but we always continue to learn. But it is fascinating how a newborn is learning and discovering the world. So active touch is like discovering the world and then when you have learned how that the object look like or feel like, you can use your mechanical you can use the hand, because the hand is an exploratory tool, but then is also a very effective tool for doing things. So the two phases follow each other. "
"Paolo Dario","Interviewer","So over the last thirty years of robotics we have seen commercial robots that have arms and hands and now they can walk and we are really just starting to see the beginning of robots with real touch. And what are the real challenges for consumer products that take advantage of this kind of touch?"
"Paolo Dario","Interviewee","See, this is the current challenge. And I would say that due to technology and due to progress in understanding of models on learning and perception lots of progress have been done in implementing complex and affective behaviors in robots. Still, this area is not reached the level that one would envisage and then one would really like to achieve in consumer, say, robots. So we are pursuing or there are two main areas that are pursued. One is based on, let us say, the AI-style kind of approach that is developing a more and more effective algorithms to understand and to provide the robot with ability to discriminate, with ability to explore and manipulate, for example, objects. There is another route that can be pursued and that we are, for example, myself I believe in this very much that is the one based on the biological model. So understanding the brain, what are called the neurorobotics and there are models. And I would say now the majority, I dare to say, the majority of roboticists are working in this direction to so to take as a model the structure of the human brain, so the different structures and to try to replicate to understand and then replicate different levels of behavior starting from, now quite a lot, from low level animal species so back to basics in order to understand how these robots can become aware of the environment that they are. So to use touch in an active manner. To explore and then negotiate, let us say, environment that are not well known. I would say that here there is a new area that is becoming extremely promising in my opinion. That is the field of embodied intelligence, okay. embodied intelligence and people like Rolf Pfeifer at the University of Zurich have pioneered these areas recently. And then there are colleagues in my lab like Professor Tushita Laski who are exploring these field very, very deeply. The idea is that body and brain cannot be separated. This is my opinion that the most attractive and promising approach in the last few years. So in the past the idea was that if you fabricate different components I mentioned the tactile sensors and then the finger and then the hand and so on, and then the brain. Then you process these with some software. You can do things well. Like, the reality seems that this is not the right way to go. Of course, it works in many circumstances. But this is not how biological organisms really work. In biological organisms you cannot separate actually, the function, the body structures and morphology, really, are developed, I would say together with the processing. And actually the processing, in some way, depends on the morphology with a very simple, basic behavior of neurons or group of neurons with different morphologies, you get different behaviors. So those features and imagines what we can call the connection, you know, the nexus of brain, body and mind even. You can come eventually to develop robots that could be as effective as biological systems. When I say biological systems I do not mean necessarily humans. Actually, it is probably more appropriate to start from basic, of course, trying to accelerate the evolution. But beginning from simple animals up to more complex animals. Some simple animals exhibit extraordinary performance and how they do is my own curiosity more and more and the curiosity of many colleagues. And it is not, how you say, admitting that we are not able to achieve complex behavior. it is just a parallel way, because we are still taking a lot of benefit from novel technology. We are robotics has been able in the last few decades to develop extraordinary effective technologies. Okay. And to incorporate them into very reliable, very dependable machines. We think of Mars or just and industrial robot or even the floor cleaning robots. They are extremely defective [sic] using available technology. So robotics, we are very optimistic, but we believe that in order to make the real next step that is obtaining behavior that could eventually allow to leave robots together with humans and then they can interact. We should probably pursue the other way. So, for example, developing what we call the soft robots. Soft does not means necessarily sponge-like robots. It means soft behavior that is partly that is partly physical softness, but in part is a contra-softness. it is ability to adapt and to negotiate other shapes and machines and people. So this combination, those are the real frontiers. You know, given that we are already able to develop very effective components. So that the basic is megatronics incidentally, I should add that they have been one of the pioneers in Italy and also in Europe, Japanese have been the real pioneers so megatronics. Megatronics is the real concept of fusion, not just the addition. But really the fusion of mechanical structures. So you need the body of sensors, actuators, energy energy's very important. Energy will become one of the main issues in robotics. We cannot afford to have robots that consume, like, a heater, a boiler energy like a boiler. We need a robot that a very, very low consumption that means they have very smart solutions in them, then communication, architectures; all these integrated is megatronics. So we know how to make megatronic robot platform for robots [sic]. But next step is to go, as I say, beyond megatronics. So rather than developing different components, putting together and then trying to miniaturize, we need to design entirely you know, deeply integrated systems in which there is not distinction between what is mechanics, what they are the actuators without the sensor. What is the intelligence, in a way? And this is how bodies in biology are built. And so I go back to my original passion: biomedical engineering."
"Paolo Dario","Interviewer","But it is really hard to design deeply integrated systems, is not it? Why "
"Paolo Dario","Interviewee","Absolutely. And it is a challenge, in fact. But I am not saying that we should forget the other one. I am saying that the megatronic approach has been a major success of robotics, still is a major success and we should design robots according to the megatronic approach if we want to develop machines that can be used by people now. But if you ask me what is the frontier of research? I would add to the previous one that is still there, this one of we call sentient machines. We call actually, we are pursuing these in these new adventure that is the European initiative on FET flagship initiatives. You know, FET stands for Future and Emerging Technology. Flagship is an initiative of size, one billion Euro, ten-year duration. President Obama just launched a sort of U.S. flagship in the U.S. ten years also, similar size of funding. I would say more industry-related and application-related. The concept is co-something. So co-worker human-robot cooperation, which is perfectly fine. Okay? And this is more along the line of the megatronics paradigm. Also, in Europe, we have initiatives in this field. I am fully supporting and part of it. So how to increase and to improve the performance of the megatronic platform plus the software? So intelligent machines. Robot are high performance, intelligent machines. But, in my opinion, the new research frontier okay, entirely research frontier, or probably the most interesting for me and most challenging, as you said, is building new bodies and new brains for new robots. And so reducing or even eliminating this distinction between the different components, but building the system all together. So, of course, we can find the different morphologies and different organs in a body, but sometimes they are sort of indistinguishable. They work as a system. They really work together and this is, in my opinion, is a marvelous concept. Probably is the real new generation of machines. In the future one could use this concept to maybe for building cars or airplanes. "
"Paolo Dario","Interviewer","Well, what do you think the major applications are gonna be for this new generation of robotics and megatronics?"
"Paolo Dario","Interviewee","Well, our main field of application is taking care of humans. Okay? Because this soft behavior one could call gentle behavior, you know is like but I do not want to use a word that can be misleading, but is like a pet. But sometimes you use the word pet, you have the impression of sort of low quality, low level. But from an interaction point of view, okay, how you to develop the combination mechanical properties, you do not want to have maybe a machine like this at home, you know? If course, this is a fantastic piece of engineering. But it is also diverse. You know that if you touch this machine, it will be hard. So, of course, you can put something around, but in most cases the increasing behavior of a machine is something that you immediately distinguish from a living being. A living being is silent and is not noisy, is very, very sweet acting. The word is gracious. You know, I like this very much. Okay, this concept of graceful behavior. Actually, it was proposed or its importance was already mentioned by Steve Jacobsen almost thirty years ago. Because he developed the robot for Disney. And he had always this idea of graceful behavior. But he had in mind to make a robot for an amusement park, let us say, but actually this is really a fundamental feature. You know, I can tell you my real dream is, in fact, I fought to put this concept in the flagship proposal. But it was at this time it is in standby because it is considered to be frivolous. But my real dream is to develop a dancing partner robot. Because I think this would be the highest expression of performance, because a robot able to dance a passionate tango or a waltz or it is a fantastic demonstration of performance. it is like having a Formula One. You know, the Formula One the performance is handling and, above all, speed. But so a robot is a different kind of performer and dancing but not in a robotic way in a totally human way, you know. I am not able I do not know if you are able, most of our listeners are really not, but they can easily recognize by carefully observing a human dancing nicely how difficult it is. The marvelous coordination of planning, of expression, of motion capabilities, coordination, and also emotionally interaction with your partner. it is fantastic. And one could say well, it is frivolous. it is not particularly useful. Yeah, my answer is a dancing robot, like Cinderella, could remove his or her dancing suit and maybe put on a working suit and be a waiter, be a worker plumber. Do a lot of different things because when you are able to develop this kind of performance, you are able to develop useful one. But combining dream and usefulness is, my opinion, is a fantastic new frontier of robotics. And, again, it is in my opinion this is a really big issue it is not possible to achieve this with, let us say, the traditional approach. There are lots of things that you can do with the traditional approach and I fully support. I am fully involved I am fully, I say, positive! But if you really want to develop a behavior like a very humble worm or a professional dancer, man or female, you need a different approach. And this is the one, in my opinion, robots should pursue."
"Paolo Dario","Interviewer","The idea of the robot team that can beat the World Cup champions. "
"Paolo Dario","Interviewee","Ah, but this is "
"Paolo Dario","Interviewee","Yeah, but this is different kind of performance. Anyway, it is a strength. Okay? Of course, there is something coordination, but gracefulness. Okay? The football player is not particularly graceful. Well, one could say a gymnastic, a champion of gymnastic is also very highly coordinated, but dancing has an added value that is coordination with the partner. It is also communication, being exchanging information. And this is my vision. Again, I am saying that in order to do this we have the solution, as I said. Of course, it will take time. We want to develop new, entirely new materials, entirely new actuators, like muscles, new sensors, new energy, new communication, new nerves and fusing them together is the way I mentioned, using this science of embodiment. Not just screwing pieces together. This is the con. When you achieve you are able to put together the system, I think one could develop a paradigm. Of course, it would take decades, but no so many. Actually, we are confident that if we start now working in this direction as we are doing and many others are doing, we can achieve these in a couple of decades, even earlier. "
"Paolo Dario","Interviewer","Okay, before a couple of wrap-up questions, I just want to get one more historical question in, which is when you decided to come back to Italy after the States and Japan, what did robotics look like in Europe and in Italy and how has it evolved?"
"Paolo Dario","Interviewee","Yeah, it is an interesting point. I would say that robotics in Europe in the 90s was not as definitely not as advanced as in Japan and as in the U.S. in the field of non-industrial robotics. You know, Europe was maybe one could say leading, but certainly being one of the major players in industrial robotics. Okay? So the goal of Europe at that time was industrial robotics while in the U.S., and in Japan especially, the field of non-industrial robotics was explored very deeply and in a more advanced way. So this is why in the 90s I spent so much time with and in Japan and in the U.S. Okay? But then I started to introduce this concept gradually, of course, with a lot of criticism, by the way, because Europeans are very pragmatic and many people say, Well, this is not useful, the idea of service robots. Non-industrial, medical robots. And they gradually became very popular and accepted. So now I dare to say that robotics in Europe is probably leading this area. I can not say why maybe Korea is also working very much. But Korea is a relatively large but not so large country. You know, Europe is about five hundred million people. The U.S. is very, very good in military robotics now. The choice that the U.S. has done mostly were in the military field. Military field American robotics is at the top. Japan has declined, I must say. My Japanese friends will forgive me, but they have been very good in some areas, but not as visionary and as good as in the 90s. I think now Europe, essentially due to the major effort that have been invested, and I have been one of the players in the game, also, by convincing the commission there are many, many names. Eric Christiansen , for example, have been leading person in this and now he is at Georgia Tech. he is doing the same in the U.S., by the way. But we created first the Euron network. Now it is called the Europe. Still Euron is there, but we were able to gather so the European community of roboticists to convince the commission to make major investment, a few hundred millions Euros, in this area. And so I think that to get now really Europe is at the top. It was not like this. "
"Paolo Dario","Interviewer","And what is your advice for young people who are interested in pursuing a career in robotics or getting involved in robotics?"
"Paolo Dario","Interviewee","My advice is very simple, that is, first of all, to study a specific discipline to acquire a very basic competence in area like mechanical engineering, like computer science, like control and so on, because I think this is very important. Robotics, in my opinion, is for graduate students. it is not for undergraduate. It is I have this opinion, that first you must dominate, be good in one discipline. But you should, if you want to become roboticist the same is for biomedical engineering, by the way you should not become a real specialist. Okay? On the contrary, after your basic studies that can be at the B.S., but better at Master level, rather than go narrow into a specialty, you must go wide in interdisciplinary. And these are really the difference. Robotics requires a broad vision, interest, curiosity and ability and will to learn different things rather than being specialized, to be non-specialized. Okay? And to be able to deal with different things. To be curious physics, biology, basic science and material science, intelligence, even social and ethical, philosophy issues. You know, it should be this is really robotics, is a paradigm of actually a paradigm of how intelligent systems, humans even, are. So and you can do this with at the graduate level with working in a good group in my opinion, a large group , not a tiny group. But you can also follow and select very good advisor there are so many robotics [sic] now and learn under his or her guidance. But I think this is my recommendation. So selecting one of the best robotics groups in the world and be part of the community. So be involved in large, international projects is very important. I say this, especially, you know because sometimes especially in the U.S. graduate students tend to remain in their own university for all their PhD period. This is wrong, in my opinion. I strongly recommend not to do this. Fortunately, in Europe we do not have this attitude. Actually, for example, it is compulsory to spend one year of your PhD abroad. Compulsory. Because this is very effective in learning, but also in opening your mind in understanding how things work in a different environment with different people. it is not only a matter of eating different food, learning different language. it is also this. But it is a matter of becoming acquainted with how different people, different areas maybe, work and this is very important to reach the skill that is needed to become a real leader in robotics. That is, as I said, in a way, robotics is against specialization. Okay? It is pro-very open mind. But it is fascinating. I would advise everybody to work in robotics. Actually, many people advise us, because they recognize that robotics is so fascinating. Also, it is so attractive for ordinary people, for media. It is a way to have access to many different communities, because robotics can do everything. You can work with the rescue people. You can work with nurses and surgeons. You can work with artists. You can work with philosophers. You can work with neuroscientists who can get a Nobel Prize, with material scientists. You can publish together with them in June of with as an factor that will never be possible with traditional robotics. So it is expanding your mind, your reach, your culture, your networks. Like, my feeling, it is fantastic. "
"Paolo Dario","Interviewer","Great. Is there anything you would like to add or anything that we did not cover?"
"Paolo Dario","Interviewee","No, I think it is . There are many other things, but I think That is okay."
"Paolo Dario","Interviewer","Well, I guess the final question is Ducati or Moto Guzzi?"
"Paolo Dario","Interviewee","No, I must admit that my motorcycle is a Suzuki V-Strom so it is an Enduro. But I had many Italian motorcycles. At the very beginning of my passion for it, which goes back to when I was sixteen. So I had Vespa scooter, a Piajo. I had an Agusta MV Agusta that was world champion for many years. I have a Moto Morini that is now well, just the back was a fantastic motorcycle. And then Japanese, unfortunately, for my Italian pride, but very nice motorcycles. I can say one final thing. You were talking about sentient. Sentient is this sort of empathy between that one would like to implement between a robot and a machine. Okay. A robot and the human. So, for example, the metaphor of the dancing partner robot is like this. You know, is how to create an empathy that is really moving together, having no, looking eye to eye that is typically of a couple dancing. Of course, this is a dream, but it is a way. But, actually, to think about sentient with, like, a cat and the owner or a dog or a horse. And this kind of empathy. But I consider as an empathy or the relationship between myself and my motorbike. Of course, I have a wife, I have two daughter, I have many friends. Real empathy is with them. But when I am alone with my motorcycle there is an empathy. I talk to her and this demonstrates and this does not happen with a car. It does not happen with a TV. It happens with a motorcycle, with a bike. So you have this empathy. I really think that the same kind of empathy could become real with the robot companion, you know. That companion is not only assistant. it is an assistant in empathy. You know, it is some level of emotional interaction. But I want to say I do not pretend that the machine is intelligent, has its own consciousness or nothing like this because my background as a mechanical engineer is such that I like the concept of a machine that has some degree of intelligence. Not as much as me, but the same level of empathy that I have with my motorcycle I think is very nice and fully affordable to all. This is what I like to achieve."
"Paolo Dario","Interviewer","Well, it is sort of an extension of yourself when it is "
"Paolo Dario","Interviewee","Yeah, of course, exactly."
"Paolo Dario","Interviewer"," most effective. But I think the dance partners is even more complicated because not only are you empathizing with the partner but They are empathizing back with you. So there is double "
"Paolo Dario","Interviewee","No, but, in fact, it is fascinating though."
"Paolo Dario","Interviewer","Yeah. Thank you very "
"Petar Kokotovic","Interviewer","."
"Petar Kokotovic","Interviewee","Yeah, That is different. that is alpine. Next time you come I will take you to these rocks you see. it is right about here. "
"Petar Kokotovic","Interviewer","Do you climb or hike?"
"Petar Kokotovic","Interviewee","Hike. I am too old climb but there I am in the top there, you see. that is a bit of a climb. "
"Petar Kokotovic","Interviewer","Conquered. "
"Petar Kokotovic","Interviewee","Yeah, conquered. "
"Petar Kokotovic","Interviewer","Why do not we just start by having you tell us where you were born and where you grew up and went to school?"
"Petar Kokotovic","Interviewee","Well, that sounds very boring. Yeah, born in the unfortunate city of Belgrade. I went to school there. That was disrupted by World War II. The city burned including a bomb that fell on our house. And then there was a glorious time of four years without school that for some kids was disastrous, for some kids was fun but it was war time. After that, it was scrambled to have three or four shifts in a school building, many buildings were missing, destroyed. Then things regularized and I think Belgrade provided excellent education, in fact. And the university I remember it as the top quality. While the textbooks are missing and so on you would find enough of English language books were being received by hundreds and hundreds of aid organizations. Then we were reading from Russian books and so on. So I think the education was very good. The labs were maybe somewhat obsolete but fundamental education was quite good. Mathematics was particularly good. "
"Petar Kokotovic","Interviewer","What did you study there?"
"Petar Kokotovic","Interviewee","Electrical engineering. Yeah, this was at the time the hardest to get into and some kids like when it is hard. There was this qualifying exam I do not know how many hundreds apply and as I recall only 100 get in. They give you tough questions to write about and so on. Then another point of selection was after two years you have to pass with whatever score to continue the study or else you can be eliminated. And there was some remarkable professors that influenced us. I mentioned to you Mitrovich . This was the beginning of automatic control in most countries and this was certainly in Belgrade the first time that so called server systems course was presented. And you know, server system meant, for example, in the artillery arrangement, you may call it robotics, if you wish, but basically the antiaircraft artillery has to follow an airplane. So this was a development of World War II, you know Wiener, Norbert Wiener participated and mostly MIT Labs were developing things. So the radar became available. The radar's antenna would follow the plane. There would be an image of the plane and the server system would have to adjust the radar in at least two dimensions. And then the radar was to be followed by the alignment of the antiaircraft artillery. So that was one of the earliest products of World War II that was fully automated. So we studied that and then I went to the nuclear science institute near Belgrade. Many of us were recruited for that kind of work. The first project was on this experimental nuclear reactor, the bigger one, the safe one just to try the level of the heavy water inside the reactor, also to adjust the odds. And then we had lots of industrial projects so that control systems group or automation group or a process control group. And there was quite a bit of cooperation Belgrade, Szeged, Sarajevo mostly this triangle. So pretty much people of the same generation. Some of us were in the same train, not only in the same train, but in the same sleeping car as we went to the congress in Moscow in 1960 all by train, you know, two-and-a-half days or so; plenty of time to discuss. So you had guys from Szeged, Sarajevo, Belgrade, some other cities. So we almost created a committee so that when we returned back to Yugoslavia from the congress We will start some joint working and indeed we did. So that was the beginning, if you wish, for me, certainly but for the field it was not much before. The field, in a sense, the modern version of that field started in World War II. But if you want to take history, of course, the old Greeks or old Mesopotamians, they were controlling damns. They were controlling irrigation systems and so on. So that concept of regulation control is very old. "
"Petar Kokotovic","Interviewer","Was there anything called robotics or what you would call robotics going on ?"
"Petar Kokotovic","Interviewee","Yeah, this was the first major project was the there were many amputees, you know, former parties and resistance fighters and many amputees also from bombings just the war victims. So there was a big need especially for artificial arms and legs. And the artificial arms were a big challenge not only in Yugoslavia but people were trying in Germany and other places to develop with the growth of electronics. I have to tell you that transistors just appeared and some miniaturization was possible. Several motors became sufficiently small for the war time applications. And the idea that maybe artificial arms could be created motivated many people. So Belgrade had this project later called Belgrade Arm organized by Professor Ica Tomovich . A group of us started. I did not continue for very long. Others continued. This developed into bigger robotics project, bigger robotics operation. There was a section in the Pewpin Institute for a while supervised by Tomovich and then taken over, continued by Boco Brotovich . But my information about that period is all ready too vague. I was in this country. I was not there. So I know only these three or four years and they were sort of an enthusiastic start maybe not always realistic. You know, fantasy and dreams very often propel you especially if you are in a less than super developed country. The development also when a country is developed, it sobers you. It shows also what is impossible. When you are not so developed when you are young you have all sorts of heroic ideas that transfer into technology. Some of them sometimes succeed. "
"Petar Kokotovic","Interviewer","So they were looking at a cable control system for that hand?"
"Petar Kokotovic","Interviewee","There were several designs. The first one was with the single motor and some sort of a switch mechanical coupling that would pull the cables. That was the most primitive original thing. Then the idea was that maybe there would be ways of doing it with some rotating axels and pulling the fingers individually. The hope was that the motors would be so miniaturized. Then there were even as I recall ideas of the pneumatic and it was not pursued in Belgrade but elsewhere to have pneumatic pipes as little pistons to pull the fingers up and down. So the mechanics of it were extremely difficult, especially if you wanted to have fully anthropomorphic human hand. If you were satisfied with the three fingers only or with a claw or something then it was easier. It happened that years after I believe a French product succeeded. I remember maybe in the seventies staying in a hotel, a bed and breakfast place and I saw a youngish man taking the coffee cup and drinking. And I realized it was pretty much that same idea that worked. Plus, apparently, in his case he did not have to use motion. Apparently, he was able to control it by his own nerves that means that all ready then. As I mentioned the first IFAC Congress if you take a look in the proceedings of that first IFAC Congress where the Belgrade Hand or just the skeleton controlled by cables, wires was described. There was also a presentation and I remember the name of the Russian author was Kobrinsky . I attended the demonstration. The demonstration was with a patient who was trained enough to concentrate so that he would create strong enough electric signal in the ending of his amputated arm so that he could do two basic operations closed and opened and that was demonstrated all ready then. The electronics for the time it was very clumsy obviously, a big apparatus, not portable and so on but it worked. So that was that line was a fascination that the robotics should serve the industrial needs, of course, that was well known. First, was positioning as you would say pick and place operations. That I connected with the early isotope manipulators that were not automated initially that included a system of mechanical transmissions so that you could control an artificial hand by basically squeezing and opening with your own hand. So that existed in industry for all sorts of hazardous materials, for handling of the hazardous materials. And that helped the mechanics of these types of hands. But, you know, industrial robotics as I worked in industrial control they would appear, they would go to first move some heavy objects then as we know painting was one of the early applications that succeeded. And I pretty much only occasionally then would follow what happened in robotics. You know, working in our conference is not just some robot sessions or talking to a colleague who was working on it. By the way, I think, my young colleague Mark Spong then came and joined Illinois and he wrote one of the first textbooks. I do not know if you know Spong with the Vidyasagar textbook. he is now dean at Dallas, University of Texas at Dallas. So he being an early textbook writer in that area can tell you more about it. There was a lot also of as I recall he was there is even a name for it help me now, to transfer the feeling of the touch. I forgot this. "
"Petar Kokotovic","Interviewer","Tactile. "
"Petar Kokotovic","Interviewee","Yeah, tactile but there is"
"Petar Kokotovic","Interviewer","Haptics. "
"Petar Kokotovic","Interviewee","Yes, haptics. Yeah. The development of haptics started and he had quite a bit to do with it. He got me interested in just a mathematical subject of if you design a robotic control, say robot arm control. Assuming that the material is completely rigid how can you do correction for actual flexibility? So that fit some of theories we were developing separate from this issue namely the inclusion of additional tolerances and compliances that while assuming that something rigid in your design, it is rigid, then you can redesign it without repeating everything but just adding a corrective term for flexibility. So that was well received. Yeah, there was a significant oh, now, I remember. There was a significant robotic center at Georgia Tech, Atlanta, Georgia. This was a nationally financed pretty big operation. The names now escape me but one was our former student from Illinois who I do not think worked in robotics when he went to Atlanta but David Taylor . he is a wonderful researcher. He may give you some information about that center there. I am not sure what it is called now. I think it is called manufacturing or something or other. It started as robotics, I believe, but it became manufacturing. So that is another aspect. Many of these robotics centers may be understanding that robotics is somewhat undefined and if defined then maybe unnecessarily narrow. They brought that into the concept of manufacturing because pick and place was one thing, right but more complex automation required understanding the whole factory floor and passage of the material, all sorts of things of this kind. So the complex automation absorbed, subsumed the robotic elements as just individual actuators if you wish. You know, you have this body of a car to be painted. You see this thing the car comes, it is slightly rotated this and that way the painting goes. And the paint, I think, goes through the drying machine and then to something. The new body comes to be painted and so clearly there is robotics but there are many other things along. So now the robotics proper as I recall in Belgrade, the major activity was Boco Brotovich and then I remember visiting there. He was talking about exoskeleton's. Obviously, he was similarly connected with the rehabilitation organizations and this was a good application to use robotics not to provide the whole motion but to assist in the disabled person's motion or in the recovery person's motion. So rehabilitation centers use it. And then when I came here through the work of this former graduate here and my colleague professor Buttner I learned about their surgery machines so much so that I was very happy to see how they operated and even took my wife, she had her knee operated by one of those yeah, they are quite widely used. You must know about these orthoscopic and very fine surgeries that can be done now. Computer Motion, a local company was very much in the forefront of these and they patented many things and I think were financially successful. As we said they were sold to Intuit and I have not"
"Petar Kokotovic","Interviewer","In Belgrade who funded these kinds of initiatives?"
"Petar Kokotovic","Interviewee","Yeah, well, the Pewpin Institute was state funded. And also industry. We were getting some grants from industry. You would have to show the interest of industry in order to also get some state funding. There were commissions, I forgot, ZomTech or something Zower for technical development and so on. Then you would try some international aid. But as I say Tomovich was particularly successful with a U.S. Veteran Administration. So for a while Belgrade Hand was financed by the U.S. Veteran Administration. I noticed maybe five or six years ago that actually U.S. Veteran's Administration is continuing to finance more advanced models. And there was this report, I do not know, I have seen I think even on the television program of one of these amputees that is so successful, a military person that is so successful with this more advanced, with very advanced versions. Still the training and improvements are needed but I remember seeing this and reading. So that line I do not think has ever been abandoned and every new development was cultivated through that. Then, as I said the rest is probably described in the Belgrade publications which I have not followed from the group of Boco Brotovich."
"Petar Kokotovic","Interviewer","What years were you a student?"
"Petar Kokotovic","Interviewee","What years was I a student? I was at the university from 1952 until 1957 probably. What happened is I went to France first during my studies. Then, again, to Germany so I sort of delayed getting my diploma because it was easier to travel before you get your diploma. The moment you get your diploma you have to go to the military service, right. So most of us, this was in the early time, the Yugoslavs got the opportunity to travel, students and positions were open for us industry. So I was in France. It was a good automated power station where I worked. And in Germany I worked in a factory. And they were cooperative and nice and showing us some advanced projects and so on these post organizations. So it was good. I still have friendly relations with Stuttgart. Some young people when I told then I worked in Stuttgart they realized, They are around 50, they were not born quite. But yes, I will send you an email this little autobiographical sketch which I wrote for IEEE. What happened they sent a guy to interview me and it was a long interview. The transcription of it, you know, he wanted me to tell him more about the Soviet science at the time but the transcription of it even though I was remembering what I was talking I could not reconstruct even my own thoughts. So I begged him to remove it and then I said I will write it for you on my own. So rather than having an interviewer because that particular person might have been too tired to or I do not know. Anyhow, maybe my English was too bad. But in this I refer to in the state of the sixties, you have to understand the post-Sputnik era. Sputnik shook the West. They just could not believe it. I was in Germany and the dog was sent to space. Remember, there was a little dog in the satellite and then, of course, when the man went to space et cetera. So then the idea was that the Russian mathematics and especially Russian applied mathematics and control theory were responsible for these successes. Cold War. So I am a victim of World War II somewhat and beneficiary of the Cold War because even before I got my Russian degree some American colleagues met me and said as soon as you finish we will arrange for you to come to the United States. So I was really repackaged slightly when I came back to Belgrade and literally a couple of months later, three or four months later I went to the U.S. and that was it. "
"Petar Kokotovic","Interviewer","Where did you study in Russia?"
"Petar Kokotovic","Interviewee","At their Academy of Sciences Institute called Institute for Automation and Telemechanics. At that time it was IAT. Then when they became too big and got a new big building prospered beyond their dreams they became Institute of Control Sciences, Institute of Control Problems, rather. But just about everybody who was known in the field was either a member of that institute or was somehow associated. Very often, they were just the front sometimes for some classified organizations. So if you were to if you were declassified then you were to present some results, then you present them as the member of that institute, even though you might be a member of something else. And this was one of the firsts that started a professional journal in that area. And now we celebrated the 80th anniversary of my colleague David Main in London. So he remembers how they in London were grabbing every bit of the translation or finding people who would translate this from the Russian magazines. This is how far advanced at that moment or at least was believed to be so far advanced. You know, there were mathematical breakthroughs there that were of immediate help to engineers and that was appreciated. "
"Petar Kokotovic","Interviewer","How did you decide to go to Russia?"
"Petar Kokotovic","Interviewee","Well, that is a touchy subject. That is a touchy subject. I applied for a Fulbright fellowship. And the Fulbright commission at least at a time I do not know now was composed 50 percent of the local members, 50 percent of the U.S. members, right. And there were situations in Yugoslavia happening, people were getting unhappy with what was then called the bureaucratization and misbehavior of the leaders mostly on the level of misusing the public property. You know, government cars were present in various resort areas, various restaurants and so on. it is pretty obvious they were not there for official purpose or so on; many such things. So there were basically criticisms and so on. And as a typical thing for this was to immediately start diffusing the pressure. So the leaders, for example, Belgrade leaders would go to various organizations, especially where the younger intellectuals were working and say, okay, comrades tell us what is wrong, let us discuss it, so on. We were also tired of this kind of sort of a farce. So this comrade came and he was saying, okay, tell us there was no way that anybody could misuse any government property in our institute. We had none basically. But I was sitting next to the window which was overlooking at the parking lot. So I said comrade, I do not know see one of these cars is an expensive Mercedes. This is the only candidate that could be misused, is this by any chance your car? I was making what I thought was a good joke but it exploded. They attacked me. They said I was agitating against Tito or something or other. And it just happened that the professor from the university liked me a lot and he was a member of the Fulbright commission. So I get a call from him and he says, Idiot , what have you done? And I said well nothing serious. He said, What do you mean it is not serious? We were all ready told to remove you from the list of candidates for Fulbright and to send a letter that you have not satisfied on the English test, which probably was also true. But I would have probably received Fulbright other I do not know. Anyhow, and then moreover, he said, You know what, the things are so serious from what I hear you better leave the country for a while. Invent some business trip or something or other. He said, Better yet I am also on the commission for some Soviet fellowships and we have ten of those. Nobody wants them; only two ballerinas and one violin player. No engineer wants them. But interestingly I was reading some of this Russian literature and I very much wanted of course I preferred Fulbright but I very much wanted to see Professor Felbom . So I thought okay I will go there. I will get one year fellowship and I will go there and stay a month or two until the dust settles and then come back. But it turned out it was a very good opportunity that they gave me. Again, they would not put me in that institute. It was closed to the foreigners. that is another interesting story of the time. But when I somehow tried to get in touch with Felbom the secretary would always say he is out of town. And then I read popular science page in the Moscow newspaper once a week it comes and in the palace of popular science Professor Felbom is giving a popular lecture. So I rushed there, introduced myself to him after the lecture. And he says come to the institute. I says how can I come this is closed? I will take you in. So he waited for me at the door. Amazing, I am a kid there and he is a famous, world famous guy. One day, the next day he waits for me and passes. And so I finally get embarrassed that this guy would have to come down from the third floor to take me up. So I tell him I am unable to come, I have something else to do next day. But then I come the next day and I just walk in and the guards salute. They saw me with an important person three times in a row and then I started coming every day normally passing through, not showing anything, just passing through like everybody else. I made sure I bought some Russian shoes and Russian pants. And I had to change my glasses because western glasses were recognizable as a , et cetera. So to make the long story short the secretary of the institute somebody introduced me to her. I all ready had chocolates and other things ready for the purpose. It was well known. So finally she came once and said Give me your pass so I can extend it. And I said, Marsha, what pass? And she really got white. She says, What do you mean, you do not have a pass? I said, no. I did not even know that there was a need for a pass. And poor woman, she rushed and did something she said when was the first time you walked in? She gave me an old pass and she gave me a new pass. And I managed to stay there. And I told this story to but I told him make sure you get guarantee. do not play the tricks. Now, the second time the trick will not work. So by then we organized things so they were allowed to go and he went to work with Emeliano Vinukin that was interesting. Yeah, these were the times, the funny times that you had to as much as they were clamming KGB's this and that, basically they were stupid. You could play tricks. I was able to get rid of my tail as a joke, you know. You read Agatha Christie and there it is he is behind you reading back there and you just wait in the subway, wait when the door starts closing. And just about halfway the door you jump out, right. And these tricks were common for us to joke with them. "
"Petar Kokotovic","Interviewer","So you were there for two years?"
"Petar Kokotovic","Interviewee","No, one year only. "
"Petar Kokotovic","Interviewer","Then did you go to the States?"
"Petar Kokotovic","Interviewee","Yeah. Back to Yugoslavia for a few months only. But from there I was on an organizing committee. Although I was in Russia, I was on the organizing committee of a Dubrovnik symposium. And then I became well connected with the top of the Russian of that Institute, which was also top of the Russian establishment in this area of science. For example, Alexandar Lotov was the president of IFAC. He was a remarkable man. He was fluent in English. He had an international passport. He was one of the Soviets that could travel anywhere. So much so we became friendly and now that I asked him, recommend some theater shows here in Moscow to me. He said, Oh, no, there are no theaters in Moscow. There are only theater museums. If you want to see some new plays, you better go to Broadway. Wait until you get to Broadway. No Soviet would dare say this unless he was well yeah, there were all of these remarkable people. So seven of them came to Dubrovnik as a package. So they called themselves, the movie was very famous then, The Magnificent Seven, remember that movie?"
"Petar Kokotovic","Interviewer","Yeah. "
"Petar Kokotovic","Interviewee","So they called themselves the magnificent seven. "
"Petar Kokotovic","Interviewer","Who else was in the magnificent seven?"
"Petar Kokotovic","Interviewee","The Russians. This was quite a representative group. Mark Eiserman . Yakov Chipkin . Slava Yemellano . Vladi Butkin was the youngest. Tolya Butkovski. Mayorov . Rosenberg , maybe. Did I get to seven? Yeah. They were quite advanced. They stayed in Lapad, in a hotel there. And apparently that was a hotel where they would put the Soviets. At the same time, there was a delegation or a group of the Russian writers including their leading woman poet Bella Akhmadulina. And I remember it was a rainy afternoon. Nobody was swimming in Lapad Beach and I went swimming and whoops, a face appears from the water like one of those she was a bit of a beauty; yellow porcelain or pink porcelain and so on. so we became friends and her husband was also a major writer, Nagibin. So we then organized that I was taking the tour of Russians by bus. And the Soviet writers union by two busses were returning together from Dubrovnik to Mostar; Mostar Beach to Sarajevo and so on. I have another Mostar Beach story but That is separate that we can do off because this says fantastic things about Mostar people. I will say it. In Mostar an elderly man was sitting, you know, with a fez and I was walking with Bella she was a true beauty, a striking beauty and showing her this and that. He stands up comes and kisses her from one side, from the other side and Yuri was behind, her husband, he just got panicky. what is going on? The old man was not disturbed at all. The husband runs and he says in our language, Are you the husband of this indescribable beauty? And he congratulates him. This guy he just looks like I was translating. So then he, of course, wrote a story about it. Yuri Nagibin in his collection of stories because that describes Mostar in my terminology maximally. This was fantastic. "
"Petar Kokotovic","Interviewer","So what were some other interactions between Eastern and Western scientists in this time?"
"Petar Kokotovic","Interviewee","Yeah, there was quite a bit. That was the time when I was even encouraged to invite Soviet colleagues. So we brought Yemellano was invited to Urbana. Wutkin stayed for a year as my guest in Urbana. Then Eiserman we got Yemellano and Eiserman once together to I have these pictures, it is funny them playing with my kids and so on. And for example Potraygen and the group they came to MIT. The came to oh yeah, about these connections you want to contact Professor Balakrishnan at UCLA. He has a movie of Potraygen giving a lecture in 1969, 1970 to I forgot when at UCLA. He would be more than happy to share this with you. Professor Balakrishnan. Speaking of which, have you heard of Boris Kogan? Yeah, this was one of the seven. Boris Kogan who is now probably 95 I think he still has an office at UCLA. He came to UCLA in his late seventies; a remarkable character. He was one of the lab directors in that institute. So he is a walking history. Last time I talked to him two years ago he was perfectly lucid. So I have not been in touch lately but it is not hard to find him. Everybody at UCLA he is kind of a legend. Everybody will know him. By the way he was in contact with Becky. Maybe Becky will know closer contact. There was another important name that I should mention who is among us Walter Karplus. So he did a lot for interactions. So he interacted with Yugoslavia and was a frequent visitor and then with Soviet counterparts with Boris, for example. He even arranged for Boris to come. I was not quite in the loop. Boris Kogan. And then there were official contacts as well. Apollo Soyuz was a major one. We had a joint meeting. This was only my second visit into Russia well the first visit after I left. There were all sorts of also unpleasant things with visiting Russia especially if you were there before and then settled in the U.S. That was not in that way convenient. But anyway in either 1973 or 1974 there was the Apollo Soyuz recapitulation reporting meeting that was held in a sports training center, near Yerevan in Armenia. This is where their Olympic team was practicing because that was the same elevation I believe as Mexico City. This was just before the Mexico City Olympics. And we were attached to that group, Apollo Soyuz. And there was just too much of intelligence supervision. I mean the spies all over so much so that when I came to my hotel room a ravishing blonde was sitting on my bed and saying can I do something to help you. I immediately walked out and went to the room of my colleague who was the director of the institute in Germany, Jergen Ackerman , a very good friend. I said Jergen come to my room and then both of us come to the room. And I said look this lady wanted to help me but what do I do know, I do not need any help? So she escaped, of course. But I saw her around. She was part of the official group. But it was clear. So they wanted to trap you into some inconveniences and it was standard and take a picture or two and then blackmail you into cooperating. By the way, whenever you went to a trip a CIA person or FBI person would come and tell you that such things might happen. So to be very careful and avoid such traps because there would be cameras and so on that would embarrass you. Yeah, but this was a good meeting. Apollo Soyuz was a good progress and things, contacts went up and down depending on the major change was, of course, with Khrushchev when he came to power. "
"Petar Kokotovic","Interviewer","How did you wind up at the University of Illinois? And what kind of work was going on there in control?"
"Petar Kokotovic","Interviewee","Yeah, this was all due, as I describe this little autobiographic document, this was all due to Malcolm Balkenberg . So you will see the details there. He organized not for me to come to Illinois but he organized a series of lectures for me. So I gave lectures at about 20, 30 institutions, universities but also research institutions in this country, which took about three or four months. In some places it would take two weeks, like a short course, which was in Urbana, Illinois and maybe at Berkeley and a couple of other places like this. At that occasion I made contacts with all sorts of American colleagues. And I did get several offers then. But Mac he really acted as my mentor so he was a very significant person, wonderful. So he says, why do not you stay in Illinois? I felt the atmosphere was so friendly, I do not know if you share my impressions, people were really fantastic. So I felt totally at home there. Here is the Illinois trio. These are the guys. Bill Prickins , Joe Cruz and myself. "
"Petar Kokotovic","Interviewer","So which department?"
"Petar Kokotovic","Interviewee","Electrical engineering. But mostly coordinated science lab. This itself was a product of Cold War. It was first called control systems lab and was doing things for the Korean War, during the Korean War and then evolved to a multi-disciplinary lab. it is still there very successful multidisciplinary organization. And it was very enjoyable. You were with colleagues, 50 percent there, 50 percent in the department, electrical engineering department. So these were a wonderful 25 years. And if it were not for Anna my wife who then belatedly, you know, went back Reagan abolished her organization educational in helping the inner city kids I mean abolished the grants for this, you know, like Head Start and these things lost under a very generous president. So she went back to get her Ph.D. and then in Urbana you do not get a job if you have a Ph.D. from that place. So then she got an appointment here and I said okay, time to change. Every 25 years I make this change a few more times. "
"Petar Kokotovic","Interviewer","So you had encounters with Heinz Foerster and . "
"Petar Kokotovic","Interviewee","Yes. These were fascinating people when I first came to Urbana. And Heinz was easy to talk to. He was gregarious. And you would see him everywhere. you would just ask one question you get a whole little story behind it and he would take you to whatever lab. It was not always clear what was in it but Heinz would always give very imaginative explanations. And it was very different with Ross fortunately. Through friends I had a very direct connection. So we would have almost weekly dinners at the friends' home because she cultivated this connection and she was not really in any technical field. So I got to know and basically to listen to him. I could not possibly follow any of those suggestions. I had too busy a career to basically maintain my own position and to develop the field in a different direction. But if I were in some area closer to where his ideas could be implemented this would have been fascinating but soon after he left. I met him 1965, 1966 and maybe 1967. I do not whether he left in 1967 or 1968. About Yugoslavia I want to say another thing. You know, that the father of cybernetics is Norbert Wiener, right? Well, he was also one of the early visitors because there was a conference on cybernetics in Opatija as early as 1960 or so. So Wiener came and then had a tour of Yugoslavia. I was assigned for a couple of days to take him around Belgrade. I still have some pictures. Some journalist wanted to have an interview like this so I arranged for this and we were sitting somewhere in Calamegda or somewhere they interviewed Wiener. The only thing that bothered me was his holding his cigar. I could smell that his fingers were burning and it did not bother him at all. They were burnt for years probably. You know, you sit with somebody you smell the flesh burning. it is quite"
"Petar Kokotovic","Interviewer","So would you say there was a strong influence of cybernetics on early robotics?"
"Petar Kokotovic","Interviewee","Yes. This whole business if you read I will have to leave now. If you read Wiener you will see that he all ready was enchanted by some pathological oscillations of human hand and so on. So that was definitely very influential. The whole cybernetics at that time was more of a he coined a term that was more like a dreamland. And his book is called Cybernetics Human Use of Human Being. So it is an interesting thing to read about John Fornaiman in one hand and Wiener on the other. One was hawkish militarized person. And Wiener, although he worked for military projects during the war, he on the other hand was human use of human beings. It was a very different person, different nature. I will tell you one vignette which was fascinating. This conversation goes at the lunch table. And I thought we were talking about this arm section from his book and all of a sudden he is talking about some irregular verbs in the Macedonian language. I was shaken. And I said finally it was clarified his father was some world linguist and as a kid he was losing track obviously I said because of old age. And when I talked to people who took courses from him said no, no, that was always the case. But anyways he knew irregular Macedonian verbs and so on which somehow jumped into a conversation about cybernetics. "
"Petar Kokotovic","Interviewer","Was there anything robotics going on in Illinois while you were there?"
"Petar Kokotovic","Interviewee","As I say, Albert Chen , Professor Chen had a robotics lab and this is when Shaiman Hand was bought. So one of my students worked on Shaiman Hand. There were other things there not just the Shaiman Hand, but there were more on the software side. Chen was more of a software person. And then I should say later on Mark Spong came so that period was then characterized by the work of Mark Spong who wrote a book about, a textbook for it. And he also made small robots for laboratory experiments. One was called Penajabot . One was called acrobot , little acrobats they were something or other. So he did not go into sophisticated things but sort of elementary operations. So you will not be here when the lectures are over. "
"Petar Kokotovic","Interviewer","We will have to figure out what we are doing and call some people. "
"Petar Kokotovic","Interviewee","As long as you do not have to figure out who you are. This is a California disease. "
"Petar Kokotovic","Interviewer","I think your life is a process of doing that. "
"Pradeep Khosla","Interviewer","Introduce yourself. "
"Pradeep Khosla","Interviewee","Oh. So I am Pradeep Khosla. I am the dean of engineering at Carnegie Mellon, and to take you back into my life history I was born in India, and I went to high school and undergraduate school in India. So my undergraduation was from Indian Institute of Technology Kharagpur, which is one of the five IITs and the oldest IIT. And I graduated in 1980, and I decided that I was going to go work in India for a while because I was patriotic kind of stupidly. And I was in India working till 1982 in the area of real-time control of power systems, and then I decided it was time to come to the US because I wanted to be a faculty member. I wanted to do research, so 1982 I came to Carnegie Mellon."
"Pradeep Khosla","Interviewer","What was your degree in?"
"Pradeep Khosla","Interviewee","My undergraduate degree was in electrical engineering, but my honors thesis was in computer science. It was designing a disassembler for TDC316, which was the Indian equivalent of PDP8, I believe. "
"Pradeep Khosla","Interviewer","When did you come to school in the States?"
"Pradeep Khosla","Interviewee","I came here in 1982 to get a Master's and hopefully a PhD, and I was fortunate enough that I got both at Carnegie Mellon."
"Pradeep Khosla","Interviewer","Why here?"
"Pradeep Khosla","Interviewee","So when I applied to the US I had admissions in three places, and at Carnegie Mellon there was a professor who listed his research interests as computer control of power systems, which is exactly what I was doing, what I wanted to do, so I said Okay, I will come to Carnegie Mellon. Plus I had a classmate of mine who had come here in computer science, Bud Mishera , who is now a faculty member at Courant. So I came here. "
"Pradeep Khosla","Interviewer","What was the relation between computer control of power systems and robotics?"
"Pradeep Khosla","Interviewee","Well, it turns out that when I came here that catalog I was reading was four years old. There was no Web at that time, so people had moved on, and robotics was becoming very hot. In 1980 is when Roger Eddie at Carnegie Mellon started the Robotics Institute, so there was a lot of excitement, a lot of people involved in it, and so I decided to work in that area because it was still computer control of electromechanical systems."
"Pradeep Khosla","Interviewer","Who was the initial professor you wanted to work with?"
"Pradeep Khosla","Interviewee","So I came here to work with Chuck Newman , but that I did my Master's with him, but Chuck was a control systems guy, so I had a co-advisor, Fritz Prinz , who was in mechanical engineering, so my Master's thesis was seam-tracking for welding robots, where the idea was that if you are going to use these robots for welding then how would you track seams? And so I developed an algorithm, and then while I was doing my Master's I really got very interested in robotics, and for my PhD I worked with Takao Kinate . He was my advisor for PhD. "
"Pradeep Khosla","Interviewer","What was your thesis project?"
"Pradeep Khosla","Interviewee","So at that point this is about 1983, late 1983 Takao Kinate was working with Harry Asada , who is now a professor at MIT, on developing what is called a CMU direct-drive arm one, so that arm was based on new technology, a six-degree of freedom manipulator based on a new technology where there were no gears, so the motors were directly coupled to the lengths using samarium-cobalt motors, high magnetic intensity motors. But that arm hung from the ceiling. It weighed like, I do not know, 600, 700, 800 pounds, so its payload capacity compared to its weight was way too small. And we had this idea of creating what is called a SCARA configuration manipulator, which would be very appropriate and useful for high-speed assembly. So my PhD thesis was CMU direct-drive arm two, and that design was a SCARA design. And, for example, the adapt robot is a SCARA design, and it is a direct-drive robot. "
"Pradeep Khosla","Interviewer","The first SCARA robot was made in Japan, right?"
"Pradeep Khosla","Interviewee","Yes."
"Pradeep Khosla","Interviewer","Did you have any connections with that?"
"Pradeep Khosla","Interviewee","No. So what we wanted to do was so we knew the advantages of SCARA configuration, and we knew the advantage of direct-drive. Because of lack of gears they were higher-precision, faster. So we combined the two to create a new design for a SCARA configuration robot that was direct-drive. "
"Pradeep Khosla","Interviewer","What were the advantages of the SCARA configuration?"
"Pradeep Khosla","Interviewee","The SCARA configuration is like the two lengths are horizontal in a plane, so gravitational forces do not act on these lengths, which means the motors do not have to pick up the weight of the robot, so they could be sized smaller. And if They are sized smaller that means the torque is used for speed, and direct-drive configuration gives you better precision. "
"Pradeep Khosla","Interviewer","What kinds of things had you been using before you had the CMU one and CMU two arms?"
"Pradeep Khosla","Interviewee","I was not using any system. I was not even in the business, right? But this was actually a very challenging PhD thesis. I may not be exactly right, but I think I am nearly right. This was also the first experimental thesis where the thesis was the design of this arm, the electromechanical design of this arm. Now, because this arm is higher-speed, higher-precision it required higher sampling, faster sampling rates, and at that time there were no computers fast enough to create what we wanted was 1,000-hertz sampling, so sample the control system 1,000 hertz. So I built a multi-processor architecture using a special processor that had just come out in the market. It was called Marinko . I remember that. It was a 64-bit word length CPU, and I had to write code not in assembly but in bytes. I had to write code in A, C, F, G, because that is all they had. They did not have an assembler at that time. So it was actually rather challenging. So we did that, and we for the first time demonstrated real-time control of a direct-drive arm at 500 hertz. Now, in the process of doing that it turns out that the computation of these dynamical equations is extremely intensive, which is why no computer could compute those dynamical equations and sample at 500 hertz. It took longer than two milliseconds, so That is why we had to build the CPU. But there was also an implicit assumption where the dynamics of the system are known, so there is a very famous scheme called the computer torque scheme, which works extremely well if you know the dynamics or the dynamical parameters of the robot. So the other contribution I had was showing theoretically that even though it is a non-linear system it is linear in the dynamical parameters under some transformation. And then we implemented real-time estimation of dynamical parameters, and then using those parameters we implemented real-time control to show how computer torque really worked very well. "
"Pradeep Khosla","Interviewer","Who were some of the other people that you worked with?"
"Pradeep Khosla","Interviewee","So my advisor was Takao Kinate, so it was Takao and myself. We also had some staff members. Don Schmitz was a staff member, and he was a mechanical designer and an embedded systems person, so he had great contributions to make. I mean, honestly without his creativity in design I do not think we would have built the system as good as we did. There was another electronic technician, very creative guy, Mark De Louis . "
"Pradeep Khosla","Interviewer","After your PhD what did you do?"
"Pradeep Khosla","Interviewee","So I finished my PhD in 1986, and at that point I was looking for faculty positions, so I had several offers, and CMU was one of the first, and no better place to do robotics research than CMU. Second, we had a lab already set-up. I had an experimental set-up set-up, and so I decided to just stay here. "
"Pradeep Khosla","Interviewer","What were the other places that you were considering?"
"Pradeep Khosla","Interviewee","It was Courant Institute, it was University of Maryland College Park, it was University of Rochester. I can not remember the others. Might have been Caltech. "
"Pradeep Khosla","Interviewer","What was the next project you worked on?"
"Pradeep Khosla","Interviewee","So I did two things. I continued on this direct-drive arm research, and we moved on to demonstrating force control, because that was a big thing. When robots come in contact with the environment there are forces of interaction that are generated. So the idea there is not just to create or to control the position but to control the force of interaction so you can slide around an object, you can pick an object, so you can see this has a big impact on grasping research, for example, designing hands. And the fundamental work in force control was done by Mark Rayburt at MIT. I believe it was part of his wait. Was it Mark Rayburt or Matt Mason? One of those two. It was called compliance control. it is a very fundamental piece of work that showed that you could actually when a robot interacts with a surface or an environment there are certain degrees of freedom where you can control the position. So if you think about a surface and I am touching it, out here I am allowed to control the position, but going into my palm I can only control the forces, because I can not control the position. So they had this model of separating the space into where positions could be controlled and where forces could be controlled, and that was called compliance control. And robots to become useful had to be compliant with the environment. So we demonstrated, again for the first time I believe, high sample rate force control strategies. But the most interesting part was my first PhD student was Richard Volpe, who is now at Jet Propulsion Laboratory, and Richard was a PhD student in the Department of Physics, and I was a professor in electrical and computer engineering. Richard wanted to do his PhD in robotics, so I went and talked to his advisor in physics, and we agreed that I would become the co-advisor. And this is Carnegie Mellon. You know, we allow faculty to advise just about across the whole university. So Richard was the one who did work in force control for his PhD, and with a physics background he brought a wealth of knowledge and a style of thinking that typically would not have existed. So he had several contributions, but one of his contributions was showing the equivalence of impedance control and force control. So at that time there were two camps. One was impedance control, which was Neville Hergan , and the other people were doing force control, and there was some impression that these are different strategies. And what I wanted to do was run the equivalent of a Turing test, which is if I implement a force control strategy and a impedance control strategy and I do not tell you which one is which, can you tell the difference? And we demonstrated that there is actually an equivalence between the two, which was rather interesting. "
"Pradeep Khosla","Interviewer","What kind of tasks did you demonstrate?"
"Pradeep Khosla","Interviewee","Oh, in this case it was more like following a surface, and there was also a strategy for impact control. When a robot came in contact with the environment at high speed, could you do it in a way that it just touched and never bounced around? So if you imagine two stiff objects, when you hit one against the other there is bouncing. So we wanted to demonstrate what is impact control, which is there was no bouncing, right, and that would then lead automatically to compliant control. "
"Pradeep Khosla","Interviewer","What was the reaction of the community?"
"Pradeep Khosla","Interviewee","I think when you look at research and there are a lot of young people involved the initial reaction there is always this notion of trying to manage and maintain your space in the community. But looking back 30 years, 25 years the reaction is more reasonable, more muted and more rational, I believe. So one cannot judge the reaction to research at the instant you publish the paper. "
"Pradeep Khosla","Interviewer","What were some other projects you worked on?"
"Pradeep Khosla","Interviewee","So after that I had this notion that well, in the following way. So if you think about computers, They are called general-purpose machines, where the idea is that any function that can be computed can be implemented on any general-purpose computer. Now, people talked about general-purpose six-degree of freedom robots, and intuitively it is obvious that not every task that can be done by a six-degree of freedom robot A can be done by a six-degree of freedom robot B, A and B being two different configurations. So that led to this both scientific and philosophical question in my mind as to why are these called general-purpose robots, because They are both six-degree of freedom robots. I call them general-purpose, but I know that this robot A can do a task and this robot B cannot do that same task, right? So clearly there is a problem. So I started thinking about what would a general-purpose robot look like, and to develop that notion so what I wanted to really do was build what I think of as a Turing robot just like a Turing machine. So I came up with this notion of a reconfigurable modular manipulator system, which was a project again I started initially with Takao Kinate. So the project was called CMU reconfigurable modular manipulator system, which went the following way, which said that if you give me a finite set of tasks, let us call it set T, and if I create a set of modules, set M these are like Lego, independent modules then if I can demonstrate that for every task you pick from this set I can pick a robot from this module set, I can build a robot from that module set which would do that task, then in some sense you would have defined a general-purpose robot, which would be the box of Lego, vis-à-vis the set of tasks that has been predefined. So the only constraint was the set had to be finite, right, but it did not put any constraints on the number of tasks in that set. It would be a million, two million, five million. Just could not be infinite. So conceptually this made a lot of sense to me, but it had significant problems, so now we have to think about design methodologies. If you pick a task from here how do I figure out what kinematic configuration works, right? So let us assume I have a method to figure that out, because that was part of our research on designing mapping tasks to robots, and that was Chris Paridas' PhD thesis, who is now a professor at Georgia Tech. And that was some very interesting work that was done. So the next question is so let us assume that problem is solved. So you give me a set here, a set there. I can pick a task, and I can tell you what kinematic configuration works. So we put it together just like you would put Lego together, so then the task was How do I design these modules so that I can just put it together? And, again, Don Schmitz was involved in helping me design this system, and the idea was that whenever you connect two modules together power, data, communications automatically get connected. So when the system is configured the system is totally connected. there is nothing else to do. But I am still left with the problem of programming the system. I have to figure out the kinematics, the forward kinematics, the inverse kinematics, the control strategies, right? So we had a project which would automatically determine kinematic configurations, so as soon as you build the robot every module was a smart module. It knew about itself, but it did not know about anybody else. And then we had algorithms where as soon as the system was built they would all transmit what they knew about themselves, and the system would figure out what this kinematic configuration looks like, what are the forward and the inverse kinematics. And that was a Master's thesis, Laura Kelmar . I have lost track of her, so I do not know where she is. Which was fine too, but I am still left with the problem of controlling the system now, automatically determining control strategies. And then we realized that this was a non-trivial problem, because to do this right you had to have capabilities in the operating system that would allow me to configure controllers automatically. And there was no operating system at that time that allowed us to do this. So my PhD student, David Stewart , his project was called Chimera, C-H-I-M-E-R-A. It was a real-time modular operating system where this operating system allowed you to create or assemble modular code. So the idea was just like I am assembling this robot using Lego blocks, if I had Lego block equivalent of software pieces, could I then connect them together automatically and create a controller for this system automatically? So Chimera was that environment that allowed us to do this, and we demonstrated how this would be done on a physical system. So all my life it is been all about theoretical work mapped and supported by experiments. So we demonstrated this as really successful, and if you look today a lot of work in modular robots in different shapes, sizes, forms across the country, across the world, and I believe that the work we did was probably the first or the second work in the world in that area, and that has laid the basis or at least demonstrated you can do it. Modular systems of today look different than what we had, but nonetheless it showed the utility of these systems and how they could be done. So once we had demonstrated this system the next goal was to say Okay, can a high school dropout program this robot? because at that point and even today to some extent you literally need a PhD in embedded systems or a PhD in something to program robots. That does not make sense if They are going to be useful. So we developed this iconic programming language called Onica , and that was Matthew Gurd's it was his PhD thesis where the idea was that somebody with an understanding of the task but no understanding of the robot or the technology could program. So this iconic programming language was puzzle pieces, so each icon was color-coded and shape-coded, so it looked like a puzzle piece, like a 1,000-piece puzzle. So the shape-coding was for colorblind people to be able to connect them together. So when you brought two pieces together that did not make sense, but if the puzzle pieces did not fit-in the system would reject it automatically, so it was an aid to help you program too now, because you could not just bring any two pieces together and create arbitrary programs, because they had to follow a certain sequence. So now every one of these puzzle pieces in the background had sophisticated code behind it. So when I brought two puzzle pieces together the code got combined automatically based on this real-time operating system, Chimera, that allowed me to do this. So now I could program a robot at a very high level, and it was all seamless. The code got configured automatically, the controllers got configured automatically, the kinematics got configured automatically, and you just do the task. And we demonstrated that with."
"Pradeep Khosla","Interviewer","What would one puzzle piece stand for? "
"Pradeep Khosla","Interviewee","One puzzle piece, for example, might be move. The other."
"Pradeep Khosla","Interviewer","So then you would have like move left. "
"Pradeep Khosla","Interviewee","Right, whatever. That is right. And then."
"Pradeep Khosla","Interviewer","How would that compare to the Lego Mindstorms kind of programming environment?"
"Pradeep Khosla","Interviewee","Yeah. So conceptually it is similar, but, remember, this piece of work is 1990, right? So then after that we got interested in swarm robotics, but it was a little bit okay. So the idea then was so 1994, 1995, 1996 I spent three years at DARPA, and there I managed large programs in robotics, in real-time control and in manufacturing, automation and design engineering. And that gave me a broader insight into two things. One was the needs of DoD and how we would have used or we would want to use robots in warfare. And second was capabilities of several universities who were all my contractors, like Stanford, like Berkeley, like U Penn, including companies like Lockheed Martin, Boeing, Northrop Grumman. They were all my contractors. So that was a spectacular three years where using my own background I could influence the direction of the field and at the same time using collective intelligence of the community I could learn a lot more and influence the direction of how robots were going to be used in warfare."
"Pradeep Khosla","Interviewer","How did you try to shape that direction?"
"Pradeep Khosla","Interviewee","So the real-time planning and control program, for example, was a more science-based program developing algorithms and so on and so forth. There was another program which was called small-unit operations, where the idea was how would you empower a soldier. So at that time there was this view in DoD which said that conventional techniques of battalions and platoons are not going to work. We need to have small units, like six to eight people, special operations who go do something interesting and useful somewhere. Now, to empower these people because They are in a very dangerous zone you need to be able to deploy forward-looking sensors. You need to be able to collect information. So the idea then was could we create robots small enough that could be thrown who would then one robot would give you vision information from camera. The other might give you thermal information, infrared, whatever. So that was the program there. So when I came back to Carnegie Mellon Dick Urban who was a program manager also at DARPA at that time had another thought where he wanted to combine small form-factor he wanted to build small form-factor robots. So Dick told me Pradeep, can you build a robot five centimeters on the side? Right? Now, sounds easy. There are many robots right now which are that size, but this is, again, 1996, long time ago. So at that point we build these robots about this size, and they were called millibots, right? Now, clearly in a robot this size they were wheeled robots, so you could not pack all capability that you needed. So we had this vision, which went the following way, where We had said that no single component of this system has to be able to do everything, but as a system it has to be able to do everything. That means there might be in this system of millibots robots that have IR sensors. There might be robots that have sonar sensors. There might be robots that have camera sensors, right? So think of this system of robots being several blind men feeling an elephant, but they have to be communicating with each other so that the system operator, me, knows that it is an elephant, right? So the vision here was can you have multiple robots behave like a single logical machine. So I want to interact just with one machine, so as soon as I give a command to that machine, says Tell me what is in this room, the system should automatically figure out what are the capabilities of each one of these subsystems it has, who can do what, create code, dump it on that, let them do it, collect the information and interact with me as a single logical system. So this was now an extension of this modular robot that I was talking about but in a slightly different way where I had several independent systems who were going to behave like a single logical machine. So That is the system we built. it is called millibots, and there was a Scientific American article that we wrote on that, which I think is pretty well-cited, so."
"Pradeep Khosla","Interviewer","What would you say was the overall role of DARPA in shaping robotics? "
"Pradeep Khosla","Interviewee","I think if there is one agency that can take credit for okay. So no agency can take all the credit, but if there is one agency that can take credit for pushing the technology at the cutting edge it is DARPA. DARPA had a very big role in robotics in general, but if you look at, for example, the autonomous land vehicle program, right, without DARPA there would not be any Grand Challenge one or the Urban Grand Challenge or what was the other Grand Challenge called? There were two Grand Challenges recently in the last two years. Those Grand Challenges we were able to demonstrate capabilities because of 20, 30 years of DARPA investment in autonomous land vehicles, for example. Similarly, DARPA made investments in manufacturing and automatic assembly, and DARPA made investments in the next-generation controllers. So DARPA has had more than a 30-year history I believe or a 30-year history of investments in robotics that have brought us to where we are. "
"Pradeep Khosla","Interviewer","In DARPA how is the policy about where robotics is going made? How does the interaction with the military happen? "
"Pradeep Khosla","Interviewee","Yeah, so there are meetings, but the way the interaction happens is DARPA brings program managers who are domain experts, MEMs, robotics, computivation , solid-state physics, whatever. does not matter. And DARPA has a mission which says that they want to be doing cutting-edge research but of relevance and application to the military but not necessarily in one year. It could be five, 10 years, right? So as a program manager you know what your passion is. You know what the mission is of the agency, and you have access to just about every other agency in the country, including the three-letter agencies besides the DoD. So what you are expected to do is go talk to various people, figure out what the needs are, understand what the state of the art is, understand how much can it be purged to satisfy this need, and build a program plan which then you pitch to either your office director and to the director of both and so those layers are not that many, just two layers of other smart people who look at it and say yeah that makes sense, but have you thought about this, have you thought about that, so there might be a couple of iterations. Once the program is approved then you go put out the BAA and you run it like a project unlike the National Science Foundation where you are funded, you are funded, I am funded and you are all doing your own work. DARPA we would put together just like my modular robot, a project where you are doing component A, you are doing component B, somebody doing component C, and the program manager would have the overall oversight to make sure these components connect and then they all put together to solve the problem that is of interest and relevance to the country and especially the DOD."
"Pradeep Khosla","Interviewer","But, the people who are doing the projects are not necessarily aware of the larger?"
"Pradeep Khosla","Interviewee","No, absolutely they are because when you build a vision for a program like that you cannot build it top down. You talk to the customers to see what their needs are. You talk to the community to see what the state of the art is and what their passion is, so it does not make sense to define a program where nobody in the community wants to work on it and we want the best minds to work on it and the only way you get best minds to work on it is to have a challenging problem and give them freedom and empower them to do great stuff. So, it is a delicate balance between enabling them significantly, i.e. total freedom versus getting your job done. So, I learned a lot in terms of project management, managing people, and these are the best of the best so."
"Pradeep Khosla","Interviewer","And so, when you are making the decision of how something that looks much like the very basic science, how do you make a decision of whether it is going to have an actual impact on application in five to ten years?"
"Pradeep Khosla","Interviewee","So, this is why DARPA wants to hire people who are topnotch domain experts in the area, right. Because these people have a vision, these people have good taste. They have a sense of quality. They know what can be done and how long, so it is intuition, it is experience, that is experience of other people all coming together."
"Pradeep Khosla","Interviewer","And, how did you before you started working in DARPA for the three years, was your funding previously generally from DARPA?"
"Pradeep Khosla","Interviewee","Yeah."
"Pradeep Khosla","Interviewer","Where was it from?"
"Pradeep Khosla","Interviewee","I had money from both NSF and DARPA, but it was purely accidental when I started working for DARPA where Gary Denman, who was the director, so I joined DARPA in 1994, January, so Gary Denman, I think it might've been 1993, June or something, came to visit Carnegie Mellon, he was the director of DARPA, and I remember this clearly. I pitched to him this project Chimera, the next generation operating system in a programming environment and how it was going to change everything we are doing and better systems. And, rightly or wrongly for some bizarre reason he liked it, and he said how much money would you want for it. I forget what the number was, I said like $10 million or $5 million dollars, something, it was a big number, way beyond a professor seven years out of PhD would say. His response back to me was why do not you just come work for DARPA, implement this, you will not get 3X the money and the world will solve the problem for you. Just at that time, in 1993, I had just been promoted and I was looking for the next thing to do, and this came at the right time, so I talked with a couple of my mentors and they said hey this is a great thing, go do it. So, I took three years off and I said okay I am here Gary, tell me what you need to do. "
"Pradeep Khosla","Interviewer","So, did you get the funding at that time?"
"Pradeep Khosla","Interviewee","No, so Chimera was just one project right, so the funding was real-time planning and control. That was a program which involved planning algorithms, control algorithms, the underlying software base, so it was much broader than just one real-time operating system."
"Pradeep Khosla","Interviewer","After DARPA when you came back to CMU did you continue to implement that program?"
"Pradeep Khosla","Interviewee","No, so when I came back to CMU That is when I did this project on Millibots."
"Pradeep Khosla","Interviewer","Okay."
"Pradeep Khosla","Interviewee","Right, which was the next generation of modular systems where you would have multiple physical systems with a single logical machine."
"Pradeep Khosla","Interviewer","And so, what came after the Millibot?"
"Pradeep Khosla","Interviewee","So, after the Millibots what happened is I started getting interested, as you can see, so my career involved electrical and computer engineering. It involved software engineering. It involved mechanical design and embedded systems, so towards the end of Millibots I started realizing that once you have many of these systems out there where the code gets generated automatically, the code gets downloaded, the probability that one of these systems could be taken over by an adversary is extremely high. So, this is now 1998, 1999, so that led me into this whole notion of security in embedded software so how do I make sure that one of these machine subsystems does not turn rogue on me? Right, because that would be a bad thing. From there on, I just got interested in security in embedded systems and in 1999 I became department head of Electrical and Computer Engineering and as a new department head I was looking at the department thinking about what is the next big thing we should be doing and I realized this computer security for embedded software is going to be a big thing. So, I created a center, which now is CyLab. It is the largest cyber security research center in the country at a university. I just got interested more in software security."
"Pradeep Khosla","Interviewer","Who are some of the people that you collaborate with on that?"
"Pradeep Khosla","Interviewee","Adrian Perrig, who is a professor at Carnegie Mellon. he is one of my main collaborators and the other collaborator is Rohit Negi, but Rohit is an information theory guy, so with him I collaborate I have two PhDs on sensor networks, so if you think about these little Millibots that I call them and they start running around, you can think of them as deployable, mobile sensor networks, right. So, now the fundamental question is okay so if I have enough of these I know I can sense enough of the environment, but I do not know what the sensing capacity is. So, just like a channel has information capacity, like Shannon's Theorem, so we got interested in what is the sensing capacity of this system. So, Rohit as an information theory guy brought to bear his knowledge and we have some results on what would this capacity look like? So, we have been doing work in sensor networks."
"Pradeep Khosla","Interviewer","And, what are some of the special challenges for security in embedded systems versus more traditional computer systems?"
"Pradeep Khosla","Interviewee","I do not think, so on a very low technical level the problems are different, the challenges are pretty much the same, but in embedded systems, so take power systems, for example, a lot of CPUs that are used for power system management and control are embedded CPUs and the problem there is that they control critical infrastructure like the CPU in your car is an embedded CPU. it is an embedded software system. It controls your car. If that gets taken over and your car starts to do things that you did not want it to do, it could be bad for everybody, same with power systems. So, it is the implications that are different, the fundamental challenge is still security of software systems."
"Pradeep Khosla","Interviewer","It seems like in terms of the general application of your work initially you were doing a lot of things that were more kind of industrially oriented, oriented towards industrial application and then after DARPA now you are looking at some other kinds of applications."
"Pradeep Khosla","Interviewee","Right, so you can see the transformation, so there is a project I did not talk about where it was a similar notion of a modular system where people it was on the Troicabot project where there was a system of three PUMA robots like in a triangular configuration that Westinghouse wanted to get rid of, but I had an interest in them so they gave them to me. And, where people were talking about robotic assembly where all the assembly would happen with robots, but clearly programming these systems was painful, right. So, at that point we had this vision of here is what should work. If I build a CAD model of an assembly, right, and I put it into some system, what should come out the other end is a program to assemble that from components and then I should download this program to the system of Troicabot and demonstrate automatic assembly. We actually did that project where it had geometric reasoning involved in it because now you take a CAD model. You reason on the CAD model to figure out how it is going to be disassembled, then you more often than not We will reverse sequence which creates the assembly sequence, right, which tells me what motions I should have in the robots. Once I have that I have this iconic programming language that I talked about, which at a high level encapsulated those motions and brings them together, right. The software gets created automatically. I decide which robot the software goes on, which one of these three and then out comes your assembly. So, we did a big project that lasted for like five years in that area. So, my pre-DARPA was more industrial applications, but more thinking about this touring robot and even today, I mean really few people, at least from what I can tell, have been pushing this notion of what a touring robot looks like. We build these robots to solve a task or two, but we have never really addressed the problem of if there was a touring robot what would it look like and then post DARPA was mobile robots, Millibots, making multiple robots act like a single logical machine, more field/DOD oriented. About 2000 onwards, it is more software security, embedded insecure systems I am sorry, security of embedded systems. that is also the time when I became department head, 2004 I became Dean so my interest had expanded to building organizations that could accomplish these big goals and tasks without me having to do all the work on my own."
"Pradeep Khosla","Interviewer","As the Dean how do you see the position of the Robotics Institute relative to other robotics programs around the world?"
"Pradeep Khosla","Interviewee","I think the Robotics Institute over the last 30 years has made a significant impact on the whole community. There was a time when the Robotics Institute was a when it started. Then there came a period when MIT, Stanford, Michigan had great robotics programs. Then there came a period after that where many of these programs kind of got diluted, not in the quality sense, but more in the sense of looking at other issues in life in the research area. I think we are at a point right now where there are more robotics institutes in the country than we ever had before and many of these are populated by students that graduated from here. The robotics scenario in the country, the research situation, on one hand looks bad when it comes to the amount of funding, but on the other hand if you look at the amount of technology and the impact that That is created is purely amazing because if you think about computer vision as part of robotics a lot of visualization, a lot of HCI type of technology came out of that as the core. So, robotics now is more diffused as an area and it is made a very big impact, I think."
"Pradeep Khosla","Interviewer","How do you see kind of culturally and socially the trajectory changes in the Robotics Institute? you have been here since almost the very beginning, so."
"Pradeep Khosla","Interviewee","Every organization when you start there is a core group; there is a very strong camaraderie. there is only so many people that you have to interact with, that you have to remember, and you know just about everything about nearly everything that somebody else is doing so you are really well-informed, right. So, that was Robotics Institute. Today, the Robotics Institute is about I do not know $60-$50 million dollar a year operation. It has got components like the NREC, the National Robotics Center, it has components like social robotics. It has more faculty than even some departments at Carnegie Mellon, so it is bigger, it is more diffuse. Having said that, I do not remember everybody's name, which is unfortunate. I do not know what everybody else does, but I know approximately what is going on. But at the same time, it is high momentum, higher energy, it is more exciting. When I need to work with somebody in modeling graph dynamics, there is somebody, Jessica Hodgins, for example, I will talk to her and it is just more exciting."
"Pradeep Khosla","Interviewer","And, do you remember when the PhD program started?"
"Pradeep Khosla","Interviewee","Yeah, actually I was involved in defining the PhD program. let us see if I can remember, I might have to look at my resume to figure out the date, but that was."
"Pradeep Khosla","Interviewer","How was it decided to start a PhD program and who were some of the people who were involved in that?"
"Pradeep Khosla","Interviewee","So, there was committee typically Carnegie Mellon was a very entrepreneurial place. You set oh getting a PhD in robotics would be good so we put a committee together and I was one of the committee members, but we just defined a PhD program, end of story. Unlike most universities where you would spend like two years, the reality I think it was less than six months we defined a PhD program."
"Pradeep Khosla","Interviewer","But, how did you decide that then was the time to have a PhD program in robotics?"
"Pradeep Khosla","Interviewee","Because at that point, the field see if you look at a PhD program it has like two components mainly. One is what one would call the coursework component and the other is the thesis component. Now, at a place like Carnegie Mellon you could do the thesis like I did in electrical and computer engineering and you cannot tell the difference. But, we at that point, had the feeling that there were a set of core courses that described the domain and having some confidence in them was necessary, right. So, these were courses in perception, cognition, and manipulation was the three areas initially defined. Just like electrical engineering would define signal processing, solid state, so these were the three areas and so That is why we created the PhD program. It was more to create a common base of knowledge on which you could build your research capability on."
"Pradeep Khosla","Interviewer","you have been in other, besides DARPA, you have been in other government policymaking, what would you call them?"
"Pradeep Khosla","Interviewee","I am not."
"Pradeep Khosla","Interviewer","Agencies, well you were just talking about being with and."
"Pradeep Khosla","Interviewee","Oh so, DARPA I spent fulltime, nearly three years. Then, I am on the advisory board, for example, CSRIO Australia, NIST in the US. I was on the advisory board of UCAV program, which was the Unmanned Combat Aerial Vehicle program where starting from just autonomous flying machines to literally fighter aircraft being unmanned and autonomous. That was a program. So, I have served on advisory boards on several universities, government programs, government agencies, and including companies."
"Pradeep Khosla","Interviewer","What do you see are some of the future tones in robotics or where is the field going?"
"Pradeep Khosla","Interviewee","I think when the field started manipulation was the basis, I mean creating a robot that could do humanlike-talent assembly like window washing, whatever. Then it morphed into mobile vehicles, the autonomous vehicles and in doing so computer vision became a big part of robotics, but then at some point computer vision by itself had offshoots like visualization, like human computer interaction, so today I think of computer vision as robotics, but there are some people who think of that as computer vision. They do not think of that as robotics per se, right. So, robotics today is very diffuse, so in my mind people ask me what is the definition of a robot. I say whatever you want it to be is the definition of a robot. it is like defining pornography, you know, when I see it I will tell you. So, when I see a robot I will tell you. When I see something I will tell you if it is robotics or not."
"Pradeep Khosla","Interviewer","How do you see the robotics work in the US as compared to robotics, for example, in Europe? Are there particular differences?"
"Pradeep Khosla","Interviewee","There are differences, but there are also some so I see the work in the US and in Japan both being extremely exciting. The difference is that in Japan there are companies that are committed to robotics and they developed technology which at a superficial level does not look like it has applications, but it has many applications. I will give you an example. A company that developed a piano playing robot, now if you think about it, it is a nontrivial process to develop a completely articulated system that can play piano pretty much similar to a reasonable level expertise of a pianist, right. A company that developed robots as pets, I thought it was rather futuristic for somebody to think about that instead of having Chia Pets, which are these plants I could have a robot pet, which could have some emotional interaction with me if it is as simple as blinking a light, to smiling, right, pet dogs. You would not see that happen in the US. At least, I do not know of any company that would do it in the US, but there are these Japanese companies that would do it to create markets like the Sony dog robot. I mean that created a market. Sony made good money, so I think That is the difference. So, at the university level it is pretty much a similar type of research, but when it comes to some really creative, far out applications the companies are willing to spend. I also think when it comes to mechanical design; Japan focuses a lot more on the mechanical design of these systems than the US does."
"Pradeep Khosla","Interviewer","What about Europe or now Korea?"
"Pradeep Khosla","Interviewee","Korea, right, so They are all in play right now. So, I think the real big impact of robotics is going to be what we at Carnegie Mellon call quality of life where can we improve the quality of life of either disabled people or older people using these technologies. And, some of these technologies do not look like robots anymore. So, for example, a camera sitting in my mother's house in India so I can monitor if she is okay or not sitting in the US you might think it is not robotics, it is a camera, but the technology of computer vision, of processing that information was created in the context of robotics."
"Pradeep Khosla","Interviewer","Do you maintain your connections with IT and have you seen the diffusion of robotic technology in India?"
"Pradeep Khosla","Interviewee","I have not seen as much. There is clearly more robotics in India today than there was 30 years ago, which was nonexistent, but as I look at India today, the focus is not as much on robotics technologies as on web-based systems, some IT systems. it is a whole lot of stuff, but I do not see great mechanical design research in robotics being done in India. I do not see the next generation software research being done in India in robotics right, where it is been done in Japan. it is been done in the US. it is been done in Europe, especially France and Germany. Those are the two major players I think."
"Pradeep Khosla","Interviewer","Okay, go ahead. Do you want to follow up on that? No, it is not a followup I was going to change to."
"Pradeep Khosla","Interviewee","Is this going okay? I mean are you getting."
"Pradeep Khosla","Interviewer","This is awesome. So, you mentioned that you were on the advisory committee for the Combat Aerial Vehicle."
"Pradeep Khosla","Interviewee","I was. The program died, they killed the program."
"Pradeep Khosla","Interviewer","What do you see are some of the social and ethical issues about arming autonomous robots?"
"Pradeep Khosla","Interviewee","I do not know if I see ethical issues the way we use robots today because even though we think of them as autonomous systems, there is still a human being behind the decision making process. They are not just making up their own decisions. So, what we have done is removed the human being much farther from the sphere of harm. So, if you think about Afghanistan and the drones that we used to shoot missiles, so instead of a pilot flying the aircraft and have the possibility of being shot at, now we are flying a drone with a missile loaded on it, but back there somewhere is a human being who is going to make that decision on when to fire and who to fire on, right. it is not clear to me that there are any ethical issues in this context."
"Pradeep Khosla","Interviewer","But, if you are removing a human from the to a totally autonomous system ?"
"Pradeep Khosla","Interviewee","I can see us human beings as becoming nervous. I can see us human beings as thinking here is another society of intelligent inorganic systems that could take over and we have seen that in many Sci-Fi movies, but sometimes I wonder about if I look at the evolution of this world right, it is clear human beings were not the first creatures in the evolution process. There were single-celled creatures, multiple-celled creatures, and so on and so forth. Now, I do not know much about whether these creatures can think or not. I do not know what they felt when human beings came into being and started hunting and destroying these people, so there is a philosophical argument where some of us believe, not necessarily me, that human beings are the highest level of evolution, not clear to me because by that definition evolution would have to stop, so if I buy evolution I do not know what the next generation is going to look like, so I do not know."
"Pradeep Khosla","Interviewer","As an expert, would you be comfortable with having autonomous vehicles, I do not know a lot of different kinds of autonomous vehicles, a lot of different kinds of autonomous applications out there, both in civilian applications, also in military applications."
"Pradeep Khosla","Interviewee","Yeah, actually I would be. So, for example, in civilian applications the DARPA urban challenge, right, so if you look at driving, more people die in road accidents than, for example, die in airplane accidents in this country and across the world. So, dying and the more people are maimed and disfigured and disabled because of road accidents, why would we not want to use technologies that have been demonstrated to be safe and not cause any harm to a third party that would improve our accident ratio, I mean that would reduce the number of accidents to zero. Why would not want to have a goal of zero accidents on the highways if autonomous systems if we can create autonomous system technology that leads us there I think it is spectacular. You know, we as brothers, sisters, parents would never have to worry about our family member not coming home on time and wondering if he or she was in an accident. I see that to be a great thing. I have no ethical issues."
"Pradeep Khosla","Interviewer","Chuck was just telling us about one of their early demos of the autonomous land vehicle and they had put his three year old son in front of this thing as it was going. Of course, there was a person inside there, but do you think that there is a possibility of coming to the point where you could have like technology going with people passing through human controller in a sense?"
"Pradeep Khosla","Interviewee","Absolutely, I can see it."
"Pradeep Khosla","Interviewer","When do you think that I know it is really hard?"
"Pradeep Khosla","Interviewee","So, I think there are two issues. One is does the technology exist to demonstrate that and is there enough of a wherewithal for us to accept that, right. Those are two different barriers. I think the technology exists today. It could be made robust enough in five years that on highway at cruising speeds we can see autonomous vehicles, right. But, for us human beings to have 100 percent confidence that nothing ever is going to go wrong, that bar is higher. So, that bar, I think in about 10 years we would see it on highways where we would have cars. In fact, we already see cars with infrared and radar for obstacle detection in the car, lane changing systems. These are all incremental technologies that are helping us make driving safer and the look on the time, and I think it is less than 10 years when these would be integrated and a car would be autonomous and I would be in the car being driven by the car, reading my email, texting, a lot safer situation than me driving and texting. "
"Pradeep Khosla","Interviewer","And, do you think in Japan there is a lot of what I see as kind of deliberate work being done by the government, by various companies to present robots as this thing that we can have in our daily life, do you see that as at all being something that is also being consciously done in the US?"
"Pradeep Khosla","Interviewee","Right, yes, what about these vacuum cleaner robots? You know, they look like these dust balls that run around collecting dust. it is a very simple technology, right, but just like the example of cars you take somebody does the vacuuming for you. Then the dishwasher is smarter, the refrigerator knows when there is no milk, and you are going to incrementally add it all together and now you have a house where you could be sitting here and on your way home your grocery list could be generated. You would approve it; some third party would deliver it, right. I mean there are companies that deliver groceries and your life; your quality of life will be very different. I think a lot better because now if you are interested in social sciences or in filmmaking you will have more time to spend on that instead of worrying about groceries, worrying about driving, worrying about a whole lot of other stuff."
"Pradeep Khosla","Interviewer","And, for a young person who is interested in robotics and creating robotics what would you tell them?"
"Pradeep Khosla","Interviewee","I would tell them go for it. It is as good as it gets. It is very exciting. it is very open-ended and you get to define your future."
"Pradeep Khosla","Interviewer","I have one quick question that goes way back, but just cause it stuck with me, but I mean CMU obviously made a huge commitment to robotics That is different potentially from anything that I have seen; do you have a feeling for why they decided to make that commitment?"
"Pradeep Khosla","Interviewee","Yeah, actually it is."
"Rachid Alami","Interviewer","So the way that these usually go is we start with your name and where you are from and we go through your schooling, which universities you went to, what kind of projects you worked on, who you worked with. "
"Rachid Alami","Interviewee","Yes."
"Rachid Alami","Interviewer","And then end up with the different institutions you were involved with, and then end up with where you think robotics is going in the future basically. "
"Rachid Alami","Interviewee","Wow. "
"Rachid Alami","Interviewer","So we want your life story in short. So yeah, let us start with your name and where you were born and when."
"Rachid Alami","Interviewee","Okay, so my name, I am Rachid Alami. I was born in Morocco in 1954, 1954 and I studied in Morocco first until I was 20. So this is the first part , and then I went to France to Toulouse to attend engineering school. So I have chosen engineering school in computer engineering couple of times in computer engineering. And then I spent three years and became an engineer. "
"Rachid Alami","Interviewer","And that was undergraduate?"
"Rachid Alami","Interviewee","Yeah, it is the equivalent of undergraduate. Even in France engineering school is at the end of engineering school you have the equivalence of a Master's. it is the equivalent to a master so then you can enter PC program, our system. But I did not do this after engineering school. I decided to be engineer so I went back to Morocco and worked as an engineer for two years as a computer engineer for two year as a computer engineer for two years . "
"Rachid Alami","Interviewer","Oh so your degree was in computer engineering."
"Rachid Alami","Interviewee","Computer engineering, yeah. "
"Rachid Alami","Interviewer","How did you decide to go into computer engineering?"
"Rachid Alami","Interviewee","Okay, to be completely frank in fact you know in this system of engineering schools in France after the bachelor that you have, you have two years to prepare to prepare to enter to have exams and then you have to choose which engineering school you want. And I did not want to specialize so I did not want to do civil engineering or chemistry or as a draft engineer. I wanted to stay as general as possible and That is why and so I was essentially doing mathematics so I chose from an engineer point of view what was closer to mathematics which was computer engineering, particularly at that time. At that time computers were still something that people do not know did not know that much so I have chosen the less specific, the less specified and something more generic than a specific field. That is why I had chosen this. "
"Rachid Alami","Interviewer","What about engineering in general? Before even computer?"
"Rachid Alami","Interviewee","Ah, yes. So basically in Moroccan-France system you can enter engineering school to do science also afterwards, okay? it is simply a kind of good way to do it because it is very selective, and because it is selective it is good somehow. Somehow it is. This is how the system is built, and That is true that when I became engineer I found out that I wanted to know more, to do more. That is why I came back to research, or I entered research. "
"Rachid Alami","Interviewer","Where did you work in Morocco as an engineer?"
"Rachid Alami","Interviewee","Oh in Morocco it was two steps. First when I came back to Morocco with my diploma I decided to teach computer engineering so I went to engineering schools in Morocco to apply for a position as a research assistant of a professor. Assistant professor somehow to be a professor afterwards, so I entered first in engineering school as a teacher. And I found that it did not have enough computers because at the time computers were mainframes. It was very expensive to have a computer and most engineering schools did not have a computer. The students programmed on boards, on cards, and then went to a place where but they did not have the computer themselves. So it did not like it and I went to a department an administration department where they had computers, and it was so I left the university and went to an administration which is the Ministry of Equipment and Dams, the Ministry who manages the dams etcetera who had the biggest computers in Morocco. I went there to have the computers so almost two years I worked on the computers of this department. And there I developed computer models for dams, etcetera. "
"Rachid Alami","Interviewer","And that was just before the 1980s?"
"Rachid Alami","Interviewee","That was-"
"Rachid Alami","Interviewee","Yeah . That was between 1978 and 1980."
"Rachid Alami","Interviewer","Okay. "
"Rachid Alami","Interviewee","I was engineer in 1978 and during 1978 and 1980 I was an engineer. And in 1980 I decided to know more to go deeper and this but already I had some experience in research there because I had even as an engineer in Morocco you had interns from the University of Rabat and we worked on things and read articles etcetera, etcetera. "
"Rachid Alami","Interviewer","What kind of work projects were you?"
"Rachid Alami","Interviewee","It was essentially computer models of flows, flows to study floods in Morocco to study and so it was essentially data to accumulate data from to study influence to try to estimate how would a flood will develop in addition will develop starting from the rain data. Tried to build models of this so I liked it too, it was quite interesting at that time. So it was entering the research with this issue of building models and putting the models in the computer and running the models, running the programs, okay? That will already simulate things so that was the beginning. "
"Rachid Alami","Interviewer","And so when you went back to Toulouse for your Ph.D. Is that where you went?"
"Rachid Alami","Interviewee","Yes."
"Rachid Alami","Interviewer","What was that like there? What was the department like? Who was there? What was the research like?"
"Rachid Alami","Interviewee","Okay, okay. If you want the stories I will tell you. "
"Rachid Alami","Interviewer","Yeah, stories."
"Rachid Alami","Interviewee","You like the stories."
"Rachid Alami","Interviewer","Uh-huh."
"Rachid Alami","Interviewee","You like the stories, okay. So I have to come back. I have to come back a little. When I came to Toulouse the first time so in 1975 we had an engineering school at in Toulouse. We had an excellent teacher, excellent professor who was a professor of A.I. at that moment, researcher in A.I.,1975. It was really the beginning of A.I. And he was also professor at this engineering school and he was doing something very good. He was doing a kind of introduction to all what is informatics from the chip, from the- at the time from the electronics and the assembly language and the thing that now very far to A.I. Going through all the disciplines, all the domains in computer engineering and computer science. And I was impressed by this professor and by the fact that A.I. at that time already was a challenge for computer engineering. So when I came back after being an engineer, I came back to do research in A.I. . Okay, so I came back in 1980, eight-zero to do to try to find a lab and I went to Toulouse because I knew Toulouse and I had friends there. "
"Rachid Alami","Interviewer","And who was this professor?"
"Rachid Alami","Interviewee","I went to and found him and came back. He was Henri Farini , Henri Farini. He has retired now I think, yes he retired. And he has worked and written books and afterwards so I went to him and asked him if he had some Ph.D. program. Well he had a Ph.D. program but he has a place for me, and he told me Well there was a place, there was a very good place because I know you are enthusiastic. there is a really good place where you have to try it is LAAS. I had never been to LAAS before so I went to LAAS which is on the campus which was another lab. It was a lab of automatics and systems so informatics was not trivial to see there so I went there. I went there and tried to find this George Arault that I did not know. And the story started like this. And by chance he was starting a program and looking for a computer engineer in computer, someone to develop programs in a new language at that time. And so I said well I will do it. "
"Rachid Alami","Interviewer","So what kinds of projects was George Arault working on at the time?"
"Rachid Alami","Interviewee","Ah yes. Now we are in the 1980s. At that time George Arault was starting the first national program of robotics in France. George Arault was a very became incrementally at the time, he started already to be a central person in robotics in France and elsewhere also, and he at that time he had- he took time to prepare it but around when this program was ready to start and it was a national program and of course LAAS was one of the main points of it, not the only one but one of the main point at that time he was they were buying computers new kinds of computers for that time which were mini computers because mini computers, 32 bits computers and at that time that was the first time where the users had real time computers that touch themselves. They were not blocked behind the fence where these mainframes that were behind the fence and you have just give the . They were buying the first computer that you the students were touching, were plugged into the robots at the so I lived this adventure of having our own computer and it was quite big. We called it a mini computer at the time and it began like this and there were things missing, this computer. We had to build languages, programs etcetera and there was one- so this program- sorry, I should do it like this. George Arault has built a program and he was coordinator of this program called ARA. ARA in French is Automatic Robotique Automation. which is in English Automation and Advanced Robotics. At the time already they were making a difference between robotics and advanced robotics. You know because it was a challenge of doing advanced robotic. Already thinking about the intelligent robot, the autonomous robot, that was a dream of George from the beginning. And so I am one of the sons of ARA I should say. We say this in France we are a number that we know, that we know and at that time we are a number in France and elsewhere now, one of the sons of ARA because this program started that time and you obtained finance for at that time."
"Rachid Alami","Interviewer","Who was involved in ARA?"
"Rachid Alami","Interviewee","It was all over France, you know in the different centers there was Toulouse, there was also people from Paris, people from Grenoble, essentially Grenoble Paris at that time and already Montpelier also big centers. That is where the big centers that started Robotics as that came also which is in South of France, these were the centers where we were starting Robotics, and Toulouse was one of the big centers because we had one of the computers. We had the computers, we had the computer and we were an integration place so people were coming from other places to integrate their software, their ideas in our system. So we had the computer. We had the manipulator, two manipulators, etcetera."
"Rachid Alami","Interviewer","And so what were some of the types of questions that were part of this advanced robotics?"
"Rachid Alami","Interviewee","Yeah, so ARA was built also it was organized into different aspects, so one was the essentially what they called advanced data operation. we are not doing this, people of Paris essentially are doing this, advanced data operations so it is operating a distance robot which was far and at that time the application were essentially for nuclear plants for example to do to operate a remote robot which is still necessary today, very necessary today. So that was one of the applications of this advanced operation. The other aspect was more at that time and even everywhere in the world robotics was quite linked to manufacturing so there was one another theme was advanced manufacturing essentially. The third one was what we call advanced autorobics which was the autonomous robot that you have to develop tools to control it and to program it offline. At the time it was essentially offline programming so the intelligence was essentially offline, not online. And so there were- these were the main points and it was organized in workshops. We had two or three workshops per year so we also and challenges for example for the advanced robotics we had as a challenge to assemble electrical contactor which was quite complex to find assemblies of who can do automatic. That was basically the challenge, essentially assembly robotics auto for doing assembly."
"Rachid Alami","Interviewer","And how was this funded?"
"Rachid Alami","Interviewee","It was funded by the French government through it is different agencies Ministry at the time of research and education, essentially. There were also industrials- industry partners involved that essentially gave equipment or provide these challenges of the electrical contactors to assemble, etcetera, also subsystems. "
"Rachid Alami","Interviewer","And so what kinds of questions or projects did you start working on? "
"Rachid Alami","Interviewee","Oh myself. So myself I started at that time which was I was hired to do with the intelligent part of the robot and in order to do this to the intelligent part of the robot at that time in order to do intelligent- to develop systems in A.I. I should say, planners or expert systems like we said, rule-based system at that time, it was necessary to have one language that was the language of A.I. which was Lisp and in the computer that we had if you should remember at that time when you- when we were buying a computer we did not have a standard operating language, operating system. Each computer has its own operating system so you had to learn the operating system and the assembly language of that computer. And because of this, this computer did not have a Lisp interpreter so I was hired first to build a Lisp interpreter in order to run my A.I. programs in it. So I first built the Lisp language, a Lisp interpreter which was used by the community so I already had a number of users in ARA, a number of students were using my system and I was so I was obliged to deliver and maintain the system for four years. I had done it with pleasure. So I built a Lisp interpreter and then I began to build my own system inside. I remember, own system was essentially a programming and control system of what we call at that time a flexible assembly cell. What we call the flexible assembly cell it was system composed of robot of sensors which were not onboard of the robot but near the robot for example you have a camera, and also a number of other devices like a conveyor belt. A number of object deliveries, subsystems etcetera. And this the assembly cell that we have built there at last, we had two robots and between them a conveyor belt and a number of systems to deliver cameras, etcetera, and simple sensors also like contact sensor and things like that. So that was the idea. The idea was to build the cell. We called it flexible. Why flexible? Because the idea was to develop programs that would allow you to parameterize as much as possible programming of this cell because at that time essentially robot programming was by moving the robot and learning trajectories and simply re-executing trajectories. And we wanted to have programs that are more general that run the system. For example the flexibility came from the fact that we wanted this flexible assembly cell to assemble objects the contactors, part of it, something. We have chosen this simple spots of these contactors to assemble and the challenge was to program this assembly with two robots, two manipulators and conveyor belts etcetera and the challenge was that the objects would arrive in this order, a known order and the robot system will have to identify the objects to localize them, to take them to assemble them to store momentarily to use buffers to store the objects that are coming online, to build the assembly and when the object is assembled to put it again on the conveyor and it goes. That was amazing idea and so we worked on this on how to I worked on this programming office, this aspect of program directories, programming grasps programming. Essentially they wrote the high-level system. A system that they called NNS, No Name System. And this system was the system that was running the flexible assembly cell and to sufficiently generate to allow people to program in it different assemblies. It was not one assembly. Yes, one assembly program within it you can program inside the system different assemblies. That was in a flexible way. That was a challenge. "
"Rachid Alami","Interviewer","And the robots themselves that were part- so you seemed to have a manipulator, grasping and stuff like that. "
"Rachid Alami","Interviewee","Yes."
"Rachid Alami","Interviewer","What were the different components and also did you make them in-house or did you purchased?"
"Rachid Alami","Interviewee","Oh yes, we purchased the computers but the robots, we purchased the robots sorry, right. And of course there was all this activity of finding the good robots, purchase them, write the control programs of these robots, and there were two robots. The two robots were French robots. One was a small company called Semi , and at that time it was difficult to have- to buy easily what you want. You had to go through market and there were various limitations for market etcetera. And also at the time they wanted to push of course the French industries so we- one of the two of us was the same. it is a small company. it is a small company building this kind of- it was quite beautiful robots. At the time the equivalent of already at that time I knew very well my colleagues in America for example in Japan etc. at the time, essentially the American had Puma robots. We had our Semi which was equivalent somehow. And there were several Semi in the ARA programs so we were able also to share, to share software and ideas and hints, etcetera. And the other robot was built by Yves Renault It was a big robot, Renault Automacion which is one subsidiary of robot. We were building the robots for in-house use. In Renault. So they are the two robots so we bought them, but we had to program the controls of these robots. It was not delivered with it so it was not at this level to program might be by other researchers doing this low-level control. I was doing essentially the high-level control the A.I. part. The A.I. part where other people were doing but from that moment I had to link between A.I. and the control programs. That was essentially my contribution is to plug from A.I. to the control of the Robot which I still am doing now , still working at this issue of making the robot really use planners so that my work was essentially this. And for the rest there were cameras with vision system etcetera. At the time it was black and white vision, it was 2D vision, very simplified, based on contours only so you localized the object only on 2D, etcetera. "
"Rachid Alami","Interviewer","Who were some people that you worked with closely?"
"Rachid Alami","Interviewee","At that time? People who were involved in the ARA program. You have George Arault, I mentioned him. I am trying to mention people that are still exist. One who was a little more senior than us, already senior at that time compared to us even if he was young, was Jean-Claude LeTemps who is not in Stanford. So he was one of the partners of ARA who was responsible for the Grenoble part of it because it was in Grenoble. And in terms of students I can mention Vincent Hayward who was in Paris at that time. He is one of the ARA boys one of the ARA boys. And then he went to McGill . Now he is back in Paris but he- his main career was first in U. Penn. and ten McGill so Vincent Hayward. Also Emanuel Mazere who is still a researcher. Who is now a researcher in robotics in A.I. in Grenoble. Who else I can mention? I can mention Etienne Domp , also who was in Montpelier who is a senior researcher in Montpelier today. Others, I can find others. Yeah this is basically I am looking to people who were not from my lab but other labs. So as you see there were people from some different places and so all these people are good friends of me today. "
"Rachid Alami","Interviewer","So what was your thesis project for your Ph.D.? "
"Rachid Alami","Interviewee","What do you mean? Essentially it is developing this NNS, No Name System, No Name System which is a high-level control, programming and control. It was programming and control system, both sides high-level control for flexible assembly cell. That was basically the main result which was quite advanced at that time. I presented here and there in different conferences here in the U.S. etcetera and at that time it was one of the main issues, the main challenges in robotics to build this- yeah. And at that time when we started to think about motion planning for example. So we started to look at this. We were very interested by people who were doing this and beginning to do this essentially here in the U.S. Thomas for example at M.I.T. so there was him and there , it was us. That is why we had a lot of contact. It was one of the guys who influenced us at that moment. It was very interesting at that time. Other people that were of high interest for us and also collaborating at that time it was a small- we knew almost everybody. Lou Paul also at U. Penn. at that time. "
"Rachid Alami","Interviewer","And did they also come visit you?"
"Rachid Alami","Interviewee","Oh yes, yeah. George Arault was they were friends essentially of George Arault, and we had a lot of contact already at that time, already in the beginning of 1980s and from 1980 to 1985, 1984. Eighty-four it was the first IKRA I attended the first IKRA and presented NNS, the first IKRA which was in Atlanta in 1984."
"Rachid Alami","Interviewer","And then so you also had exchanges kind of student exchanges or people went-"
"Rachid Alami","Interviewee","Yes well at the time they were not- the exchanges came afterwards. At that time we had contacts and we read papers etcetera, and we contributed to conferences. It was quite intensive in terms of contacts and reading papers and going and visit. At that time I made visit of main labs in the U.S. already. "
"Rachid Alami","Interviewer","What were the labs you visited?"
"Rachid Alami","Interviewee","At that time it was in 1985, 1984, 1985, 1986. Oh it was essentially M.I.T., Sam U., Stanford, U. Penn. Yes I think basically these, S.R.I. also, Berkeley. "
"Rachid Alami","Interviewer","And this was when you were already a professor at-"
"Rachid Alami","Interviewee","Me?"
"Rachid Alami","Interviewer","Uh-hum. "
"Rachid Alami","Interviewee","No, I in 1984 I applied see I am not professor. I am full time researcher in CNRS and so CNRS provide this possibility to have positions so I applied to enter to CNRS so this is French system so CNRS is an agency. There is national competition to enter so you do not enter at Toulouse level. You enter at national level so it is national competition. It is quite difficult to enter CNRS until now. Today also it is very competitive to enter the CNRS so I entered CNRS. At that time I do not want to stay that much. I will stay only five years or three years and I will see. And I stayed. So in 1984 I entered CNRS. I did my Ph.D. in 1983, end of 1983 and applied and entered CNRS in 1984. "
"Rachid Alami","Interviewer","And were you then working on a different project? "
"Rachid Alami","Interviewee","We continued this ARA program for one or two years until 1986 and then other projects came and I worked also with another colleague who entered CNRS two or three years before me who was Raja Atilla a year or so. I was working on the flexible assembly cell and was working on ELAR on the robot and incrementally we mixed both in the sense that we made everything to go towards autonomy and not offline programming or assembly cell but more autonomous issues. "
"Rachid Alami","Interviewer","And what were some of the challenges in taking the systems more and more toward autonomy?"
"Rachid Alami","Interviewee","It was a dream of the beginning. We wanted that dream. The omnipotent smart, clever robot from the beginning so whenever it was possible we moved towards that direction. Okay we are still going that direction. I think that basically these people I know at least Raja, George, myself, etcetera when we stayed there, our dream was this one. That dream the big dream of the robot that is autonomous that is omnipotent that is able to do everything to learn etcetera, the full dream of the robot. And all the projects were for us only steps towards this dream so. "
"Rachid Alami","Interviewer","I will come at it from a different way. What problems did you run into? "
"Rachid Alami","Interviewee","Oh. "
"Rachid Alami","Interviewer","Or so when did the dream get tripped up?"
"Rachid Alami","Interviewee","Oh so we had a number of dreams. We found out it was difficult. Yeah, we found out it was quite difficult, okay? Yeah. "
"Rachid Alami","Interviewer","Not a five-year plan."
"Rachid Alami","Interviewee","No. No and so we entered interesting questions of what is real navigation, what is really assembly, what is contact. What does it mean to program at a high level so at that time the main challenges was what we call the task-level programming going from a factor 11 programming to I am using the vocabulary of that time, okay? We are no more using this vocabulary today. But that time we were thinking about using task level programming so programming in the sense that you program the assembly without even mentioning the robot. Describing what would happen and the dream was to infer the program for a specific robot that would achieve the task. That was the idea of the task level, you describe the task. And again to come to issue motion planning and then at the still now so that was a big challenge which is still here of generosity and description at the highest level that you can possibly at a symbolic level of a task. And work on inferring all what you should be doing. Of course we got through difficult for example we found out that navigation which was assumed to be simple was not that simple at all. And so we found out also to give you ideas what happened in our lab not only in our lab, but however in our lab. In our lab we found out concretely that you had motion planning that is in the configuration space but if you have a system that is not homonymous , like the robot that we have Helar was unfortunately not homonymous so it created a complimentary problem to us to solve and perhaps it is because of this that my colleagues worked on this non- homonymous issue because it had a robot that was like that. Also issues of uncertainty in building models SLAM problem so we found out concretely that there was a need to solve this problem at the SLAM, so we contributed, not myself but my colleagues to the SLAM issue. I contributed more on the issue of task-level programming: how to program at a high-level, how to decompose the system into subcomponents, how to decompose a task into different motions so at that time we are speaking about what we called grasp synthesis, local motion around the object, the gross motion when you are far from the object, this aspect. And so that was a challenge to find out what were the components, what were the- sorry- the sub-problems, to find solutions for the sub-problems essentially developing plan is motion plan or grasp planner or local motion planner. And at that time we had also the ambition of completeness so we were trying to develop essentially ethical systems that will solve the problem completely and incrementally appeared this aspect of randomized search and systems that were not complete by construction but complete only well at in time I should say basically. So the challenges came like this we were decomposing the problem and building the different components. And the other big challenge that we stared at that time was the grounding problem, the link between the geometric and numeric data, the signals and the symbols. Tried to build and we found out it was difficult, difficult to do it in a generic way and even if you build a generic system you have a guy that says Oh, this place, this symbolic place is X23Y44 etcetera, etcetera directly by yourself a symbol to a number which was wrong. You should assemble a symbol to a property to satisfy a property or an attribute and have a system that will compute this. So we went through this I think essential issues of robotics basically and we are still there."
"Rachid Alami","Interviewer","So when did you go from the more kind of manufacturing or oriented applications to some of these other applications?"
"Rachid Alami","Interviewee","Oh, okay. Myself, I in fact it happened for me, for me around 1986, 1987 essentially because even though I was very pleased with this issue we were in an environment where the application was essentially industrial and so it was essentially oriented towards offline solving problems offline so it was not after solving a number of issues essentially based on CAD etcetera, it was no more interesting for the assembly line but still the problem of assembly today is important and not solved okay but autonomous assembly you had papers and this conference of autonomous assembly. But at that time assembly was looked only as an engineer process. And autonomy was oriented towards navigation mobility. And so the challenge for autonomy was more in this field. Even though at that time I was- I did not understand this very well because I thought autonomy was also in the assembly. But well things go like this. I went to essentially mobile so I worked in other projects which were essentially project's for develop to develop robots for rescue basically, recue applications and space applications so the second challenge was the Mars Rover French initiative so we worked on this. "
"Rachid Alami","Interviewer","What was the name of that project?"
"Rachid Alami","Interviewee","Yeah, it was in France it was RIISP, Robotic- R-I-I-S-P. And this also was a project that was built by George, George Arault, He built a new project in the middle when ARA finished he built a new program which was a challenge of the autonomous robot and one application of the autonomous robot was because it was necessary absolutely necessary it was the planetary robot and so we convinced the French agency the Caness George essentially a member of the- to build a program with this so we had a national program. It was basically a number of labs working with Caness to think about this complete mission and we spent years thinking about the complete all the components that are necessary to build programs and operate a robot on Mars. So we had to program this and we looked to all these aspects. This program stayed only on Earth in the sense that we have built robots. We have around exploration on Earth. Even in Caness, they have built a model of Mars and a model of the moon and soil and we played there essentially with this program has never gone until really implementation but so everything so when the Mars Rover project appears in the U.S. and it went there etcetera we were understanding everything because we have thought about this also and we knew the different parts of it. For example this issue link to the fact that you have low bandwidth and you have long delay that will go from five to twenty minutes between Mars and Earth so you cannot program- you cannot teleoperate the robot impossible, the robot should be autonomous. Even if it is so you have to program once every day somehow. All these issues we studied at that time. This was between I think 1986, 1987, I do not remember, 1992 or something like that, 1990, 1991, 1992."
"Rachid Alami","Interviewer","Did the NASA folks make any contact with you?"
"Rachid Alami","Interviewee","We had contact of course. We had contact also we knew what was happening here and there. We had there were conferences etcetera but of course we are a research lab so we are not building the final project. The idea was- there was after this first project there was another project that were more applied with industrial partners that were assumed to build a second prototype, you know, it is similar to what happens here. It was not yet a flying prototype but a real prototype of the system. But the thing did not go because after that you know the main choices in Europe made that the Mars Rover never happened, the program, I mean the real program never happened. So the Caness maintain it as the Caness was responsible as a French agency of preliminary study so they have done the study, this preliminary study and they were ready to do a second step but it did not happen completely for a number of reasons, essentially money. it is very expensive, very, very expensive. Of course it could have been done only at the European level or international level, it did not happen."
"Rachid Alami","Interviewer","And this was just a French program?"
"Rachid Alami","Interviewee","It was yes, at the beginning it was a French program, then it was the second step after this French program to which I contributed. I contributed also the second level a little, a little was the European program. It was European program but not a Space program. Not yet the Space Program. It was Europe program oriented towards the of the robot. Not really the flying system. So I think we were quite aware of the global problem from the robotics point of view, for the other point of view it was different. So we were running VxWorks we are still running today on some robots. Yesterday when we were two days ago when we are in the NASA, they were running still VxWorks on some of the robots. it is a real-time operating system."
"Rachid Alami","Interviewer","I was curious about the public discourse in the 1980s about space. I mean, because the U.S. we had the shuttles and everything and there is kind of NASA and everything. So was there I guess what kind of discussion was happening about a French space program? What was kind of the catalyst for this project?"
"Rachid Alami","Interviewee","Oh, I think this program of the French Mars rover or the European Mars rover was at the level of specialist. It did not reach really the public. But in Europe it was quite easy because we thought out autonomy and not sending people there already. So it was accepted and justified to build and to think about the autonomous robot that you would have to operate from far and which has autonomy from the beginning. So it was quite natural and quite well accepted. So we did not have really so we presented public was not really concerned, because it did not reach the level of."
"Rachid Alami","Interviewer","So in comparison I mean, NASA has this whole focus on human or used to have a focus on human flight, and now that That is kind of gone so in France there was never such a ."
"Rachid Alami","Interviewee","No, there are human "
"Rachid Alami","Interviewer","Space station?"
"Rachid Alami","Interviewee","Yes, on the shuttles and space station, but we are not thinking about human on Mars. But for us as researchers it was also contextual autonomy was necessary, and I wanted autonomy. we are happy. we are happy to study this issue. But also we are trying to take into account that was interesting also the reality, the context of the application. For example, at that time, still now, you have limited power, limited computer resources on the planet. You have to limit your computation and this issue, issue of, again, the bandwidth, issue of the delay all this taken into account. we are thinking about also the you know they have the in fact the mission was completely built so it about this satellite that was there to maintain communication between the robot and the Earth with different rendezvous of possible communication between the robot and the satellite, and then Earth."
"Rachid Alami","Interviewer","So here still there is not that much unless it is maybe about tele-operation discussion of where the human fits into "
"Rachid Alami","Interviewee","Yeah, there is no here the human was my first contact with here, the human was at Earth, and we are thinking about what the human should do operate robot at a distance and to program it, and that way. So we worked with it was essentially issue of interfaces and what program will you send. So we work with people from ergonomics, etcetera. So it was not yet; this came far after that. It was not yet the robot and human who share space and task. This came afterwards."
"Rachid Alami","Interviewer","So what were some later what other things did you do?"
"Rachid Alami","Interviewee","So that was the French. Then, another program in fact, they corresponded to the and here, the essential work that we have done, and there there I began to where we worked intensively with the Raja Atilla, and other colleagues, and this project was responsible of part of it. It was responsible of another one, worked together. So our main result there was thinking about the architecture, control architecture of a system: what should be onboard, what should off-board, what should be online, what should be real-time, which could be used we thought anytime algorithm, thing that could run offline, etcetera. So essentially our contributions, us, was linked to robot architecture and planning. At that time we started another project which I did not contribute that much so Raja will tell you more about it which was kids project, which was it is there that they worked on SLAM, essentially. They did not work on this aspect. So I worked essentially on control on intelligent control, I should say; on control architectures. And then came another project which was another European so we have several projects on this. And so we went from space to rescue robotics same problem, same idea robot moving in rough terrain. So environment it has to discover while moving in it. It does not know it beforehand so you cannot program anything really in detail because robot will discover. So that was basically the idea. We had a number of projects on this, national or international projects. And then we had another project which was a little different, which we came again to Earth, which was linked to multi-robot aspects. And this project was called MARTHA. It started in 1992, and there I was really responsible of the main part of the main contribution of LAS in it. In MARTHA, the problem was how to operate the MARTHA project is essentially thinking about robots for logistics. You have a number of robots to transport, for example, containers in harbor from one place to another, or also for freight essentially, applications in railway stations also you might have this, and harbors, in airports also. You have to transport small containers at airports. And it was a very interesting project where we had essentially two contexts of application: the airport and the harbor. And the idea was to think about how to operate a number you cannot have one robot doing this. You might have 2, 10, 20, 50 50 robots doing this in a big environment. And the issue was how to do it in a way that you do not program everything, that you have flexibility, etcetera, etcetera. So it is there we started to seriously I started seriously to work on multi-robot cooperation, how to make the robots cooperate, and if you make them cooperate this allows you to give high-level mission to all of them and they will arrange by themselves what to do. So that was the basic idea. So we started in this project which was quite a number of constraints. You had industrial partners, you have real users even though you try to make them fundamental research. So we started issues of task location, who will do what at which moment; of coordination, coordination at level of directory, how to make them move without colliding and synchronize, and immediately if you think about motion planning it is combinatorial. There is a combinatory explosion for this issue because if you have 50 robots, you have 150 degrees of freedom, etcetera, so you have to do something. So we studied this issue these issues, I should say and also we have some quite interesting results on this and how finally you could have robots essentially and we found it quite interesting, and it worked quite well. it is this notion of what we call plan-merging. The idea is that the robot, through communication, merges itself in what the other robots are doing. And this is done by deliberation. So the robot, essentially through communication, exchange their plans. They exchange their plans and they deliberate to synchronize themselves. And so I introduced and we worked about this issue what we called plan-merging."
"Rachid Alami","Interviewer","Kind of a robot democracy."
"Rachid Alami","Interviewee","Yeah, somehow. Somehow. Somehow. Yes, in the sense that the idea is that in order to send to acquire the information on the robot and to send everything to a central station that will have a global view. At the time we had far more limited that what we have today. You really had to do things onboard because you cannot it was through 1996 and still we had the best we did not have Internet, not yet, really. And we were using 9600-volt maximum, which was quite limited. But however, so yes, it is kind of a democracy. So the robots, by negotiation, decide what to do at this level, and we tried also to compose at different levels. So they negotiate what to do. it is essentially a transport task. I will go there and get the object because I am not far from it, or I will move not far from this so I can take this task with me at the task location. The second level is coordination, and coordination we plan-merging mechanism, which is somehow an inspiration from traffic. When you do traffic, you merge your car in the traffic. So there are rules for merging. You have rules. If you do not respect rules, you will create problems to the others and to yourself. There are rules, and using these rules and so if all contribute and you have a certain structure in the environment, if you have rules and structure you can do quite efficient plan-merging. And quite efficient, and it can resist even to errors. The robot can replan, to renegotiate their plans, etcetera abandon, do something else and come back. That was possible."
"Rachid Alami","Interviewer","What were some of the competing frameworks or some work by other people on this multi-robot not cooperation, but navigation cooperation at the time?"
"Rachid Alami","Interviewee","Essentially here again we find the same people. We find the same. We had also new collaborators and new friends from at that time also what was important, starting from 1987 even, 1987 and incrementally, there was this European project beginning to be launched and constructed. So we had to find European partners to work with, and it was a challenge to we knew incrementally each other and we found people who were sharing the same challenges with us, etcetera. So we found interesting people to work with, essentially in motion planning. At that time motion planning community was created in Europe and also in essentially in the U.S. and Europe, and there was contribution here. So you find the same people that you have in motion planning here. Again, Latombe. Lozano Perez was there, and others. At that time you had a number of the number of people who worked with Jean-Claude Latombe became then do their own research, like Lydia Kavraki, for example, and others. And in Europe there were also people doing motion planned that lived in France and Grenoble. Again, , and in Netherland, for example, Markova Mars and others. And in Italy also, began to work with our Italian friends also at that time. So that was a second step, I should say. And the idea was to link multi-robot cooperation and motion planning. Why? Because essentially the task was linked to motion task. And then there were also contributions in CMU , working a lot in robots, mono- and multi-robot things. Going from number of names I do not remember. I should have prepared a little. Reid Simmons, for example, in CMU was working on this issue. Also people from MIT like, at that time, Lynne Parker, who is now in Tennessee working on this issue of distribution of tasks between robots using different architectures, who are discussing different architectures. Also people in Japan; for example people working on multi-robot issues Hajime Asama in Japan, for example, at that time. This is for multi-robot aspect. We are still working now on multi-robot, but in other aspects. So it is no more for logistics. it is more for, I should say, military or rescue applications. And also in the future also, we are starting a new project now of assembly in the air with using rovers. Well, using UAVs. "
"Rachid Alami","Interviewer","Is this for what is the ?"
"Rachid Alami","Interviewee","So this is very interesting. it is very interesting. The application is essentially building or maintaining structures that are high in altitude, in mountains or in buildings. Building or maintaining or changing an equipment or repairing an antenna, for example, things like that. And today you use people who climb there, and we would like to do it with flying. Flying assembly. Flying arms and grippers, etcetera."
"Rachid Alami","Interviewer","How did you get interested in personal and service robots?"
"Rachid Alami","Interviewee","Oh, yeah. So that was another step, again, of the I think I came to it because it started because we or myself we have organized and for me it was it was also an idea came in to discussion between us with Georges Giralt and the others, thinking about new challenges for robotics. And in fact we organized I think it was the first it was the first workshop. We called it at that time I should have prepared a little I think it was a workshop that was called the first Workshop on Human-Friendly Robotics. And it was a CNRS NSF workshop. It was organized between co-organized by CNRS, which is my institution, and NSF. And the two people who have organized were John Canny, from Berkeley, and myself. So we organized this first workshop in Toulouse, in LAAS , and it was in 1999. So it was the first workshop on human-friendly robotics, thinking on what does it mean. What does it mean? What could we do about it? So it is there that our adventure started. And incrementally we thought about this number of issues. Then I tried to build starting from this, we had a number of discussions. We have done some kind of thinking and we are mapping and defining challenges. And based on these challenges, we organized a second workshop at that time in California. First in Toulouse, then in California. Again, I think it was linked in Toulouse it was independent. The second one I think it was an IROS project workshop. IROS workshop. And then I applied for a French national project that we called HR+, Human-Robot Plus. The idea is that the human and robot will do plus than human or robot. That was the idea of the HR+ project. "
"Rachid Alami","Interviewer","How did you come to the idea to the question of what is human friendly?"
"Rachid Alami","Interviewee","Well, because of our experience, we know how the robot is stupid, how the robot is difficult. We know what is a robot very well, and we know that there was a difference between our dream and the thing that we have in front of us every day. In fact, sometimes I well, I like to do jokes about this. I say that the robots are far more autonomous than we think because they never do what we want. We just want them to do what we want. We do not want them to be autonomous. We just want them to do what we want no autonomy. They never do."
"Rachid Alami","Interviewer","you have succeeded already. "
"Rachid Alami","Interviewee","Yeah, exactly. And then you think about this, because I say if you give to robot a task and you do not give the robot a deadline, it could take an infinite time to do it. It starts by doing nothing. "
"Rachid Alami","Interviewer","I think positively next time something does not happen."
"Rachid Alami","Interviewee","I am doing what you said because I have infinite deadline, okay? So we came through this so we came to this like this, and then we tried of course when the ideas come, they appear everywhere. You think you have the idea alone and it is everywhere. Then you have of course to go deeper. But the shallow idea, basic shallow idea, goes very fast everywhere. So we can not say we have started human-friendly robots. We think, but I am sure it is not true. I mean, it is something that happens here and there. However, we organized workshop and we sat down and worked together and thought together and produced so it was interesting in the sense that we went deeper than simply this shallow issue. We tried to understand what that mean. So we go to issue of safety, through issues of reliability. If you put human and robot together you have to think about certifying your system. You cannot leave it like this. All these issues, and of course utility. The robot should be useful to do something, etcetera. And then you add something which is complementary, is that this robot is designed to be used by naïve users, not by engineers. So you have to do something. This user will not program in they will not speak in C or in C++ to the robot with a keyboard, even though it does not work. So you have to think about all this issue. And it came really like this. And then we found out incrementally that a number of things that we thought had been almost done have to be revised because you have to take into account the human. For example, motion planning. In motion planning for a number of time, we are doing motion first, we are very happy when you had one solution we found the best. Ugly. Ugly path. it is okay when you see it on paper, less it is still ugly but you accept it when you see it in simulation. When you see it really executing on the real robot, it is awful, because it is a path in the configuration space, not in the space. This is the first thing. This is first, second it is not and then we thought about optimization. Optimization was essentially linked to minimum time. And so people were working about optimizing, which means finding the shortest path in the configuration space. And this is not good, because the shortest space in the configuration space does not provide your directory that is understandable by human or acceptable. If I do this to give you an object, you will not understand. All this, okay?"
"Rachid Alami","Interviewer","I would think you are very good at ?"
"Rachid Alami","Interviewee","Because I am perhaps I am very optimal in some space, but not in . And so we began to think about this, about what are the criteria of a good plan, a plan that would be that first would achieve a task, then would be legible a behavior should be legible , and acceptable. And so I presented this today. My work today is I summarized in one point, in one word. I work in order to make the robot not incongruous. This means that we are trying to think what to do in order to make the robot do the pertinent task at the right moment, in the right place, etcetera. And this is not easy. Not easy. It means that you have to understand what is the task, understand what is your partner, to understand how the partner behaves. If the human really wants the robot to give the object or no, because human change mind, they have urgent thing that happen that make people do something else and all this would be taken into account. Again, you have serious question of safety. Serious. And so then based on this we started to work seriously on different aspects, and this we have done through European projects with partners. We had several projects. One we just finished three years, which was called PHRIENDS. It was essentially focused on physical robot interaction. Now we are starting new project on this issue. The coworker, basically. The coworker, this is a robot that will work you have the assistant, or the robot who will assist the elderly people, etcetera, which is a real challenge, which is I think very interesting, and perhaps useful. This is modest. But at least interesting. And you have the coworker which is also interesting, and perhaps useful. And the coworker is a robot who will work this time with a professional. But even though it is professional, it will not have a keyboard, will not have , etcetera, so the robot has to be flexible and to adapt and to be reactive, to be proactive, to intervene, to be responsive to the human, to be in a way always ready to leave the place the human has priority in doing things, etcetera. And for this you need good perception. You need intelligence. You need physical safety, of course, but all these issue that we and it is also and in fact I think it is also an initial link to the notion of interaction. And I think you can find it. I think you will find it. A number of people, of researchers, who are still doing I am still doing multi-robot cooperation are also interested in this decisional aspect of human-robot interaction. it is the interaction that is important. The interaction. The notion of interaction, which is independent of the task. You have to manage it as an entity, as a concept. In both situations you have between robots and between human and robots, and in the future you will have I am convinced of this you will have teams of robots and humans. The robot will have to cooperate with the other robots and with humans. All this will be mixed together so the two concepts should also merge. The same robot should be able to interact with human, interact with the other robots. It will have these two abilities. And we hope that part of these two interactions are based on the same concepts also. Not all, at least part of it."
"Rachid Alami","Interviewer","Do some people come to mind I mean, Reid Simmons, I guess, is one."
"Rachid Alami","Interviewee","Reid Simmons, again, is one contributor to this. Today, human-robot interaction, you have full community working on different aspects. When you think about Reid Simmons and I agree, it is decisional aspect and a control architecture aspect. Yes, you are right. There are a number of people in CMU working. They have excellent results on multi-robot cooperation, task location, etcetera. They have worked on this a lot. They have a number of results. In Europe also there are different places when we have worked on this, from Zaragoza to other places in France. And yes, we have also contributed we have colleagues for example, I am working a lot with colleagues in TUM, in Munich, Michael Beetz, who is very interested in this issue also of the autonomy and autonomy in collaboration. And this is based I think essentially on the issue of, yes, robot intelligence. it is one of the cognitive robot, somehow. it is the cognitive robot basically, and one of the aspects of cognition that is key for me is interacting with human, working together. it is not because some people think a human-robot interaction, they see it independently of something to do. We are trying to transform it into something that is linked to a task to perform. Human-robot has there is a task to do. There are other person thinking about human-robot interaction for other issues that are also very interesting, which is support or, for example, very interesting work, which I am not doing, which is, for example, using robots to interact with autistic children, etcetera. Very interesting also. it is a different field, but however and this is also interesting because it makes it opens our mind also, because we have to think about human, what models of the human. So more and more in robotics today you have it. You have people not only in robotics, in neuroscience, etcetera who are studying human or using robotics to study human a presentation of Nakamura the other day, which was very interesting for this."
"Rachid Alami","Interviewee","Yeah, for the muscular aspect, etcetera really using robotics to study human, to understand the human. And I am doing the other way, but both are not independent. Working with people who study human and contributing a little to it, to serve the human. We need models. We need to understand the human to serve the human and to work with him, and for this you need models also. And of course this happened independent he mentioned it, for example: if you understand the human, you will recognize a human who is tired, for example, and then the robot will not interact in the same way with a person which is tired and with the person which is not. It will recognize a human that has difficulty to move or not, or a really dynamic guy, etcetera. It will not do the same. And so we are preparing from the other side a robot that, depending on this, will not put the same costs to the task it has to do. If the guy is strong, etcetera, it will not try to assist him, to give an object to him, etcetera. If the person so this could of course intervene. Also it will be far more efficient to share the load if necessary sometimes instead of putting all the load on the robot, etcetera, all these issue."
"Rachid Alami","Interviewer","So this notion of cognitive robotics in Europe people talk about it a lot and there is a whole the COGNIRON project, which you are part of. Were you around and hearing where this notion of cognitive robotics came from?"
"Rachid Alami","Interviewee","The COGNIRON project was a project that we were coordinator in Toulouse. It was a FET program. Well, this is jargon of Europeans. FET is Future Emerging Technology. it is basically projects that you do not have direct applications. They are to do fundamental issues. The COGNIRON project was very interesting because it allowed us to open our mind and to have some time and some resources to think globally about this. And we built this project it was quite interesting because we were able to look at the different parts, the different aspects of the problem from user study, to learning, to dialog, to motion, to control architecture, to decision, etcetera. And we had partners with us on all these aspects, for example people from KTH. Henrich was there at that time, before coming to Atlanta was part of this project. We had people from Germany, Professor Dillman and his team also on this project. We had people from Amsterdam. We had people from in COGNIRON we had from Switzerland, from EPFL, and Aude Billard. And also people from U.K., Kerstin Dautenhahn. And having all these people on board, we were able to have a look at these different issues and incrementally try to build this figure of what would be, this cognitive robot in this field, the companion the companion robot. So I think COGNIRON can and after that, other projects went in this direction. And so yes, there is a community in Europe thinking about these different aspects of human-robot cooperation. In COGNIRON, we had also people from IPA , Stuttgart, working with us, Martin Hegele and the others."
"Rachid Alami","Interviewer","So after COGNIRON, what are some of the challenges that you see in this kind of intelligent robotic-human environment?"
"Rachid Alami","Interviewee","Of course, it has not solved the problem. It just opened, and looked a little in it, but I think in an interesting way. We are moving towards different issues, moving more from this. So I think for us in COGNIRON we put a number of issues linked which we have to understand what is this interaction level, which are essentially doing today. So We will essentially continue to investigate the different aspects. In interdisciplinary also approach. We perform psychology, developmental psychology, sociology also. We are also interested and this will I think open a little more the issue is in the future we think about this robot will be it is not the future; it is today this cognitive robot will not be isolated. It will be in an ambient system. It will have to interact with a number of other robots and other devices that exist cameras, smartphones, tablets, or , and human who might be perhaps equipped with a number of devices. So all these issues should be we are just beginning to look at this issue. But I think we are all of us in this challenge because we are beginning to have robots who have two arms of the humans who can do work with human, and so I think we continue towards that direction. And at the fundamental level, and also we try to find reasonable and acceptable application contexts. I think one of the contexts is elderly people assistance. Even though we do not think they will of course the robot will not replace the nurse or the parents or the children. It will simply give more dignity to these people. They will be able to take objects that are far, to be assisted. And having this, they will not have to wait a long time for a simple thing. Give me this, if they cannot reach. And this happens in home, this happens in institutions. And so there is room for this. Also of course for assisting handicapped people. It is certainly very, very important also. Very, very important for these kind of applications."
"Rachid Alami","Interviewer","I was curious about what kind of mentoring you do with younger researchers in the lab and everything like that. what is your experience doing that?"
"Rachid Alami","Interviewee","My experience I like to work with students and PhDs because basically because it is with them that we build the concrete challenges: let us do this. You are in charge of this. And we are trying to do these two issues. You have kind of a challenge in each one. But also we are adding something, and this is perhaps different from what is done in different places. Because we have also this perhaps stupid ambition to build a complete system. And so we need several persons working together, and we need to build systems that will go beyond one phase, because so often I say it is not able to finish have this issue also. So I like to struggle with this problem of giving challenges to students, to PhDs, essentially. So sometimes it works very well, sometimes it works less, of course. It depends if people it depends on a number of issues. But from time to time we have good success. We find things. We make things more concrete. We find out interesting small problems, for example, we to give just an example, I presented yesterday. We found out that you take one task, and it is huge problem, just the handover problem. Just the handover problem. If you take it completely, you really want to have a generic robot that does handover, you are there for years of working and issues, etcetera. In fact, by doing this, if you want to do it in a generic way, you will also solve other problems. You will also solve other you will solve a number of not only the handover. There are a number of tasks that you have to do in face to face, in approaching, in sharing space, in moving towards the guy. You have to move and to retrieve. You have to wait. You have to interact. You have signals at different levels when you do this, etcetera. And so essentially we played that kind of games with the students, kind of challenges."
"Rachid Alami","Interviewer","If you had advice to give to young people who are interested in robotics, what would it be? How to start."
"Rachid Alami","Interviewee","They have to share the dream, first. Yes. They have to share the dream, really, and also they have to pay attention to not to be too disappointed, because robots are far, far, far from being able really to do things. So somebody's disappointed because they say, Oh, I thought this problem is solved in order to add this. And it is not that case. So they have to share the dream. They have to be quite ambitious and to persist in their direction. And also to be modest. it is because it is difficult. And the last thing, which is I think important, but I think it is true for everything: to think about how things could be done in a generic way, in a way that will be reused, that will you draw lessons you draw lessons from what you are doing . I think when a PhD finishes with a lesson that you draw, you are happy. But they have to share the dream. "
"Rachid Alami","Interviewer","Is there anything else you want to include? These are mostly all our questions, but if there is anything else you wanted to add, please let us know."
"Rachid Alami","Interviewee","No. I was very frank, so . No. No, I do not think so. I do not think I have some very specific issue to say. I really think there is a lot to do in robotics. It is far to being and what is good also it is interesting that we are what is also interesting, I think it is I like robotics because it is a field that allows you to open your minds, to see things from different aspects. So to say this, but when I see my other colleagues in my lab working on other issues which are very different networks or , it is boring . Robotics is not boring. Robot . "
"Rachid Alami","Interviewer","we are going to put that as the first thing . "
"Rachid Alami","Interviewee","what is this? it is a boring thing, or the microelectronics, something like that. Or control. it is small dream. it is not the big dream, you know? You get it?"
"Rachid Alami","Interviewer","Yeah, we get it. "
"Rachid Alami","Interviewee","The clever smart, clever, omnipotent robot is "
"Rachid Alami","Interviewer","Build another human."
"Rachid Alami","Interviewee","Yeah, to play with. "
"Rachid Alami","Interviewer","I just had a quick fact question. That first workshop you said you had, the HR+ or "
"Rachid Alami","Interviewee","No, it was not HR+. HR+ was my project that they built after that. It was in 1999 "
"Rachid Alami","Interviewer","Oh, Human-Friendly Robot."
"Rachid Alami","Interviewee","Yes. Yes."
"Rachid Alami","Interviewer","We can stop this probably. I was just curious who was there."
"Raja Chatila","Interviewer","So, if we can start with your name and where you were born and when."
"Raja Chatila","Interviewee","Okay. So, my name is Raja Chatila. I was born on January 29th, 1952 in Damascus, Syria. And"
"Raja Chatila","Interviewer","And so then, where did you go to school? How did you kind of get to college and decide where to go for college?"
"Raja Chatila","Interviewee","Yes. So, I went to school in Damascus. Actually I went to a school which was French and Arabic school; it was a school run by a French organization close to the French government, actually, in Syria, because Syria during the period between the World War I and II was under French mandate; so there was some relationship with France and, cultural relationships but, of course, at the time I was born Syria was independent. So, I went to this school. I, basically it was a school where you go to primary school and then through high school; it was the same place. And I was always attracted by science and math and so on, so my math professor, actually, when I was 15, 16, who was a French guy, since I was one of the best students in the school, he offered me to obtain a grant from the French government to go for higher studies in France. And well, of course, I accepted because that was a unique chance and therefore I left Syria when I was 17 after graduating from high school to go for higher studies. So, in France, of course, the system is always more complex than is elsewhere. We have a system which is called engineering schools or Grandes Ecoles, a higher which is living side-by-side with the universities; it is not within the universities. And usually, I mean, the tradition in France is that people who are very good in mathematics and physics and so on, preferably go to those schools. But entering those schools requires first to go to a special preparatory school during two years for, it is called higher mathematics and special mathematics, and then you have a competition. Actually you take an exam, it is a competition, and according to your marks or the school to which you applied and if you succeeded you go to this during school; so, this is what I have done. It was not the classical university, however, at the same time, I also took some math courses at the University of Paris. It was in Paris; that school was called St. Louis School. it is in the Latin Quarter in Paris. Then I went to an engineering school in the city of Toulouse in the southwest of France; it is the National School of Civil Aviation. So there I graduated three years later as an engineer in electronics specializing, of course, in electronics related to aviation more than general electronics but it was a general diploma anyway in electronics. After that, I made an additional diploma, a kind of additional Master's Degree because the Engineering School is three years after the first two years in control science and my dream was always to do science research and not to go to industry That is I wanted to contribute to science. And initially my hobby or my attraction was to astronomy and astrophysics although I went to an engineering school. I mean, it is not necessary that you do engineering. If you go to those engineering schools in France you can do anything afterwards, even finance, for example, they are very, I would say, you have a general education and you can do almost anything. Anyway, so after that I went to I applied for a grant at a research lab nearby in Toulouse for doing a Ph.D. in space science and astrophysics and that first you have also an additional Master's Degree to pass so this is where I started and then something happened. Actually my advisor passed away, died, and the lab next door was LAAS, Laboratory for Systems Analysis and Architecture which had a different name at that time; it was more close to control science and I had met also someone who is George Giralt and therefore I decided to go and do my thesis on robotics in that lab. So why robotics? During my studies in the first Master's in control science I had also a training and a project on machine learning so I had already some knowledge about robotics and some interest about the mystery of studying artificial intelligence and so on. So it was something that attracted me also but it was not as strong as my dream when I was young about astronomy and astrophysics. However, fate decided that I do this anyway and so I started the thesis with George and that was in 1977. So, George Giralt was actually he is an exceptional person, he was just back from the United States after a sabbatical at Berkeley and there he was completely captivated by robotics research that was going on in the Bay Area and specifically about studying mobile robots; mobile robots as opposed to fixed robots which are arms and, at that time, the main study and the main application of robotics arms was manufacturing. Mobile robots, on the other side was a different issue; it was about making a machine move in its environment, discover its environment, et cetera, which was a really big question. No one really knew how to do that. So he wanted to start this project at LAAS and so it was a good coincidence because he did not have a student to work on this project so he hired me to do that. And hence, I was, it appears, I mean, a person doing research on science, not the scientific but how scientific research history, told me that according to his own research I am the first to have got a Ph degree on mobile robotics in France and I got my Ph degree in 1981. So, that project was called, in French, HILARE, which is the acronym of the robot on which I worked and basically the issue, the study, was about robot navigation. How to make a robot, a machine, a physical machine move in its environment avoiding obstacles, discovering the obstacles which it did not know about in the beginning, taking decisions to avoid them and going to a given location. So that was my thesis subject which was called Robot Navigation Space Modeling and Decisional Processes; and of course, this, today, is quite common. I mean, you see mobile robots moving all over the place but at that time no one knew how to do that. So it was quite a challenge and one of the I am happy to be one of the first to have started on this."
"Raja Chatila","Interviewer","What were some of the problems you were working on, the part of making the robot move around?"
"Raja Chatila","Interviewee","Well, there were, I would say, different kinds of problems and it is important to say that since the beginning I had to consider them all; and this is very important in robotics to have this system approach, system view, because everything is interlinked. So, to start with it was a real robot; it was not a simulation. And, by the way, at that time, computer simulation was something not as easy today. I mean, I am speaking of times where microprocessors were just starting to be used. We had mainframe computers. So, it is not and we did not have computers with an operating system that enabled you to have a good user interface, a mouse; all this did not exist, okay. So, to get back to the challenges, to the issues that I was working on, it was the first challenge, the first issue is that it was a real robot that I had to make move; it was not a point on a screen, which means you have all the difficulties of real experimentation and all the hassles of real experimentations and the problems that come from that. The fact that the computing power was not so important as today so we had a system which was with very low computing power on the robot itself; it was the early Intel 8080 microprocessor and so since it was not possible to do all the computation on the robot it was radio linked through a very, very slow radio link, 9,600 baud; That is very slow. And to a small mainframe computer which, itself was not sufficient neither, which was linked to a computer in a national computing center, which was in Paris. So, I was in a lab in Toulouse and this big mainframe computer, which was an IBM 360, was shared with other people, of course, doing something else. So you imagine that making experiments was not that easy and something that you decide on the spot. So That is from a practical point of view, actually. And also when I was building the robot, I was not by myself; there were other people working and some engineers and researchers to physically build that robot and integrate it. And so, also there was the sensors that we were going to put on that robot. At those early times, we were investigating the use of ultrasonic sensors, sonars, and those were not just manufactured like that. You can not buy them; you have to make them yourself. So we made the sensors. And we wanted to have vision on the robot. So vision is a very, at that time, it was, of course, a very important issue and an open problem and another Ph.D. student came in to the lab also afterwards, maybe a year after me, to study vision on the robot. In the meanwhile, because we are naïve and optimistic, we said well, maybe we will leave this guy, do his research on purely on vision and he will be ready in three years and then vision will be solved. But in the meanwhile we need to do experiments with other sensors so we also bought one of the first laser rangefinders, which of course, was not absolutely used for robotics. It was used for topography, things like that. It was just a point laser like the laser pointers you have. So we mounted it a motor to scan the environment very slowly at that time also. So, I mean, the experimentation was also to build the robot and the experimental conditions were not, of course, as easy as today. So That is first set of situation where you had to do the physical mounting of the robot. Again, I was not alone; that was one issue, the computer infrastructure, the program for communication and so on. And then there was the scientific problem that I was addressing which was robot navigation. So, question: How do you represent space, objects in a robot environment? And it was important to understand that for making the robot move, it was mostly important to present the free space so that the structure, the structure that the robot was going to use to compute its motion was the free space structure, which had to be derived, computed from its perception of the obstacle layout. So, how to structure free space and it was one of the issues to understand that we needed geometrical representations and we needed topological representations which express the way space portions are connected. So, one of my contributions was to find a way to decompose free space into regions, geometrical regions, and build a connectivity graph of those regions. And there was, already at that time, I said we need also a third layer of presentation which was semantics, which was not just the shape of the areas, not just the way they are connected, but also something that designated them in terms of usefulness or dangerousness and so on or any other label, but that was not so much used at that time. Basically we focused on geometry and topology. And then the second question is okay, once you have this free space presentation and structure, how to move, how to compute the motions of the robot in this space? And this is a motion planning problem which was not formulated at that time. So, one of the problems was to express how you move an object in a spatial representation and other peoples were working on that, like Tomas Lozano-Perez at MIT, for example, which has written a very seminal paper in 1981; actually we were working on the same issues at the same time but I had dreaded it before that and I had also my own approach and representation of robot and so the issue was to reduce the complexity of this motion planning by correct representations of space and the robot. So that was the second issue. And, of course, it meant not just to devise theoretical models but also to implement this on the computer as a computer program and to make this run, of course, debugging the program and so on and so on with the tools that we had at that time and then make the real experiments and make the robot move. So That is what it was about mostly."
"Raja Chatila","Interviewer","What were some of the specifics of your approach compared to the approach other people were taking at the time?"
"Raja Chatila","Interviewee","Well, I think one important point was I wanted to represent space as much as possible close to reality. So, for example, today it is well known, you can have different kinds of representations, you can have a grid, a regular grid, superimposed on the space and basically the space is digitized into this grid, which, of course, makes you make some approximations of the shape of obstacles and so on. And if you want to have good approximations, reduce this cretization induced by this grid you have to have a very fine grid which means a grid that has small cells which means a high complexity of computation which was completely to avoid at that time. So, my approach was to say let us try to represent space in a way that is, as much as possible, without deforming the shape. So, I came up with a model which relied on the geometry of objects and acquired by sensing and therefore free space was represented actually by polygons and I came up with an algorithm for decomposing free space into polygons; it was 2D. Those polygons represented the exact free space shape and it was not a grid; it was an actual representation of free space and they were polygons so that those polygons were convex, and That is one other issue, so that in each cell, in each convex cell, the robot can move in a straight line from one frontier to the other and so on, from one cell to the other. The polygonal shape was, in a way, an approximation, if you had, for example, some rounded parts of the environment but mostly at that time we were working indoors so you had walls, objects that are always, more or less, polygonal in shape. So it was not so bad in terms of approximation. However, the issue was to represent space as much as possible close to reality. So that was one point in the spatial representation. And the other point was right to the motion planning issue itself. So, there were several approaches already known about planning motions and the idea of representing the environment using those polygons was to extract a graph representation, which is the topological representation, and then to compute the motion of the robot using this graph; so, abstracting geometry into the topological structure and then doing a graph search. And there were some techniques for doing the graph search like the A-star algorithm that was around since 1972 and the graph that I wrote, in a way, was something close to two techniques that were around. One is called the visibility graph which is a graph that represents the shortest path in free space. And the other, it is called Voronoi graph, which is a graph that represents, I would say, middle points, middle ways between obstacles so that the robot is not going to hit the obstacles. So, my representation was closer to the visibility graph but I had to take into account, of course, that the robot had a shape which made it, of course, not go into the I mean, taking on the shape to prevent it to go into the obstacles. So, the configuration space, as expressed by Tomas at that time, was the idea which was very important was to reduce robot shape into a point but making the obstacles larger by half of the robot. So, I did not take this orientation. I made the computation in the geometrical space and not in the configuration space; so that was another difference."
"Raja Chatila","Interviewer","And what were some of the studies that you did; experiments that you did with this robot in navigation?"
"Raja Chatila","Interviewee","So, of course, it was not enough just to come up with those methods, they had to work, actually, on the machine, right? So, I made, and with colleagues at that time, so our experiments were making the robot move from one place to another. We set up an experimental environment with wooden obstacles and so on that we made so that we can give them different shapes and that were light enough so that if the robot collided it was not broken. But the robot was really in aluminum and steel and it was really difficult to break the robot. And, indeed, I remember on one experiment there was a colleague working on a table and the robot well, we made a mistake and so the robot, at full speed, went and collided with the table on which that colleague was working and the robot was so strong that it moved the table and that guy was somewhat afraid. Anyway, so we had to make real experiments and real experiments mean a lot of failures and what was interesting is to study the causes of failures. Because when you have a failure in this context what you do, you get back to your programs. You make some debugging and so on because maybe the failure is due to a bad computation or something and then you get back to experimentation and you find out that some failures do not disappear; so what is happening there? You could go around those failures by approximating things, for example, because the robot was executing its path and after moving a few meters it started to go into the obstacles, to hit the obstacles instead of avoiding them. So you could say well, let us make some approximation and artificially augment the size of the robot. But you could also say hey, what is going on? Why is it always doing this systematically? So, asking this question is, I think, a sense of using a scientific method which means you had a kind of theory, your program, your system, your models that should have enabled the robot to go from one point to the other over the obstacles but it was not doing that. So, which means your something was wrong. Something was not taken into account in the model. So, it was a kind of discovery, but that was after my thesis so I am kind of jumping in time but I will get back to what I did after the thesis. So it was that question that led to the discovery of a phenomenon which was that there are in the robot phenomenon, simple, I mean, today, when you think of it, it is quite simple, but, of course, when the robot moves, well, it is a machine moving; it has wheels; it is moving on floor. Therefore, there is some slippage. When we compute the path, when the robot computes the path that it is going to follow, there are some parameters to take into account like the wheel diameter, the distance between the wheels and so on; all those parameters are uncertain but, at that time, in the competition, they were considered as being exact. We did not consider that moving was also generating uncertainties on robot position. So we had to think over and say well, there are problems that you cannot go around with, that you have to really cope with; it is the fact that the robot is generating uncertainties while it moves. And, by the way, how did we get obstacle positions? We got them by perceptions by using this laser rangefinder. But the laser rangefinder provides measurements which means they are also uncertain. We considered that those measurements were exact, in the beginning. So, necessarily, we have to take into account, to consider that we have uncertainties on robot motion, we have uncertainties on perception and this should be treated as a problem, okay; that was in 1984. So, in the meanwhile, after I have got my Ph.D. in which those issues were not considered, so we had made successful experiments and so on but in seeing those issues without really considering them as important. But then after my Ph.D. I went to Stanford University for a postdoc; so I stayed there for a year with Tom Binford at Stanford at Stanford AI lab and working on a project Tom Binford wanted also, at that time, to have a mobile robot at Stanford University. So there was a precursor a few years ago, earlier, with Hans Moravec who had worked on stereo vision at Stanford University and, at that time, Hans has moved to Carnegie Mellon and Tom Binford wanted to start a project with a new robot in a project with the company is now Adept but at that time it was Unimation. And so Brian Carlisle was heading, at that time, the company and they built a robot which was omni directional; it was able to move in any direction. It has special wheels, called the Swedish wheels that enable it to do that. So, basically, during my postdoc, my job was to procure this robot from Unimation and to set it up and to implement my thesis results on it. So That is what I started to do, what I have done, during my postdoc at Stanford University. And then I came back to France in 1983 and I had a position at CNRS, which is the French National Center for Scientific Research, as a researcher and I continued my work as a researcher at LAAS, the same lab where I had graduated with in the group that George Giralt was heading. "
"Raja Chatila","Interviewer","When did you get to Stanford?"
"Raja Chatila","Interviewee","So, I was in Stanford, basically, in the year 1982"
"Raja Chatila","Interviewer","Through 1984."
"Raja Chatila","Interviewee","No, to 1983. "
"Raja Chatila","Interviewer","Oh it was one year, okay."
"Raja Chatila","Interviewee","Yes."
"Raja Chatila","Interviewer","And who was there at the time? Who do you meet or work with"
"Raja Chatila","Interviewee","So, basically, the professor, the leading professor was Tom Binford but there was also there Oussama Khatib, so I will back to Oussama because we had met before. Oussama Khatib, there was Harlan Baker, for example, were in this group at there was John Craig; there was Ken Salisbury; so very nice people and very competent people; that was a great experience for me to do this postdoc stay at Stanford and the whole scientific environment of the university, of course, unique. You meet people like also Bernie Roth; so I was not working with him but, of course, Bernie is also a unique character in the robotics community and this is where I met him first. And the environment around Stanford University and the Bay Area, there was SRI. At SRI I have met people like Nils Nilsson. So, Nils Nilsson was, for me, a kind of a reference because was the father of Shakey and Shakey, the first paper on a mobile robot, was published in 1969 and was a reference for me during my thesis. I mean, that was really a marvelous project because first it was really a pioneering project and it, since the beginning, they had the insight and the understanding to consider all issues from higher planning decision making to execution, system architecture and so on. I will get back to system architecture as well. But so that was really a reference because the seminal paper really identified all the issues and solved them in a way, of course, that was enabled by the technology of that time. But many, many important ideas were invented during Shakey: strips , the planner, A-star, the use of visibility graphs for guiding motion. So it was really a great project. So, also meeting these people, you know, it is like it was really wonderful. And also I met people at Berkeley. There had been a mobile robot project also at Berkeley which inspired George but after that they, Berkeley did not really develop that so people at Berkeley were more AI and control people. And Lot Freezad was at Berkeley also at that time. So, names."
"Raja Chatila","Interviewer","And then you went back to CNRS as a researcher?"
"Raja Chatila","Interviewee","That is right. So that was 1983. So then I, in a way, I continued to work on the issue of robot navigation and really considering those problems that I did not completely address during my thesis, now, those issues about uncertainties. And another issue was about going further in representing the environment. As I said, there was the geometry, the topology, but semantics; semantics in terms of this is a room, this is a corridor, this is a door and this is how to extract those information, how to discover the structure of the environment in terms of its semantics of its structure with those labels from the basic geometrical structure. So, as I said, I had a basic geometric structure which was the cell and the graph and in work with Jean-Paul Lamont, and John-Paul Lamont had joined the lab at that time, and his thesis was to use those representations to try to organize the graph and from the graph extract the semantic information; so he was working on that, that was his thesis, and I was working with him also on that; so, several topics. And then, as I said, there was this issue of uncertainties which was important and there was also another issue about architecture. So, I will get back to uncertainties but architecture is basically the question of the organization of the robot system. Since we have programs doing perception, programs doing space modeling, programs doing motion planning, programs doing motion execution; all those programs had to communicate with each other in a timely fashion so that when we issue the command to the robot to go someplace it actually does all those computation and goes there. And we wanted to add also something which is beyond just using a plan to move; it is also detecting new obstacles like people moving and avoiding them and continuing to reach the final destination. So there was also an issue about using obstacle avoidance algorithm that we came up with and there were other work on this issue also, of course, by other people and so to take into account also realtime situations like detecting obstacles, avoiding them and so on. So this made us think about how to organize robot control system so that it can cope with those situation of being at the same time able to plan, execute motion and, at the same time, to take into account unpredicted events, realtime constraints and do that. So, and this control issue was also not so much addressed at that time and was one of the directions that I was working on. There was also another colleague working on that as part of his thesis but I was very much in this; so, different directions. "
"Raja Chatila","Interviewer","Who was the colleague?"
"Raja Chatila","Interviewee","His name is Mark Vissett ; he became a research engineer at LAAS afterwards. So, those different directions were actually investigated at the same time and to get back to the issue of uncertainties, when we considered that it was a problem that we should really address and cope with, then we started to do some theoretically modeling of that and we understood some thing which was really tricky; it is that we needed to build a map of the environment, that was what the robot was doing to move and we needed, at the same time, to build this map incrementally as the robot moves in its environment. To be able to build this map incrementally, we needed to put together different views. And how do you put together those different views? You need to anchor them in some location, which was the robot observation location, and to connect those different views. Connecting those different views was using different robot positions but different robot positions were themselves, uncertain. And the way the robot localizes itself, it is by using its own motion; it is autometry, measuring displacement; and this, as I said, generates uncertainties. So, the only way for the robot to really localize itself and correct those uncertainties related to its motion was by observing its environment, okay. But that means that it was correcting its position using the map that it was building. And, as I said, to build this map it needed the different positions to put the map pieces, the different views, together; so, mapping, putting those views together, and localization, which is correcting robot position using the map itself, were two problems that were linked. It was not formulated this way in 1984-1985; it was more formulated as how to map the environment in the most exact way, taking into account uncertainties, but by asking the question how to map the environment in the most exact way considering those uncertainties, you discover that you had a chicken and egg problem with correcting robot position using the environment and using robot position to build the map of the environment. This is how SLAM came up. As I said, at that time, it was not called SLAM and one of the first papers about SLAM, again, with a different name and it was more space modeling, uncertain space modeling and so on, was a paper I had written with John-Paul Lamont in 1985. We had done this research in 1984 already but it was presented at Ecoles in 1985 in St. Louis and that was one of the first paper actually dealing with SLAM without using the word SLAM. I am getting into many things because there are a lot of connections. I wanted to say something also; when I was in the United States, actually on my way to Stanford I stopped by Boston and MIT and this is where I met people like Tomas Lozano-Perez, whom I knew before because he came also to Toulouse before that, so I met him for the first time in Boston but we met before but it was also very important for me to see him again, and Rodney Brooks. Rodney Brooks, who has just finished, just finished his thesis at Stanford, moved from Stanford. And at that time he was at MIT. I think in the meanwhile he went to for some period but at that time he was at MIT. And so, with Rod Brooks, it was, in my view at least, a very, how would I say it, world contact. I mean, I felt really as like I have met a friend. So Rod is someone I cherish very much; he is really also an exceptional I suppose you had an interview with him or you are going to have one? "
"Raja Chatila","Interviewer","we are going to."
"Raja Chatila","Interviewee","So, he is an exceptional person. But at that time he was working on also similar issues; motion I am assuming about 1982 on motion plan applying actually his thesis work, which was about using generalized cylinders for object recognition plans basically, on motion planning using. So we went into some discussions and I have met Rod many, many times afterwards, of course, and the interesting thing that if he was doing work in similar things at the same time, so he also, in the 1984-1985 was working on uncertainties and he wrote a paper also on this issue of modeling space using uncertainty taking on uncertainties. So it was very interesting and Rod came to Toulouse also. At that time we had a conference and Rod, afterwards, worked also on robot control architecture and he came up with the well known subsumption architecture. At the same time, I was working on a different approach, which was not subsumption because I did not believe in that, and for robot architecture based on sort of layers including planning and realtime control and so on. But he put planning away. So, yeah, that was I mean, those years, 1983, 1984, 1985, 1986 were very rich years where several people were working in different directions with in a way, I am going to make the comparison but it is not, of course, it is just a comparison, on those times, robotics research in this area, I mean mobile robots and so on, made us look to different problems; so, each individual working in mobile robotics. So taking example of Rodney Brooks, myself, other people was interesting moving to motion planning and to space representations and to robot architecture, how to organize the system and so on. Nowadays, people are much more specialized. You have the SLAM guy. You have the motion planning guy. You have the uncertainty, processing guy and so on. So, the comparison is with the Renaissance as compared to today's scientists. You know, of course, science has advanced very much and it is difficult to be competent in all domains but when it started people were competent in all domains. And so, I think, this culture of having a systems view and looking to all aspects is very important to understand that everything is connected. You cannot solve a perception problem on a robot without considering that this perception is not made by just for itself; it is made to be used; it is made for motion, for action. So there is a connection between perception and action and this connection has to be at the core of the way you process the sensor data. It put constraints on sensory data and the action is the connection between the robot and its environment. So you have to also take into account at the same time the continuum perception, action, and the interaction with the environment and, of course, this puts constraints on the decision making processes which have to be able to cope with realtime constraints, unexpected events but, at the same time, enable the robot to take decisions at the long term, to anticipate and so on. So, if you do not have this, you miss the global picture and therefore, the solutions that you are going to come up with will not be the right ones; they will not give you the possibility, really, to have an integrated systems working together. "
"Raja Chatila","Interviewer","At some point you also became interested in learning, right? "
"Raja Chatila","Interviewee","Yes."
"Raja Chatila","Interviewer","More deeply in learning."
"Raja Chatila","Interviewee","Well, yes, actually this is interesting because I started with a project before my thesis; it was during, as I said, my Master's in control. I had a project in machine learning; it was not robot learning, it was on machine learning, so I have worked somewhat on that. And then this was just a kind of problem, still open problem that I did not address for some time. Then it was addressed again when I worked with John-Paul Lamont on his thesis about learning environment structures, but that was a different kind of learning. It was actually structuring the data that the robot had already or the representations that it had. It was more a way of extracting information from data structures but I did not get back to learning in terms of so That is where it was in the 1980s also. I did not get back to learning, as such, until many years later in, actually in the years 2002 with different work which was more related to trying to learn almost from scratch the sensory, motor representations that are related to representing objects and actions. So the idea so we are jumping a long period here. We are jumping a long period. In those years, I had a student who was very, very excited about that; William Pakee , actually he is in San Francisco now; he has a small company in San Francisco; so he was very much excited about the issue of learning representations from scratch. What does this mean? It means that the robot initially has very, very little knowledge about everything; about its environment, about itself; it has just simple processings. For example, in an image, it would just extract gradients and edges, spatial directions, and so on; very simple stuff. In terms of its actions, it only knows about controlling for example, if it is a wheeled mobile robot, controlling each wheel separately; just making small motions. Consider that if it was an arm, it has an arm, it was just moving fingers like that without controlling the whole action. So, the challenge was how to I mean, consider that a baby just born just knows how to move his limbs or her limbs and does not know and just perceive vaguely some shapes but no connection between those; so the idea was how to make those connections. So that was another issue that I worked on with William and another student who came up afterwards, Nicole on developing a system that would learn sensory motor representation. As I said, the representations of space, objects and so on are going to be linked to what the robot is able to do with them so that it develops its representations at the same time that it develops its own actions. It learns to control its motion by and through developing more sophisticated representations of its space and this is guided by a learning process with some motivation, some values, some value functions that start with very simple values and also themselves become more complex as the robot knows to do more complex things. "
"Raja Chatila","Interviewer","And you mentioned kind of a human baby is something that learns in this fashion in testing the world; did you have any theories of that sort in mind while you were coming up with this robotic learning mechanism?"
"Raja Chatila","Interviewee","Yes, of course, I mean, again, we are speaking about the years 2002, 2005 and so on and, in the meanwhile, there has been a wealth of work in robotics inspired by biological systems, neuroscience, and so on and neuroscience researchers were coming up also with a lot of theories about how we develop our abilities, how we learn and so on. So there was, and there is today, a very rich interaction between those areas; neuroscience and robotics. So there is inspiration, of course, because the only working system that we know about is biological, human beings or animals, but my view is that it does not necessarily have to be that way. it is not, and in a way, you can say "
"Raja Chatila","Interviewee","and so on, an instance, in biological systems, s, but it is not necessarily the only instance of achieving intelligent systems or systems able to interact with their environments to learn and so on. If there is a general theory or theories of intelligence and learning and so on, then this general theory could be applied to different instantiations, different ways of doing it. So, basically, we do it by using our neural net, which is our brain. We do it by having a mechanism for learning which is encoded into the way the neurons interact together and integrate information and, of course, the studies from neuroscience and the mathematical models of neurons explained to us how this works. But, at the same time, when we do artificial neuron nets, for example, this is implemented on computers, on machines, on a general model for computation. So, is the brain amenable to a touring machine? That is, of course, an open question and if yes, it means that there is, indeed, a more general model of computation that you could use and not necessarily using just neural systems to learn. You have also other theories for learning, other methods for learning, which are based on mathematical models. For example, you take reinforcement learning, which is based on processes at the end, if you wish, because they are using built on equation and not integrating neural signals. So, I think, I believe, I mean, this is my view, we can achieve artificial intelligence with robots not necessarily imitating biological systems but we have to really seek this general theory of intelligence that can be implemented in different ways. Natural intelligence evolved with a lot of constraints that have been taken into account by evolution and we can probably build systems that have maybe a different approach but, again, which are as intelligent as natural systems. So that was my view. Hence I am not advocating I did not do it with my students either, to imitate exactly what is happening with the theories that come from neural science. There were a source of inspiration and proof of concept, in a way, that you can do that but you do not need to really implement it the way it is done in nature. Although most that, at a given moment in time, we have only models of what is happening in the brain, approximate models, false models, controversial models proposed by neural and so on. So, of course we could implement those models to help neuroscientists to maybe prove that this model is working and this model is not working, computationally speaking, but it does not make sense to have a kind of religion which is the only way to go is to make it nature. I do not believe that. There are many ways to go and nature is one of them, a great one, a source of inspiration and a proof of concept again but I think we have to seek the more general theory anyway."
"Raja Chatila","Interviewer","And I think one of the things that I skipped over was your Eden project. "
"Raja Chatila","Interviewee","Oh yes. Thank you, I wanted to"
"Raja Chatila","Interviewee","Yes, so the Eden project. Actually, in the meanwhile, as I said, I worked on this issue of uncertainties in 1985 but then came several projects that, more or less, oriented my research. So, one issue, one problem, was related to, for example, using mobile robots in warehouses; it was funded by IBM France. So we built a small model robot, smaller then the initial one, and worked on that for doing some indoors navigation in warehouses and automated docking of the robot and so on based on the research I have done before and developing also control architecture. So each time we had projects, they were a funded project, they were addressed but at the same time they served as a basis or as a means to develop more profound or more general scientific questions, not just do the project as an engineering project but as a scientific project. So I had students working on that, one of my students, Fabrice Norace was working on this issue and at the same time working on the issue of architecture because we had to cope with that. So, then came the time, in the mid-1980s of European projects; that was a great thing because the structure that each European nation was doing research and we met as scientists, as colleagues, in international conferences. We almost never worked together in Europe and the European projects were those projects funded by Europe, by the European Union; at that time it was not the European Union, it was the Common Market or EEC, European community, with the objective of making different European nations working together on joint projects. And there was this project called SKIDS with different European participants. There was Germany, France, United Kingdom, Greece, and the problem was about fusing sensory data; having different sensors, cameras, fixed or mobile, mobile robots; observing a situation and trying to understand the situation by fusing all these datas. At that time, our partner in the United Kingdom was the University of Oxford, Mike Brady, who is another exceptional character, and he had someone working with him, and that guy was Hugh Durrant-Whyte. So this time of Hugh had actually had his thesis in the United States with Rozeena Bakshi at U Penn. And I met Hugh the first time at Rozeena's. She was giving a party in 1985 when I came for this conference at St. Louis with the paper on mobile robot on coping with uncertainties for modeling and Hugh had read my paper and during the party he discussed with me about it and he pointed out that there was a mistake at some point; he was right, but it was not important but whatever, so and this is where I met Hugh and he was also someone I appreciate very much, a real friend. So, we worked together with Mike Brady's group and Hugh, specifically, on this project and this project addressed the issue of fusing sensory data which was exactly the problem that I started to address with the processing of uncertainties and so on but in a different context; but that was also a very exciting period. I think the project started in 1986 for four years and so I met Hugh different times in that period. And also another project came up at that time; it was a European project as well, a different kind of European project called Autonomous Mobile Robots, AMR, and here, for the first time, the issue was to study outdoors, robots; robots for intervention outdoors. So, and there was some industry involved in this project. French industry, for example, Matra was involved and I am going through projects in time very quickly"
"Raja Chatila","Interviewer","So we went to AMR"
"Raja Chatila","Interviewee","Yes, and in 19 so it is working?"
"Raja Chatila","Interviewer","Yes."
"Raja Chatila","Interviewee","And in 1989, if I remember, there was big excitement about planetary exploration, Mars, and the French National Space Center, CNES, which is our NASA, asked us to come up with a project for Mars exploration. So what they did was a very interesting thing. They made a kind of national project and they asked different research labs to come together to study all the aspects related to sending a model robot on Mars. I am speaking about the robotic side of it, of course. And George Giralt was the coordinator of this project; so he was, again, very instrumental in making things well coordinated and advancing things. So we had many partners from France working on different aspects and we had the responsibility, basically, in my lab at LAAS of navigation over rough terrain and the other aspect was about control architecture and general planning while other worked on locomotion, wheels or other systems; tracks; others worked on divisions specifically; others worked on communication and on the interaction with the ground station and so on. So, at that time also, we studied how to have a kind remo a kind of theater operation but we called it theater robotics which means the system has the remote robot, because of the time necessary for communication, has to be autonomous enough to do its tasks and to not put itself in danger taking into account that you cannot just operate it with like 15 or 20 minutes delay between Earth and Mars. So, we also developed architectures for having these disconnected systems where you had a planning system on Earth and a supervisory and execution system on Mars to achieve this capacity because, of course, sending a robot to Mars means robots that do not have much computing power; so this is why the planning was on Earth. I mean, task planning and we wanted to have the motion planning and navigation issues on board the robot. So, starting in 1989, we had this project and what we did, what I did, is that to organize internally in my lab using for selling all this with the external partners, I have started a project called Eden. We had, now I am saying about 1992-1993, there was an event in that period which was the collapse of the Soviet Union and the opening, actually, of the Soviet Union of Russia to the western world and actually the Russians were very much advanced in developing robots and structures, I mean machines, able to move on harsh terrain. And one of the robots that they developed was used actually in Chernobyl in 1986 to remove debris and rubble. And just after the collapse of the Soviet Union there was some French industry, I am speaking about Matra, , had bought, from Russia, one model of those robots and this robot was called Adam."
"Raja Chatila","Interviewer","Adam."
"Raja Chatila","Interviewee","And hence the Eden Project, of course, had to use this robot for testing our work on mobile robot navigation in natural terrain. So Eden means actually this; it is Experimental Displacement in Natural Environment, in French, and the robot was Adam that we used on that. And so, that was the early 1990s, 1993 and so on that we really developed a full working system with novel techniques, novel algorithms, novel approaches for perceiving and modeling natural terrain and planning motion on natural terrain taking into account the fact that on natural terrain you have slippage; you have stability problems; you have to actually cope with different kinds of situations. You have sometimes flat terrain, sometimes slopes, sometimes very uneven terrain and terrain; all this has to be modeled taking into account devising specific algorithm for navigation, in this case. So that was a great adventure of coping with a novel issue, and very exciting one, because the purpose was to go to Mars. And, remember, I was my initial excitement about astronomy and so on, so it was a dream come true to work on that. And so, I think that was really successful because we came up with really seminal results on that and, of course, others were working on that in the United States mainly at JPL, at CMU and we had many exchanges and meetings and discussions in international conferences and so on with the people at CMU, people at JPL. It was not a joint project; everyone was working for himself but, of course, scientists meeting, that was very exciting. Unfortunately, in a way, in 1994-1995, the French decided to stop this project because the European Space Agency, at that time, put the emphasis on Earth observation and not on planetary exploration. And so, the money went to developing first a European shuttle, which was called Hermes, which never was really developed and then to programs on Earth observation, which finally ended up in the International Space Station and so on instead of planetary exploration; and the United States, a project of Mars exploration has continued; in the former Soviet Union, also, and I will get back to that in a second; and finally we had Sojourner on Mars in 1997, 1996. So that was, I think, a great thing. In the meanwhile, as I said, the Russians were also continuing and another robot was bought from Russia by another French company called Alcatel, at that time; it was the Matshokhod model, which has conical wheels and which has an articulated body; a very agile robot, and we had it at the lab. We worked with that robot; it was called Lama because it was able to really move anywhere. And on that robot we had also it was part of the Eden experiment and we were able to do a lot of interesting things on, again, agile motion planning on uneven terrain and coping with sandy or gravel dunes and so on. And another model was bought also and was used on an experimental terrain at the Space Agency in Toulouse, the French Space Agency in Toulouse, and that one was called Eve. So we had Adam and Eve at the same time. Yes, so those were very exciting years and then kind of disappointing because we never went to Mars but we were ready. We had everything running. It was not space ready but in terms of the results, the systems, we were really ready; so, yes. "
"Raja Chatila","Interviewer","Who were some of the people who worked with you guys?"
"Raja Chatila","Interviewee","So, in the Eden project, and more generally on the project of the Mars exploration, at that time I had a student who then became a researcher at LAAS, Simon Lacroix, who started working also on SKIDS, by the way, on the SKIDS project I mentioned. Well, as I said, George Giralt was the coordinator of the project. Also Rashid al-Ami was working on that; he was more working on the issues related to planning and control architecture and I worked a lot with Rashid al-Ami on those issues afterwards at that time and afterwards. In the late 1980s, early 1990s We had developed control architecture general enough for mobile robotics which was used in all our mobile robots and that was also an important work in the area and also another person, Nick Sameo who was the motion planning guy I would say on even terrain he came up with very clever algorithm for taking into account the terrain configuration and he has made very, very good work on that because we were able to experiment early on even terrain. Now Nick is working on other topics in motion planning as well. it is on medical motion planning studying how molecules form, how we can combine proteins for example. This is also one of the great applications of robotics motion planning into biology he is working on."
"Raja Chatila","Interviewer","I think That is going to have to change this thing and think about if we have missed anything and then I am going to ask you one last question about advice for young people."
"Raja Chatila","Interviewee","Okay."
"Raja Chatila","Interviewee","Too long?"
"Raja Chatila","Interviewer","No, no, no. This is normal."
"Raja Chatila","Interviewer","We do not start always with a new tape."
"Raja Chatila","Interviewer","it is amazing how easily immediately it becomes deserted because I went into the room that was the conference room and maybe an hour after and it was all disassembled."
"Raja Chatila","Interviewee","Yes, moving to something else."
"Raja Chatila","Interviewee","Anyway "
"Raja Chatila","Interviewee","It will not be complete because of course a lot of things will not be mentioned, but That is fine."
"Raja Chatila","Interviewer","I think only when you start explaining what happened do you realize how many things actually happened."
"Raja Chatila","Interviewee","Yes. it is amazing."
"Raja Chatila","Interviewee","Yeah, I want to mention two other projects."
"Raja Chatila","Interviewer","Yes, so other projects."
"Raja Chatila","Interviewee","Yes, another project I would like to mention was the COMETS project. That was in 2003, 4, 5, and so on. It was about aero-robotics, drones. It was a European project with Spain mostly and Portugal and at that time we became interested in robots that fly and so do not forget that I have made my engineering studies in these aviation school and my Master's in control in the engineering school which is called National Aeronautics and Space School. So I had also this tropism to aviation in general and so it was very interesting for me to move into aero-robotics and that project was very interesting. It was about cooperation between different flying robots. Germany, University of Berlin was also partner. The idea is to have different robots. We had plane, helicopter, and so on, cooperating together. Of course controlled and cooperating together autonomously for some task and the task was detecting forest fires and we made a lot of experiments in Portugal also. The team went there and was one of the most active in this project to build the understanding and the control system for both the control of individual aero-robots and our case we had this blimp and which was called Karma and the other, the coordination with the other flying robots and there are some projects continuing on this issue coordinating with ground robots, aero-robots, and so on, but that was one of the first project actually in aero-robotics that we have done."
"Raja Chatila","Interviewer"," funded."
"Raja Chatila","Interviewee","it is EU funded, yeah. EU funding was very, very important and still is."
"Raja Chatila","Interviewer","And they seem to do very large projects."
"Raja Chatila","Interviewee","Yes. It depends. I mean it depends because there were times where we had small ones, then they grew up in terms of funding and then Europe is really now putting very much the emphasis on having both smaller projects like two or three partners, three partners, working on a three-year project, pretty small, but and large integrated projects with more partners, maybe longer, and in the future what is planned is what we call flexion projects, ten years, with enormous amount of funding, but many people of course participating in that. So it is yeah, I think this will push research and European integration much more. Another project I want to mention, maybe this will be the last one I mention, but it is a very important one. it is the commune project. So in that time I mean about 2002-2003, one of the branches at the European Union which was called Future and Emergent Technologies launched an initiative called Beyond Robotics. The idea was to study robots with advanced cognitive capacities, advanced interactive capacities and so on and I have coordinated a project called Cogniron which run between 2004 and 2008 with partners from Europe like Henrik Christensen who was at that time in Sweden, Kerstin Dautenhahn in England, Rudiger Dillmann in Germany and many others. Cogniron means the cognitive robot companion so the objective of the project was to study cognitive functions of a companion robot. What is a companion robot? it is a robot that interacts with people, assists people, just do tasks for people and this was a very important project to study the issues related to human-robot interactions, how to model humans from the perspective of the robot, how to jointly do tasks with humans, but also on the more robotics aspect of cognition which are autonomous decision making, planning, cognitive architecture, how the system is organized, learning. Learning was one important issue there and this is where I mentioned what we have done on that with some other partners working on other aspects of learning. For example, Aude Billard in EPFL working on imitation learning was in this project as well. Roland Siegwart was in this project working on other issues related to perception and navigation. So Cogniron was really a project that put together many competent researchers from Europe working on those issues about learning, decision making, cognitive architectures, human-robot interaction, and communication dialog. It was the University of Bielefeld and that was an entity graded project, a large project, and I think that is was really very seminal and yielded a lot of results that are now exploited in other projects, European or national projects and so on."
"Raja Chatila","Interviewer","Do you have a feeling for why there was such an interest in developing a companion robot?"
"Raja Chatila","Interviewee","Well, yes. I think what happened over the years if you wish was that in the beginning we were in the beginning of robotics 50 years ago, mostly the motivation for robotics was manufacturing, was automated manufacturing. So people wanted robots in the factory mostly I would say at that time to replace people, to make a work faster, more productive, more precise, and so on and so on. So it was robots without people. When we studied which was a different thing at all when we studied mobile robots and so on, the emphasis was on autonomy. We wanted to study autonomous robots, how to achieve, how to build a machine able to make decisions by itself, to move by itself, to avoid obstacles by itself, to go places by itself, to do things by itself without any human intervention. The human intervention was just in the beginning to give a goal and when we studied Mars rover, of course, it was again autonomous robots on Mars, no people, and again the emphasis was on autonomy. Some operation which means there is a person, a specialist, doing some control remote control, but very light control, but the robot is basically autonomous. As those autonomous functions were developed, at the same time came up some issues in society and basically in the industrial world it is the aging society where people started to address the problem of what is going to happen when everyone is going to get older, so we needed some more maybe some assistance or some help from machines. So the issues came up and mostly I think Japan was very driving on this to study robots for assisting humans. So in a way there was some maturity in understanding some basic autonomous functions which are necessary for robots to interact efficiently with humans without the humans controlling every motion and so on. That was a necessary step and there was a kind of need. I do not believe it was an expressed need and it is still not an expressed need, but there is I would say an anticipation of the fact that we are going to need robots in our homes. So this convergence of this potential need and the capacity to achieve enough autonomous functions so that the interaction with humans could be easier for humans started this issue of robot companions, I think, and made it possible and there was a potential need. So it was the was mature to study that. And I believe it is very developing and indeed we have robots with more or less enhanced capacities for interacting with humans. For example a vacuum cleaner like Roomba does not interact with humans, but it is in our homes and we have some experimental devices for very, very simple interaction, but this is probably a great avenue to explore to achieve robots that really are going to share our space for our benefit of course. So yeah."
"Raja Chatila","Interviewer","What do you think are some of the challenges for robotics in the future the next ten years or something?"
"Raja Chatila","Interviewee","Well, I believe the main challenges of intelligent machines are not solved today. I mean the questions that we try to address in the early days of robotics are still open. General perception, seeing, understanding, situation understanding, this is not solved. There are results. There is progress, but I do not know of any system that you can just put anywhere and it understands meaning, analyses a scene, says well this is a camera, this is a chair, this is a door, and these are two people speaking together."
"Raja Chatila","Interviewer","Must be an interview or like ."
"Raja Chatila","Interviewee","So this does not exist and this is a very fundamental problem, perceiving and understand what to perceive. So since the problem was addressed since so many years and we did not solve it. It probably means we do not have the proper instruments, the proper theories or the proper processing power or the proper and so on. It will not be solved just by chance, by augmenting processing power. You need to know how to do it. So I think this is a very important question and a fundamental one, but I want to say that it is not to be addressed by itself. Again, you do not perceive just for perceiving. You perceive for action and therefore we have to consider the connection between perception and action all the time, not just perception by itself. Which means you have to integrate perception with action and this will necessarily be based on learning processes because you cannot imagine beforehand those interactions between perception and action without I mean abstractly speaking. So learning is another issue too that has to be developed. Learning methods, learning theories, we have a lot of results on learning, but we have big problems with efficiency, with ability to cope with real situations, real problems, dimensionality, not toy problems. So there is a lot of work to be done there as well, I think. And too, of course there is the issue of robot interaction, social interaction, but this is more or less this social intelligence issue is important. I think it would be instrumental in accelerating learning, of course, because you do not learn just again by scratch by observing. You learn also by interacting with people and learning from people. Learning from people for a robot or learning from other robots, also this interaction is important. What I want to say in terms of novel issue to address, I believe that we did not solve those issues and we should continue and there are mathematical issues. There are modeling issues. There are deep questions about how to those things, but what I believe is that we need to if we consider all those things together, there is a point which was not so much addressed until now which is the problem of self-awareness or consciousness. What enables actually in natural systems also to drive or control or achieve those processes, perception, action, interaction and so on, is related to the fact that I have some awareness of myself with respect to the rest of the world. Myself is my body and my way of integrating, I would say, the external world with respect to my own existence; my awareness about where I am. So this is just to say that I believe studying self-awareness for a machine, robot consciousness, we do not have theories of that. Of course they all have theories of consciousness for humans and so on, but we do not have a theory, a mathematical theory or a computational theory of that. I think this is probably at the center of those issues and of enabling us to really understand and achieve an artificial intelligence, a human level artificial intelligence."
"Raja Chatila","Interviewer","And just to wrap up, unfortunately since I think maybe They are out there. I do not know. Could you tell us if you have some advice for young people who are interested in getting into robotics?"
"Raja Chatila","Interviewee","Well, I think robotics is a very exciting field because when you work in robotics, you work in all the other fields at the same time because basically in a way robotics is about developing an artificial being. So you have of course the issue of sensing; you have the issue of perception; you have the issue of computation; you have the issue of building the body, which means mechanics, material science; you have the issue of studying the notion of mind, which is also related to philosophy; you have ethics; you have interaction. So really entering into robotics is a wide spectrum of possible studies in all domains. All domains in conjunction with the science That is going on in those domains, for example independently from robotics. So it is also a multidisciplinary venue. I mean you can discuss with neuroscientists, with social science people, with philosopher. They have interests I mean I do not know about any domain which is richer than robotics. it is really a comprehensive domain. Of course one will specialize, but what is important is to keep in mind the full picture and a second point is that when addressing a problem, my advice is to never try to solve it by hex . Of course hex will work sometime. They will do great things, but those are hex which means they will not be journal solutions and so on and doing this is missing the real problems. Again remember the issue of uncertainties and how SLAM came up. This was because we did not do hex to solve the problem. We really tried to address it and we came up with solutions which were developed afterwards and SLAM became a great domain to understand robot navigation. So no hex. You can use hex if you want, but you should know these are hex and just for temporarily maybe solving other problems, but no hex."
"Raja Chatila","Interviewer","Great. Thank you very much."
"Raja Chatila","Interviewee","Thank you. So what I forgot to mention?"
"Raja Chatila","Interviewee","I am sorry. What I forgot to mention was my stay in Japan, but "
"Raja Chatila","Interviewer","Maybe We will catch you at another one of these things."
"Raja Chatila","Interviewee","Yes."
"Ray Jarvis","Interviewer","The interview goes, as we start with where you were born, and your name, where you were born, and then go through the different places that you went to school, the kinds of things that you worked on, people that you worked with, institutions that you were a part of, that kind of thing, and then we end up with where you think robotics is going."
"Ray Jarvis","Interviewee","Okay, now you said you had limitations, so "
"Ray Jarvis","Interviewer","Yes, so our next one is at one-thirty."
"Ray Jarvis","Interviewee","Okay. I just want to make sure, so I do not make it too "
"Ray Jarvis","Interviewer","We will keep an eye on the clock. I am doing the times, and I will try and make sure, yeah."
"Ray Jarvis","Interviewer","So if we could start with your name, and where you "
"Ray Jarvis","Interviewee","Okay, I am Ray Jarvis, I was born in Rangoon, Burma, 9th of January, 1941. My parents had kind of British background, and some Asian background mixed. We came to Australia in 1947, landing in Freemantle on the west coast, and I went to a Christian Brothers school in a suburb near where we were, and finished up going to University of Western Australia, where I did my undergraduate degree in Electrical Engineering, and subsequently completed a PhD in Electrical Engineering. Following that in 1968, I spent two years at Purdue, in contact, somewhat with Professor Fu, who was one of my examiners. But I actually worked with Professor Ed Patrick, who was working on pattern recognition in those days. Went back to Australia to join the Australian National University as a senior lecturer, and was essentially given the task of setting up a computer science department, which began as an embryo group within the department of statistics, and a few years later, we became a separate department, but we were still, strangely, in the faculty of economics, which is a bit odd. So I worked at the Australian National University for 14 and a half years, went to a Chair of Electrical Engineering at Monash University, which is in Melbourne in 1985, changed the name of the department to include computer systems soon after, and established an intelligent robotics research center in 1987, and have been director of this group ever since. So the group, essentially included other academics from in the department with backgrounds in computer systems, with several different interests in robotics. So my colleagues had complimentary interests to mine, and we tended to work in a fairly democratic way, collecting a few students, roughly 10 to 12 between the four of us, expanding up to about 24 when the funding was good, and dying back to about ten when it was not so good. My own robotics interests started off with combination of global search, as it was called in those days, and some pattern recognition background, drifting into image processing, and then computer vision and robotics. So the computer vision, robotics, about 1980 to 1982, still while I was at ANU, so when I established the center at Monash, my main interests were things like robotic hand-eye coordination, various range finding methods, stereo depth and then I switched between the hand-eye coordination to robotic navigation of vehicles, generally wheeled, sometimes tracked, and mixed indoors and outdoor experiments, so about halfway through, I suppose, my time at Monash, I got interested in larger outdoor vehicles that could operate in rough terrain. Those that sense the environment in sufficient way to carry out either tele-operated tasks or fully automated tasks. And I suppose the biggest project I worked on the last five years, we completed a year and a half ago, it was working with the country fire authority who were interested in robotic vehicles that could assist with putting out forest fires. And that work split up into several different approaches, one was vehicles that could go and do forward scouting, to check whether some area was safe, others that were capable of clearing the path for another vehicle, and then finally, the vehicle that, itself would carry water and extinguish flames. And the idea there was never to be too concerned about the degree of autonomous control, but just make sure that the human operator was at a safe distance. So the concentration there was on rich sense of feedback, and very simplistic control of existing mechanisms like steering, brake and accelerator, without modifying the vehicle more than absolutely necessary. I guess another project which I had several goes at, was the creating a semi-autonomous wheelchair, and the idea there was to allow for an adaptive shift between the wheelchair being fully under the control of the user, to taking over a certain amount of control when that user showed some signs of fragility, either from poor sight, or tremor, or tiredness, and I guess the key factor there was to be able to shift the responsibility between the user and the robotic equipment on board, so this vehicle was able to avoid collisions, but also give advice as to safe directions, and sometimes pull the sort of the vector of intended direction toward the safer, and to change the parameters so you were switching between the fully autonomous to fully human mode. I had several goes at that. The first vehicle was simply one where you moved a joy stick and you had indications of where you could go safely and you were shifting around. The second version of that was where you had an eye-gaze tracker looking back at the user, so that a severely disabled person could go wherever they liked, simply by looking, so it was just where your eyeballs, not even your head, necessarily, you could keep your head still and look sideways, and that turned out to be very successful technically, but incredibly expensive, so nobody is going to work with that. Then I had a variant of that, which was a walking frame, that was motorized, that could convert into a wheelchair, again, with the same thing, and the last version is using connect sensor, which now brings the price down. One connect sensor feeding forward to work out the obstacle space, one feeding back to see what the user is doing for gestures. So I guess I have mixed my interests between path planning, vision, robotic navigation and generally have been absolutely convinced that experimentation is the only way to go. I have developed a few theoretical ideas on clustering, on distance transform methodology, for navigation and convex hull, sort of geometric, some computational geometry. So I have done a few theoretical things that have solid founding, but most of my interests are making things work in physical space, and to show, I suppose, the relationship between concepts and reality and adjustments that are required to take the existence in a cluttered space into account. My ongoing interests remain in the area of human machine interactions, and particularly in thinking about the different types of intelligences required for human-robot interaction. And I had this idea that there were three types of intelligence, highly related, first, I call relational intelligence which is about how the robot can find its way around without bumping into things, in an efficient way, how it can recognize and handle objects. This is all about things in space, and what they are, and how to move. The second I call transactional. Now some of the computer scientists would call this dialogue. I call it transactional, because it is about the way the human and the robot communicated, but beyond that, how the robot came to understand what the human required, but within its constraints. So the negotiation took place to get the robot and the human to make a deal about what was going to be done, and there is a little bit more than just the gesture, or just the voice or just understanding of dialogue. Now the third level, I call social intelligence, and it is how to have robots mix with humans in such a way that the humans feel comfortable. So it is not just fulfilling the task efficiently, it is about having some notion of cultural limitations about proximity and approach and interruption and then timing, and also to include, perhaps, some aspects of, I suppose you call it entertainment and flexibility and a bit of softness in the whole approach, and I think That is the one of the hardest areas, particularly, it is extremely hard to get funding in that area, because it seems too much like social science, but I think, in the end, We will have to master that part as long with the other two, sort of harder layers. So That is the work I am doing now. I have sort of been semiretired and hopefully will get an emeritus status to stay linked with my equipment and colleagues at Monash, but my main interests are continuing this work about multiple robots in a human interactive environment, sensor rich, mainly interested in vision, and laser range finding, navigation, gesture recognition, voice and somehow protocols for human cultural limitations on behavior. So That is probably brings me up to date."
"Ray Jarvis","Interviewer","That is a great story. So we are going to try to delve into some of those episodes of into the different projects and some of the details of things you were interested and the kinds of technical and conceptual challenges that you were dealing with so if we could start with when you well before we start with your PhD, I was curious, how did you decide you wanted to go into electrical engineering, in the first place?"
"Ray Jarvis","Interviewee","Oh, okay. I guess I was interested in making things. As a kid, I was always making things like projectors for film for photography or models of things, and I always had this notion that I would like to be in a situation where I could make things, but I did not really know whether it was bridges, electrical things or mechanical things. And I suppose I did not decide that strongly until I was in my final year of high school. And then it seemed to me that electrical engineering appealed to me more, because it looked like it was going to explode into lots of different areas, and as I got more and more into it, I think I was reasonably pleased with my choice, so I never really seriously considered moving sideways into mechanical, civil or chemical engineering. I went to a the school I went to at university of Western Australia, had this common first year, which many engineering schools have, and then they kind of split up into specialties. But in fact, there were still some common courses that were run right up into my third year. It was actually a five year degree, so the specialization only came halfway through the fourth year, and then continued into the fifth. So I actually, looking back, enjoyed the mixtures of topics. For example, in addition to electrical engineering, I learned a lot about mechanical design, about surveying, about strength of structures, material science, and a great variety of things, which I suppose at the time, we did not think were relevant, and in most areas of electrical engineering, would not have been relevant. But in robotics, happened to be incredibly relevant, so even knowing how surveying was done, was a huge benefit when you start to think about how to localize a robot in an environment, and the use of theodolites and lasers and all this kind of stuff. I also remember that we were taught to sketch things a lot, and I did technical drawing in high school as a special subject, which was not taught by my school. I actually went to night school and did technical drawing, because I like the idea of visualizing, so I think That is where I started to think as visualizing things as being the thing I really was interested in. "
"Ray Jarvis","Interviewer","Do you remember any things that you built when you were younger, that really stand out, like, any specific "
"Ray Jarvis","Interviewee","Well, I guess I did build a number of different versions of photographic enlargers and projections, and I built models of boats and things like that, and my brother went into chemistry, and he used to make explosive things, so I enjoyed making things that shot rocks out of pipes and things like that, slightly dangerous things, but I was generally interested in things that one could make with very few tools, and inexpensive bits and pieces. So I do not suppose there is any particular thing. I just made whatever I could with the things I could find around me, cheaply. So I did not really know too much about how to go to a disposal store and buy things. I also had a sort of hobby interest in radios. I happened to have a next door neighbor at one stage who had an interest in this, and used to give me old radios and muck around with valves and make crystal sets and twiddle around trying to hear what was happening. So I had a general interest in gadgets of one kind or another, and then this interest in gadgetry has actually stood me in good stead throughout my career. So I think if any of my colleagues were asked, you know, what sort of captures what I have been interested in, I suppose you could say it is gadgets of one kind or another, which I have accumulated quite a few."
"Ray Jarvis","Interviewer","So after you got to the university and during your EE degree, undergraduate, did you were you working in the lab at all at the time, or was that in your "
"Ray Jarvis","Interviewee","No, there was not much opportunity to create things at that stage, but I do know that our engineering course was very, very lab based. We did many, many hours in the laboratory. In fact, for most of my classmates, the laboratory work was considered dull, but I actually enjoyed it, because I just liked to see how things worked, so if anything, I had a greater interest in the experimental laboratory work than I did in the more theoretical side. And I think that this is partly, of course, why I have always considered experimentation as the way to do things, although I perfectly happy to slot in theoreticians and people who have more philosophic views. I guess I am just saying, yes, we need all that, but the thing I do best is experimentation."
"Ray Jarvis","Interviewer","And when you got to your PhD, what kind of environment did you get into, and who were you working with?"
"Ray Jarvis","Interviewee","Okay, now when I started my PhD, I had recently developed an interest in computation. This is 1963, 1964. The university at that stage, had a very small computer, it was an IBM 1620, and I, with the help of a friend, developed some programming to optimize the circuitry for switching circuits for binary switching circuits. That was my first introduction to actually using a computer, so as my PhD developed, I got interested in hybrid computing, which is combining analogue computation with digital computation. In those days, it was considered that, to build dynamic models of differential equations on a hybrid well sorry, on an analogue computer, allowed it to simulate physical systems at, maybe thousands of times faster than you could with a digital computer in that day. But as digital computers became more powerful, then their need for the analogue side dwindles. And I was in that in between stage, where there was still benefit of combining two types, so I had an analogue computer with a link to the campus computer which upgraded from a poor old IBM 1620, to a Digital Equipment Corporation, DEC 10, which was apparently the second time shared machine made by this company, that was outside the US continent. So the university of WA was the first outside the US to actually acquire one of these seemingly very advanced machines where multiple users could all clatter away on their teletypes and share memory and do their computations by either mixing with their colleagues during the day, and sometimes in blocking large chunks to be hands on, single user at night, to do the heavy computations. And I had a long cable between the physics school where the computer was housed, and the electrical engineering lab I was working in, about 200 yards apart. So part of the problem was how to get digital signals backwards and forwards without noise and this sort of stuff. So I built the interface between the two computers, I built models of different dynamic systems on the analogue, and I got interested in using the digital computer as the means of optimizing parameters, so That is where the optimization of parameters came from on a hybrid computer. So my thesis had a very long title, it was all about using a time shared computer and a hybrid system to do global optimization. In those days, there was always that well people still today realize that if you have an optimization problem which is monotonic, that means there is only one valley if you are looking for the bottom of a valley, you could use steepest descents, slide down the valley and so on, but as soon as you had multimodality, it was a different problem. So I was deliberately trying to work out what happens if you have a parameter space which has almost chaotic multimodality? And it turns out that you have to consider how to spread your testing as well as concentrate simultaneously. And so that was called global optimization, and That is where I first got to know about King-sun Fu, was at Purdue, because one of his students had done a version of this, using a probabilistic method. So what you try and do is have a method that was able to randomly select where to sample, but also possibly had some local refinement going on simultaneously, so that was the idea of how to work on two levels at one time. So my thesis came out with this sort of randomized search methodology for global optimization. But it was still fairly theoretic in the sense that the types of multiple modal surfaces I was working on, were not from industry, they were just things I constructed myself. And then the question became, what if the shapes of these valleys shifted in time? So the idea was to have an ongoing real time process that could track shifts and particularly those shifts that were meant, but the valley that was the deepest went up on a valley over the hill went down, you do not have a direct path, and how do you keep a watching brief to so a lot of it had to do with strategies for keeping a watching brief on what was happening in different parts of space, and then with some idea of not wasting time, because obviously if you have spent a long time on the hilltops looking at the next valley, you are not going to overall, minimize. So that was my thesis work, and then That is where I know about the work of King-sun Fu, so when I graduated in 1968, I was attracted to go overseas, and it was fairly natural for me to say, okay, Purdue is a good place to go. I had never been outside Australia, except when we migrated initially, and so it was a great, kind of excited exploration to go to the United States and spend I intended initially to spend a year, stayed two years, but ironically did not actually work with King-sun Fu, worked with Ed Patrick instead. And That is where I got interested in pattern recognition. "
"Ray Jarvis","Interviewer","Who was your PhD advisor? "
"Ray Jarvis","Interviewee","Oh, it was Dr. Brian Leary. Leary, L-E-A-R-Y, who did not have a strong interest in my topic. But what he did have was faith that I could do it. So he would say, I am not quite sure what you are doing, but I think you can do it. And it turned out to be the best attitude, because I did not want too much advice. Quite frankly, I had an idea and I did not want someone to divert me from what I wanted to do. So that part worked out well, because if I had had no real sort of drive, then the supervisor, not being specifically interested. So he was generous enough to say, I am telling you now, I do not know much about it. I am willing to act as your supervisor, because you need one, formally. I will help where we can to get resources, but do not expect and I took that to be very honest, and made the most of it, basically. So that was good. So he would not be embarrassed to hear that I reported his non-specialty, because he was really up front about that, and I appreciated that at the time. But I find sometimes when I have my own students and they start drifting in areas where I am not familiar with, I tell them outright, either to get advice from my colleagues who are specialized, or I tell them, look, if you want to move in that direction, I can not help you. It may be better for you to find another advisor. I think it is good to be up front, because it is not good for a student to believe his advisor is an expert, and find out later that his suggestions are almost wild guesses, and do not really reflect what is happening on in the field. And I think That is dishonest, so I am I really like the straightforward approach. So "
"Ray Jarvis","Interviewer","And so when you got to Purdue, what was the situation there like, what kind of "
"Ray Jarvis","Interviewee","Okay, now what I found out was that Ed Patrick, who had a very strong theoretical background in pattern recognition, had a number of students working in this area. I got friendly with one of his students, and we worked together on a project or two, and one of them was to build an interface to their computer, to do some image processing. In those days, one did not have sort of standard cameras, so this was a scanning method of collecting data and analyzing. So that was my first interest in the image processing side. And I also was very interested in various pattern recognition methodologies and Ed Patrick was very smart in sort of high level mathematics about probabilistic structures and the like, and he happened to have some good external grants. So it was really nice working with a group where there was funds for travel, and there was no concern about buying components, and things like that, so for me, it was rather nice. I did a little bit of lecturing as well, in computer logic, theory, and stuff like that, so it was a pretty nice time. We wrote a couple of papers together, I got interested in an area called clustering, which is non-supervised pattern recognition, and I authored a paper, which I acknowledged his support as second author, on a clustering methodology, which turns out to be more useful than I ever imagined, because it was called, clustering using a similarity based on sharing near neighbors. Now the title actually tells you the method. So the method was just super simple. What you did is imagine all these points in, say, Euclidian space. You found, maybe K nearest neighbors, and K may be seven or ten for each point, and you looked at the neighborhood list of two points, and you said, these two points could be considered put together if they shared a lot of neighbors. it is a bit like saying, tell me your friends, you tell me your friends, if many of them are in common, you are probably friends. And it is a very, very simplistic computation, and it does not make any assumption about underlying probabilistics, so it is totally non-parametric, and by changing the size of the neighborhood and the thresholds, you could adapt to many different sorts of clusters, clusters that were long strings of points, They are sort of very globular and so on. And then 20 years afterwards, and say, five years ago, I just looked up clustering, and I found everywhere They are referring to this JP algorithm, and I was, what the heck is JP algorithm? It was Jarvis Patrick algorithm, so I was very pleased to find it was in great use, and by pharmaceutical and molecular people who were working in the field on the edge of medicine and molecular chemistry. And they were using this as a standard method for clustering their different kinds of products and making this clustering available to their customers and the like. So it was a pity I did not patent it, but you know, I was pleased to see it was used, and That is where the kind of mix came drifting out of global optimality into pattern recognition and imagine processing that finally led to my interest in computer vision and robotics. Yeah."
"Ray Jarvis","Interviewer","Did you, while you were doing the clustering work, did you have a particular application for it in mind, or was it "
"Ray Jarvis","Interviewee","No, I think I was simply picking up the interest of the people around me. Patrick King-sun Fu, was, international figure in the pattern recognition are at the time, so I think I was just trying to absorb the local specialties. At that time, I did not really think about slight shifts, but certainly later on it was interesting, because my old interest in optimality and pattern recognition came together. So I picked up some of my thesis topics again, when I went to the ANU, and instead of just oh, I guess it was mixed. So I guess instead of looking at the question of how do you find when the minimal points have shifted, in a way that you cannot track them, I developed this idea that you could have a pattern recognition algorithm that tried to detect when there was a sufficient change to warrant a re-exploration. So That is where the pattern recognition and the optimality came together. And then when I went to the ANU, I got more and more interested in collecting image data and analyzing it, so I drifted away from the pattern recognition side, but I did find applications for clustering in the image processing on several different occasions. So probably that idea of mixing it came to its peak when I went back to Purdue on study leave. I kind of felt a bit guilty going back to the same place, but there were still some of the colleagues that were there before, and that was just a one year stint, so I went back, and this time, did work a little bit more with King-sun Fu and some of his students, and there the image processing and the pattern recognition came together quite strongly, and what I was interested in then, was what is now called image segmentation. So someone gives you a photograph, and you show it to someone else, and say, can you take a pencil and draw an outline of the major things in this and then say, can you get a computer to do that? And it turned out, it turned out to be really difficult in those days, partly because they were computationally intense, took a long time to do, and I tried to use the idea of clustering, to group the pixels in the image into a conglomerations, and I developed a number of different strategies that were based on graph theory, basically, saying that you could imagine every pixel in this image as a leaf node, and what you are looking for is how to get the leaf nodes to conglomerate into larger and larger pieces, but not to cut across the boundaries of different objects, and the clustering helped there. So by the time I went back to the ANU after that, I had this strong interest in the segmentation and the more and more concerned about how to do it faster, and you needed to do it faster if you wanted to use a robot, so I got interested in this idea of robotics as a means of testing the validity of the computer vision. And it was about that time I got interested in the 3D aspects. So until then, it was just 2D imagery. Now I visited, I think, SRI when Bob Balls was there, I do not know if I met him that time, but he had some colleagues there, David Nitsan and others who had built a laser range finder. One of only one or two in the world at that stage, and I was fascinated by the use of time of flight laser ranging, and when I went back after that visit, I was determined to see if I could get some funding to build one in my lab in Canborough, where the Australian National University is. And I applied for what is called an Australian Research Council grant, for mainly the equipment money. I had worked out how I could possibly buy off the shelf equipment, and I put together a budget, it was mainly about the costs of various things, and in those days, the Australian granting committee was split into smaller groups, and they often visited laboratories to talk to the applicants, and try and ferret out some of the background information and whether that was it was in fact, a very good way of doing it, rather than just looking at what is written on paper. And I met up with three of them, and they spoke to me very openly, and said, oh, well we partly came just to see your lab, but we are also doing this job for the Australian Research Council and we only think it is fair to let you know that we have got some opinions about your plan by some experts in in that case, it was CSRO which is a commonwealth research organization in Australia. I was not given any specific names, and they said, well, the experts there believe that what you want to build is not possible under with this kind of, you know, under the plan you have got. And I thought, oh well, at least They are decent enough to tell me, do not have false expectations of getting the money, and had a nice chat, and they thanked me for the visit, and then they gave me the money. So now I was really under some pressure. They told me it could not be done. They said, have a go, and to my delight, I managed to get it working, and I used to boast this was the first laser range finder in the southern hemisphere, which it was in those days. That was sort of 1982, it was very really early, and That is where I really got interested in the third dimension, because that used to be the thing that stopped you doing the segmentation and the handling properly. There was no point just outlining figures on a photograph. What you really want to know how to recognize things, and to find where they were in space. So about that time, I had this notion that robotic manipulation was perhaps the most honest way of testing whether your vision was operating correctly. Anyone could look at your sketches and say, hey, that looks like what I would do. But how do I know that that sketch or that segmentation has sufficient information to actually permit manipulation. And I thought, if you could actually show that manipulation was supported by this analysis, you then had a way of saying, even if you have objections to some of the philosophic ideas, I can demonstrate a practical outcome, and therefore, from an engineering point of view, that is a good and solid result. Then I thought, what I need is a robot. And again, with some funding, I had something like 20,000 dollars for a robot, and in those days, a decent robot such as the one made by Joe Engelberger's staff, was called Puma, and this one was called Unimate, the small one is called Unimate 250. Those cost about 45 to 50,000 dollars, and I had 20,000 dollars. The local agent for Unimation, I think they were called Unimation Incorporated in those days, said, why do not you ring Joe Engelberger? So with nothing to lose, I remember trying to pick my time, so it was sort of mid afternoon, in the United States, and I spoke to Joe Engelberger, you know, the great the father of robotics and all this kind of stuff, and he just said, oh, look, leave it with me. Maybe I can find a refurbished unit and send it to you. And indeed, good to his word, this box arrived with the Puma 250 at 20,000 dollars. So that was my first robot, and between the time I got it and the time I finally shifted to Monash, it was over a three year period, I started to do hand eye coordination. So I was using my laser range finder, and other methods, vision methods to allow robot to pick up blocks. So I scavenged a lot of the building blocks from my kids' playpens and stuff like that, and I had all these different colored blocks, and I could manipulate them and pick them off a table, and put it into different and I was quite pleased with that. Again, the experimental side was seen as critical for me, rather than the more theoretical side. "
"Ray Jarvis","Interviewer","Were you in contact with the other people who were doing manipulation in Blocks World at the time?"
"Ray Jarvis","Interviewee","No, but I certainly I knew the Blocks World Experiments in great detail, and in fact, taught them in my classes in computer vision, so I knew all the work of Winston and Guzman and the others, and also some work that was happening at SRI simultaneously. In fact, there were two schools of thought about how to do it. The SRI people were dealing with one aspect, and MIT was going in the other direction, and the two actually came together later. So I was very intrigued by the Blocks World Experiments, but I was really more interested in trying to exploit the physicality of the 3D analysis, rather than the notion of clustering vertices, which is the Guzman approach of sort of reasoning about block structure from the appearance of the edge data. I said, if I have got a 3D analysis of things physically existing, I can pick them up even before I know what they are, and what is more, I do not need to know which things are attached or not attached to other things, because, by picking them up, I will find out. So it was this is active this is now called active vision. it is how to actually improve your quality by saying, the manipulator is allowed to change the world, and therefore, the change can expose things that you may not have known statically. So I was very keen on the idea of interacting. And so a number of other projects that followed along this line, it was all about what I called post-recognition, manipulating first and then recognize. For example, picking up an object. I have got this object, now let me look at it. Now decide what it is, which is not what humans do, but from a robotic point of view, it seemed to be much simpler, because once you separated a physical object from a clutter, you now had it in isolation, and you could change the viewpoint. So one of the projects we had when I had just established the Intelligent Robotics Research Center was, in fact, if your hand eye process by which we had a 3D scanner this was not a laser scanner, but a stripe scanner, collecting 3D data, and then picking up unknown objects holding them up to the camera and then recognizing them. And that was pretty successful. And that project, about three years, with a few colleagues and so on, was one that we were hoping would be taken into an industrial application with a very large company we had as an industrial partner. This company BHP, which is one of the largest mining companies in the world. They combined with a company called Billiton, BHP Billiton is quite huge. To give you some idea of the size, but of course they have grown since, that last year, they posted a profit of 22 billion dollars. So it is big stuff, and early days, they had a research laboratory about one and a half kilometers from my campus, so it was quite good to work with them. So we got interested in the hand eye coordination stuff, and also in mobile robotics, so they were talking about the possibility of using mobile robots in a steel plant, and mostly the sensors that we were developing, not so much either the demonstration with the hand eye coordination, or navigation, but we were developing a number of 3D sensors, stripe light and trying to speed things up and get quality. And, in fact, one of the outcomes of this research project, was a stripe light 3D system that was used in the steel mill to test the smoothness of the surface of a rolling mill sheet coming out. And BHP claimed that that application alone justified the money that went into the research project, so actually took one of, probably about five ideas, and at least used that within in house. BHP at that time, did have a commercial wing, that was meant to take good ideas and commercialize outside, but they were a little bit hesitant, they did not actually take this product, and I think that wing of BHP disappeared anyway, so we were a bit disappointed at what we thought were usable industrial ideas were not exploited, except for that particular range finder that was built. "
"Ray Jarvis","Interviewer","How much money was involved, if you remember?"
"Ray Jarvis","Interviewee","I think it was a million dollars over three years, so it was enough to employ about four people. Yeah, in the Australian context, that was considered quite large. And it was one of those very early, what was called a good GIRD was Government Industrial Research Development, so it was not meant to be pure research, it was meant to be something you did with an industrial partner, and the hope was that by using public purse funding, you would encourage the industrial partner to exploit the market with the outcomes, and certainly BHP were one of the key industrial partners for quite a number of different projects. "
"Ray Jarvis","Interviewer","What year was this?"
"Ray Jarvis","Interviewee","Now that is a bit harder. I think around 19 about I think it would be in about 1991, 1992, 1993, about then. I will have to double check, I am not sure of the exact yeah, it would be about then. About a little later I joined one of the panels of the Australian Research Council, and I think that was about 1992 to 1996. So I think, yeah, this other project was before then. That was interesting, just to be a member of the panel, be like being on an NSF panel or some such thing, in America. So I got to learn, I guess what you could call the art of writing submissions, and how to do it and how not to do it with many, many examples. And I got good at writing proposals, I think, about that time. And so typically what this committee would do was collect 300 applications, farm them out to assessors, subdivide it into the panel members to act as the lead for discussion on maybe 100 samples each, and then incorporate our own responses with those of the referees, and come to a common idea about the quality of project, and then more or less democratically decide who was going to get the money. It was a fairly intense process, so the pre-reading maybe took a week or two, and then you would meet together in a room, and you would sit in that room for three or four days, and then take your results up to the next committee. So I learned, I guess three basic things. One is, how to write a grant so that someone reading it gets the impact and the sense of it in the first page. That was something That is critical. We found some of the people who had very deep, narrow fields, tended to carry on about some theoretical issue that very few people were interested in, and you would get through 20 pages, and you would come out of that saying, sounded all right, but I still do not understand where it fits. So I got that idea that when I read many applications, and people make good points in the first couple of pages, I was much more positively disposed to reading the rest of the detail and fully understanding it. The second was, I really enjoyed working with those people, because they were all top people in their own field, and you got to know, I guess their mental processes, how they thought about things, how they approached things. So that was very and the third thing was, I got to know a lot about the research community, because, in addition to seeing the proposals, we also did site visits to talk to people, saying, how's your project going, are there any bottlenecks? You know, have you the right sort of facilities, to do this work, and I found that useful, because you had a feel for what other people in the country were doing, where your own research fitted, and how, essentially, to tap the source. So during the time you are on the committee, of course it is tricky, because your projects have to be your proposals have to be sent to another committee who probably do not understand what is happening, to avoid that kind of in house, inside knowledge aspect. So that was a bit tricky, but fortunately, through that process, our projects did not get lost in the system, and in 1996, I think, after I had been it must have been a little earlier. Yes, so I think I must have started in the ARC Committee, maybe 1993, 1994, 1995, 1996 or a little bit around about 1996, I was given a special grant, which was terrific, so what had happened is, I had written a project. That project was regarded as good. And so good that they said, here is some money, but you do not have to do that project, which is great, because now, you are saying, That is impressed us, here is some money, do whatever you like. And I thought, well I am not going to work on that project, I will keep that one, that is a good one, maybe I can use it again. And I used the funding for buying equipment, basically, because I thought, I will never have this opportunity again. So I had that flexibility for three years, I think it was 1996, 1997 and 1998. Again, the dates are not all that clear. So I had three years in which I had complete freedom over, not a huge sum of money, but probably about quarter of a million dollars, buying things, so I tried to say, look, let me buy things that are going to be good for ten years, so I got lots of pieces of equipment that I used for 10 or 15 years. "
"Ray Jarvis","Interviewer","What kinds of things did you get? "
"Ray Jarvis","Interviewee","Robotic manipulators, vehicles different sensors, range sensors of various kinds, and so on. So I got myself kitted up, essentially, and was able to then do a lot of the experiment work from then on, so that was extremely valuable to have that freedom. "
"Ray Jarvis","Interviewer","I was curious, you mentioned that you got to see the lay of the land, what was going on in Australia in research. What were some of the topics and things that people were very interested in?"
"Ray Jarvis","Interviewee","Oh, okay, because the particular committee I was on, was looking at computer science, various parts of engineering, as well as some of the physical sciences, and you have got a quite a wide variety, so some things I remember was a very strong interest in one university's in solar cell manufacture, very early work on silicon cells, and they had pretty well the most efficient cells in the world for a while, and I remember feeling, is not it too bad that the government is not exploiting this? And it is early stuff. And I think, in fact they sold it overseas eventually. That is the sort of thing. There were other people doing pure artificial intelligence, you know, this sort of reasoning thing. I do not think the idea of Bayes Networks was there, but certainly there were people talking about more discreet, maybe extensions of the sort of stuff you saw in the Blocks World, but then Lisp was the big language at the time, so it was all about reasoning, about spaces that might have been involved with making decisions in industry, or selecting diagnostic stuff for drugs and the like, I remember that aspect. There were also people working on micro-scale, I suppose VLSI circuitry at that time. That was big, everyone was walking around with had been already walking around with a textbook, Carver-Mead textbook, was the bible for VLSI designs over a number of different projects building up in Australia, and that was expensive exercise, because unless you were getting your chips manufactured somewhere else, you had to have clean room facilities and it took a lot of expense. I remember that being one of the things I was quite impressed with at the time. And I suppose there were also, let me think. Yeah, I guess the solar work and the VLSI work, apart from robotics, were the ones that really impressed me. there is not was not a huge amount of robotics happening in Australia in those days."
"Ray Jarvis","Interviewer","What kind of things were people doing in robotics?"
"Ray Jarvis","Interviewee","The best known research project in robotics in those days were the sheep shearing project run by a friend of mine, James Trevelyan, T-R-E-V-Y-L-A-N, and in fact, rather annoyingly, for about ten years, whenever I was at an overseas conference, and someone picked up my Australian accent, they would say, are you James Trevelyan? And "
"Ray Jarvis","Interviewer","You need a "
"Ray Jarvis","Interviewee","Are you James? So James was doing this sheep shearing project, and whilst this may sound very agricultural, it turned out that he was a master of mechanical design. In fact, you can ask any of the people like Osama Khatib, and others, and people know James as a very elegant designer of mechanisms. And so some of the things he designed for the shearing head on a robot arm were exquisite, and still have a huge respect for that work. And he wrote a book about this called, Shear Magic, I think it was, yeah. So that was what people understood to be the robotics impact in Australia about that time. There was so my group started up at Monash, there was a little bit going on with, I guess a little later on, anyway, Peter Corke was in CSIRO in Queensland, so that group was growing. A little bit of work happening in New South University of New South but there were really only about five groups you could identify, each with three or four people in them, doing any robotics work. And then the big impact was when Hugh Durrant-Whyte. You may have heard Durrant-Whyte took up his chair in Sydney University, and established the Australian field AFI Field Research Center, that was momentous, because Hugh came with a lot of very strong ideas, very, very strong industrial links to people doing port automation and mining, and built up his group to 40 or 50, 60, 70 people, in the end, and absorbed a huge amount of funding from both government and from industry, and in fact, in a way, other robotics groups, even mine, really did not get a lot of look in, because he was so powerful in attracting the funding, and legitimately competing. So Hugh and I were hopefully going to set up a field research center together, but our first attempt had failed, because most of the money was going to big science. Our projects were not monolithic enough, right, so if you were going to spend ten million dollars, and you could buy one instrument for people doing gravity waves, or something, then you could not say, well, I could use it in smaller pieces, because then those other people would never get a look in. So Hugh and I were interested in writing that up, and we failed, and subsequently, when the call went out for special research centers, the money was relatively small, and I rang Hugh, and said, shall we go together? And he said, No, the money is too small, and we split, and what happened was that his group got the Center for Autonomous Systems, and we got a second ranking support for a center, but at half the funding. So we were called a sort of half center, but we did different sorts of things. So Hugh's center was big scale stuff, mining, port automation, then eventually into underwater and aerial on the big scale. Our stuff tended to be gadgets, small sensors of various kinds. My colleague was interested in touch sensing and thermal sensing, others were in ultrasonics, and I was working in vision. So the things we did were really small scale, and Hugh was doing the big scale stuff. And the meanwhile, Peter Corke was starting to do big scale stuff as well. So I think Peter and Hugh worked together for a while. So the landscape changed quite a lot, to go toward the group that Hugh set up. there is still some work happening in WA, and at University of New South Wales, and our Monash group had a reputation in sort of a limited size of operation. So Hugh was keen to use the phrase that Australian academic research community was punching beyond its weight, right? You know the term? So it means where a featherweight has moved up the scale. So it was true, because if you took the population and the small number, we were making quite a good impact. You know, we would find lots of Australians at international conferences, much higher than the proportionality would suggest. But nevertheless, we never got very strong recognition. Robotics has never been a national project in Australia. There have been funding for various particular things, but no one has ever come up and said, hey, this is where we really need to have certainly there has been strong emphasis on alternative energy sources, on things like medical issues and mining and all this kind of stuff, but not specifically robotics. So given that we were all scrabbling for our funding from a bigger pool, having to compete against a bigger pool of relatively unrelated engineering and science, we were doing reasonably well."
"Ray Jarvis","Interviewer","So what kind of research did you end up doing with your you mentioned you had kitted yourself up at some point, and that was at Monash already there?"
"Ray Jarvis","Interviewee","Yeah, That is right, we were already there. So, I started well because I was able to buy bigger pieces of equipment, I started to get interested in a lot of outdoor robotics. So two of the big things I bought both related to my visit to a laboratory in Finland. I can not, again, remember the exact date. What had happened was a colleague of mine, a Professor Aarne Halme, who was running quite a big laboratory in the University of Helsinki, had a conference that I helped with by reading some papers and became good friends, and he introduced me to some Russian engineers who had been part of the Russian space effort, and they had a large laboratory just outside of St. Petersburg. On this first visit, anyway, to Aarne Halme, there is a Swedish no, no, there was a Finnish company that built a big tractor-like vehicle that was incredibly powerful and had a very low impact on the soil, and they were presenting it as a potential vehicle for robotic agriculture, because it did not dig up the earth, and they were able to show that this thing could be driven with high precision and did lots of nice things. And I got interested in that machine. I finished up having one bought at slightly reduced price, around, I do not know, 50,000 dollars or thereabouts. And also I had visited the laboratory in St. Petersburg. It was just a few hundred miles train trip between Helsinki and St. Petersburg, and spoke with these Russian engineers, and my wife, who is half Russian, could speak Russian with them, and she thought it was wonderful. So we did a deal over the making of a small scale Martian robot, called a Marsokhod. M-A-R-S-A I have forgotten where the H is. Marsokhod you probably Google it, you will find it. So I went there, did a deal with these engineers, and we finished up drinking vodka and eating sausages, about ten o'clock at night in the European in the white nights area, it was light until 11 or something. And my wife had a wonderful time talking to these engineers in Russian. So it was a lovely sort of feeling, and then subsequently this robot was delivered without the motors, to Helsinki, where my colleague Aarne Halme fitted it up with Maxon motors, which were seen as the best at the time, and he then brought it as excess baggage to a conference he was attending in Australia, at my invitation. So in not that big, it was this big. So this thing was something that was just fabulous, because it had an articulated body that was made of aluminium, and it had slightly conic wheels that had special serrated sort of fins on it, and this was made out of titanium and aluminium. And titanium cannot be welded, so every connection was a rivet, manmade rivet, and I was told that the Russians were really good at mechanical design, but it was better to get the instrumentation done elsewhere, so the combination was Russian equipment, and Finnish setting setting up with the motors and the like. So that arrived and then I did a lot of work on that machine in a rough environment. But this thing could climb objects as big as its own wheels, just go over the top, because it was like being able to articulate over the body, and I do not know if you spoke to Rajesh Attila, but he had a full scale one of these for many years in a project they called Eden, and he will tell you how wonderful this design was. He had a more sophisticated one that could extend the wheels as well, but I had a lot of fun with that over a number of years, so the big track machine, and the Martian rover with two of my key experiments and a lot of sensory stuff, and then trying to work out how to navigate, how to climb things, how to build models in the environment, and I extended some ideas I had on path planning, originally in about 1984, and used it over and over again in different circumstances. I may go on and talk about that. This methodology is based on an idea called distance transforms. Distance transforms started out as a way of analyzing binary images, and the two key people were Asrel Rosenfeld, and John Pfaltz, I think, were the University of Maryland, I do not know if they were there at the time, but this became famous stuff on how to analyze binary images. And their interest was, if you are looking into a microscope, and you can see the outline of a cell, how would you make some measurements about the shape of that cell, and its volume and so on, and one of the ideas was to use what was called a grass fire, and when you light fire around the periphery and let it grow inwards, and you mark the path of this trajectory toward the inside, and that was called a distance transform, because if the outer layer was zero, the next layer would call one, two, three, and you got into the center, and you could do a lot of computation on those numbers, to work out things like the area, the amount of the the ratio of the perimeter to the area and these sorts of things. And general shape, and you could actually take the skeletons, a kind of compressed version of this, and recreate the original and so on. So my idea was to turn the algorithm inside out, and say, how do I get this same type of propagation arrow to work on the outside of things which I called obstacles? So my breakthrough was turning that algorithm inside out, and having something that propagated distance in such a way that it flowed around obstacles and it gave you a very, very simple way of global path planning. Because after you sort of had a start point, and grew distance out from that all around the obstacles, you now had all the free space, all the places the robot could go, with a number on it, saying precisely how many steps to the goal. And if you went down the quickest way, you were guaranteed a global solution. So that was my idea in 1984, and I found you could extend it to any dimension. So I actually had a three dimensional one. In fact, one of the very, I think the first ISRR, I came, I presented the three dimensional version of that. And this algorithm has been reinvented several times, once or twice, even in my presence, you know, I have actually been in a room where someone has said, ah, I have discovered this, and fortunately some gallant colleague has gone up and said, hey, that was done ten years ago. So this algorithm, it turns out that you can extend it, so one of the extension that I did was with a student of mine, about five years ago, where I said, instead of finding paths simply from A to B, what if you had to go from A to B, but be unseen from most positions, most of the time, so what I call covert paths. So had applications in security, how to get from A to B, to be least detectable, and then, how to go from A to B, if you knew a sentry looking for you has entered that door, and is going to move probabilistically through the space, where should you go to find a hiding place, where should you go if you needed to escape from a hiding place, and then that extended onto, you are in a disaster zone, where should you look for victims of an earthquake, and again, how do you find paths that are weighted by the expectation of certain things. And it turns out, these paths can incorporate all sorts of other factors about being seen or not seen, potential for discovering things, and it also worked when you do not know everything, you could say, for the time being, I will do this, and then I will get a little bit more, and I can do that, and shift. So it is fast enough to keep on applying. So this idea, I used for quite a few of my projects, and the simplicity, I guess I found appealing. I did not really want to get into very, very complicated methods when this suited what I wanted. So even my outdoor work, this distance transform was one of the key underpinning path planners I was using. And I had some students working on related projects on this. So I am still interested in the visual side, but for the outdoor projects, more in laser range finding than cameras, and the combination of how to build maps, how to plan, how to move. Now that was before this idea of SLAM had got any strength. The SLAM idea grew out of the need to go and explore new areas, and how to develop maps of new areas. And the only way you could do that effectively before that point, was to get out a theodolite or do a survey using standard equipment, moving very accurately from point to point, and taking readings of angles back to edges of buildings and objects and slowly but meticulously putting that together, and even in early surveying, this idea of closing the loop existed. So I remember mentioning doing surveying and stuff in my undergraduate, I remember there being a technique by which you started somewhere, you started to measure angles and distances, and when you went further and further round, the tendency would be small accumulations of error, because each depended on what you thought was your current location, that depended on your previous measurements and the idea in surveying had always been that, when you came back to where you started, you would say, this is meant to be zero, zero, but all my things are saying minus five, plus ten. So you knew you were in error, and then there was quite simple ways of distributing the error to make the corrections all the way along. Now the current SLAM is really that technique, but at a much more sophisticated level, and probabilistic, the use of common filters and extended it was all about how to distribute and propagate the error to minimize the but you still have to complete the closure, because a lot of controversy is how you absolutely know for certain you are back where you started. You make that mistake, everything blows up. So a lot of work in SLAM is about that. Now by the time I sort of realized how important this area was, there hundreds of people were already doing it, so I decided not to do it. So I went in the opposite direction, so I started doing what you could call the opposite of SLAM, so I bought a very with a colleague, we bought a very expensive laser range finder, which you could put in the middle of a city square, and over a period of two hours, collect every detail up to 800 meters away, right, so you could just the whole volume high precision, fractions of a well maybe half a centimeter, and with a high resolution camera, get it all painted as well. So instead of building your maps incrementally, I said, well you just put this down, you collect everything at once, and you now have a sort of a cyber-model of that whole space. And if you could not see everything from one position, you could pick three or four positions, and then you can, with a you can not automatically, but with a little bit of hand help, you can get the stitch together of all these things. So we did this over a number of spaces around the campus and also sort of a property I finished up buying out of Melbourne to do some of this big field work, and so I sort of argued that in some circumstances, where you have either acces to existing plans of buildings, or you are prepared to spend half a day collecting this information, if you are going to have a robot working there for ten years, the cost of collecting this is of no significance, so why do I need this complexity of a moving robot who is doing all this high calculations of common filters. So I just said, if you were prepared to do this once, and do it accurately, there was no need for that. So you know, That is so I am saying there is room for SLAM, but you could do it this way if you were being practical about an existing, relatively organized space. And then the notion was, okay, you have got this very exact map of things. Could you now put a robot in there, could find its way easily around this? And one of my students worked on the idea, you have a camera pointing up at a panoramic mirror, and it could see right around all in one hit. You could collect that image, and then you could hypothesize, where should I be to recreate that image from the cyber model. All right, so what you are really doing is saying, I have got an idea of what is there. Where must I be to get that same so that was nice. So you could actually say, I am collecting this live data and I could do a search using particle filters to work out where must I be in this cyberspace for this same data to be visible, and That is where you are, and that worked pretty well. So you could just move this robot around with its mirror and camera, and it could almost in real time, tell you where it was, and plot it fairly accurately. And it was not necessary, in fact, to have a robot, you could actually put it on a walking frame, and so this student actually bolted on a walking frame, and walked around like this, and you could see a map of where he'd been and so on. I thought, this is good. So later on, I got a second laser range finder, called a Velodrome, which is about the size of a human head, and can be bolted on the top of a vehicle. And that was not as accurate as the first one, which was called a Regal, if you want any details. A lot of people that bought these things. So what that could do was collect range data very, very quickly, up to 120 meters away, so it could collect one and a half million samples per second. So that gave the opportunity to knowing what is around you quite accurately, you know, ten times a second or something like that. You could spin it at about ten hertz. So it meant that you had live data from your vehicle, and it covered from about plus two degrees to minus 24, so it actually covered the volume that the vehicle may be running through, because you are not worried about overhanging branches above that, nor things, of course, under the ground. So it allowed you to not only avoid things, but we used that range data to now hypothesize, where must I be in the cyber knowledge to get this set of range measures, and you did not really have to use the 3D, you just use a slice. So you got the nice way of say8ing, I can avoid obstacles, but I can also and we found that in an area of about 150 meters by 150 meters, you could find out where you were to 13 centimeters, in real well ten times a second. So I am still working on that, because I think, well, okay, if I have a vehicle in a bush land setting and I am prepared to say nothing much has changed, of course one of the problems are, the trees grow, so, but if you use your scan about where the trunks are coming out of the brush, That is not going to change that much, as the growth above that point, so we found out, if you take something about a meter above the ground, That is reasonably stable. And I have been back to the same site six months apart, and it still works, and this sort of thing. So I am still keen to use this combination of pre-scan data and this fast scanner for localizing a robot, so I am going back out to this property to do this sort of work. I guess That is probably a good story, too. I bought this property when I knew that I could not do this work on campus, because there were not enough playing fields and stuff, and then students always come and gawk, and then it is dangerous, because this is a big robot, they could run over your feet, so there were all sorts of risk issues. So I got a bit frustrated, so I finished up buying a 20 acre property about three hours drive from Melbourne, it happens to be near some sort of foothills of some reasonably looking mountains and a fresh water lake nearby. it is a lovely spot, so we used it partly for mostly for the work, but we also enjoyed going out there. And so the big work I finish up doing with the fire engines and all sorts of things were done out there, so what happened is that I went to the Country Fire Authority, and we had a project with them for five years, and so the big stuff was done out at this property, so in fact, even today, I have three large fire trucks out there."
"Ray Jarvis","Interviewer","So you are not in danger of forest fires. "
"Ray Jarvis","Interviewee","No. The trouble is that I am not sure that there is even petrol in the tanks. I have got to be careful. Yeah, they could be used for firefighting. "
"Ray Jarvis","Interviewer","So you know, maybe some of the folks in the last, maybe ten because I think we got quite a bit early on. Maybe for the last 15 years. "
"Ray Jarvis","Interviewee","Well I had from 2003, to 2007, set up this center that I told you just slipped off the first rank when Hugh Durrant-Whyte got his center. And that was called The Center for Perceptive and Intelligent Machines, and I had partners in three other institutions. The partners in Melbourne were a group of people doing database analysis with artificial intelligence methodology, a group in Perth who were doing pattern recognition, and computer vision, and a particular individual working at the Australia National University who had spent 20 years studying vision in insects, particularly bumblebees. He was very well known for that work, and he had come up with some wonderful ideas about optical flow, which is a process by which you can work out three dimensional structure by working out how things move as you move through the environment. And he had picked out some analogies from insect vision to do this work. His name was Srinivasan, his he is sort of a world leader in this field. he is since moved from but anyway, it was his mirrors, in fact we finished up using, so amongst other things, he designed wonderful optics. Now they were the people that we collaborated with, but the collaboration was very loose. It was very hard to bring those four different interests together on focus, and, in fact that was pretty much the downfall of our center, because the finances were subdivided too early in my opinion, but that was the deal that I had to do, and it was very hard to jog people away from their current research interests. They were individually doing extremely well, publishing well, getting recognition, so there probably was not sufficient incentive to be more centrally involved. My job was to actually try and stir up more and more collaboration. I guess, in the end, I have to say I failed, could not get this to work. So They are my should be collaborators, rather than my but most of my work I have done just with my students, and to some extent with my immediate colleagues. I had not, in fact, done a great deal of collaboration sort of on the ground, except in very, sort of ethereal terms of saying talking to people at conferences and swapping a few things, so I found, because my work was highly experimental, it was not too good just swapping a theoretical paper. I actually needed people who had knowhow of how to build things, and right there on your particular device, so I did not collaborate a great deal."
"Ray Jarvis","Interviewer","So in terms of the one thing that Selma has been asking everybody, is in because They are going to do a piece on education, too. What are some insights or some advice you might give people even at high school age?"
"Ray Jarvis","Interviewee","Oh yeah. I guess to start with, we found that there were many students in undergraduates who developed a strong interest in robotics, partly because of a few demonstrations we could do, but also because typically computer systems people spend a lot of time sitting in front of a computer. And I think the prospect of actually seeing something move was kind of a refreshing thing. So we had no lack of interest, and for a while, I was teaching courses in pattern recognition, computer vision, automata theory, path planning, and they were usually a specialized group of students who were really interested in this. I was always excited of how students would come up with new ideas in small classes. So I was very lucky to have small, really interested classes, it made the job much easier. Now some of our students who had an interest in graduate work, would come to us, but I think our group attracted more foreign students than locals, in the longer term. We had a lot of students come from some Malaysian students, some Indian students, Iranian students, and some locals as well. So I think the second thing to say is, we told all our students, at least I told all my students, two things to remember, one is, do not read any literature until you have started to think about your project. That was controversial, because everyone said, hey, you have got to do a I said, do not do it. I said, three things can happen. One, you will find your ideas have been already done, that puts you off. The others, you find your ideas have never been done, but for good reason. And the third thing maybe that you feel that you have lost your ownership of something. I said, actually, it is better to think hard, ab initio, about a problem, and then when you have written down some ideas, then go and look at the literature, check it out, and that way you will get either affirmation, or you will be diverted. So the literature, I said, was actually corrosive. It would spoil your creativity. That was controversial but those students that did that, actually I think, got a lot out of that. "
"Ray Jarvis","Interviewer","Yeah, I could see that, because the other side is even just looking at a problem a certain way, and you start seeing it could be just slightly "
"Ray Jarvis","Interviewee","Yes, you may have found something new, and that newness is kind of gone, because you have been distracted. The second thing I think I told all my students is that in this center, we are only interested in theories that can be proven with physical experiment. We told them right from the beginning. Have good theories, but we want to see the thing move correctly, and that was always the, kind of motto of our group, in fact, all my colleagues believed in that, too. So that was good, because it meant that if you had someone who was just strong in computer science, but had done very little hobby type things, they got told, well you better find out how to make something, go and talk to the people in the machine shop, get to make your things, know how to put the wheels on and stuff like that, so our students generally were able to were good at maintenance of their own projects, right, so that was the second thing, and I guess the third thing was, once you have got this idea and you have looked at the literature, sort of aim pretty high. there is no use just incrementing an idea by epsilon, you know, aim for something exciting, and even if you do not quite get there, well you will get a better thesis than you otherwise would. So That is it. "
"Ray Jarvis","Interviewer","Yeah."
"Ray Jarvis","Interviewee","Done? "
"Ray Jarvis","Interviewer","Sounds great, we really appreciate it. I mean, unless there is "
"Ray Jarvis","Interviewee","No, no, no."
"Red Whittaker","Interviewer","Introduce yourself and tell us where you were born and where you grew up and where you went to school."
"Red Whittaker","Interviewee","My name is Red Whittaker. I grew up in Hollidaysburg, Pennsylvania. it is a little town near Altoona in central Pennsylvania. My high school was Hollidaysburg, my undergraduate was Princeton, and my graduate work was at Carnegie Mellon University."
"Red Whittaker","Interviewer","What did you study as an undergraduate?"
"Red Whittaker","Interviewee","Engineering."
"Red Whittaker","Interviewer","Mechanical, electrical, both?"
"Red Whittaker","Interviewee","All the above."
"Red Whittaker","Interviewer","How did you first become interested in robotics?"
"Red Whittaker","Interviewee","I built a great deal as a child. I had my tools, I had a junkyard that I could pilfer, and I made things, a lot of things, and dreamed a lot, dreamed about space, dreamed about robots and built things and made them work. After my formal education, I sought something that would dent the world that I could do with my own hands that would happen in my time. I considered computing; that was a little cooked. Computing would do well with or without me and robotics- my brand of robotics, field robots, were still the stuff of science fiction dreams, fantasies, and That is the one that I chose for my life."
"Red Whittaker","Interviewer","What do you consider to be your first robot?"
"Red Whittaker","Interviewee","Well, my first robot was the explorer that entered and ultimately cleaned up the basement of the Three Mile Island nuclear reactor and that was a galvanizing experience, also an important milestone in the field robotics technology and trade. And then if We had really trace back at the age of maybe eight I made a robotic space creature and spaceship to travel in and so it is hard to say which one of those really has the impact in my life."
"Red Whittaker","Interviewer","How did you wind up making the robot for the Three Mile Island cleanup?"
"Red Whittaker","Interviewee","I had chosen robotics, chosen Pittsburgh as the place to make it happen and speculated on what robots might be out in the world, not in buildings, not assembling and spray painting cars, and sought that opportunity to make it real and take it to the world, and Three Mile Island was that kind of opportunity, was a place that precluded humans, was a compelling motivation for need and agenda, it was local, and something had called to me. It was very purposeful."
"Red Whittaker","Interviewer","Had you already built the robot before the disaster—"
"Red Whittaker","Interviewee","Oh "
"Red Whittaker","Interviewer"," or did you build it "
"Red Whittaker","Interviewee","Robotics was in infancy so that idea of a full-up operational working machine was a little bit beyond belief and it was an era where there would be no research initiatives for robotics, no- certainly no research contracts in that area. So what I pitched and sold was a full-up functional working competency, a tool if you will, as though it were accomplished, as though it were available, as though it were on the shelf. And then with that charter and commission to deliver the great tool I took the money and burned around the clock for about six months and delivered the goods. It was not expected so when I delivered that robot they were a little astounded, not really expecting that there would be a robot, that it would be real, that it would be ready to go to work. And those operations and everything that it took to apply it and make a success of it was also a big part of the experience."
"Red Whittaker","Interviewer","What were the biggest challenges in the robot?"
"Red Whittaker","Interviewee","Ooh. The first was to endure. The idea of going right out of the laboratory and in to work and to operate for years without fault was above the standard. The next was that it was sealed, submersible. It was a flooded basement. It required a very forceful, effective mobility. It required that ability for operation from substantial separation and also to convey enough of the situation to an operator that it was possible to get the job done."
"Red Whittaker","Interviewer","It was a cable control system?"
"Red Whittaker","Interviewee","It was tethered, it was radiation hardened, it was very So let me take that one again. Could you ask it once more? Was it tethered?"
"Red Whittaker","Interviewer","Was it tethered?"
"Red Whittaker","Interviewee","Yeah. So it was tethered and I remembered many comments from the day that well, That is not a real robot, and I have never been too religious about what is a robot, what is not a robot, and at the time robotics was very full of itself, a kind of a priesthood of what robots should be in an era when there really was not much of anything around of real competence doing anything. "
"Red Whittaker","Interviewer","How did you train the operators who operated that?"
"Red Whittaker","Interviewee","So there were three volumes including maintenance and operation and then lots of training sessions and hours and hands-on and tremendous human force, human capability that was with and around this to make a success of it. And in the early days if there was that community initiative to succeed then something was possible and without that then no matter how great the technology would be the whole enterprise would go down. "
"Red Whittaker","Interviewer","How many people did it take to put that together in six months?"
"Red Whittaker","Interviewee","The original cleanup robot was a children's crusade; it was an army of youth. Like many great robot teams it was maybe a head count of 25 and a dirty dozen of 13 stalwarts and 3 or 4 on the inner circle who would burn and die and give life to make it work."
"Red Whittaker","Interviewer","Were these your students or was this a company or "
"Red Whittaker","Interviewee","Since that whole experience was emerging from the primeval ooze, there would not be the graduate culture because there would not be degrees, and so these were students and enrolled from mostly the undergraduate ranks who just delivered with incredible hours and initiative and intentionality, a great craft culture going well beyond the big ideas to implementation and refinement, a great deal of testing, no boundaries for time, effort or what it would take to do the job."
"Red Whittaker","Interviewer","Did those core three or four stay with you? Did they "
"Red Whittaker","Interviewee","Oh "
"Red Whittaker","Interviewer"," doing what?"
"Red Whittaker","Interviewee","Those three or four have gone on to be the greats so I am sure So one of the student leaders from the nuclear cleanup machines educated Master's and Ph.D. in the trade and then went on to lead a great research group for a while, then led the Robotics Engineering Consortium for its heyday and has now recently created his company "
"Red Whittaker","Interviewer","Who is that?"
"Red Whittaker","Interviewee","Carnegie Robotics and the who is John Bares so I will try that again. So John Bares, a student leader of the nuclear cleanup robots, was conscripted as a sophomore, paid the dues, educated with undergraduate Master's and Ph.D. under my direction, led the Robotics Engineering Consortium, and most recently founded Carnegie Robotics."
"Red Whittaker","Interviewer","Who are some of the others who worked on that first project?"
"Red Whittaker","Interviewee","One is Chris Fromme who went on to be the chief technical officer of RedZone Robotics, has built himself in many ways and is still quite active in the trade. And another woman, Leona Champeny, was a tremendous technologist and businesswoman in her day and then stepped aside professionally for one of the great Leona Champeny, a woman leader in the team, was a great technologist, a businesswoman, then stepped aside for an early romance and to build a great family. "
"Red Whittaker","Interviewer","When did you start RedZone Robotics?"
"Red Whittaker","Interviewee","So RedZone was created in 1987. "
"Red Whittaker","Interviewer","We will edit all this later."
"Red Whittaker","Interviewee","Yeah, I am sure."
"Red Whittaker","Interviewer","After the Three Mile Island robot what was your next big "
"Red Whittaker","Interviewee","Oh "
"Red Whittaker","Interviewer"," robot project?"
"Red Whittaker","Interviewee","I embarked on the Three Mile Island robot in the fall of 1983, delivered it in April of 1984. That first entry into the containment building was in November of 1984. By that time the two great developments was the first of the autonomous robot excavators and significantly the first outdoor navigation machine, the Terragator terrestrial navigator, and both of those were completed in 1984. So the pace, the rate at the time, were two or three great things a year and small things more often and once embarked there was no looking back. Field robotics has never run out of great things to do, great machines, technologists, places to go, and it is not over yet and I am not dead."
"Red Whittaker","Interviewer","Could you talk a bit about some of the other landmarks along the way? there is the volcanic exploration "
"Red Whittaker","Interviewee","Yeah. Well, the- these robots are not apples and apples; They are not So some robots are significant for what they do, some for the technology That is under the hood, some for where they go. So let me try that. So perhaps the biggest transformation in field robots was the mastery of outdoor navigation and that was once viewed as a challenge that was beyond reach in our time, and in an era when robots were unsuccessful moving down the hall and turning left at the first intersection field robotics was already out in the world and down in the coal mines and going up against the world as it occurs, not as faked or contrived for success. And the Terragator was the first of these great machines and its distinctions included the first navigation of a sidewalk by camera imagery, the first use of laser scanning aboard a mobile robot, first three-tiered robot architectures, first accomplishment of continuous motion. In the early going, mobile robots were not very mobile. There was a lot of stepping, stopping, processing, inching, stepping, stopping, processing, sometimes a year- sometimes a foot at a time or a foot, then an hour, then a foot, then an hour depending on the complexity, and then mastering the changing of seasons, the different lighting conditions. And then there was the step-by-step evolution of trail following, road following. In the field robotics world, mines, caves are the working environments that are corridors and the enclosed, having ceilings and walls as well as the open world, and so robots in that lineage were the Navlab, Navigation Laboratory. That was 1986. it is a blue Chevy van, built it out in the snow, did not have a shop at the time, and it was one of those religious moments when it gets up and goes. And then the machines that followed in 1988 and 1989 were the quiet development of the off-road rock trucks and the introduction and mastery of GPS to guide an outdoor machine; I actually have the first patents for that on the wall. And of course looking back there is nothing to it; you want a GPS now, you put it in your watch. There actually was a time when each channel was rack mounted and the satellite constellation was not in the sky and the estimate of position was maybe within a city block but not capable for navigation and where the window was available 20 minutes a day and the latencies and errors were beyond reach."
"Red Whittaker","Interviewer","At what point did you guys find enough to really do continuous navigation?"
"Red Whittaker","Interviewee","The timing for competent GPS navigation depended a whole lot on who you were and how you went after it and that- I first exhibited that competently in 1987 by a thread and then a higher reliability, higher speed navigation by 1988 and incorporated into off-road rock trucks in 1990. "
"Red Whittaker","Interviewer","What were some of the innovations in the excavation machinery?"
"Red Whittaker","Interviewee","Excavation is a penultimate application of field robotics because it took robotics into the natural world. At the time many of the AI manipulation programs were stacking blue blocks on red blocks and yellow blocks and that is a world of formal geometry and shapes, colors, whereas excavation is a little like playing in a sandbox. it is a diffuse medium and it is shaped by interaction with manipulation and then it is particulate; it is not a continuum. Moreover, it was not enough to use vision. It was not enough to just see because the working end of an excavator tool was actually below the surface and it is a problem where a great deal of force and reasoning about force mattered and at a time which was so before the capability of most of the technologies that could be applied to do that today. I can remember to get the compute power for it exploiting one of the first parallelized geometry engines and then to utilize that right in the robotic control to speculate, formulate on bounding boxes and changes in geometry and how the joints might change and to do that at a rate that would exceed the implementation of motion. "
"Red Whittaker","Interviewer","You did a lot of wheeled robots but you have also done some walking robots."
"Red Whittaker","Interviewee","Wheeled, tracks, legs, flying. I am not religious about how to get around, mobility, yes, it is meant the world- it meant the world. Before the fulfillment of field robotics, the working world was nailed to the floor and then the transformation was to take these mobile machines to the world and to the work and there is no going back, but yes, good working- good So walking machines have included Mars prototypes like the Ambler and if you are going to go into volcanoes Dante's a pretty good name for a walking robot, and Dante was distinguished in that it was a repelling machine so beyond walking it was a climbing machine and then coordinated the forces on its tether in such a way that it could negotiate vertical and even overhung surfaces. "
"Red Whittaker","Interviewer","What were some of the challenges on those machines?"
"Red Whittaker","Interviewee","Some of the great challenges in the climbing machines like Dante were achieving the energetics and forces relative to body weight in earth gravity so in an era when actuation was not so capable and that power density was not so capable it was challenge enough to get the forces and get the forces in the right place and then to coordinate all that motion in such a way that you are not working against other motions, not performing isometrics but coordinating to do useful movement. Other innovations in Dante was the first of the spherical laser scanners, first of trinocular vision. Humans are used to getting by with two. Dante on its mast coincidently had two sets of trinocular so a total of six cameras and all the software that made that work and blended and fused the two sets of 3-D from the two sets of trinocular in order to get a composite range and then to merge that with the laser. Dante had noncontact proximity sensing in its feet so that it could sense how close is the ground without touching it. "
"Red Whittaker","Interviewer","Beyond pragmatism, do you have a design principle or something that conceptually drives how you design them?"
"Red Whittaker","Interviewee","In conceiving and actualizing Dante, I performed a great number of genetic variations and determined that for its overall mission that a decapod, a ten-legged thing, was the right way to go, and there was a little part of me that just could not do it in part because if ten legs was the right way to go why would not we see it in nature. So I built the eight-legged thing and deployed it in Antarctica and one of the great moments of that experience was on the shoreline of the ocean seeing these little walking creatures that had ten legs. So it turns out that there are hundreds and hundreds of decapods in nature; I just did not know about them. Now I know a lot about them. But I embark with the vision that for every biological creature there is or will be a robotics counterpart and that despite all the tools and methodology for configuration and auto-configuration and proportioning and shaping of machines I apply the insanity check to see that a machine configuration as a counterpart in nature. "
"Red Whittaker","Interviewer","Do you directly draw inspiration sometimes from natural systems?"
"Red Whittaker","Interviewee","Absolutely. So we one of the great influences for me is Carnegie Museum which is 300 steps away from where we are sitting with some of the world's greatest collections of biological things, anywhere from the great dinosaurs to the tiniest insects. And yes, I study them a lot. "
"Red Whittaker","Interviewer","Hmm. Can you tell me about the First "
"Red Whittaker","Interviewee","I learned about the first Darpa Challenge on the 14th of March 2003, which coincidentally was exactly one year until it was competed on the 13th of March 2004. So that was a clear one-year time period to go get it done. And when I heard about it, it sounded like it had my name on it. So I got a team together rand went after it. About the nine-month mark, I scraped the first dollars together and in technological challenges, you do not start with a budget and you do not ever have what you need, just what you have at the time. I brought a junk cover from a farmer and cooked some technology, got a pick-up team, and showed up in the Mojave. I was playing to win and I came off the starting line good race pace, ahead of the game, and destined for the speed and the distance. Got wind, veered off, and high-centered maybe seven miles in. And there really was not anything that was close, meaning that there was nothing in the field that would have the speed, distance, duration, technology to pull it off. Not sure that anyone had the competence to win that race. It was maybe beyond accomplishment in the nine months. And then a lot of the popular reaction was that it was a falling, Oh well, it went seven miles; well, it was only averaging 15, 16 miles an hour. And that was just built the story for the next time around. "
"Red Whittaker","Interviewer","What was it that actually caused it to veer off course?"
"Red Whittaker","Interviewee","So I have the unique distinction of having rolled more Hummers at high speed that any roboticist on the planet. And in preparations leading up to the race, was really pouring in long-distance, high-speed practices and in the course of one high-speed turn, rolled that Hummer a week before race day. And so that was a comeback story coming out of nothing; long hours, pretty steep odds, and rebuilding. And the whip calibrations were not quite right; the sensing was not quite on. And the difference between the orientation of the sensors in the vehicle were enough to offsite that Hummer to the outside in a curve and that was enough to go over a berm on the other side of the road, which then high-centered the front axle. "
"Red Whittaker","Interviewer","And then when you came back for the Second Challenge?"
"Red Whittaker","Interviewee","Well, let us see. So how the first race worked is that nobody won and that evening, it was announced that well, It will be competed again and will double the prize. So I deliberated and viewed that it was that there was some unfinished business. And so this time around I got another Hummer and another team and another sponsorship and put it together and really had the dominant technology. And I had two machines that could take anything anytime, any day. I just whatever the capability was, say in a practice or a trial, if somebody could show a capability, I had just notch it a little higher; capability, notch a little higher; two machines, either interchangeable. Coincidentally, I had rolled one of them, but they were ready to play on race day. Now since I had two machines, I went in with a rabbit and hare strategy and had the slower one finish about the time that I estimated the competition would come in. And to the quicker one, to beat the competition by one hour. And they were interchangeable, could go either way. So about three-quarters of the way in, the lead dog was maybe 40 mile 40 minutes ahead gaining in every second, looking strong and lost engine power. So, if you can believe it, the Hummer engine died on me and that shockingly how it worked was that it would die to an idle and stop and then get a little bit of engine surge where it could pick up and travel almost to a walking speed and saw-tooth to a stop and then that engine'd get to a little walking speed It will like and then it would keep that up. And it kept that up for all those minutes. And meanwhile, that slow second would keep creeping up and right before the finish line, there was the crossover. But surprisingly, even without an engine, it came in just fine. They both did within a couple minutes. And the post-race analysis showed that a fuel line, flexible fuel line was kinked. Now after the race, I got in to drive it back to the tent and would not drive and looking over, saw that a fuel line was kinked and that that sharp dent in the fuel line was probably a consequence of putting it back together after the rollover. The so"
"Red Whittaker","Interviewer","So who were your teams on the first and second race? Who were the leads?"
"Red Whittaker","Interviewee","Who were the team the leads? "
"Red Whittaker","Interviewer","Leads are your top "
"Red Whittaker","Interviewee","Yeah. "
"Red Whittaker","Interviewer"," students in the "
"Red Whittaker","Interviewee","Great. "
"Red Whittaker","Interviewer",". "
"Red Whittaker","Interviewee","So the challenge race is the significant development of the challenge races was to really build a community, a world community and some of the greats from my team was undergraduate, Kevin Peterson , a graduate student, Chris Ermson , other technologists like Dave Ferguson . And in many cases, these were people who would then find themselves in the work and commit into it and commit their lives to the future of automated automotive automation. So these were very diverse teams, everyone from the PhDs from the robotics trade to a volunteer whose day job was with the post office. And it to really do it the way that we did it, took a little bit of everyone; takes a village to dot that kind of thing. there is never enough money; there is never enough time to think about that kind of initiative. It really you can not buy souls to do that work; there is not enough money to pay people off and you can not birdfeed or twist arms. They play for their lives; they play with their souls. "
"Red Whittaker","Interviewer","How many people altogether are on each team?"
"Red Whittaker","Interviewee"," 30 is about right for the challenges and That is in part because there was a lot of mechanism there were a lot of logistics because we were from the east and the practice in racing was from the west. That First Challenge was maybe a quarter million lines of software. The Second was maybe three-quarters of a million lines. Nah, I take that back. The First Challenge was maybe a hundred thousand liens of software. The Second was maybe 300,000. The Urban Challenge was maybe three-quarters of a million lines of software. So there is that going on. And then there electromechanically, They are built and one of the developments for this group was to create a stabilized gimbal, a mechanical neck that would point in the best direction for the sensors to work and keep those sensors rock solid no matter what the vehicle has done under. We imagined that the races were going to be the difficult terrain and the high speed that was advertised and the long distance that was advertised. And so we trained on terrains with difficulty 5, 6, 7. Competition days were 2, 3. And in those kind of blistering terrains, we just butcher suspensions and go through tires and hammer chassis and that kind of program really called for lots, lots of people, lots of different kinds of people. "
"Red Whittaker","Interviewer","And who were your sponsors?"
"Red Whittaker","Interviewee","Caterpillar was an enduring sponsor through all the challenges. And in the Second Challenge, I had the good backing of: Boeing, SAIC, a little from Intel, some from Google. In the Urban Challenge, the big dogs were General Motors, CAT, and Intel was back, Google was back. Continental was a very interesting company; they make great automotive radars. And all the sponsors are sometime sin for the adventure or the branding, sometimes in of the technical participation. And so a caterpillar is authentically driven to the future of off-road automation. A General Motors is all in when it comes to automation and safety features for the road and they will be for eternity. "
"Red Whittaker","Interviewer","Can you tell us about the Urban Challenge and how you got that one?"
"Red Whittaker","Interviewee","Chris is the Urban Challenge was just long time later; there was a big gap in there in six months. And the Urban Challenge was announced on the second of May 2006 and then competed about 18 months later. So that is actually a long, long time. And I deliberated quite a bit before embarking on that one. By that time, it is pretty clear that the fundamentals of automated driving were mastered and that the right kind of program, right kind of team would do a good job with it. And I really did not have a sense of any unfinished business or I it was not lifted or compelled to chase it. If I were known, I am actually not a prize junkie; and then I for what it I pondered a month and really did see that there was unfinished business, that just was not okay to have left that hanging impression of a dead Hummer engine out in the desert. So I chased it and nailed it and really no looking back. It was a real accomplishment in the arena of behaviors, of planning that would go layers deep. The perception developments were machines that would sense in all direction, surrounding themselves and at a high resolution and with the quality to really understand environments; of course, takes some computing to go along with it. It really built great, great community, great people. These challenges have a way of transforming belief. Before the fact, there is that sense that They are a little bit beyond reach or it will not happen in our time. And course after you do them, the world looks back and kind of, Oh, it was nothing to that, and it gets old pretty quickly. That adage about 15 minutes of visibility definitely applies to technological challenges. And then it is a magnificent time in the robotics culture when three technological prizes occur in quick succession; that is not common in other disciplines. And so to have the Grand Challenge, the Urban Challenge, and the Google Lunar X prize "
"Red Whittaker","Interviewer","Can you tell us a bit about your efforts in the Google X Prize? "
"Red Whittaker","Interviewee","Google is offering $24 million for a robot that broadcasts back from the moon and I will win that. There are bonuses for going 5 kilometers and that is just sock and trade for a good robot outfit. There is a bonus for navigating to a historical location like Apollo. there is a bonus for operating after enduring the very cold, long lunar night. And the reason why that is a $2 million is that it is believed to be undoable and I have got that one nailed. "
"Red Whittaker","Interviewer","Bringing a sleeping bag?"
"Red Whittaker","Interviewee","Ahh, sleeping back works fine on Mars; Mars is pretty soft stuff robotically. You have the advantages of an atmosphere so you kind of Frisbee in, then you pop a parachute, then you float down, take all the energy out of it and then you really can get by on Mars with a sleeping back for a human. It does not get so cold, does not get so hot; just beautiful for electronics. Ultimately the moon is as hot as a baking oven and is as cold as liquid nitrogen and has the hard vacuum and the radiation of space and is a very challenging environment for a robot. And so a part of it like all of them is a good electromechanism, a good amount of it is the sensing which always evolves, it get s better. And then in the case of the moon, some of the tough stuff is the propulsive descent and landing. You get one chance; it is it happens fast, it is unforgiving and it is it controlled sensing and propulsion the whole way in. So there is a lot on the line in those few seconds. "
"Red Whittaker","Interviewer","And how do you launch? Do you have to have a private launcher or"
"Red Whittaker","Interviewee","You do not. So you the I am launching with a Falcon 9; that is a commercially-built launch vehicle. Once in orbit, the upper stage of the Falcon 9 reignites to throw this spacecraft towards the moon. It then cruises for a couple of earth days, floating and then when it is near the moon, it visually walks onto the appearance of the moon and registers itself for orbiting, lines up over the intended landing site, and at the right time breaks on in. The slower you go, the more that you get pulled by gravity. And the last couple hundred meters are merely a dead vertical elevator descent where the sensing and the controls bring a very soft touchdown. Back in the day, this style was for big linkages and a lot of mechanical absorption of energy and That is done because there was not enough sensing and control for an ultra-soft landing. And my bet is on the sensing and computing and the controls that'll bring it in so that a fairly rigid spacecraft is able to level and touch right down. "
"Red Whittaker","Interviewer","So who are some of the people you are collaborating with on the"
"Red Whittaker","Interviewee","Ooh, so the my allies for the moon are a great frontline: General Motors, Lockheed Martin, Caterpillar, Aerojet for propulsion, Harmonic Drive for locomotion, International Rectifier, one of the greatest hardened electronic firms in the world, and sponsors yet to come. "
"Red Whittaker","Interviewer","And other roboticists?"
"Red Whittaker","Interviewee","Generally, the challenges have not attracted mainstream roboticists. it is interesting that every time that I embark on a prize competition, an early move is to offer it, This one is for you. This one has your name on it. Well, what if I lose? Mm, is that the right kind of activity if I am pursuing tenure? Well, of course, the sure way to lose is if you do not play and prize competitions are not for every person in the same way that They are not for every institution. So although I had anticipate that there is a lot of collaboration yet to come, today it is a little solitary. I would not call it lonely, but it is solitary. And then most of the kindred spirit is that fountain of youth that just bubbles up to go for it."
"Red Whittaker","Interviewer","Yeah, over the whole course of your career, who are some of the students that and people that have worked for you that really stand out in here? . "
"Red Whittaker","Interviewee","Oh. I do not pick favorites with students or people any more than I pick favorites with robots. it is a little bit like a really good family who have favorite kids for gosh sakes. Oh, yeah, I have loved them all, I have loved them all. "
"Red Whittaker","Interviewer","But others that have gone on to be successful roboticists? "
"Red Whittaker","Interviewee","Well, here within Carnie Mellon [sic], graduates from field robotics have gone on to lead the Robotics Engineering Consortium, the first of the tenured teaching professors, be the first to the tenured research scientists to I am not sure I am saying anything here. I mean, this bus I just am not big on picking choosing people. So I am sorry that that does not "
"Red Whittaker","Interviewer","That is okay."
"Red Whittaker","Interviewer","How do you motivate them? I mean, you work with very with large teams of people—"
"Red Whittaker","Interviewee","The first essential element of being up to something is purpose. And so, an early one that we spoke about was clean up Three Mile Island. that is a pretty wordy mission statement, probably the longest I have ever tolerated in my career. And others are win the race. And these are battle cries that call to people, not to everyone, but some people. And then the next is to get clear that it is a commitment and that we are bound in common purpose, in for the duration no matter what. The next is very clear metrics of success and that They are objective. That is something That is uncharacteristic in a great deal of research and extremely powerful in life and in technological leap, distinct from inch at a time, bite at a time, step at a time. there is more to it, and those are the basics. I am not so sure that it is possible to motivate teams or others that do not motivate themselves. And That is why an enterprise that is intrinsically enrolling, meaning that the thing itself is the powerful draw go to the moon for thirty million bucks. People from the world email, call, how do I play? I had someone from China just asked how do I join the X Prize team. And I responded start swimming. And, of course, I have no idea whether I will see that person or not, but That is how you tell whether somebody really wants it. "
"Red Whittaker","Interviewer","We have to meet Chris upstairs in five minutes, but what I can do is I can go upstairs just to make sure that we are not late or whatever. And you can finish up because I think that makes sense. I will be out of your hair in a minute. what is the room number? we are not in a room. we are going to meet at the Oh, you are meeting in the cafeteria? In the lobby. Yeah. I will let her get by here. So, I am going to ask you about the combine."
"Red Whittaker","Interviewee","About the ?"
"Red Whittaker","Interviewer","The combine?"
"Red Whittaker","Interviewee","Oh, yeah. "
"Red Whittaker","Interviewer","Go ahead. No I just wanted to say thank you very much, great meeting you. "
"Red Whittaker","Interviewee","I am sure you will cut something out of it. Great pleasure."
"Red Whittaker","Interviewer","Bye. Okay so "
"Red Whittaker","Interviewee","I was a so, I am recalling Nomad, which is a great name for a robot that roams the desert. And Nomad is a veteran of Antarctic meteorite search, veteran of the Atacama, discovering actually the first little meteorite there and also the first fossil. And Nomad is unique in that it was a mouse done in AI as well as robotics in that it was a search engine in the natural world. So, it was the first to have a classifier and the first to learn, in this case, what is a meteorite and what is not. And there is just so much in the mobile robot community about navigating, and avoiding obstacles, and safeguarding, and planning. And that is shallow relative to the purposeful action of a good machine. I thought about Nomad because it has maybe three thousand parts. And they were designed and developed by two great master students Eric Rollins, Ben Shamah. They never took real jobs. They created Velocity 11, and then sold that to Agilent. But they are the roboticist's roboticists, the great builders. there is whole generations of those great ones. Robotics has taken me to all of the continents and both the Poles, out to sea, underwater, underground. And the real gift are these great people. Certainly there is something to say for the technology and the machines and what they do and how they have become successful in enterprise, and in what we do. The people really remain the great gift. Anyway we were talking about you were calling it a combine, so the I came to the idea of driverless farm machines working on my own farm. And the miles are endless. With narrow equipment, it takes about a mile of driving to cover an acre. And then That is done many times a year, repeatedly, persistently over the years in the same patterns for generations. And I am a big I work a big land, mostly at nights and weekends. And I am pretty serious about my day job. So, it is pushing the hours and working into dark. And I awakened being slapped by branches. And I had fallen asleep while doing tractor work and drove right into the woods. And I swore that would never happen again. And later in the same year, I woke up going very fast downhill. And I rolled a machine. And then I said this really is not going to happen again, and considered the automation of tractors and fieldwork, and considered that this is a fairly slow. it is remote. it is not a lot of people around. Almost is good enough. And that it is an immense industry. And the rest of it really was fairly straightforward. And not too long before having the first driverless tractors together, and then that has gone on to become quite an industry. Now, if you want it, you could buy it from the factory. You can get add on kits that will steer for you, and throttle for you, and drive those impeccable patterns, miles at a time, dead straight, no overlap. It is something that really, really makes sense in the market, and one of those big changes of before the technology and after. And it is amazing that almost everything that humans have comes either from mining or farming. And field robots are making immense impact in both of those and gaining ground every day. "
"Red Whittaker","Interviewer","Did any of your technology go into these commercial automated farming ?"
"Red Whittaker","Interviewee","Oh, of course. Sure. "
"Red Whittaker","Interviewer","Which companies adopted your technology?"
"Red Whittaker","Interviewee","Commercializations that came from those early automation ventures included John Deere, there is one EZ Steer, which is a branded name, Trimble, others that now commercialize those features for tractors. "
"Red Whittaker","Interviewer","And just to go back to the very beginning again. So, who was your thesis advisor, and what was your graduate thesis on?"
"Red Whittaker","Interviewee","My thesis advisor and mentor in life is Paul Christiano. That was in civil engineering. And the topic was a dynamic analysis of plates on elastic media, very mathematical, involved the integration of complex Hankel functions and some math, which at the time was hitherto unachieved. And now, it is so interesting to go back into the numerical packages that have that be computed in a second without a great deal of depth, but at the time challenging. Paul went on to lead a department, lead a college as a dean, lead a university as a provost, and is now deceased. "
"Red Whittaker","Interviewer","And how did you start your faculty position at Carnegie Mellon?"
"Red Whittaker","Interviewee","I am born to teach. And I came along in grad school at exactly the time when undergraduate enrollments peaked. And there was a demand for teaching. And I stepped into that, teaching much of the engineering curriculum starting as an early graduate student. And I do not mean TAing, I mean teaching the whole thing. And I credit a great deal of what I know and what I can do from the teaching of it, and of course, these great teams over years by engaging and working with students. So, when I graduated, I was offered a teaching research position at Carnegie Mellon and embarked on that. I picked up the Tear award for teaching excellence, and then moved from teaching into research as the vision of field robotics pulled on me, the work over time to create the institutions, the degrees, the education, the base of research, the literature, the identity "
"Red Whittaker","Interviewer","So, did you start out in teaching in the civil engineering? And when did you come to realize "
"Red Whittaker","Interviewee","I started teaching in civil engineering, but a lot of crossover into mechanical. I was broadly capable across engineering and did my teaching in civil, mechanical, and electrical. "
"Red Whittaker","Interviewer","When did you come to the Robotics Institute, or when was it created?"
"Red Whittaker","Interviewee","The Robotics Institute was created in 1979 with a corporate gift from Westinghouse Corporation. And I embarked in the engineering college as a PhD graduate in the same year, and came up developing the robots for the working world while the Robotics Institute was evolving from computer science. And then the great marriage of the two, my formal crossover was 1986. "
"Red Whittaker","Interviewer","Okay, I have to run, but is there anything you would like to add before I go?"
"Red Whittaker","Interviewee","It amazes me that field robotics has come into its own, say, in planetary exploration where there was no sense of a robot and a clear perspective that it was the realm of astronauts and heroism, and romanticism. And now, there would not be a human mission on the books. And our eyes and ears to the planets are robots. Or that field robots would be so mainstream in the developing the world, exploring the world, securing the world, and in worlds beyond, that there is such an early consciousness for land, sea, air, space. And it is amazing to see them fulfill even underground in a subterranean world, everything from sewers to caves to mines. it is a pretty big leap for a couple of decades. Anyway, the "
"Red Whittaker","Interviewer","Any advice for young people that want to get into robotics?"
"Red Whittaker","Interviewee","I envy the timing of people coming into robotics now and reflect in many ways I was a little too early for the game, that these early work machines have been a little bit beyond the capability of computers in their time or in the early going to have to make digitizers for a camera, or controllers for a motor, or to embark without computers that could really do much of anything. And That is if all were known, I would have done just fine. But it is amazing time and amazing decades to come. And this trade is good for lifetimes yet to come. And for people embarking, the trick is to get in the game for real, that nobody begins with a lot of mastery or even breadth across everything that matters. You start by doing something, and ordinarily it is one something that you know or where you can contribute. And then by the doing of things and by osmosis and through experience to pick up the rest of what is called for. And there is also a great advantage in starting early. So, I am from the era of the great imposters, meaning that it was before the time of robotics credentials in the same way that the Wright brothers would be before the time of aeronautics degrees. And my own life work did not really start until the mid-thirties. And the opportunity now is to engage and immerse so wholly, and to do so from youth. That is what makes the great ones. "
"Red Whittaker","Interviewer","Thanks."
"Red Whittaker","Interviewee","Sure. "
"Reid Simmons","Interviewer",".in your career and robotics and We will just start by asking where you were born and where you grew up? "
"Reid Simmons","Interviewee","Okay. I was born in Akron, Ohio, lived there for two years and then moved to Buffalo, New York, where I spent most of my formative years. I was an undergraduate at University of Buffalo, so hometown and then went on to spent a year working for a company in Ann Arbor doing computer design, graphics, and then moved to MIT to do my graduate work in artificial intelligence. "
"Reid Simmons","Interviewer","And when did you first encounter robotics?"
"Reid Simmons","Interviewee","When I first encountered robotics, so Rod Brooks was at MIT at the time and he was very active doing robotics, so a number of his grad students were contemporaries of mine and I saw what they were doing and they had robots running around the lab, but I was kind of a good old-fashioned AI guy and did not actually do anything in robotics during my graduate work. When I graduated, I was intended to go into industrial research and That is where I spent most of my time looking for jobs and then towards the very end of my job search, I get a call out of the blue from Tom Mitchell who along with Red Whittaker and Takeo Kanade had landed a fairly large NASA contract to build a prototype Mars rover and Red was going to do the mechanism and control and Takeo was going to be doing the perception and Tom was going to be doing the AI. So he was looking for someone who post-doc could come in and do AI for robots and it was such an intriguing idea, something I had never really considered, but it was such an intriguing idea that I ended up taking the job. Figured I had be in Pittsburgh two years for the post-doc and 22 years later I am still here and it is funny actually. A couple of years ago, one of my students came up to me with a copy of one of my papers that I had written when I was a graduate student and he said, Is this you or is it a different Reid Simmons? because he could not believe that what I do now that I had worked in this very different area 20 years ago, but so I basically completely changed focus of attention once I got to Carnegie Mellon."
"Reid Simmons","Interviewer","In your graduate work, what was your thesis and what was this paper?"
"Reid Simmons","Interviewee","The thesis work was on combining what is called causal reasoning, first principle reasoning, and role-based systems and I did the work in the domain of geological interpretation. So basically trying to understand, given what the earth looks like now, what the forces were that caused it to be that way. So where were the earthquakes and the falls and there were volcanoes that split the rocks like this and sedimentary rocks, so it must have been originally ocean bottom that then rose up and things like that and so it would reason about patterns and first principles in order to come up with these interpretations. "
"Reid Simmons","Interviewer","And what year was the linear project, you remember? "
"Reid Simmons","Interviewee","It started in 1988 That is when I got here, went on for, I think, four years. The NASA work was just great. We did lots of work with NASA over the years and thoroughly enjoyed all the work with them. They just had the best problems and really good people that worked at the NASA centers that I could collaborate with that was a really good time."
"Reid Simmons","Interviewer","How had you gotten to know Tom Mitchell and who invited you over for the first time?"
"Reid Simmons","Interviewee","So Tom and my advisor, Randy Davis, were good friends and so I guess Tom just put out question to people he knew whether they knew of anyone who was graduating. I do not think I had met him at conferences beforehand, but it was made basically through my advisor. "
"Reid Simmons","Interviewer","And did any of your work on causal reasoning come in handy on the linear project?"
"Reid Simmons","Interviewee","Not on that project but subsequently some of that work has been applied. A lot of what the work well, I guess some of it has been applied. A lot of the work was, what was I going to say, a lot of the work I did as a graduate student was involved in planning and so I have done a lot of work since then in planning, not so much in the rover project but subsequently that and so things have come back, but even there, things have changed dramatically as a result of some of the graduate students that I worked with, we all got very interested in probabilistic reasoning and probabilistic planning and so That is basically kind of taken over the way that I look at how to deal with robotics problems. So there is a lot of uncertainty in robotics and reasoning about uncertainty in a probabilistic way. it is something that we find very important. So That is what we have been doing a lot of since then. When I first got here, there was a lot of so robotics in those days were basically kind of one-off mechanisms. I remember very distinctly that at those times that Red's group when they built a new robot, before they started programming it, the first thing they do is build their own operating system, real-time operating system, for the robot because there really was not anything out there that was suitable, light weight, real time. They could do what they wanted. So they would do a lot of that on their own and every project was different and so they do that again and so I felt that there was a need for tools that would help make putting robot systems easier in particular at the higher levels. So a lot of work done in controls and real-time systems but not much work at that kind of what we call the task-level control. So for the first seven or eight years that I was here that was my focus was on designing robot architecture, software architectures and that was completely different than anything I had done as a graduate student, but it was more out of necessity than anything else that we embarked on that and since then I have been kind of going back to my roots, AI roots, in terms of planning and reasoning, but so that was something that was important to do."
"Reid Simmons","Interviewer","What were the big challenges in designing a robot operating system and architecture?"
"Reid Simmons","Interviewee","The big challenge was that there was this gap between the kind of real-time control that you needed to make the robots operate in the world and the kind of unbounded computational nature of the AI parts of the system. So you wanted the robot to react quickly to contingencies but still you wanted it to plan and that planning could take a large amount of time. So it was kind of bridging that gap is where we spent most of our efforts."
"Reid Simmons","Interviewer","And what were some of the things that you worked on during the first rover project because you mentioned NASA has all these interesting problems?"
"Reid Simmons","Interviewee","So designing the robot architecture was a large part of it. We did work in gate planning, so where the rover should put its feet. It was a legged rover, so where should it put its feet and that was basically a combination of using perception to understand where good places were to put for the rover to move and planning paths and that lead to a long, probably a decade long, set of work that we did for NASA in terms of path planning for rovers, navigation planning, I should say, navigation planning for rovers, which culminated actually in one of the graduate students who worked with us in the early 90s went on to NASA and took the ideas that we had developed here at Carnegie Mellon and ported them to the Mars rovers, the spirit and opportunity, and so basically they have been running our algorithms for seven years now, which is really cool. It was interesting when they first launched. We all said that if the rovers worked well, it is a great win for NASA, and if they do not work well, Carnegie Mellon is going to get blamed, but they worked flawlessly and it was really great to see, so that was really exciting because we actually had some impact on an actual mission."
"Reid Simmons","Interviewer","And who were the people that went from here to there?"
"Reid Simmons","Interviewee","This was Mark Maimone and he is still at JPL and he is working on the next generation rover, so."
"Reid Simmons","Interviewer","And he was in your group, a student?"
"Reid Simmons","Interviewee","He was not a student of mine. We hired him as a post-doc to do some work and then when the post-doc ended, he went on to JPL to work with NASA."
"Reid Simmons","Interviewer","How many PhD students have you trained while you have been here?"
"Reid Simmons","Interviewee","I think I have graduated 12 or 13. I do not have the exact count."
"Reid Simmons","Interviewer","So your PhD students where have they gone onto and what are they doing and ."
"Reid Simmons","Interviewee","Basically, all over. My first PhD student is still here. He graduated in 1995. Actually funny story about that. My wife was pregnant with our third child at the time and we worked really hard to make sure that his defense would not coincide with the delivery, but she ended up being three weeks early and she happened to go into labor that day. So I was in the labor room with her on the phone with his defense because his external member would come in, everything had been set up, and the it was just easier to do it that way and the nurses could not believe that I was doing this. It worked out fine. The defense ended and then she went into the delivery room and everything worked out fine, but I always remembered exactly when his defense was because it was the day my son was born. So anyway, so that was 1995. So he is still here. he is a professor as I am in robotics. "
"Reid Simmons","Interviewer","What was his name?"
"Reid Simmons","Interviewee","Sanjiv Singh and I got one other no two other students in academia. One is Sven Koenig who is now at University of Southern California and Chris Urmson who I co-advised with Red Whittaker, did the Urban Challenge and he is on leave at Google, but we all expect him to come back. The rest of them are scattered around. A large number of them are actually at NASA, both at NASA Ames and at JPL. It was really good synergy for NASA and us. They would provide us with funding and We had provide them with well-trained students. So I think four of my students are still at NASA now."
"Reid Simmons","Interviewer","And within JPL and Ames, are they all in the same research group or?"
"Reid Simmons","Interviewee","it is kind of spread out."
"Reid Simmons","Interviewer","And did you work with the same NASA groups every time or were there different groups that you have worked with at NASA?"
"Reid Simmons","Interviewee","There were a number of different groups. So there is two groups at Ames that I was involved with and three groups at JPL."
"Reid Simmons","Interviewer","And who were the groups, who were they, people?"
"Reid Simmons","Interviewee","So there was a group at Ames that was doing robot work, Terry Fong, Mike Sims, Dan Clancy. There was a group at Ames doing program verification, Charles Pecheur and Klaus Havelund. The JPL group, I worked with Steve Chan, Rich Doyle, I do not remember his first name, Aljobary was his last name. I can not remember his first name and Esanesnes . No, I guess I never really worked with Mark Maimone. So that was kind of the group. I am sure I am forgetting names. It was spread out over different groups. I mean, they all kind of worked together and everything, but."
"Reid Simmons","Interviewer","And after your post-doc have you continued to work with Red Whittaker in collaborations?"
"Reid Simmons","Interviewee","Some, not a lot but some. "
"Reid Simmons","Interviewer","What were some of your collaborations?"
"Reid Simmons","Interviewee","There was some massive work. There was a lunar rover project that we were involved in together, not a lot. I have been working a lot with Sanjiv Singh though who is as I say was my first student and we have been involved in a number of activities over the years. The most recent one being multi-robot coordinated assembly. So one of the things that I have is, a lot of people will kind of do basically have the same path for their whole career and they just like pushing this big idea as far as they can push it and I do not have the patience to do that, so I have been kind of bouncing around. So every five or six years I start up a new effort and the old ones kind of die out. So the architecture efforts that was kind of the first thing I did That is died out. I do not do much of that much anymore. The rover navigation stuff was big for a while That is died out mostly because NASA is not funding any work in that area. "
"Reid Simmons","Interviewer","Okay. So you did the architecture, the navigation."
"Reid Simmons","Interviewee","Oh, and then there was a period of doing indoor robot navigation and most recently we have been doing multi-robot assembly, large scale assembly, so a coordination of multiple robots and I guess my current passion is human robot interaction, particularly human robot social interaction. So we have gotten a number of projects in this area both for conversational interaction how robots can engage people and talk to them in a socially acceptable way mostly dealing with nonverbal communication and navigational interaction, so how you move through space in a socially acceptable way, things like how do you get on and off elevators, passing people in the hallways, things like that. So every number of years a new thing comes up."
"Reid Simmons","Interviewer","How did you get interested in the human robot interaction?"
"Reid Simmons","Interviewee","Good question. This is a good story. In the mid 90s, I had a student, Sven Koenig, who was very interested in probabilistic reasoning and he and I put together a system that did navigation using mark-off models and it was different than what most people right now, nowadays, it is very common because it turned out to be a very useful thing to do and Sebastian Thrun came up with a much better way of doing it than we had one it and it is very popular now but back in those days it was not really very well accepted. So Ila Norvach had done a little bit of work using probabilistic planning but not in any real big way. So what we wanted to do is we wanted to demonstrate that this thing was more reliable than think-competing technologies and so we did an experiment where we would have the robot wandering the halls for hours a day as long as his batteries would last every day and eventually it accumulated like 300 miles of driving indoors and while we were doing that we noticed how people would react to the way that the robots react to the robots. I mean, this was 15 years ago the idea of seeing robots actually driving around you. I mean, it is one thing to go into a lab and you see it in a protective setting but to see them actually driving around you was very unusual in those days and we noticed that people would react to the robot in very different ways than they would react to the people and realized that a large part of that was probably because the robot was not driving around the environment in ways that they expected. So it was very unpredictable. So in particular things like the robot would be driving towards someone. Someone would be walking. The robot had this algorithm that when its pathway would be blocked, it would go to the largest open space and so more often than not that was to the person's left, so the robot would start moving over to the left, but the person who was assuming that the robot would be doing the socially acceptable thing would also be moving over to his right and they would come at each other and then the person would move out of the way. In the meantime, the robot saw its pathway was blocked, so it would go this way and so there was this dance between them until finally invariably the person gave up and the robot would win and go on its way and so eventually people would just get in the habit as the robot would come, they would just kind of move to the side, let the robot pass, and then continue and we realized that this was kind of socially unacceptable and if robots were going to actually be accepted in society, they would have to abide by people's rules. So that got us into this human robot social interaction and it is something I think that it is going to turn out to be more and more important as robots become more common in society. "
"Reid Simmons","Interviewer","What were some of the first studies that you did with robots and social interaction, what kinds of robots were you using?"
"Reid Simmons","Interviewee","We started off by using Xavier, which was a robot that was built early 90s to study navigation. It was a 24-inch base, so it was pretty big, kind of cylindrical robot and the two studies that we did then were well, three actually. One was having the robot stand in line. So that turned out to be a really cool project and led to some nice results. The second was having the robot pass on the right, which turned out to be fairly straightforward because of the way that the system was architected. We just needed to add a little bias for the robot to go one way or the other and the third, which was actually never published, was having the robot move on and off the elevators in a socially acceptable way and those all culminated in 2002."
"Reid Simmons","Interviewer","Is it two?"
"Reid Simmons","Interviewee",". the mobile robot."
"Reid Simmons","Interviewer","Oh, okay, okay, not the triple AAAI one. "
"Reid Simmons","Interviewee","Yeah, the AAAI. "
"Reid Simmons","Interviewer","Was it two or three? Never mind, you will find it. "
"Reid Simmons","Interviewee","Okay. I am pretty sure the first one was 2002."
"Reid Simmons","Interviewer","Okay. You probably know better than me. "
"Reid Simmons","Interviewee","Where we had the robot we entered Grace, which was a robot that we had designed specifically for this competition in the AAAI Mobile Robot Challenge. The challenge basically was to have a robot attend the conference and the idea was you drop it off at the entrance of the convention center. It would have to find its way to the registration booth, register. Once it got there, it would get a map of the environment and a location where it was supposed to give a talk and then would navigate there and give its talk and we were shocked at the publicity that came out of that. I mean, there were hundreds and hundreds of people who came to the convention center to watch the robot perform. Basically, the robot needed bodyguards because it could not navigate through really thick crowds. So we would have to push people away so that the robot would have any chance of getting anywhere. It was really crazy. So we did rather well there and participated in a couple of more after that and that kind of set the stage for a lot of the work that we did subsequently to that but that one involved getting on and off elevators and standing in line. We did not actually use the socially acceptable passing in corridors because we expected that the robot would be in these large open spaces and that was a multi-institutional effort we were involved with. Northwestern, I am going to forget someone, Metrica, Naval Research Lab in Swathmore. I think those were the five that were involved in that project and a large part of what we did was integrate all this software that have been developed over the years by different researchers into kind of one system and that turned out to be quite an effort but well worth it in the end. Well since then, there is been a large focus on conversational interaction, so we developed this roboceptionist project where basically it is a stationary robot with a graphical face and a monitor and a pan tilt head, so it can move its head around but it has a cartoonish but three-dimensional face rendered in graphics and this is a joint effort with the school of drama. So they developed a character back story and continuing episodes in the life of the robot and we can program that in and you can talk to the robot about its life. You can ask it about its parents or its siblings or its love life or what it thinks about its job or its boss who happens to be me and the robot for whatever reason thinks that I am a evil guy. that is a continuing story line no matter what the character is. I am the evil guy. The Carnegie Mellon School of Drama is world class and the writers that we get for this is mostly in the graduate writing program are just really, really, really good and so there is been a lot of really interesting story lines that come out of that and very interesting. it is a very different type of human robot interaction study because most of the studies had been and still are controlled. So you go into a lab and you sit down and you talk to the robot or you interact with the robot and this is what they call in the wild. The same with Xavier. The robot is just there and it is an uncontrolled experiment. So we get reactions that differ wildly from what you would get in a laboratory. I mean, it would be hard to imagine people going into a lab when they know an experiment is taking place and swearing to the robot, but we get that all the time or propositioning the robot. We get that all the time. So there is all sorts of interesting things that we discovering about the way people interact with the robot and some of the things are, for instance, we had one of the students, Rachel Kirby did a study where she implemented an emotional model on the robots. The robot could express emotions and moods and it turns out that just showing different facial expressions. So if the robot looked sad, people would interact with it differently than when the robot looked happy and maybe That is not surprising in retrospect, but the fact that people who have absolutely no idea of what is going on could just one day They are walking in the hallway and the robot looks happy and they go over and they interact with it. The next day, They are walking in the hallway, the robot looks sad and they just avoid it That is what happen. So those are some of the things that were been very interesting discoveries."
"Reid Simmons","Interviewer","What are some of the technical challenges that have come up with the social robot?"
"Reid Simmons","Interviewee","So, in my mind, the main technical challenge is that people are infinitely variable. The robots, even with mission learning, the robots basically adhere to rules. There are certain rules about how to interact, how to behave in certain situations, and people just present an infinite variety of the ways that they interact and it very quickly so the robot could do the right thing first for a little while but then invariably the interaction breaks down because the person asks question of the robot is not capable of answering or they try something like sarcasm or humor that the robot just does not understand or something happens like they turn their back on the robot for a second and the robot does not realize it and continues to talk to them and they get pissed about that and they walk away. So all those things happen with high regularity but none of the things happen regularly enough that we can actually capture that and say, okay, here is a new rule for the robot. We do that but still there is a large number of a quarter of the things that people say to the robot, the robot does not respond to it in a reasonable way. it is even more so I think when you are interacting with the robots spatially. So the way people move through space is predictable for us as humans but it is really hard to kind of explain, just rationalize so that you can write it down in a set of rules that a robot program would understand."
"Reid Simmons","Interviewer","And who have you been collaborating with in this direction of your research?"
"Reid Simmons","Interviewee","Mostly people at Carnegie Mellon. there is a drama professor, Anne Mundell, and writer, Michael Chemers, been involved with Illah Nourbakhsh. Manuela Veloso has gotten very interested in this area now, Aaron Steinfeld, Jodi Forlizzi, have not had a project but have interacted with Sara Kiesler."
"Reid Simmons","Interviewer","How did you decide to build a roboceptionist?"
"Reid Simmons","Interviewee","People had been kind of complaining for a while that we are the Robotics Institute and most of the time you come in to the Robotics Institute, this is in the 90s. You come into the Robotics Institute and you never see a robot and so there was a push to develop a robot presence that would be there all the time and we were concerned about having mobile robot because of the danger and also the fact that it would not be available full time. It'd only be available for a couple of hours a day as long as its batteries lasted but mostly because the danger of having a robot wandering around completely unsupervised for 40 hours a week. So we came up with this idea of a robot receptionist. Randy Pausch actually suggested to me that a great way of keeping people engaged would be to have the robot involved in a soap opera, so that they would have stories to tell and that people would be engaged with that and keep coming back to hear its stories and so that basically was the genesis of the interaction with the theater department and, yes, so we decided that we wanted to so the other impotence was that there had been a number of technologies that had been put out in the environment. So HCI, Human Computer Institute, had this really cool piece of technology. It was a bubble machine where , do you remember, okay."
"Reid Simmons","Interviewer","I have heard of it. "
"Reid Simmons","Interviewee","Okay. It was a bubble machine and so basically what it was is that it had these it was tubes of water and these air bubbles that would come out periodically from the tubes and they would form patterns and you could program the patterns and it would do the patterns that you wanted and it was really cool and people, I mean, in the early days when it first come out, there were lines of people waiting to use it. Everyone liked to play with it and then over time people stopped using it and the mechanism got old and started leaking and they took it down, but I think by the time they took it down, it was hardly used at all. So the question was how could we develop a technology that would maintain people's interest over very long periods of time and so the idea was to have a robot with a character and a personality and as Randy Pausch suggested story lines that would capture people's imagination and make them interested in coming back and hearing more about the robot's life. So That is what we did and it turned out to be a fairly successful experiment. The first year that the roboceptionist was there, we had a huge number of people interacting with it, which then the second, third year kind of calmed down, but this had been going on for seven years now and it is been pretty even over the length, does not mean that the same people come back all the time, but there is enough repeat visitors that it keeps the interest level up on a daily basis."
"Reid Simmons","Interviewer","And what were some of the other robots that you worked on?"
"Reid Simmons","Interviewee","So, let us see, we had Xavier, which basically did robot navigation. There were a couple of Mars rovers, Ambler, Ratler was the lunar rover, did that work with both the Ambler and Ratler work with aircrockov . Marshal Lubeir was also involved in those projects. We have a robot called Bullwinkle, which is a mobile manipulator, and it coordinates with this robotic crane that we borrowed from Nist ten years ago and have not gotten around to returning yet. it is huge. I do not think they will ever want it back because it would basically need a trailer to an 18-wheeler to cart it back. We have the Grace and the roboceptionist. The latest robot that we are just starting to use is called COMPANION. It was developed by Rachel Kirby who is co-advise with Jodi Forlizzi at the HCI Institute and it is a omnidirectional humanoid robot, so it is got a fiberglass shell That is shaped roughly like a human. it is got a graphical face like the roboceptionist does, but the face rather being on a big screen is imbedded in a three-dimensional head, so it looks much more organic and it is going to be used for social navigation. So one of the things that Rachel found in her thesis was that robots that the non-holonomic robots that basically have to turn their whole bodies in order to change orientation turns out to be not very socially acceptable. As the robot turns, people are getting confused about what the robot is going to do. So people as They are moving down the hallway tend to keep their body aligned with the direction of travel and they just sidestep it if they want to move away from someone. So we have developed a robot that can actually sidestep like that and we think that It will prove much more socially acceptable."
"Reid Simmons","Interviewer","And how does the robot sidestep, what is different about the design compared to the others?"
"Reid Simmons","Interviewee","Well, instead of just moving in the direction that its body is facing, it can move side to side as well. So it can keep its body in this orientation and just move to the side. "
"Reid Simmons","Interviewer","We were just talking to Ralph yesterday with the ball robots, so is it on something like that or do the wheels just kind of turn?"
"Reid Simmons","Interviewee","Yeah. it is this thing They are called mecanum wheels or Swedish wheels and basically the wheels have rollers that are kind of set at a 45-degree angle so that as the wheel turns, these rollers turn as well and they can just slip. So depending on the direction which you if you push in this direction, they go forward. If you push in this direction, it just slips to the side. So it is not like ballbot but."
"Reid Simmons","Interviewer","Could you tell us a little bit more about the different NASA projects that you worked on?"
"Reid Simmons","Interviewee","There were a lot of them. So I worked on the first one was Ambler, which was a very large eight-legged, six-legged I think, six-legged walking robot, very unique design. It was designed by John Bares as his PhD thesis and John joined the faculty here and has been very successful since. Had some projects with architectures, had some projects with navigation both for lunar rover and from Mars rover, actually had a project, I forgot about this one, had a project that was develop an autonomous spacecraft. So this was basically AI in space. So this was actually a mission, this flew. I was part of the team that worked on this project. It was to autonomously control spacecraft. Normally, They are controlled from the ground, tells them when to turn on their motors, how long to burn everything. This was all decided on board using AI planning technologies. It was a very, very fast-paced, very intense project, very large project, probably the largest project that I have ever worked on and it was really cool because it flew. We went down to Cape Kennedy and saw the launch and then six months later actually did its thing. It was quite cool."
"Reid Simmons","Interviewer","What was the spacecraft and what was the mission?"
"Reid Simmons","Interviewee","The mission was to visit some astroids. It was called Deep Space 1. So it was a technology demonstration mission. So it demonstrated a number of different technologies. The only other one that I remember was an Ion propulsion system, which is I believe since been used in other missions as well. As far as I know, the AI in space hasn't been used again, but it was a great development effort."
"Reid Simmons","Interviewer","When was this? "
"Reid Simmons","Interviewee","What?"
"Reid Simmons","Interviewer","When was this?"
"Reid Simmons","Interviewee","Jeez, I do not remember, 1998 somewhere around there."
"Reid Simmons","Interviewee","And then we have had work on multi-robot assembly most recently."
"Reid Simmons","Interviewer","And as far as you know, is that the first spacecraft that was completely controlled by AI?"
"Reid Simmons","Interviewee","Yeah, yeah, definitely."
"Reid Simmons","Interviewer","And there have not been any since?"
"Reid Simmons","Interviewee","Not that I know of. No. I mean, there is been spacecraft that have had AI components in it but as far as kind of being completely controlled by AI system, no. I do not think so."
"Reid Simmons","Interviewer","So can you tell us about how you designed that system and how it operated, the architecture?"
"Reid Simmons","Interviewee","I do not know. it is not that."
"Reid Simmons","Interviewee","Yeah, it is not interesting."
"Reid Simmons","Interviewer","it is not interesting? Is Amelia another robot then?"
"Reid Simmons","Interviewee","Yeah. So Amelia is the base that became Grace. She was called Amelia for a while but there really is not much to talk about. Amelia was mostly that we used the same base, put a face on her, and it became Grace and she is been known as Grace since then."
"Reid Simmons","Interviewer","I see NASA Peer Award."
"Reid Simmons","Interviewee","There are a couple of them. Oh, I remember what this was. Another project I forgot to talk about was that I actually was involved in for a number of years was a robot architecture problem. So NASA wanted to put together a common architecture that they could use for kind of a lot of their robot projects and I was involved in that for a number of years. We basically took the navigation work that we had done and integrated it into this architecture and it turned out to be it was interesting effort. The architecture was fairly successful. They ended up open sourcing it and people can use it. it is called Clarity and it was run by Esinesnes and yes, so it was rather successful in NASA, gave out awards to people for that, so."
"Reid Simmons","Interviewer","What about your work on mixed autonomy and you mentioned the Crane and Bullwinkle, could you tell us a little bit about that?"
"Reid Simmons","Interviewee","Yes, so one of the things that we had noticed in doing some of our multi-robot coordination work is that the robot would actually this is another area that I should mention that I have been very interested in. One of the things I have been very interested in is fault detection error recovery. So one of the things that robots do very poorly is noticing when They are in trouble and so I mean, this came from I was involved for many years in the AAAI Robot competitions and you would go there and you would watch and you would see the robots do things over and over again basically get stuck in loops, so they would there would be let us say they have to collect orange balls and so they'd see an orange ball over there and they would turn towards it to go and there would be a rock in front of them, so they could not go over the rock, so they'd turn away from the rock and then the cameras would detect an orange ball over there and so they'd turn towards the orange ball and there would be a rock in front of it, so they and they would do this forever, literally forever. Sometimes, we just had to stop the robots because it was clear they were just never going to get out of this loop and similarly the Mars rovers would get themselves into trouble where they would the more they would try and not even noticing they were in trouble, the more they would try and move according to their plan the deeper and deeper they would literally dig themselves in until eventually they would end in catastrophe more often than not. So very much interested in trying to detect these types of behavior changes and be able to react to them in reasonable ways and one of the things we realized is that, again, where I was talking before about humans being infinitely variable, the environment is variable as people, but it is still pretty variable. Different things can be thrown at you and we realized that to get robots to be 100 percent autonomous, do it all by themselves, was just not going to happen anytime soon and so we were very much interested in looking at how people and robots could work together to help this out and so what we were interested in is having the robots be able to detect when they were in trouble and be able to determine for themselves when they could get out of the trouble themselves and when they needed to ask people for help. So a lot of my recent work with students like Brennan Sellner and Laura Hiatt had been in terms of recovering from failure. So either from how to detect that the system was failing or how to recover once the system was failing and then in some cases how to ask humans for help to help the robots when They are failing."
"Reid Simmons","Interviewer","And what kind of tasks are you doing this in?"
"Reid Simmons","Interviewee","Mostly assembly tasks. So putting together large structures like space structures."
"Reid Simmons","Interviewer","And this is also is it a NASA project or?"
"Reid Simmons","Interviewee","It has been supported by NASA, yeah. we have since been looking for other areas of supports since NASA support is kind of dried up, but there are other manufacturing companies that are interested in this type of behaviors."
"Reid Simmons","Interviewer","Has most of your research been supported by NASA or have you had other funding sources?"
"Reid Simmons","Interviewee","I would say for the first ten years, I have been here 22 years, the first half of the time I have been here, it was almost exclusively NASA, but, since then, they have kind of branched out. I have had a little bit of Darpus support, not much, ONR support, NSF support, industrial support. We just an Air Force contract, so but, yeah, NASA had been my big support up until a few years ago."
"Reid Simmons","Interviewer","You mentioned that NASA support was running out. Is there a particular reason, are they not doing so much funding of robotics anymore or?"
"Reid Simmons","Interviewee","let us not go there."
"Reid Simmons","Interviewer","Okay. "
"Reid Simmons","Interviewee","it is political."
"Reid Simmons","Interviewer","Okay. What sort of industrial partners have you had?"
"Reid Simmons","Interviewee","Good question. General Motors is I am trying to remember, has actual industrial. Well, I guess not a lot of industrial support. I am sure there are others. General Motors is the only one that brings to mind right now."
"Reid Simmons","Interviewer","Have you had other outside collaborations apart from NASA and ?"
"Reid Simmons","Interviewee","No, not really."
"Reid Simmons","Interviewer","What was the Atacama Desert Trek field experiment?"
"Reid Simmons","Interviewee","Oh, this was another NASA thing. This actually was something that was led by Red Whittaker where they sent a robot to the Atacama Desert, which is the driest desert in the world and basically had it drive around for weeks at a time. So it was basically trying to show that robots could operate in very harsh environments."
"Reid Simmons","Interviewer","So I do not know if you have something at 11, but it is getting there. So we have kind of an ending question but is there anything you would like to add or something that we missed before we go?"
"Reid Simmons","Interviewee","No, I think you have covered a lot of things, yeah."
"Reid Simmons","Interviewer","Okay. So our final question was would you have some advice to give to people who are interested in getting into robotics?"
"Reid Simmons","Interviewee","Yeah, let us see so when I got this offer to come to Carnegie Mellon and as I said I had not had any experience in robots before. So I asked Rod Brooks, who is at MIT and very well renown for his work in robotics and I knew him but not well, and basically asked him for his advice and his advice basically was forget about this planning stuff. The action is all in perception and I thanked him for his advice and I was not going to go that far field but it still is good advice I think. A very large part of what makes robotics hard is getting good understanding of what is happening in the world. I mean, as I said before that people are very variable, but one of the things that makes human-robot social interaction hard is that robots can not pick up on the type of queues that people give out, expressions and nods and prosody and all that. I mean, people are working on all that, but it is just not there yet. So it is still a very large kind of open area, so That is kind of passing on Rod's advice from 20 years ago. My own advice though is that I think it is important to do something in robotics that you are passionate about. there is an awful lot of work where people will kind of flock after the next fad and decide what to work on based on what is hot at the time and invariably well, at least I do not think that is a very satisfying way of choosing research topics. I think you want to choose research topics that interest you that you are passionate about, that you believe will have an impact on society and the field in general and then go with that and if you are right and you do good work then eventually the funding will come and people will notice. The social robot's work is one thing. I mean, I was not the first person by any means to get involved in it, but when we started there was relatively few people doing work in HRI period and even less work in social interaction and it is become much, much more prevalent now ten years later. I got into it because I saw that it was an important thing that the robots were missing and realized myself that figured that unless we had this type of interaction, robots would not be well accepted in society, but it is important, as I said, kind of choose topics based on what you think is important and what you are really interested in rather than just following the latest fad."
"Reid Simmons","Interviewer","So besides HRI, what do you think are some of the other important directions in robotics in the next few years?"
"Reid Simmons","Interviewee","Mobile manipulation, learning, and better perception, particularly multi-mobile perception as we get a lot of feedback from all our senses and we have to put them together very well and those are all going to be very important. "
"Reid Simmons","Interviewer","And given your background, what do you see as the relationship between AI and robotics over that time period?"
"Reid Simmons","Interviewee","So as robots have become more and more so, there is two things. One is that as robots have become more and more capable mechanically and we have been able to computing power has gotten to the point where you can imbed very, very powerful computers on board, it is made AI feasible to do. If robots really could not do much, planning did not really make any sense because the robots did not survive for more than a few seconds or a few minutes, whatever, it was not very important, but, now that robots are very capable and you can think about having robots that are available all the time, then the AI becomes much more important. The other thing I think is more fundamentally is that thinking about AI and robots has pushed the field of AI in a different direction. So when I was starting out, when I was getting my graduate degree, AI was all symbolic reasoning and there were a few people who were doing nonsymbolic reasoning, probabilistic reasoning, but they were very few and far between and since then once you start taking the world seriously and that there is so much uncertainty in the world, it is pushed AI into much more into nonsymbolic representations of reasoning, probabilistic reasoning, nondeterministic reasoning. Machine learning has become much more nonsymbolic than it used to be. Control learning, things like that, have become very important. So putting AI and robotics together has opened up a huge new set of problems for AI to solve and has led people into very different types of solution techniques than they had been involved in in the past. "
"Reid Simmons","Interviewer","Great. Thank you, thank you."
"Reid Simmons","Interviewee","Okay. Sure."
"Rob Ambrose","Interviewer","Okay so if we could start with your name and where and when you were born."
"Rob Ambrose","Interviewee","Okay. I am Robert O. Ambrose. I was born in 1964 in Boston, United States."
"Rob Ambrose","Interviewer","And did you stay in Boston? Did you go to school there?"
"Rob Ambrose","Interviewee","We moved from Boston very soon after I was born. My parents were in school there. And we moved to Houston, Texas."
"Rob Ambrose","Interviewer","And That is where you went to college, as w or no?"
"Rob Ambrose","Interviewee","No. So we moved to Houston. I went to elementary school in the Houston area. And then we moved to Chicago. I went to elementary school there, as well, then back to Houston. And I finished through high school in the Houston area. Then in college I went to Washington University in St. Louis, which is in St. Louis. And I got a Bachelor's in mechanical engineering and a Master's in mechanical engineering. Then moved to Austin, and I got married. And my wife and I both went to graduate school in Austin at the University of Texas at Austin. I continued in mechanical engineering with a specialty in robot system design. "
"Rob Ambrose","Interviewer","How did you decide to go into mechanical engineering in the first place?"
"Rob Ambrose","Interviewee","Well, I actually wanted to do three majors, and it was not possible in the time that I wanted to I decided I would rather do graduate work than three majors. But what I really wanted was physics, mechanical engineering, and electrical engineering. And I compared the syllabus that was available for all three of those degrees, and they were basically mutually exclusive. So there was almost no overlap, not even the freshman year. So I realized it was going to take twelve years to get all three degrees. And I decided I would rather get a different set of three degrees in less than twelve years. So I looked at the syllabi and I saw that the parts of physics that I was most interested in were well covered in mechanical engineering. And the mechanical curriculum required that I take a lot of electrical engineering classes, whereas the electrical curriculum had no mechanical engineering classes. So I decided to go mechanical. But since then I have always been interested in what I consider to be mechatronics. And as I got into my Ph.D. work I spent a lot of time on electrical design and software design in addition to mechanical engineering."
"Rob Ambrose","Interviewer","What got you interested in the three areas there; I mean that is a pretty ambitious undergraduate ?"
"Rob Ambrose","Interviewee","So the three areas of physics and well I like physics. And the parts of physics that I like the most are mechanical and electrical in nature. So I am really into electro-mechanical systems. And so I was looking for a degree that would allow me to work in that area. And then I started to develop an interest in the software engineering aspects of robotics. And I feel those are the three key things, mechanical, electrical, and software engineering that brings robotics together."
"Rob Ambrose","Interviewer","So it was just something in high school, maybe like a subject in high school "
"Rob Ambrose","Interviewee","No I have been building things my whole life. And I always liked motors, and electricity, and gears, and mechanisms. And I have been building things with electric motors in them since maybe age five. So "
"Rob Ambrose","Interviewer","What kinds of things have you built?"
"Rob Ambrose","Interviewee","Well I have built a number of robotics systems, more recently."
"Rob Ambrose","Interviewer","I mean "
"Rob Ambrose","Interviewee","Back when I was boats, airplanes, cars, and at age five I would build things and turn them on and watch what happened. There was not a whole lot of close loop control going on. By the time I got into middle school, I did not understand what it was, but I built a closed loop control system for a solar collector that was pointing at the sun using a photo resistor with a tube. And when the sun would move and cast a shadow, it would turn on the motor. And it would repoint it. And That is my first experience with closed loop control systems. And I did not understand the math. I was just completely winging it, obviously. But and still do, maybe. But the experience had a lot of impact on me. I remember playing with friction, to add friction into the system, which caused things to be stable. But then I noticed that I would it would stick. And it would develop an air and it would take a certain amount of air before it would break free and move again. And that experience, playing around with the physics of what was going on there, came back to me later when I was in college taking a linear controls class. And it was kind of intuitive to me what was going on, and I was now trying to figure out the math that explained it. So I put that was able to put those things together. And it was a good feeling to understand the math behind something I had previously experienced in kind of an ad hoc way."
"Rob Ambrose","Interviewer","And in your undergraduate did you have a chance to work in any laboratories, or participate in research?"
"Rob Ambrose","Interviewee","No really. I TA-ed classes a little bit, but never really needed lab classes to get hands on that I could just build things. We built things in dorm rooms. We built things at home on summer breaks. And I like to build things and did not need to go to school to do that. Garages are great."
"Rob Ambrose","Interviewer","What kinds of things did you build in college, other than potato guns?"
"Rob Ambrose","Interviewee","I did not build a potato gun. Built a submarine, that was kind of fun. Built airplanes, rocket powered airplanes, walking machines, a lot of boats, and a lot of rockets."
"Rob Ambrose","Interviewer","And so were these where did you find what kinds of materials did you use and where did you find them?"
"Rob Ambrose","Interviewee","Well my ability to use machine tools was not so great. And I picked that up in graduate school. And I really wish I had learned how to use a mill and a lathe early. It would have really improved the quality of my prototypes. So I was doing a lot with wood and plastic and composites glued together. I did not really get into metal until graduate work. And I really wish I had done more earlier, but I did not have a machine shop readily available. And I wish I had. My kids do. So "
"Rob Ambrose","Interviewer","What kinds of materials were available then? There were kits and things, where else did you find the other components, motors, gears, that kind of stuff?"
"Rob Ambrose","Interviewee","So I found a lot of shops that salvaged equipment. And that was great. I could go in and I could buy a squirrel cage fan that had a big motor in it and a impeller . And I could find a power supply that had been taken out of a washing machine or refrigerators have great electric motors in them. I was able to find a lot of actuators through salvage like that, power supplies. And you can find them in salvage being pulled out of heavy machines and durable goods. Even back then, the prehistoric era when I was a kid, you could find a lot of electric motors that were, for their time, excellent. Like a starter motor the Apollo rover was built, basically, with starter motors and very simple electric actuators in today's terms. But They are pretty torquey ."
"Rob Ambrose","Interviewer","So when you got to graduate school what type of environment did you find there, did you start working with?"
"Rob Ambrose","Interviewee","Well I did a theoretical Master's where I was doing linkage synthesis. It was the first time I really started to use computers to do design work. I had always been into CAD, and liked drafting, just always enjoyed drawing. I grew up in a household with a lot of architecture and drawing. And design was always being discussed. And I got into the CAD work early. But then starting to use computers to do synthesis where a more formal synthesis I started in my senior year and learned a few software packages that were just coming out that were extremely painful to use, but you were able to do so much more than you could do by hand. They subsequently led to packages that are more common like the Adams Mechanical Design package. We were using some early versions of that where you would build a file that a fax would read. And that file had a file structure where you would define mechanisms, parameters, and then you could iterate and write have the program iterate through variables and optimize. So I started- As a Master's candidate I started doing a lot of formal optimization, design theory, design methodology. Took a couple really good classes from professors who were really knowledgeable in that field and very strong computer backgrounds and mechanical engineers. So they really knew how to use computers to do design work. And I took a class we were in St. Louis, and there is a very large aerospace industry there. And one of the classes that was arranged was to use a brand new CAD system that they had developed, they were using for the Harrier and F18 programs. And they kind of used us as guinea pigs to learn how to use this CAD system and watch how we learned it. And use us as kind of beta testers of their in house CAD, which was a great system, was really very capable. And then couple into that so in these more analytical design tools. So that had a big impact. And I went into linkage design and the process of stating a requirement and then optimizing to get the best results was something that I really embraced. And then took that into my Ph.D. work at UT Austin, where I came up with a design methodology specifically for robot manipulator design. And that was the main thrust of my Ph.D. work. I really wanted an experimental component to that. So what I did was I built a set of modular joints and links. And I tested them thoroughly so I got a lot empirical data on what their performance was. And then I built a database using all that data and wrote a design program where you would state a requirement for the arm. And it would hunt through every possible permutation of putting every piece in the tool chest together and every possible configuration, and then tell you which one was best for the requirements that you just specified. And it was a great design problem. And I, obviously, used a lot of my Master's work in linkage synthesis and optimization. But I think the most important thing was I actually built those parts. And when I got to NASA, I realized that by the time I was done formulating that design problem, I knew what the answer was before I ran the program. To formulate the design space and to write it all down so you could run the synthesis, I already figured out which corner of the design space was best. So what I started doing at NASA was focusing more on visualization of the data, and not trying to wrap the synthesis loop around it, just to build visualization tools so I could try out different ideas. And then visualize the results. And then I would just, in what I call wet wear, synthesize and play around with the parameters until I got the design where I wanted it. That was a lot of fun, too. I like visualization data visualization came up with ways to see the design of the robot stretch and morph very physically. Rather than bar charts, it was the actual shape of the robot, which changed in front of my eyes as I would tweak parameters. And the payload would shrink, and you would see if you were making progress or not."
"Rob Ambrose","Interviewer","What year was this when you were doing a lot of this stuff?"
"Rob Ambrose","Interviewee","So my Ph.D. work started in the summer of 1987. And I finished in the summer of 1991. So I was using a PC and a Silicon Graphics. So discovering the Silicon Graphics was a great eye opening experience for me. it is a great computer system that allowed the open GL ph?] well the GL graphics library that then became the Open GL graphics library That is used a lot today, was a great experience. And being able to visualize design in three dimensions and move it see how it moved and see how it performed. That was a great design tool. "
"Rob Ambrose","Interviewer","How is that different from playing with the materials in your hands and shaping them while you are designing versus looking at something on a computer screen?"
"Rob Ambrose","Interviewee","it is cheaper. But it is not as satisfying to me. So for my Ph.D. work I wanted to do both. I wanted to build modules and then be able to more virtually synthesize the combination. I did not want to have to put every possible sequence of the joints and links together every time I wanted to evaluate something. I did not need to do that. But I think having designed and built the parts was very important for me to understand. And it led to some important things that happened later in my career, having actually designed and built robotics systems early. And those early robots that I built were really, really bad, horribly bad, very wrong. And I was free to do that. And that was important to be able to get that out of my system. And it allowed me to set a lot higher standards for later when I was doing it professionally, to know what could be done and have an expectation that it will be done better every time."
"Rob Ambrose","Interviewer","What do you mean when you describe bad and wrong in terms of these robots?"
"Rob Ambrose","Interviewee","Come up with some more descriptive terms. Clunky, fat, weak "
"Rob Ambrose","Interviewer","You can just describe the robot or one of them."
"Rob Ambrose","Interviewee","Well I built robots that were not deeply integrated. So I was buying components like actuators and sensors with their own housings and then putting those together, rather than starting with more basic components like the stator of a rotor stator and rotor of a motor or just the optical disc and a reader head. Buying the whole encoder with a package around it means you have got this big thing sticking out the side in a clunky looking way. And it violated my sensibilities of what design should be. But I was learning and getting feel for the componentry that had to go into the designs. And I am big on iteration. And I can just look at designs and know that they were a first rev or that the person did not care. It might be a tenth rev, and they just do not care. But you look at it and it is clear that they were putting things together for the first time and had not really thought it all out yet. Once you get all the pieces together, you realize oh well it would have been better if I had known that the nth piece that I was going to add was that way, I would have made a much different choice on the first and second piece that I selected. And it is clear when a prototype That is not well thought out like that early in the design, just has kind of a clunky look to it. That or they were just starting to understand the design. "
"Rob Ambrose","Interviewer","And who did you work with during your Ph.D.? Who was your advisor?"
"Rob Ambrose","Interviewee","My chief supervisor was Dell Tesser at the University of Texas at Austin. And Dell really liked design and liked actuators, came from an era in mechanism design and got into robotics after he graduated and went to the University of Florida, and worked with some great people like Joe Duffy at Florida, and then came to Texas before I came to Texas and started a robotics team there. And we had so Dell was great. But even better than Dell were the grad students. We had a great group of people that were just really into robotics. There were a lot of students like thirty students there. And we all were just really into robotics, and we all learned from each other and were always finding new things. And back then, that was a long time ago, pre-Google. So if you have thirty people with fairly crude information gathering abilities, that might be as good as one person today who is got the world at their fingertips. With that many people all finding things the old fashioned way where you had to go into the library and read, was better than just a person by himself. So all those people finding new things and new ideas and hanging out at the lunch table discussing them that was really important. That is where most of the learning was going on with the students all working together to figure out this world of robotics."
"Rob Ambrose","Interviewer","And who were some of the students?"
"Rob Ambrose","Interviewee","Well one of them was my wife. So I was very I am definitely married up. She did her Master's in bio-medical engineering, and then came back to mechanical for her Ph.D. and started working in the same team, same supervisor professor. So she was about a year behind me. But there were a number of other students. And several of them now are in work with me at NASA. A lot of them went into academia and manufacturing. We were pretty heavy in manufacturing, thinking about robots to do manufacturing, some very high tech manufacturing like semiconductor manufacturing and a little bit and some of the folks went into military robotics. "
"Rob Ambrose","Interviewer","And what kinds of projects were they generally also working on?"
"Rob Ambrose","Interviewee","So our group's thrust was manipulator design, and manipulator dynamics, and manipulator control. We had basically nothing going on in mobile robotics. We were very focused on manipulator manipulation. And secondary thrust and well it was all aspects of manipulation, design of manipulators, dynamics, control. And then a secondary thrust in human robot interaction. it is primarily force feedback joysticks that are essentially manipulators themselves be able to apply forces back on human's hand or arm. So we built a lot of force feedback joysticks and connected them to force feedback manipulators and built force-reflecting systems. And we had a number of consortiums where worked with other universities, which was a great experience. University of Florida, Tennessee, and Michigan as part of a Department of Energy consortium. And then a little bit more locally we had a consortium with NASA, and I volunteered for it because I wanted to go work at NASA. So I volunteered for this project that had little to do with my thesis, but I just wanted to learn about NASA. And there we had UT Austin, UT Arlington, Texas A & M, and Rice. And we were operating robots across the Internet back before that was cool, and semi dangerous. So we were learning a lot about remote displays, common interfaces between robots. We built one back around 1989, 1990. So the robots from all the different labs could take the same commands and could display some more data despite totally different everything about that robot. And you know that still persists today. There are just standard after standard after standard for robot developers. And many people would think I was a newcomer coming to that in 1990. But it is a constant evolution of commonality. And We had made our own attempts back then in the group we were a part of. And I got to operate a robot at NASA from my lab in Austin, and that was fantastic, led to later aspects of my career."
"Rob Ambrose","Interviewer","What kind of robot was it?"
"Rob Ambrose","Interviewee","It was a Robotics Research 1607 KB 1607. It was a very nice manipulator, a seven degree of freedom arm, way ahead of its time, built by the Robotics Research Corporation. Keith Kowalski and Paul Eissen did a great job designing that manipulator. And we operated it from Austin with a joystick that looked nothing like it. So our goal was to be able to build what tests were called universal joysticks that they did not have to be mapped to look just like the machine they were controlling. They could be designed to work well with you, rather than have to mimic the machine. So we had force feedback joysticks that looked very different than the Robotics Research arm."
"Rob Ambrose","Interviewer","And how did you decide you wanted to go work at NASA even during grad school?"
"Rob Ambrose","Interviewee","Well I had already decided I was going to work at NASA. So I was in Houston during the moon shot. And I decided summer of 1969 I was going to go work at NASA. So there was no fuzz on that. And there were a few speed bumps along the way. After I made that decision, I then entered kindergarten and discovered I had a bunch of education I had to work on before I could go work at NASA. So it was kind of a harsh reality to a five year old. But I assumed I could go work there right away, but apparently they like you to get an education first. So, but yeah I have wanted to work at NASA for a while. I am living the dream."
"Rob Ambrose","Interviewer","And so what was it like when your dream came true? Or how did you ?"
"Rob Ambrose","Interviewee","it is still coming true every day. it is coming true every day. I really like working at NASA. it is a fantastic place. it is I think the ultimate place to be an engineer. The challenges that we are given are literally out of this world. There is no preconceived notion that we have done it this way We will always do it that way. The presumption is that the only way we could ever do it is if we come up with a new way to do it because it is such a new problem. And there is something about NASA being kind of for the betterment of all mankind. If you take a lot of our U.S. agencies' acronyms and you bounce those alphabet soup acronyms off of people in various parts of the world, they will not react very positively to our various agencies that we have. And you know That is not good or bad, it is just the truth. And, yet, if you ask anybody around the world, what is your perception of NASA? it is a very positive one. I mean you can not fault NASA. it is doing work for all of mankind. And when we go into space we always do it with other countries. And it is a very international kind of endeavor. So it is a great feeling to be a part of that. it is very it is humbling to get to be a part of that story. And every generation at NASA gets to write a new chapter. And we are entering some interesting new times at NASA. I am hoping that our robotics engineers are going to be the ones writing those chapters."
"Rob Ambrose","Interviewer","And so what was the first thing that you started working on when you got to NASA? What group were you in?"
"Rob Ambrose","Interviewee","So I went to work for a division at the Johnson Space Center that I now lead. And that division had a number of branches in it. I went to work for the technology branch, which was the branch who was kind of looking at the far out future stuff. And there was a gentleman named Charlie Price that I worked for. I can not say enough about Charlie. He was very forward thinking, always had a gaze that was down range, always was thinking ahead. And as far as I know the only mistake he made was hiring me. He brought me in as a contract employee, and the first year there I went to over twenty places. Because I was a contract employee, he had very limited travel budget. And he was always getting invitations to come to places like this conference we are at today. And he could not go, so he'd send Rob. My first year I went to over twenty places, got to go basically every robotics lab in the country. And it was a great kind of drinking from the fire hose experience. But I got to meet a lot of people and it really helped me build a network that I continue to use today. The first project I was on was no one gets to work on one thing. I had a project that I led, where I was designing a set of imagine this, manipulator joints that you could put in a thermal vac chamber. So I wanted to learn about the space environment. So I have been thinking about how to build a manipulator in air, and now I wanted to think about what would be different in space. I did not want to just keep building fun robots, and then the only reason they would be NASA robots is they'd have a NASA sticker on them. I wanted to do what was unique to NASA, so I think That is the environment. So I tackled thermal and vacuum first. And started over on the design thinking about those components and that would be able to work in the space environment, built a bunch of parts and took them into a thermal vac chamber for some early experiments. And that was a great experience for me to get to see the way that a robot's performance changed as a function of temperature. Pulling a vacuum did not have a big effect on it, per se. If you design the materials so they can take vacuum, when you pulled the vacuum they still worked. Now you had have made the choices upfront, but temperature is a very big deal. And I set as my objective to build a robot that could work in what was called the EVA touch range. EVA is Extra-vehicular activity. it is space walking with an astronaut wearing a space suit. I wanted to be able to build a robot that could go anywhere a person in a space suit could go. So I researched what the thermal range was, and it was about minus 50 to positive 100 degrees Celsius. And if it is colder or hotter than that we do not like astronauts to touch it because they could get burned or frost bite. So I said okay That is the range for us. We will build a robot, if everything's' got to be designed to be in that range to work with the astronauts, We will build a robot that could work in that range, too. And minus 50 is mighty chilly. And a hundred degrees is boiling hot. Most robots can not take that. And what I immediately found, even though the robot worked, it worked so much differently at cold and hot temperatures, that I had to change the software. I had to have the software adapt the robot to its new temperature. So that was a major breakthrough for me was to have the robot read its own temperature constantly, and constantly update itself so that it always had the same response. So if you asked it to go from zero to five degrees range of motion, the way it went there, the rise time, the settling time where it would overshoot slightly and then stop, the amount of time it took to stop, I wanted all that to be exactly the same no matter what temperature the robot was at. And at cold temperatures when you would give it a command it would not move at all because the lubricants were sludge. So you had to have a different set of control gains. And I found what those were. And then at high temperature it was completely out of control because at high temperature the lubricants were so loose that the friction that control system was counting on was not there anymore, that had gone away. Now when it cooled down it was back. So what I wanted was a control system that would be invariant to the temperature. So no matter what when you commanded the robot you would get the same result. And you did not have to care about what temperature it was at, which is a very unusual idea. And you do not see that even today. it is normally people just warm the robot and try and keep it at a constant temperature because They are afraid of all those changes. So that was a good project for me. I built those joints. I also was on a second project where there had been an enormous I think probably the biggest robotics ever had just been cancelled. It was a project called the flight telerobotics servicer, FTS maybe five hundred million dollars. And it had been cancelled just as I had arrived at NASA. And so my branch chief sent me around the country. And we called it the FTS technology capture effort. That I would go around the country and find every component that had been developed at great expense for this incredible robot and find out what was good and bad about that component so that we would not lose that information. We had spent so much money coming up with that design that we wanted to take that into future designs. So I went to every vendor, every motor, every sensor, every bearing, the people that built the cable harness, and just interviewed them and looked at the designs. And about five years later, four years later, we got all of that equipment accessed to us. I got it all delivered to me. At that point I was further up in the team structure. So I actually was the one who took delivery of all that equipment. They had built one flight manipulator. And I have still got that in storage protected and bonded storage. So that if I needed to go do something with it I could. But I ended up using a lot of the parts, the spare parts in my own experiments because there were these incredible components and did a whole series of additional experiments on thermal vacuum performance. Developed some custom lubricants that could work in the space environment. Worked with a number of people that had been searching for these materials also and we kind of came up with some concoctions that we thought would do well in space and all of that led into my thinking in the design of the Robonaut system that we started around 1996. We had just come off this technology capture program, built our own joints and a bunch of other experiments. At that point we felt we were really ready to design our own robot. We had invested in all sorts of hands; that Charlie Price was really into robot hands and we were buying the best. We have an incredible museum of robot hands. it is really it is about the best in the world and we continue to help any little company That is got a new hand. I tend to buy it just to help them because there are so few out there and we add it to the collection, but we also learn from it and part of NASA's mission is to help get our economy moving and so giving a contract to a little company has been an important part of NASA's history. We did not invent the microchip, but we bought 90 percent of them in the mid-1960s and that was really good for little startup companies like Texas Instruments and we were giving them these contracts and if we can do that in robotics, it'd be great. So we have been buying a bunch of prototypes. we have been doing experiments kind of piece by piece, studying the componentry and by about 1996 we decided we were ready to build our own robot in-house and That is when we started the Robonaut project."
"Rob Ambrose","Interviewer","So why was the flight robotic servicer canceled?"
"Rob Ambrose","Interviewee","It involved Congress and the White House and strategic objectives for the country. And I do not it was obviously canceled before I joined NASA, so I do not really remember all the details. When I got there it already had been canceled so I was part of this effort to try and make sure we got the most out of it. But it was a big project. It had been designed to go to the space was going to go to the space station, but at that point the space station was going through some redesign. Its assembly was being moved on schedule to the right and so they decided to put more money into the construction of the station itself than robots and other things to go with it. At that point I think the space station was scheduled to be assembled starting around 1994-1995 and ended up being much later in the decade than that, but they had to reprioritize and it fell off the chopping block."
"Rob Ambrose","Interviewer","And before we go to the Robonaut, I was also curious. You mentioned in your first year you ended up meeting a lot of people and going to a lot of different places. What were some of the people and places that you "
"Rob Ambrose","Interviewee","Well, I met my personal hero, Red Whittaker, Carnegie Mellon. That was great. I had met him a couple times before, but I had never gone to CMU, so I went there for a couple meetings and you know Red's incredible and to this day I mean a lot of what we have got in our program at the Johnson Space Center is based on what I saw as the right way to do things at CMU and his students might disagree with that, but They are wrong. The way he does it is the right way to do it and sometimes you just have to do a 100-day death march to be successful and he is not afraid to do that from time to time. He also has a long-term vision for the technology and does not get too lost in the moment. he is seen the evolution of the profession and he knows where we are in that profession and what he can expect as improvements. I remember I was talking to him about students and today's students coming into robotics are so much better than they were even a decade ago and he said yeah, it is really becoming a true profession and that kind of hit me that robotics was at a turning point going from kind of an oddly formed collection of anecdotal rules and guidelines and truly becoming a profession and that was probably late 1990s when he said that to me over an adult beverage and it is true. Robotics really has matured into a profession. Who else? I met a lot of great robotics engineers at JPL. Guys like Paul Schenker and Samad Hayati, Brian Wilcox, just incredible robotics engineers and in particular for me, space robotics engineers. Rich Volpe, Paul Backes, Chuck Wiseman , some great thinkers in the field of robotics and space robotics. there is a pretty good guy up at the Ames Research Center, Butler Hine, and then universities all around the country. Osama Khatib at Stanford, Bob Cannon at Stanford, retired, Steve Rock at Stanford. A number of professors at MIT like Steve Dubowsky and Rod Brooks and Gill Pratt. I got to meet all those. Marc Raibert, great robotics researchers that were very inspirational. You could see in them their own visions for where this robotics story was going and they taught me a lot."
"Rob Ambrose","Interviewer","And so how did all of this then feed into the Robonaut system and how did also people decide that that was the kind of platform; that they were going to build something more humanoid?"
"Rob Ambrose","Interviewee","Well, Robonaut started with a idea to build something called a work system and it was an idea that was formulated by a guy named Dave Lavery at NASA headquarters and Charlie Price. They outlined in I think it was a brief white paper, three levels of a work system. The first was something that could fly around again very focused on space station and working in a micro-gravity environment with people as opposed to like a Mars rover. So that team was very focused on supporting human spaceflight with robotics and they defined three levels of a work system. One was a free flyer that could just inspect. It could provide camera views. You never have a camera in the right place. You always want it somewhere else looking back at some angle that you just do not get and as you are working you always want a new angle and a new camera and a new place, so being able to have a flying eyeball was kind of a minimal functionality. It does not have to do a lot of work, it just needs to help you see or perceive. Maybe not even cameras. Maybe some other kind of sensors. We built one of those and we flew it called the air cam, but the original name was this great name. It was EWS Number One, External Work System Number One. it is kind of a class robot. Air cam's a little nicer. EWS2 we did not build, but it was generally regarded as a mule that could move near you and keep stuff for you and you could use it as a mobile workbench or a mule that could just a pack mule. It could carry stuff for you. So astronauts are pretty encumbered with what they carry. They are having to use their hands to climb typically so They are kind of out of hands for carrying stuff and They are cognitively challenged climbing because They are in a spacesuit and They are in free it is kind of like rock climbing where the rock is falling in freefall and you have to climb in a vacuum so you are wearing a suit, but other than that it is pretty easy. So since They are challenged, they wanted something that could carry stuff for them so that they could focus on themselves and not have to carry equipment. We never built one of those, but it was a good class of machine and EWS3, External Work System Number Three was one that could actually do work, so it could work with the astronaut very likely in kind of a junior apprentice role or assistant and then when the astronaut would go in, it could keep working and maybe work at some level, not as good as an astronaut, but it is persistent. It could stay out all day long and you could leave it behind and that was kind of the niche that we targeted Robonaut for. Now we did not call it Robonaut. It went through a bunch of renames, but after a couple of years by about 1998 we called it Robonaut. It did not exist. There was none built at that point, but after a couple of years we had some of the key pieces together and I became the Robonaut project leader in August of 1999 and at that point we still did not have a Robonaut, but we had a hand and we had an arm and we were running out of time. So it was kind of a critical moment. I had been the arm subsystem lead and had built the manipulator down to about right here based on some of those experiments that I had done early in my career and we really needed to put it together so I challenged the team to let us get this thing together. I knocked out a neck pretty quickly with a head with some cameras and we put the head subsystem and the arm subsystem and the hand subsystem together and I remember the first day we turned it on and we had a teleoperator. We decided we were going to start with teleoperation because we could and the teleoperator put on a VR helmet, the same helmet we were using to command another robot We had built and to do VR training for the astronauts, gloves and a helmet, and we had a guy put that on. We turned the robot on and he reached out and he grabbed something just perfectly the first time and we said okay, we have got something here. Then reaching out and grabbing a tool and getting it in a really nice grasp where you could actually use it and it was strong and it could apply forces just instantly with zero training. Said to me okay, we have got something here. Now I knew for it to really meet its potential it would have to be autonomous, but since that'll take 50 years, in the meantime it is a person could step inside the machine and just be that good, I will take it. But clearly over the evolution of the Robonaut system we have gone more and more autonomous and with the Robonaut Two we started autonomous only and it is a great teleoperator robot, but we have hardly done any teleoperation with it. But when we reached out and we grabbed a tool for the first time on like the first try, we knew we really had something that was pretty capable and that really summed up pretty much every experiment we ever did and continued to do with Robonauts, especially with teleoperators. The first take almost every video you have ever seen of a Robonaut One was the first or second take and that was it. We did not need to do a whole lot. We actually found if we kept doing it, it got worse. So it was actually better to just take a first, try this, and We had videotape it and it would work perfectly and we would say okay, done. let us try the next thing. Try that and there is something about the way we describe teleoperating Robonauts is going is stepping into the robot and when you put the helmet on and you move your head around and the view moves so well, That is probably 90 percent of convincing you you are inside the machine and then when you look down at your hands and you wiggle your fingers and you see them, it just looks like you are wearing astronaut gloves, right? And you do this and you see your hands, you are there. we have had some really funny experiences where a person is they may be in another room or down at the other end of the same room and They are teleoperating the robot and holding like a big chunk of metal or something and they drop it. The teleoperator way over there moves his foot out of the way because the operator does not want it to hurt their toe, right? But then the teleoperator looks down and realizes well, Robonaut does not have toes and actually I am not in this thing, am I? But it was really telling the way they felt they were there. All their reflexes were there. We played around with audio and being able to talk to your friend in this robot is just amazing and I did a bunch of experiments where I would work side-by-side with the robot being teleoperated and it was just I was standing next to Fred and we were just talking about what we were going to do and I would say here, hold this, and we would try something for the first time building some assembly together and it was just like I was talking to a colleague and we were putting something together for the first time and it was just that easy and I could point at things and say here you put your left hand here. I am going to put the tray of parts on your right and he'd look over on his right and see it and we would just start building things together and that human-robot team was clearly very powerful."
"Rob Ambrose","Interviewer","So was it like 2001 did you say when you first started where you did that first experiment?"
"Rob Ambrose","Interviewee","The first time we reached out and we grabbed something was September 1999 and we went from nothing to having that ability in about two months. So we had a neck with a head on it, some cameras, one manipulator with the Robonaut, one hand on the end of it, and a telepresence control system off to the side and that came together. Now those pieces existed in July and by end of September we had put them together for the first integrated test and that was 1999. In 2000, we put another arm on, a lefty, and we took the and went upright with an upright torso with a waist joint that could move the torso and then we really in 2001 we repackaged the torso with a better computer system and some new software and went into skin design. Started looking at tactile sensors and some overlays for improving the vision system, visual system. In 2002 we built a second unit that was Robonaut. So from the very beginning I called the first one we built Robonaut 1A1, R1A1, and everybody made fun of me that, you know, this is just Robonaut. Why are you calling it R1A1? But then we built Robonaut 1B1 and R1B1 and then they started to get the picture that we were going to be building these for a while. R1B1 was very similar to the first, but all the electronics that were in a rack behind the robot were integrated in the torso and it was the first time we had built a lower body and we built a single leg for climbing in zero gravity and we did a number of experiments on a flat floor with hovering, climbing, stabilizing with the leg while working with the hands, being able to move the body on the leg. We later because the torso was self-contained, we could do that and we later started swapping out other lower bodies. Got a great project with DARPA about that time and they gave us Doug Gage actually Mark Swenson was our first DARPA program manager. He believed in us. If he had not given us our first contract, we would have been absolutely dead. He believed in us and gave us our first real grant and then Doug Gage came in and teamed us up with a great group of university researchers thinking about autonomous control manipulation. And so there I got working with Rod Grupen, University of Massachusetts and Alan Peters at Vanderbilt and Maja Mataric, USC, and Cynthia Breazeal at MIT and their students. Great team. Doug Gage gave us a Segway and we put R1B1 on the Segway which was terrifying having a multibillion-dollar robot balancing. Wow. But we really learned a lot about mobile manipulation, bringing mobility together with manipulation and we learned how that design was really bad; that the torso on a Segway was not the right answer. It could not reach the ground, so if it dropped something it had no ability even with Robonaut's arms being pretty long, it still could not reach the ground. So at that point I realized that just manipulators on rovers was not the right thing to do. it is easy to do, but it is clunky. That just you got this part, you got this part. They were not designed to go together and if the mobility system had ever seen the manipulator when it was being designed, it would have been designed differently and if the manipulator design had ever been designed thinking about mobility, it would have been different. So you hook them together because you can, but then you realize oh, arm can not reach the ground and the arm can not reach you know there is that spot in the middle of your back you can not quite reach? Most mobile manipulation systems, that spot is huge. that is a majority of the robot that it can not reach and That is really wrong. Mobile manipulation should be able to scratch an itch wherever it is got it or get a stick. The last thing we did with the Robonaut One series was we built a custom rover and we solved this problem. We went after a number of things. We built a mid-joint mid-waist that would allow the upper torso to bend all the way down, get close to the ground. It had a spine rotation where it could rotate around and we put a little workbench on the tail end of the rover chassis where it could set things down so it did not have to always carry it. It could pick things up and set things down. It could have tools that it could use on its own little workbench and I was just looking at some robots downstairs and in the exhibit hall that had a little tray where it could set things on itself. What a practical idea. We did that in 2006. Had a nice size workbench that Robonaut could turn around so the torso had an additional mid body so that that tray was not always in the way. It could turn around and it could work, but when it needed to get to the tray, it would reconfigure the torso and turn around and so I started thinking a lot about waists. I think the waist is the key in robot design to bring mobility and manipulation together. So I started studying primates and my wife and I wrote a paper on the primate waist for it was I think the first issue of the Journal for Humanoid Robotics and we looked at primates and small primates have an incredibly athletic waist. Like lemurs and monkeys, so we defined a waist as a gap between the pelvis and the ribs and the musculature deflects it. It seems simple, right? All primates have that, right? Well it turns out not. If you look at the great apes, there is only one great ape That is got a waist and That is us. If you look at bonobo chimps and orangutans and gorillas, the ribs touch the pelvis. There is no gap. There is no range of motion. There is no musculature to flex. Their body is just a rigid puck That is got incredible limbs coming off of it, but their torso is just very rigid. They do not spin. If you look at their skeletons, it is very different from us and so then if you compare the skeletons, little monkeys, great apes, no waist, and then humans with a waist again. What happened? it is interesting, but if you look at the way great apes move and manipulate, they tend to do one or the other. They are using their arms to manipulate, swinging, or knuckle-walking, but they do not tend to do a lot of sophisticated manipulation on their own. They are very super strong. Their arms are very long. So That is one of the things that I came to was that if you have a waist, your arms do not have to be as long. You can have a small zone called a dexterous workspace and if you have a waist joint you can just move that zone around. If your shoulders are fixed and you can not move them, you discover how short your arms are very quickly. So the ability to move a sweet spot of manipulation around was important and I have got some in that paper we made a few fairly naïve projections about why we might have a waist and I think the clear evolutionary endpoint is the roller desk chair. That is really a great augmentation. A very wide range of motion for swiveling, X/Y motion. It allows a person in a work cell to have a smaller set of arms that can get anywhere and just be very it is a great combination of mobility and manipulation and I think that was a lot about it. People tend to sit and manipulate for hours and so if you were going to build something and you would collect raw materials next to you, you would not want the raw materials right in your way. you would put them over here and you might have a fire there, tools over here, and being able to move around that workspace while stationary, essentially, it is great to have a waist. If you look at chimps, they tend to move, sit, manipulate, eat, get up, move, sit, manipulate, eat. They do not stay in one spot working like we do. We can hang out in one spot and get a lot of work done very quickly and then we can throw while running and that is a really powerful thing to be able to throw on the run. You do not see that in other great apes. Being able to control your upper body, stabilize it and orient it and do something athletic with your upper torso while you are running is pretty powerful."
"Rob Ambrose","Interviewer","That is interesting. I just watched Planet of the Apes and I think in that movie They are throwing while They are running."
"Rob Ambrose","Interviewee","that is a scary thing, is not it?"
"Rob Ambrose","Interviewer","Yeah ."
"Rob Ambrose","Interviewee","I think they were evolved in that movie."
"Rob Ambrose","Interviewer","They probably that way. You know they grew a waist."
"Rob Ambrose","Interviewee","They got a waist and since they were in a lot of those using human actors, it is hard to get rid of a waist in an actor. But so that was an interesting design revelation and we exploited that in the Robonaut One design."
"Rob Ambrose","Interviewer","That thing beeped for some reason."
"Rob Ambrose","Interviewer","I think we need to switch to a different "
"Rob Ambrose","Interviewer","I figured. It has multiple cards in it."
"Rob Ambrose","Interviewee","Okay. Switch over to second card."
"Rob Ambrose","Interviewer","Actually what I was going to ask is about you mentioned that even at the very beginning, the Robonaut was really intuitive. How did you actually manage to design it? I mean what was the design process or how did you go about it to make it so intuitive from kind of the very beginning?"
"Rob Ambrose","Interviewee","Well, I would first say we got lucky, but the design objective was not to make a machine just like a person. It was to make a machine that could use all the same equipment that was designed for humans. So we had fit through all the same access corridors that were designed for humans in space. So it was we accepted the human as the de facto design standard for performance and function on the jobs that the robot would do, but it did not have to do them in the same way that a person did them, but it was going to have to do the same tasks and if we could do it faster or with more endurance, that would be great, but we had to use the same tools and fit through the same passageways that were designed for the astronauts. So when we that drove the hand design. The Robonaut hand has more fingers than the minimum that you need just to hold an object and a lot of people, their first thought is well let us simplify this by only having three fingers and I am all for other people designing robots that only have three fingers, but we are going to go for five and with five you can handle tools that are designed for humans where you have to stabilize the tool and articulate buttons or switches or triggers or latches on the object and a three-fingered robot has to control things with two hands. So imagine you holding an object That is got a thumb latch that you have got to flip, but you can not do it. you have got to reach over with the other arm and you have got to control the latch. it is a little clunky. So being able to operate all these tools that were built for astronauts wearing gloves, we had to be able to do it. So the ring and pinky are mainly just for stabilization of the object. We had also decided we were going to go after a hand so it can interface with all those same tools and the hand has a feature that very few robot hands have. If you look at any of the hands that are in our museum or in the exhibit hall, they do not have a palm. The only ones that do are the anthropomorphic hands, right? The palm is actually one of the most important features of a hand and most robot hands do not have palms. Just the whole algorithm for using the hand becomes different where if you have got a palm you use the arm to put the palm on an object and then you grasp it and that is such a simple and effective way to grasp an object rather than to reach out and try and make a pincer grasp on it. That is much more delicate, slower, it is less robust. Having a palm is typically the first contact or even you envelop. So the grasp is an enveloping grasp That is very strong and rugged. That is such a useful grasp and most robots can not even begin to do it. it is just like the most basic thing and an infant has a grasp reflex, curl reflex that is that you touch their palm and they do an enveloping curl. That is really simple and powerful and most robots can not do it. So we wanted to be able to just put the hand on an object and have it grasp it. So that was one of the first autonomies we built for Robonaut. The grasping was hard to control. So much of what happens when we as humans grasp things is done where we can not see what we are doing. That our we tend to go overhand on objects and one of our astronauts noticed Dr. Nancy Curry noticed that teleoperators of Robonaut tended to go underhand to grab objects so they could see what they were doing and when she said that it was just obvious to me after that how we were doing it all wrong and humans reach overhand and they grab things, but at some point they transition from vision to tactile. We were trying to do it all with vision with the teleoperator. So we could do it, but it was taxing the operator. They were seen forces which is a computationally intensive way to get force data, but humans are great at it. I was well, we had novice teleoperators able to do all kinds of things with Robonauts because humans are just crafty. They would see things flexing and they would know that there must be a force there and they would see contact because somebody would bend or flex and they could feel it kind of in an intuitive way, but it was clear we needed to get into tactile force control and where we went was we turned that over to the robot; that all force management was up to the robot and the teleoperator just thought they were really good; that never broke the arm. They never crushed the object and they just kind of wiggled like this and it would just get it and That is because we had the robot protecting itself from the teleoperator, not doing exactly what it was told, and contextually deciding how hard to grab objects based on what the vision system saw as a delicate object. It would grab it differently than if it was a cue ball that could possibly crush. So that was our first major break in autonomy, starting to do turning over all forces to the machine and letting it handle the forces and then once you do that, you can automate the higher level actions because the robot's going to be safe. it is going to not hurt itself and not hurt the environment. So getting to that was a major breakthrough because they we could start automating everything."
"Rob Ambrose","Interviewer","I am imagining in your office you have all these skeletons of apes and things like that. So how do you educate yourself on some of these? Even just figuring out that the palm is important and you mentioned a doctor who is Nancy or Dr. , but she noticed sounded like you have the whole team there, people looking at and so on."
"Rob Ambrose","Interviewee","Sure, we have got a great group of people at NASA, and basically surrounded myself with people that are a lot smarter than I am and they make observations like that all the time and you never know where it might lead but it is that same kind of team approach to figuring out a domain. Everybody comes in with a little different perspective. Nancy has flown in space four times. She is a robot operator excel ante . She trains other astronauts how to use robots in space. She has a PhD in Human Factors and is really into that intersection between humans and robots working together, and it turns out that is our niche at the Johnson Space Center. space, but then no one can do everything in robotics, it is a big enough profession now, and our niche is space robotics obviously but my buddies at JPL build robots that go to planets without people, and we help them a little bit. And at JSC, Johnson Space Center, we build robots that work with people in space with some help from JPL and other centers too, because there is a lot of commonality, of course, but it is really our niche is building robots to help humans in space. So for the last six years I have been leading a project called the Human Robotics Systems Project, and it funds work at the Johnson Space Center plus JPL, AMES, Glen, Goddard, Langley, and Kennedy, so we have got seven centers all around the country part of this team, and we are really focused on building machines that can help people work in space. And when we turned to the moon in about 2005, 2006, I was told to stop horsing around with Robonaut, we need to build a rover. So I said, alright, we are going to get into mobility, and I focused the team on designing a rover for people, which is a different kind of a problem. The Apollo Lunar Rover was an incredible machine and it was very different than Sojourner or Spirit or Opportunity. If you just look at the design, everything about it, it is almost exactly the same mass as Spirit, but totally different performance spec and not at all smart because you would load this cognitive subsystem on board called the human, but boy it was fast and pretty torque-y and could carry a lot of payload, carry two astronauts and unfolded pretty remarkably off of the side of the lunar lander. But when we decided we were going to build kind of the next generation of lunar rover for astronauts I put that picture up on the screen and said, this is not it; said we are going to challenge every aspect of this design. we are not just going to go build a modern version of an Apollo Rover, we are not just going to swap the aluminum out with carbon and say okay this is the update. So much has changed, let us rethink this. Plus the mission's different. The mission we were given was to stay on the moon for many weeks, and the design spec for that rover just was not what we wanted. They were never allowed to drive that rover further than they could walk back to the lander. So they just fundamentally did not trust that if it broke down they would die, there was no hope, they would run out of oxygen before they would get back, so they just never drove it very far. They drove kind of spirals around the lander, and in the last mission they allowed it to get up to 10 kilometers away because they said that was pretty much the furthest they could run before they ran out of oxygen, and they started out there and they worked their way back. So it was all about getting the crew back to the landers, they could return to earth. So I said, okay, That is the job. we are going to design a rover that no matter what will get the humans back to the lander, absolutely count on it, and that way We will trust that we can drive further than we can walk. And That is what we did. We build an incredible machine. it is a rover called Chariot that we built in 2007, and it is the ultimate off road vehicle and the people that told me that were the people that built the Hummer1, and the people who built the Hummer2 and 3. When they test drove it they said, you know, this is the ultimate off road machine, and it is. it is designed to carry two astronauts and live in it for a couple weeks, maybe even four weeks. we have only tested it up to two, and it can basically drive anywhere, it is just an incredible beast. Twelve wheel drive on six legs, active suspension, it can turn on a dime, it can drive sideways any direction, it is got a pressurized cabin so you drive it in short sleeves; you do not have to be in a suit the whole time. And we built two of them now, Chariot 1A, and 1B, so you know where I am going with that. We had crew in it for 14 days, two astronauts in each of two of them, and last year we emulated a long mission on the moon, driving in the volcanic region of Northern Arizona, and we each did about 200 kilometers driving together and we tested them by having a science team that only had overhead imagery, but they did not know what had happened in that valley and so the science team had to figure out what were the sequence of events that occurred geologically in the valley. So they used the astronauts and the robots to go explore and there was a ground science team that had done their PhD on that valley and knew everything about that valley and they kind of graded the remote science team and so we wanted to see how effective they were at exploring and using this rover, pair of rovers, totally redundant . it is got redundant drive in each leg, redundant steering, redundant suspension and it is designed so it can do everything it needs to on five out of six legs. If one leg completely breaks, it can lift that paw and keep driving so it does not drag the leg, and then if absolutely everything goes wrong we have two of them and we showed that in an emergency, all four could climb into one of the rovers and spend the night driving back to the lander. So That is the way to trust it, you build a completely redundant, very capable machine, put everything into making it able to survive failures, and then you build another too, and That is what you send to the moon. And the idea was they would stay on the moon and the crew would use them. They would land, the rovers would drive up like valet, they would use them for a couple weeks, maybe a month, and then they would go home to earth and the rovers would drive to a new valley and wait for the next crew to come and then explore that valley and kind of, we called it the leap frog exploration where it might take six months or a year to drive robotically to the next valley and then wait for the next set of explorers to come and explore that valley. Those rovers are incredible and we are now working on the next generation That is going to be even better and I joke with the guys, if you look at the rover designs, what happens if you ask if somebody who designs manipulators to design rovers, that it is got legs and active suspension and the body can control where it needs to go, and along the way we brought in some ideas from JPL, Brian Wilcox, totally new ideas about putting wheels on the ends of legs as opposed to just bolting on some wheels onto a box and calling it a rover; just really new thinking about how to design rovers. And along the way we discovered that if you did that it would change the way manipulators could be mounted on the rover. And it would change the way the waist could be built. If the lower body can bend down, then the waist can be even better or different. So when we started the Robonaut 2 project, we knew we were going to build a new rover for that and we did, we built the Centaur II that has incredible articulations as a rover and when you mount a Robonaut on it, it is upper body, it can just do all sorts of things. We reprised our design with a little work bench on the back and the Robonaut 2 is so much more capable than the Robonaut 1 that it could just do all sorts of things. And the Centaur 2 rovers are much more- than our first Centaur, we just tested that combination of Robonaut and Centaur out in Arizona a month ago and we commanded it from Houston going out and picking up rock samples across time delay and very autonomous where you just got designated rock and say go get me that rock, and since it is a government robot, after it got the rock, we told it, wrong rock, but it did not mind. Robots do not complain. "
"Rob Ambrose","Interviewer","Yeah, we saw the rover part because we were at ISR, but the had not ."
"Rob Ambrose","Interviewee","you are right, yeah, it had not gotten there yet. So you saw the Chariot rovers?"
"Rob Ambrose","Interviewer","Uh huh."
"Rob Ambrose","Interviewee","And the Centaur 2 with the digger on it, the digging blade. Yeah that is a very capable design with the hands can not handle it, the bulldozer usually finishes."
"Rob Ambrose","Interviewer","Yeah, we actually have a video of it so we put it with your"
"Rob Ambrose","Interviewee","Oh very good. "
"Rob Ambrose","Interviewer","I ventured out there and got some footage of it. "
"Rob Ambrose","Interviewee","I am sorry I did not recognize you."
"Rob Ambrose","Interviewer","No, no, no, do not worry, there were so many people there."
"Rob Ambrose","Interviewee","There were a lot of people on that bus, yeah. That was a big bus. Well good. Well the Robonaut 2 project's been great. We formed this team with GM that was just fantastic, they were a great partner, and we built that team based on an aligned vision. They wanted robots that could safely work next to people and handle all the same things that were designed for people. So cars are designed to be put together by people, right, and space craft are designed the same way. Human space craft are designed so everything can be serviced by- it was all put together by people originally anyway, but it is all designed so human can fix things and service it. So where we were kind of accepting that as the de facto standard for a robot, GM is looking at that same idea. we are not trying to get rid of humans. A robot That is designed to safely work around humans kind of assumes that They are going to be humans. If you are going to design a robot that would do it by itself, you design a totally different kind of robot, it could be sharp and fast and lethal, you would not go near it. You put it in a cage, you never let people in as it is doing its job, but if you are designing a robot That is going to work shoulder to shoulder with people, it is got to be a totally different kind of machine. it is got to move at a pace That is not going to surprise the people. it is got to be smooth and soft and be able to fit in the same places that people fit in and handle all the same objects that people handle. it is a lot harder if you could redesign all the world to be handled by a simple robot, go for it, because That is definitely a better option as far as the cost of the robot that redesigned the world is kind of expensive, so we decide, okay, the world's designed for people, let us just accept that rather than fight it, and step up to the challenge of building a robot that can work in a human's world. That is what we have done with the Robonaut system; well we are on our way. we have been working on Robonauts for 15 years, and I think it is going to take about 50 to get it right. So by the end of that probably be pushing Robonaut 10, and we will have made just incredible progress. I can not even imagine what the next 35 years will be like, but it is going to be great. Even the jump from Robonaut 1 to Robonaut 2 is just huge, this robot is so much more capable, more reliable, faster, stronger, better and I expect the jump from R2 to R3 to be equally impressive and we have got a lot of pent up ideas now about what it might be and the team's eager, I think, to get going on the R3. we are not done with the R2's yet, we are still learning. "
"Rob Ambrose","Interviewer","What are some of both the technological and the conceptual changes that made that jump possible?"
"Rob Ambrose","Interviewee","Well, just all sorts of ideas. When we built the R1 it was a long time ago, it was 1996, 1997 when we were designing it and I like to design robots to implement an algorithm. So if you understand the control algorithm then you can make choices about how fast should it be, what kind of sensors are needed, where should the sensors be, what kind of motions are appropriate, and you can optimize. But you understand the algorithm that you are trying to implement, and we found some new algorithms. So the algorithms for autonomy are very different than for telepresence control, and it drives you to very different kinds of sensors, and you need more sensors, and different kinds of sensors. Sensors that might be hard to display to a human, but that are ideal for the robot. it is really hard to show force, but the robot feels it much better than a human could ever understand; so all kinds of fore sensing, very important. There was an algorithm, an idea more than an algorithm that Gil Pratt had at MIT called series elastic actuation, and it was I think one of the most important breakthroughs in robotics, where he was putting elasticity into the drive trains and then rather than sense strain gauges signals, very micro strain, where metal is stressed and it strains very minutely, a strain gauge picks that up. The problem is strain gauge picks up everything. There are much better temperature sensors than they are strain sensors and they will pick up all kinds of electromagnetic noise and they age poorly and They are fragile. So what Gil found was with macro strain, we added a lot of elasticity in the drive. You could measure that deflection with position sensors that we are seeing a lot of strain, a lot of wind up and it was easier to do without as much noise in the signal. Plus when the robots even just turned off, minding its own business and you bump into it it is soft. So a great new idea and it had a huge impact on the design of Robonaut 2. So I looked at all the implementations of series elastic and most of the implementations involved linear springs and cables and pulleys like at the MIT Leg Lab, but I was looking for something more inline and direct and so we came up with a number of very novel series elastic embodiments for the Robonaut 2 project, and we are over 40 or 50 patents now coming out of the project. So I can not go into all the details but we came up with a series elastic design that was basically one part that could be made fairly inexpensively and it just kind of simplified the whole packaging down and so with the Robonaut 1's we had already started to go to a very svelte design of the manipulator. I did not want things sticking out sharp, pinch points. Cylinders are nice but when they start sticking out at orthogonal angels they form sharp edges. I did not want to hurt people, and I also liked the idea of skin coverings that are, again, soft, and got a patent in skin design. There are a lot of other benefits to skins on robots for cleanliness and EMI, Electro Magnetic Interference Control, but safety's a really good one. Skins can protect the robot from a dirty environment and vice versa. So we started covering our robots in soft fabrics, space materials, Teflon, Kevlar, Vectren, and we have continued that with the Robonaut 2 but with a soft core and the drive trains you do not need as much compliance in the skin because it is already soft. But again, if you look at the design of the Robonauts, They are smooth. There are no sharp edges, protrusions of corners, and if you look at like a welding robot it is lethal, it is got 90 degree angles, sharp and steel bolts sticking out of it and if it hit you with that bolt might as well be a knife blade. We do not want any of that, everything's got to be smooth and svelte for working around people and we have really pushed that in the Robonaut design, it is an extremely smooth and compliant now also, and I think That is essential for working your people. You just do not want any sharps or pinch points, and that goes to the NASA design philosophy is before space hardware is certified, we go over it with a swatch cloth and look for any burs or sharp edges that could cut an astronaut's space suit and kill him. We do not want that so everything's got to be smooth, and I think That is really important for the future of robots working around people is they just need to be soft and smooth and easy to bump into and not cause a problem. Also helps when the robot bumps into things that are not people. When it bumps into itself, the robot's elbow touches its torso, it is usually a disaster. it is got a scrape on its elbow, it is got a scrape on its torso, and it probably ripped its shoulder apart because That is where all the torque was so it is got typically three injuries, just from bumping its torso, and humans do this all the time. it is actually a comfortable, because it is the end of the stroke of your arm, perfectly reasonable for your arm to touch your torso, it should not be a disaster, and yet it is in most robots. The robots have their elbows out like this because they do not want to touch anything and That is horrible. If an arm reaches in and bumps something that should be no big deal, but if it is got a bunch of wires or sharp edges or snag points, keep it away from me, so It will hurt us. "
"Rob Ambrose","Interviewer","So with the NRI there is a lot of focus now on these kind of pro robotic applications. So do you have a feeling for over time how in the community this interest in more human oriented systems has developed versus focusing on the ones that are more autonomous and have their own closed environment? "
"Rob Ambrose","Interviewee","Well, That is what we have always been focused on at the Johnson Space Center. Robots for working with people is our deal. So we are really happy the rest of the world now thinks it is a good idea too. I am the NASA point of contact for the National Robotics Initiative and I have been working with the office of Science and Technology policy to get it moving. I read some of the early papers on co-robotics. It was like I had written them myself. They were wonderful. A lot of really solid thinking had gone into some of the ideas. I asked, let me write an extra section, it was like co-worker and co-protector and co-inhabitant, and I said, let me write one on co-explorer. So I read a few pages on that and as I then started to talk to several of the other agencies, other federal government agencies about the initiative, they could all kind of relate to it, that they all had some aspect that was important to them. The NIH has great applications for robots working with people obviously, and NASA, I have already gone over a lot of the ideas, but what I wanted was each agency to kind of see itself in that theme, and pick out the aspects of it that were important for that agency's mission, and it was actually pretty easy for everybody to do, and one of the things that was probably the core value that everybody had was safety around people, that they all had some job to do and that varied agency to agency, but let us do that job with the robots next to people without hurting the people. that is across every single agency's interest so it is the easiest thing for us all to focus on and it is really important right now where robots have matured and we are now getting them capable enough, we actually might want them to be near us because they could do jobs that are worth it, now please just do not hurt us while They are doing those jobs, and That is where we are now. There are a number of other aspects. It would be nice for them to not annoy us, where we could get them to do a job quickly without having it take more time than just doing it ourselves certainly. And then there is a number of other aspects of the human robot combination that I think are probably true, and interest all the agencies, but do not hurt people is really very fundamental. We took some major steps in that when we got the Robonaut 2 certified for space station. That is a very conservative community. We do not just let anything inside the space station with the astronauts. it is got to really be safe. So fortunately we have made a lot of really good choices in the Robonaut 2's design, and we have three independent ways to feel a person bumping Robonaut or vice versa, and That is enough that it is trusted. So three independent sensing systems that can all sense forces of contact with their own cable harness going back to separate processing. When NASA goes through a design like that, it is just very paranoid, what could possibly go wrong. I will assume three things go wrong, you know, what do you get, and we went through all of that and proved the design was safe enough so that astronauts are allowed to be in the work space of this robot while it is running and that is a major breakthrough. You see some of that going on but it is dangerous. People today are in the work space of rovers and manipulators that concern me because they do not have redundancy and they are not particularly soft and smooth. A lot of the designs are just really wimpy so that you know they can not hurt you much because They are not very strong. That is not the right answer either, because what we want is a machine strong enough to actually do work, but safe enough to do it right next to us. So just making the machine extremely incapable is not the right answer. So a robot that can handle, like with Robonaut we typically handle 20 pound dumbbells and full extension to do this forever, yet we trust it to do it right next to us. That is the challenge. Anybody can build an under powered robot that can not really pick itself up, but build a machine strong enough to do work and be safe is the real challenge and likewise with mobility. So the co-robot theme is not just about humanoids at all. Robots are in so many different forms. Cars are going to become robots and what would it take for you to trust driving on the same roads with robots? What would it take for you to trust being in the car when you are not driving? What would it take to put your kids in a car and have the car drive them to grandma's house, but you are not in it, and the kids are not driving? That is tough. For me that last one's probably the hardest. what is that going to take to be able to have robots working with us, shoulder to shoulder, driving lane by lane, and trust that they will not do the wrong thing and That is where we are right now? We can build a car capable that could drive at any speed we want to drive, but making it able to do it right next to us is the big challenge. So we call that one co-driving, co-pilots was already taken. But being able to share the roads with these things huge breakthroughs are needed, I think, to make that happen, but it is going to happen. You know it is going to happen. Are we going to have mixed traffic, big trucks, little cars, bikes, pedestrians, and you are going to have robots driving in all of that, it is just a matter of who can figure out how to do it safely first. "
"Rob Ambrose","Interviewer","In that case it is also not just a problem with robot actually doing something wrong; it is the fact that people are somewhat unpredictable as well."
"Rob Ambrose","Interviewee","Oh it will always be the people's fault. Always. I mean robots should never be blamed. You can quote me on that. it is always the people, because at a minimum we designed them and so it will always be the people's fault. Robots have a bad tendency to do exactly what we tell them to do and it is definitely the person That is the problem. "
"Rob Ambrose","Interviewer","So one other thing I was going to ask you about quickly, or maybe I should not because I have talked to some other NASA people about funding. "
"Rob Ambrose","Interviewee","Thank you for not asking."
"Rob Ambrose","Interviewer","going all two hours too, it looks like we are getting close. So I think you told us a little bit about how you see this stuff developing in the future so we can get that from there, but are there any other aspects of the project you worked on that you wanted to mention or the teams or many people that you worked with?"
"Rob Ambrose","Interviewee","Well, I mentioned the General Motors Corporation, great partner in the Robonaut 2, and I mentioned DARPA, another great partner, a number of universities. I really do not think that there is any limit to our advances in robotics, we are only in the very beginnings of what robots will be able to do and our optimism mainly comes from watching students build new machines and I do a lot of work with kids in robotics and programs like Dean Kamen's First Robotics Program are truly inspirational, and every time I watch kids build some new incredible robotic it reinforces, in my mind, how the best robots are in our future, and they will not be built by me. They will be built by"
"Rob Ambrose","Interviewer","."
"Rob Ambrose","Interviewee","Maybe. They like building robots too. "
"Rob Ambrose","Interviewer","So that actually kind of nicely brings us to our general last question which is basically if you had some advice for young people who were interested in robotics, what would it be? "
"Rob Ambrose","Interviewee","there is no excuse for them not to find a robotics team somewhere. When I was a kid that was not an option but now there are so many out there that they really need to go find a team and get busy. it is relatively easy today to do that. The resources are there. Go find an engineer and volunteer. that is a good way to get a job. I have basically volunteered to go work on a project that was funded by NASA because I wanted to go work at NASA. If there is a robotics team working on some problem nearby go volunteer to help the engieers go build it, and it is amazing what you can contribute just by having a good attitude and trying. you will pick it up and learn to work with others on a team and That is, I think, the best way to get started. You do not need to wait until you go to college. That is not going to get you where you want to go. Start early and volunteer to get involved with a lot of ongoig projects. They are probably in your area and seek them out and volunteer. "
"Rob Ambrose","Interviewer","Great, thank you so much."
"Sadao Kawamura","Interviewer","And if you need to stop at any time."
"Sadao Kawamura","Interviewee","Okay."
"Sadao Kawamura","Interviewer","Or you want us to not use something that you said, just let us know."
"Sadao Kawamura","Interviewee","All right."
"Sadao Kawamura","Interviewee","Good."
"Sadao Kawamura","Interviewer","Thank you. "
"Sadao Kawamura","Interviewee","Because still jet lagged, so. Okay."
"Sadao Kawamura","Interviewer","So could you tell us your name and when and where you were born."
"Sadao Kawamura","Interviewee","Okay, my name is Sadou Kawamura. I was born in Osaka Prefecture. I grew up in Osaka and entered the Osaka University. Do you know Osaka? Okay. And I entered the Department of the Biophysics and before entering the university, I was very interested in the robots and also I was interested in the living things there, animals or fish or insects or something like that. And I did most of them. So then I decided to enter the this department, because this department is a very interesting and students must learn many subjects, the molecular biology and neurophysics and human interface and the information theory and control theory and electrical engineering, were so many. So and just I go to there, I could learn both artificial things and living things, both of them. That is my very interesting point. So but after four years when I graduated from this department, I go to the I wanted to make artificial things like robots, mechanical system or much more than studying, much more than on arriving there, biological system. So then I decided to change my major and I entered the graduate school over there, mechanical engineering, also university and I started to study over there, robots there. Part of the yeah, undergraduate students by physical engineering, at that time, I also yeah, I was studying kind of the fish robots there. We made that very interesting fish robots there and I measured the efficiency of the motion performance with the graduate students there. And at that time, the students are very interesting there. Some of my students who become the professors, the micro electro mechanical engineering field and other person become a researcher over there, brain science or other person now he is the president of the kind of the Panasonic company. So many very different areas. So then I studied the robot research there, under the supervision of the Professor Imoto. At that time, he started just to study the robot research there and Professor Miazaki he is a I those days, he is an assistant professor and studied the bipedal locomotion robots there. And not to perfect the human, just the legs, two legs. And I joined this project as my start over there, research of the robotics and in those days, motor power is very weak and it was very difficult to realize the bipedal locomotion robot, and also the some time they just do, maybe around the 30 second, 30 millisecond. So it is very difficult to achieve the field about gaining to make the motion of the robots then. So we succeeded to make the bipedal locomotion. Yeah, That is good memory."
"Sadao Kawamura","Interviewer","What year was that around?"
"Sadao Kawamura","Interviewee","You mean the "
"Sadao Kawamura","Interviewer","The biped."
"Sadao Kawamura","Interviewee","Yeah, first I made the robot itself and the second I made the computer program and but it was very difficult, to how they say achieve the feedback . So then I tried to make the feeder more input, the control but there was no good ideas to make the feet forward input. So then I try and try every day, every night, so just changing the desired trajectory. So that means the kind of we make the feed of input trial and error, so it was not so effective. So then I thought of we need a very automatic system then, kind of learning. So then I tried to make the kind of motion learning method there for the bipedal motion robots. So in PhD thesis was the elite running control for the robot motion. And at first I uprighted this technique to the bipedal locomotion robot and we succeeded making the very suitable locomotion. And after that, we applied this technique to the manipulators there, motion, the so then we did not need to tune the feedback gain because the robot they serve around the desired motion. So I think that is a very honest, yeah, control system there. And also we could approve the how our technique works well from a mathematical viewpoint. So the results, yeah, Professor Imoto , the mathematical proof is very, very helpful, yeah. And yeah, anyway, we could get good result, I believe. Yeah."
"Sadao Kawamura","Interviewer","You mentioned that you started with an interest in both animals and robots."
"Sadao Kawamura","Interviewee","Yes, yes."
"Sadao Kawamura","Interviewer","And so with bipeds there is a connection to humans and robots."
"Sadao Kawamura","Interviewee","Yes."
"Sadao Kawamura","Interviewer","So was there any did you study walking in humans ever to do some of the work?"
"Sadao Kawamura","Interviewee","Yes. Yes, yes, yes. So always, we look to the both of them and how human can walk very well, and we studied from the human locomotion. Part of the implementation using the That is very different there. So how we pick up the important point from the human motion and we implement the real robots there. that is a very important point do that."
"Sadao Kawamura","Interviewer","And what are some of the big challenges that you were facing when you were trying to do that, going from human like walking to getting the hardware to actually?"
"Sadao Kawamura","Interviewee","So as you know, the human body has many kind of number of the muscles and in the robot case, the number of joints is limited. So then how we pick up the important motion, we as the kind of maybe the center of gravity changing or other few points there. I think That is very important to them to find out."
"Sadao Kawamura","Interviewer","And what were some of the kinds of studies or experiments that you were doing then with the robots?"
"Sadao Kawamura","Interviewee","You mean the "
"Sadao Kawamura","Interviewer","People and robots."
"Sadao Kawamura","Interviewee","When I studied bipedal locomotion? Yeah, that time the of course Professor Miyazaki, that is assistant Professor, his major is bipedal locomotion in those days, and yeah, Dr. Takayaki , he was there the doctor of students there, in the same level three. Now he is the Mitsubishi rectory Corporation, and he is certainly very interested in to make the natural motion of the robots. I also studied thusly and also when I was the graduate student, I moved to the some level threes, there are different level threes. And because I graduated from the biophysical engineering, I knew many person, the previous department. So then I joined the and to study the neuronaplex or other neurophysiology and the Doctor Garpo he is a Hideo in those days he was a PhD student and I joined several seminars to study there on neurophysics there, and That is very interesting for me. And we exchanged some ideas in discussed. So such the duration of different field, That is very, very important for me, I think. "
"Sadao Kawamura","Interviewer","Did Dr. Garpo do anything with the bipeds at the time or no?"
"Sadao Kawamura","Interviewee","Not biped, but very general motion learning and also I studied many things from him about the neurophysiology and the mathematical treatment also. That is very, very important."
"Sadao Kawamura","Interviewer","And how did you combine the kinds of different things that you learned from these different fields into your work?"
"Sadao Kawamura","Interviewee","I have to say, still now, I can not complain very well. So now, I am struggling, because the living thing is very, very difficult to analyze the . So still now I am studying. I am concerning there, yeah, how we use their functions of the living things to design artificial things. In some robots, now so many numbers of industrial robots are walking and They are all over the world. And but with living things, there is a very interesting contract because in the robots' case there is small number of sensors just encode as they were some other, very few sensor. But the CPU, that is a large computation power, and very limited actuator . So very small number of options. But living things are very different. There are very large number of the sensors, but small computation power and a large number of actuators. So whether they can behave very smoothly and very effectively and very robust and very soft and from Miyagi efficiency view point, living things very nice. So they do not still now, I think the robot derive there from the living things. There are so many new ides there to make the robots there, in near future. But at same time, I believe just a copy is not good. So important point is that to make clear the functions of the animals or insect or living things. That is very important to realize the artificial things. I thought about these things at that time also. "
"Sadao Kawamura","Interviewer","And it seems living things are much more embodied and connected to the world."
"Sadao Kawamura","Interviewee","Right, right, right."
"Sadao Kawamura","Interviewer","Without so much thinking."
"Sadao Kawamura","Interviewee","Yeah, right."
"Sadao Kawamura","Interviewer","Being in the world."
"Sadao Kawamura","Interviewee","Right."
"Sadao Kawamura","Interviewer","And when you were doing, you mentioned doing the fish and then also the biped. What kinds of questions were you interested in? Were there design questions? Were there and you mentioned kind of looking at the neurophysiology of things. Were there also scientific questions or application issues that were involved in this project?"
"Sadao Kawamura","Interviewee","So probably, that is an interesting question. Just a moment. One clear things, the my hobby is martial arts, do Aikido. So then I started to do this Aikido practice when I was a high school student. So then I practiced very hard when I was in high school and also a university student. So to round one motion, so we have to do the same similar motion more than 1,000, 10,000 times, so the human beings can learn the one desired motion. So then when I was a graduate student, I thought a human can learn the desired motion through motion. So then probably the robot can also. that is a basic idea to make the locomotion of robots. So in this sense maybe the kind of neurophysiological areas that I was very interested in there, but at the same time, the fish robot case there, maybe I like the sound softer than some shape or so maybe both of them, maybe I was very interested in, I should say."
"Sadao Kawamura","Interviewer","And did people think of applying these things for any specific thing?"
"Sadao Kawamura","Interviewee","Yeah, I have heard the outward ears, of course this idea is the my PhD thesis about the of the convergence of the motion to the desired motion. So then the not only, but those other automotive and the Professor Miyazaki, they contributed this work. And this robot three there is the yeah, there are several researchers from the company and for example, the researcher from the electric Company, he used this technique to some video cameras. In those days, the camera system is different, kind of that tape then. So then they designed a , They are very important to keep the desired of the . He used our technique to yeah, make that good movie cameras there. Maybe other things, the chemical plant and That is very different. Chemical plant or some mechanical system for some access or some other very different areas this technique is."
"Sadao Kawamura","Interviewer","So what kind of things did you do after you PhD?"
"Sadao Kawamura","Interviewee","Okay."
"Sadao Kawamura","Interviewer","Or actually sorry, I know I had something else to ask of him."
"Sadao Kawamura","Interviewee","Okay."
"Sadao Kawamura","Interviewer","But what was the state of bipedal robotics? Were there other groups working on bipeds or walking robots?"
"Sadao Kawamura","Interviewee","Yes. Yes, in those days there were several groups which focusing on the bipedal locomotion and University of Tokyo, the Mira Sensei and the Shimoyoma Sensei, they are making the very dynamic by the locomotion and also the Waseda University and the Kato Sensei and the Takanishi Sensei, also they making the very good enough large, the human sides done by the locomotion robot and also other kyushu technology, yeah, the Master Sensei or other people. So there was the smaller research group there. So then we exchanged the information, yeah. But approach is a little bit different there. So some group focusing on the control theory, the other groups focusing mechanical design or the other system, interesting other things. So that made it a little bit different. "
"Sadao Kawamura","Interviewer","Why was there do you think such an interest in walking robots?"
"Sadao Kawamura","Interviewee","From a theoretical viewpoint, They are unstable. For them, it is very interesting the target from a control theory. So then, That is the main reason why people interested in the bipedal locomotion, I think. Okay?"
"Sadao Kawamura","Interviewer","Yeah, That is totally fine. So going back to your trajectory."
"Sadao Kawamura","Interviewee","Okay, okay, trajectory."
"Sadao Kawamura","Interviewer","After your ."
"Sadao Kawamura","Interviewee","After, yeah, after getting my PhD and I was the assistant professor in Osaka University, the same level three and just one year later I moved to the University. Now, I am working there, and I became associate professor in the department of mechanical engineering. And so I started my level three there 1987. At first there was nothing, completely nothing. So then I make the I bought the computers and also made the expert very, very simple mechanical system was, and it yeah, so then I continued such multi-jointed mechanism, multi-bodied dynamixers something like that. And my interest is a little bit to the theoretical approach as there was only implementation over there, hardwares. So then I started oh sorry. I did it wrong there. I started another project there, when I was there, the end of the PhD and also the assistant professor in Osaka University I studied another approach there. That is the time scale transformation technique there. We called the that is the we changed the time scale, we enlonged or shortened it to analyze the dynamics and also to make the sort of control input there. So this is very unique there because time is the just the scatter bodies, you know. So even though the body was before like the robot and also case, but time is just a scholar. So then the very simple factor can characterize the very complicated body was a non-linear technical system. So then I used this one. So because the why we consider this technique there, using the delayed running control and we can get to the desired through the many operation. So then just around the desired motion like human beings. So then they do not do the humans case there. I thought the human can image property human can image the human of thing that desired motion or that person can also image the different speed of motion. So then they go for a batting day. So we learned that very slow motion first, and after that then already we can run a very fast motion. But once we learn the such agilent motion, so we can image the different of motion put out. So then I wanted to implement like this ability, yeah, of the robot, motion control. So then, it is a little bit complicated contents, but in the time of transformation case, I succeeded prove that when I was PhD student, also the assistant professor. And then after I moved to the University I try again the non-linear time scale transfunctional case. So then one year later I could get the hint and after that I could succeeded there. They put forward how we use this technique there. So then what do we look to get is the four different motion patterns. If their robot, They are four different time scale different patterns. For example, the very slow motion like this and intermediate speed and high speed and the important point is the first part is the slow starter or high speed or high speed or slow speed like this. Anyway, the nonlinear speed, four patterns there. So after getting the four patterns there, the robot took generally to the arbitrary motion, so we could prove that that is all. So That is technique is very simple or very useful for the very complicated system. So I applied the datas maybe 10 years almost 10 years later I applied this technique to the under water world, motion controlled. Anyway, I started like that there, research there when I was there as assistant professor in the University. That is one project. "
"Sadao Kawamura","Interviewer","And did you have an idea that you can apply it to these different things at the time or did that come later?"
"Sadao Kawamura","Interviewee","At the same time, I could get to the ideas there, whereas the PhD students case there, after getting the running . And the non-university case study, once I gave up it is very difficult, so I gave up but one new PhD student there they entered my laboratory and so then I started to consider this subject again, and as he is PhD thesis. So anyhow I could get to the good results there."
"Sadao Kawamura","Interviewer","What do you think changed between the first time and then when it actually worked?"
"Sadao Kawamura","Interviewee","So at first, when I was the PhD student's case study I focused on some areas there. I did not see the different point there. So anyhow, once I gave up and they look there, this subject, the very wide view, so then I could get the new ideas there. That is very important."
"Sadao Kawamura","Interviewer","So when you were not focusing so much on the biped or that particular type of motion."
"Sadao Kawamura","Interviewee","Yes, yes, yeah."
"Sadao Kawamura","Interviewer","So when you got to Makon were there other people there who were interested in robotics?"
"Sadao Kawamura","Interviewee","When I was the associate professor, just to well professors who is specialty is robotics. The other professor is in the materials or the machinery or different areas, just did one, yes. And after 30 days, our university decided to expand the college over there in general science. So then I proposed the new department of robotics so then I prepare the yeah, and also the we started a research into the robotics there. So fortunately the most of them we could establish and 1996 there we all started the department of the robotics and we needed two years to prepare there for this department because this department is very new and maybe the first department of robotics in Japan and maybe we all over the world this is very unique because the not graduate school there, but the undergraduate case. Maybe that is now very traditional department mechanical and graduate school robotics are some very master course there. I think That is natural. I really the educational program. For Japan, the case may be if the student wants to enter the one area, one field, so it is very rare the person to change to different areas. So enter the same area of school of the same areas so but I think the very wide view is very important. Not only they research robot. Also they engineer other ordinary areas also. So then the other counterpart of it. I would like to start it at the new department so then the department of robotics case study student must learn the mechanics and the electric engineering and also the information science and also some technical human measurements. The emotion measurements or some other yeah, psychological things or something. So very wide. So now the almost yeah, 15 years have passed after the start of this department."
"Sadao Kawamura","Interviewer","And are there any other departments that you know of in Japan that have robotics from very early on?"
"Sadao Kawamura","Interviewee","Yeah. So after we started this department there are several department that started in other university. Now maybe probably there are more than ten departments there in many different now the university."
"Sadao Kawamura","Interviewer","But not very common around the world, right?"
"Sadao Kawamura","Interviewee","Oh I think so. I think so. "
"Sadao Kawamura","Interviewer","In Japan there seems to be an interest in these interdisciplinary because They are also mechatronics was kind of a more ."
"Sadao Kawamura","Interviewee","Yes, right. "
"Sadao Kawamura","Interviewer"," interdisciplinary ."
"Sadao Kawamura","Interviewee","Yeah, yeah. Yeah, but at same time we needed a interdisciplinary education much more I think. So because as I said, I think maybe that Japanese culture is their focus on the one way, so it is not so easy to mix the many areas. The European countries also the North American case maybe They are very natural to change the people want to move there. They are space or some areas that I think that maybe in Japanese is different there. So therefore we need such thing as disciplinary educational program so I believe."
"Sadao Kawamura","Interviewer","And what was the name of the faculty member who was doing robotics when you got to ?"
"Sadao Kawamura","Interviewee"," University ."
"Sadao Kawamura","Interviewer","When you just got there you said there was one person."
"Sadao Kawamura","Interviewee","Okay. One person and so the other person?"
"Sadao Kawamura","Interviewer","Mm-hmm."
"Sadao Kawamura","Interviewee","Professor Miyata , yeah. "
"Sadao Kawamura","Interviewer","And then afterwards you hired more faculty or?"
"Sadao Kawamura","Interviewee","Yes. So then we could do we put in new positions as a professors and academic staff in this new department so then I ask some people there and to become the professors or assistant professors. So then the very good professors all came to this department and the started by maybe 12 or 13 professors the year. So from the University of Tokyo or Wasera University and Kyoto University or Kyoto University and yeah, yeah, yeah. So many different universities, yeah."
"Sadao Kawamura","Interviewer","Who were some of the first people who came?"
"Sadao Kawamura","Interviewee","Professor Hanafsa , he was the president of the RSJ and also with Watanabe he came from the Kyoto University and Mieta, Professor Mieta from Osaka University and then Professor Nale . Professor Nale is now the professor in same department. He came from Kyoto University also and Hirai , Professor Hirai. He came from the Osaka but he came from Kyoto University and he was the student over there Hari Asada MIT and Professor Tanjima . He came from the Tokyo University and Professor Ishi from Waseda. Ishi from the Waseda University and who how many I said?"
"Sadao Kawamura","Interviewer","One, two, three, four, five, six, seven. You do not have to remember "
"Sadao Kawamura","Interviewee","Okay, okay. Okay, okay. "
"Sadao Kawamura","Interviewer","Not a test."
"Sadao Kawamura","Interviewee","Okay."
"Sadao Kawamura","Interviewer","So were there particular topics that people were interested in at the time or that the department kind of focused on more than others?"
"Sadao Kawamura","Interviewee","Okay. Oh, sorry. Professor Harimoto also joined us . He was at University of Tokyo. He was a professor in Osaka University and also went to the Tokyo University and moved to University. I call him. So then we have the mainly the three areas in this department. One is the robot system that we call a system, but maybe the hardware-oriented and the second area is the intelligence. That is the machine intelligence there. So and third area is some human something, maybe we considered the near future at that time human interactions very important. So then the measurement of the human behavior including the psychological things that so that area's very important in robotics. So then we said that the some main areas there are some main areas that we stated that human measurement. So we did not see the human side. it is very tough. Very few professors completed all areas of human science. So then we said to the very limited human measurement there. Yeah, so because the application of the robots is very important there. Those three areas. "
"Sadao Kawamura","Interviewer","And how did you have a feeling that the human side was very important? Was it more from the government or funding or where did that idea come from?"
"Sadao Kawamura","Interviewee","that is an interesting question. At that time there was no big funding there, the areas of the human interaction so but we considered the Japan will become the elder society so then also the human interaction, so human measurement is very, very important as the one of the application of the robots. So That is our original discussion, yeah. "
"Sadao Kawamura","Interviewer","And what year was this around?"
"Sadao Kawamura","Interviewee","You mean actually what we did?"
"Sadao Kawamura","Interviewer","Yeah, when you were kind of discussing these things and putting the department together."
"Sadao Kawamura","Interviewee","Oh, so other curriculum, educational program, we stated the several subject, so measurement of the human motion or biomechanics or bionics or some other study for understanding the human itself, so not the medical, just like medical school sense, means kind of the measurement, yeah. That is the correct word and also some of the professors have interest in the robotics and also the human machine face or medical application That is there."
"Sadao Kawamura","Interviewer","And was this in the 1990s?"
"Sadao Kawamura","Interviewee","In the 90?"
"Sadao Kawamura","Interviewer","1990s or "
"Sadao Kawamura","Interviewee","Oh, 1996 we started this department, yeah. "
"Sadao Kawamura","Interviewer","And what were you working on at the time?"
"Sadao Kawamura","Interviewee","First of all I prepared a present prepare this so then at that time it was not so easy to start a new department there. So then I came to the ministry over there, the education so many times to prepare to write many papers then to discuss and when I started this department first of all we had to do the advertisement for the high school students what the department is. that is also very difficult. Yeah, but anyway, yeah, we could continue the 15 years there. "
"Sadao Kawamura","Interviewer","Was there a lot of interest or it was strange to students?"
"Sadao Kawamura","Interviewee","One thing is the high school students are imaged, the robot image that came from the cartoon, so science fiction so then when they enter the university I ask them what is a robot. So then the answer most of the answer was the very not scientific case. So in the hour I got into staff about I explained now what is going on actually. When they graduated there from our department they could deeply understand what is the meaning of the robotics that are the system integration that they what is the importance of the robotics?"
"Sadao Kawamura","Interviewer","And the ministry of education, what kinds of things did you do with them? Was it getting approval for the department or were there other ways "
"Sadao Kawamura","Interviewee","We needed permission from the ministry of education otherwise we could not start. So in those days it was very, very difficult. Now the easier, but in those days very difficult. So then we needed two years to study that this new department. First question from the ministry of education: what is a robot? A robot is robot advance of technology? That is the question. Second question is do you know that we have in Japanese has three kinds of character: the hiragana, katakana, kanji. Kanji means a Chinese character and the hiragana is a very so children must learn start from the hiragana. The katakana is also very easy to write. So then the second question is robot we usually write the katakana, not the China character, so katakana so they did not want to use katakana name that as a university department so "
"Sadao Kawamura","Interviewee","Yeah, that is a big problem for us because we do not have the Chinese characters that means robot, so then we convince the ministry of education that robot, this name is nice. A good memory. "
"Sadao Kawamura","Interviewer","What kind of research were you working on? Probably while you were having to do all of this administrative stuff maybe it was hard to do research too."
"Sadao Kawamura","Interviewee","Yeah, yeah."
"Sadao Kawamura","Interviewer","How did your interests develop while you were ?"
"Sadao Kawamura","Interviewee","Okay. I started my own laboratory so then I had to prepare everything and but at the same time I could decide the direction of my research there even though I was just to 30 years old and so then I started also there are almost ten undergraduate students and over half of the students enter the graduate school so then I should prepare the some of the research so then I started the new project. One of the new project is that the using the tendon ribbon robots there to make the very high speed, high acceleration so then we could realize the very high speed motion robots there with very small motors because the mass is very small and so of course to make the high acceleration so we may set the very large actuators I did not want to do that there, so I took the reverse direction, that is to reduce the mass. So then the tendon ribbon was so the moving part mass there. I reduced it so then the just a small 60-watt motor is there and could realize the more than 43G. G means gravitational acceleration and that is very interesting for us and we actually made the like this side of the all very wide motion because in those days very high acceleration robots there was some high acceleration robot, but the motion range is very small. So then we realize a very wide range there and also the one Japanese company asked us to develop the large-scale robot and for the painting of the cruiser or a big ship. So then even though they use a very big crane or other big manipulators because a 10 meter or 20 meters in this case. So then That is very dangerous also, the maintenance is very difficult. So then they asked us to develop a very lightweight and safety robot that used the tendon ribbon and so that we build up the large robot case or so. it is one of the new project."
"Sadao Kawamura","Interviewer","Which company was it?"
"Sadao Kawamura","Interviewee","Yamaha. Yamaha. "
"Sadao Kawamura","Interviewer","And how did they contact you? Did you have contact before or "
"Sadao Kawamura","Interviewee","Yeah. Okay. I told you the department robotics there before I did that. We studied the robotics, flexible automation research center 1995. So then we have several professors to prepare the new department so then before start time, some of the professor move to the University. So in 1995 or 4 there were some of the professors working in the University. So then we discussed and we needed the research centers there which specialized in the robotics field. So then we moved to the many companies and we explained our ideas and our ideas is very clear and our research interest we do in our laboratory and we want to make the new space and for the company's research, so separated. So then we promised the research from the company we would seriously perform the industrial needs there. So then we explained that this idea to many Japanese companies. So then several Japanese companies agreed with us and they there not small money and we could establish the robotics flexible automation centers, but every company was national national universities which was supported by the ministry of education. In that case maybe the center's very big there, but this way it was a private university so it is not so easy to get the research fund from the Japanese government so then we decided to propose our ideas to the Japanese company and so then the space is not large if I compare with the national university the big research centers, but almost 5000 square meters that we could obtain as the centers. So then this center's really flexible and if some researcher can get their contract from the Japanese company, that person can keep the space as the person like there. So after the contract they return to what is their laboratories and next person came here. So then this is the effective way to enhance the interaction of the industry and academia. Yeah. So then we continue this center. Now I am the director of the centers there so it is very useful centers."
"Sadao Kawamura","Interviewer","What were some of the first companies that gave the donation?"
"Sadao Kawamura","Interviewee","Daifuku. One of them Daifuku and Ishida. Ishida is kind of the measurement of the weight or some other measurement or device that they produced and Daifuku, Ishida, Okura. Okura. Yeah and other many companies, the Japanese companies that donated that 1994."
"Sadao Kawamura","Interviewer","And were the labs the university labs not the center labs, were they funded by the university or the government? What other types of funding were you able to get?"
"Sadao Kawamura","Interviewee","You mean the centers?"
"Sadao Kawamura","Interviewer","Not the centers. So the center was mostly funded by companies."
"Sadao Kawamura","Interviewee","Okay, okay."
"Sadao Kawamura","Interviewee","Okay, okay, okay "
"Sadao Kawamura","Interviewer","Government funding."
"Sadao Kawamura","Interviewee","Okay. So of course we could get the research money from the ministry of education and kind of the NSF, similar to the NSF and also the other research money from outside the university. In that case we performed that research in our laboratory and if we want to start out at the center in the centers we need a contract. That is very important. And the center our university started the kind of the liaison office so before that time the Japanese university did not have such a special group there and they we started there firstly the liaison office so then they support us to find out the new good partner and also when we make the contract they support us then. That is very, very important. So then Yamaha's case that Yamaha's case was different there. They go to the my research activities, my presentation and the conference there. So then they directly contact, but the different case may be this liaison staff found out a very suitable company and propose some contract there. That is very helpful. "
"Sadao Kawamura","Interviewer","Did you have funding from METI as well or mostly ministry of education?"
"Sadao Kawamura","Interviewee","Yeah. So oh you mean MITI?"
"Sadao Kawamura","Interviewer","MITI, yeah."
"Sadao Kawamura","Interviewee","MIKI, okay. Yeah, yeah. Sometime, yeah. We go to MIKI, yeah, so and you do know NATO ?"
"Sadao Kawamura","Interviewer","Mm-hmm."
"Sadao Kawamura","Interviewee","Yeah. I myself also the several professor go to NATO also the MIKI, yeah. "
"Sadao Kawamura","Interviewer","Is there a difference between the type of work those three fund? So education is more science? MITI is IT or is it more application ? Is there a difference?"
"Sadao Kawamura","Interviewee","Yeah. Of course the each the fund has the goal so then the MOMBU That is the similar to the NSF they focus on much more science and also the NATO's case the application oriented and depending on the fund there we should change the goal. So and also the university also supported the not so big money, but the small money supporter of the research there. So then we separate the depending on the fund, yeah."
"Sadao Kawamura","Interviewer","And so what other kinds of projects did you do?"
"Sadao Kawamura","Interviewee","Well, big project is the liaison staff found that the project that was the very, very small company in Nara Prefecture the company's made the socks and this very difficult to handle the deformable in the and very good machine make the automatically the socks but the not like shape that connected each other. Do you know? And so then finally they cut each of them and they turn to this and sew this to make the complete the socks. So but the high quality socks this case not just sew each the loop here to connect just the once. So there is no like a sewing machine this one so whatever, it is very difficult to make the automatically the so then the human just to push out each group that this small needle here, so then that time that president of that company said to me just one push that one needle one in. So it is very hard the so then this company could not keep this product in Japan inside. So then the he strongly wanted to make the new machine without using the human hand. So then we incorporated this project and one master students there they joined this one and very interestingly we did not understand the terminology of that company's people. Very different. Completely we could not understand so then I sent my master students to that company and stay there three months to learn the language and also of course, not only language, but so the other technical what now actually doing now. So then we do not do level and we discuss them they make the ideas that for the new design machine. And also I wanted to make the journal program. So, because just to make the machine which satisfied this task, that is also good for the European, that is a company that requested us just develop that machine, that is not good as a university researcher that I supported that. So then, I wanted to generalize this program, so then we made the program. I think to make a program is very important to them. I was much more of the answer that my program is very, very important. So then, we made this program, the handling of the form of the object there. So, and the current niche materials so then they form of it, so then we can the some point. And so, in machines here, so then, so important we cannot touch, of course, so then the different point we must move to control this point. So then how many fingers or how many points we need to control that, how many target points then. And also the how we move this point here. So, then this problem is very interesting, then we could write about several papers that, so even about the reverse case or something like that, that we cannot write this our technically. So, then we want students there, Ricky was the most students that he entered the Ph.D. course and he go to the Ph.D. this research activities. And the company, enough they supported this project and also scholarship there. The students could get that scholarship from the company. Now, he is the associate professor in the Kaoru University. Now he has laboratory now. That is the one project. "
"Sadao Kawamura","Interviewer","And were you doing more work that was connecting the human life in the bipeds or anything in terms of motion?"
"Sadao Kawamura","Interviewee","Yes, hmm. I have several prospects, so then, so which is a suit of the human-like. "
"Sadao Kawamura","Interviewer","I am just asking because the project with the companies, those seem a little different from the things that you were doing before. I was just curious if you also continued doing some of these looking at animal and human machine. "
"Sadao Kawamura","Interviewee","Yes, yes, yes, okay. Yeah, yes, this is I continue this similar research there, basically control, after getting there, the desired motion there. How we use this that there. So, then I proposed a new ideas that basing on the time scale transformation as I said, and after that, can we use this feet to make the new, different motion? So, then round like this one, the motion. But can we use this to make the different motion like this. So, really I continued this, yeah, study there. So, very recently, almost the 20 years research started from there, the original work that. Yeah, I got new results and They are very limited. Just two different results with the case there we can apply the seven or basic motion is enough that to realize that the new designed program. let us continue the cities research there. "
"Sadao Kawamura","Interviewer","And were there any people that you were collaborating with at the time? "
"Sadao Kawamura","Interviewee","Yes, the many people collaborated then, yes. And the researcher from my laboratory and now more than 20 persons there graduated from our laboratory and they, most of them are academic staff at the university and some of them are working in the company and some case there, we started a new projected with them. And one recent project is the underwater robots there. And we are making underwater robot with Duram and also the bubble floating to change the altitude of the robot. And floating block move here so then the relatively changed the body. So, then it is easy to compensate the change of the shape of the robots there. So, to start this project, I asked the professor Sakurami , he graduated from my laboratory 1999 or 2000. Now, he is the associate professor in Tokai University, Tokai was the private university and they have that college over there, the oceanology and other concerning the ocean world. So, now we have the joint research there, joint project. And we made several types of the underwater robots. And our university location is very close to the Biwa Lake, the biggest lake Biwa that just middle part of the Japan island. So then, I asked one Japanese company and they are engaged with the Komoshowa ship there so they have several type of ship, very large one and very small one. And thanks to that company we could freely use the small size cruiser for the experiment. So then, we carried the, our robots there to the harbor and to perform the experiments there in the Biwa Lake there. That is the one project there, new one. "
"Sadao Kawamura","Interviewer","who is funding the robot?"
"Sadao Kawamura","Interviewee","Just once started there, they fund from the one company, Dai Nippon Screen Corporation, That is they produce the screen for the semi conductor. They are very interested in start of the robot business. So then, they asked to me to make some interesting robots the first. So then, they also are interested in some of the vision system also. So, we started using this fund from the Dai Nippon Screen Corporation. "
"Sadao Kawamura","Interviewer","Why underwater robots?"
"Sadao Kawamura","Interviewee","Why they thought that? "
"Sadao Kawamura","Interviewer","Mm-hmm."
"Sadao Kawamura","Interviewee","That is the case they are very interesting. The new kinds of the robots, so then, the focused on the underwater robots there, probably. And also they Dai Nippon Screen, they have the similar factories that are near the Biwa Lake, so then they are very curious there about the environmental condition of the Biwa Lake. So, they feel that maybe they favor to this and some responsibility of the environmental condition over there at Biwa Lake there. So, probably That is the one reason why they started the underwater robots there. "
"Sadao Kawamura","Interviewer","Is there an application that they want the robot to do when it is underwater?"
"Sadao Kawamura","Interviewee","Not so specialized that one at that time there, yeah. But the very general robotic technology they are very interested. "
"Sadao Kawamura","Interviewer","Any other projects you want to tell us about?"
"Sadao Kawamura","Interviewee","From the 1996 to the 2001, we have the one project, that is the kind of the human supported kind of robotics, that one from the GSPS, That is the project we develop there, some human machine interface. The interface means the mechanical contact. So then, we develop some the kind of robots that kind of are wearable case there and in this project, we focus on the pneumatic system. And the very lightweight and very high powered, but the control is not so easy because of the dynamics of the compressivity of air were part of the dynamics there. So then, I started the dynamic analysis there, including the dynamics of the compressivity there, but of dynamics there. Before that, maybe the pneumatic contrast case, dynamics suggested that the mechanical part there and not including the compressivity, especially not a of their compressivity, very complicated. So then, I propose the one control scheme for the non dynamic state of the pneumatic control system there. And that is one work there, yeah. So, yeah."
"Sadao Kawamura","Interviewer","Is there any idea for what are using the wearable robot for?"
"Sadao Kawamura","Interviewee","In those days, I was interested in the lightweight high power, so then I selected the pneumatic systems and I analyzed the dynamics and proposed a control and I wanted it to apply to our hardware and software so the application, yeah, apply to some task there. So maybe one direction is the kind of wearable system, because They are lightweight and high powered, so That is the reason why they are, yeah."
"Sadao Kawamura","Interviewer","So it is kind of like an exoskeleton?"
"Sadao Kawamura","Interviewee","Kind of, yeah, kind of, yeah but They are not perfectly exoskeleton case, They are just support the wrist part of the hand and the robot like this also the, in , yeah, yeah, yeah. "
"Sadao Kawamura","Interviewer","Maybe the last question, so it is kind longer. If there is any other project you want to mention, That is fine, but I also wanted to ask about RSJ and how you got there and also a little bit about what the role of RJS is in Japanese robotics?"
"Sadao Kawamura","Interviewee","Oh, very difficult question. Okay. Yeah, no, RSJ, do you know the RJS, the Robotic Society of Japan?"
"Sadao Kawamura","Interviewer","Mm-hmm."
"Sadao Kawamura","Interviewee","And now the more than 4,500 members including the students. And the 62 Japanese companies entered the RSJ. So, RSJ is very active, every annual conference there are more than 1,500 people attended. So then, the members are 4,500, so then the attendance is 1,500. And also we have the some of the international conference also. And because the one reason is that I think that there are several department of the mechatronics or information science and also the department of robotics, so then the last over there the academy staff and also the large number of the students studying there. That is why they so active. And also the company and they introduce the so many members of the industrial robots there. So, they succeeded by introducing the many robots there. For example, spot welding was harder task there. that is a one main story there in robots there. But now, the Japan also making the new market of the robots and so, for example, the service robot to the United States or European countries. And also, we have the civil project and a national project to make the new robots there. The service robots there. And as you know, Japan, the dramatic percentage of more than 65 years old people are increasing, so maybe how we make the good society and the service robot to work there effectively to support such in the society. So then, the one project the Japanese company making this transformable bed, a bed can become the wheelchair, autonomous wheelchair and the form of that. And so, the wearable robot there and the Cyberdine making the smart wearable robot and also Fuji Heavy Industries developed, they almost have developed the commercial use robot there, They are creating a robot there in the very large building there. Even though the people walking around the robot, the robot can walk well. Yeah, there are several actual robots there in Japan. So then, the industry supported the activities there and also we considering how make a new work there between the university people and the company's people to make the new robots there. The new fields, the as well as service robots there. that is an outline of RSJ."
"Sadao Kawamura","Interviewer","And what are some of the ways in which RSJ does this? Is it meetings or I know there is a journal, does it have any funding of its own to give?"
"Sadao Kawamura","Interviewee","We have two journals, one is Japanese, the other is the international journal. And also, we have the many kinds of the center and it has a tutorial on it and also we have provided the information there, so it is very variety over there, the activities there. "
"Sadao Kawamura","Interviewer","And I know the Japanese government makes these proclamations or directions in terms of where robotics research goes, does RSJ have any hand in that at all?"
"Sadao Kawamura","Interviewee","RSJ does not handle such, however, indirectly RSJ incorporate them, yeah. So research there. "
"Sadao Kawamura","Interviewer","Kind of in terms of people and expertise?"
"Sadao Kawamura","Interviewee","Yes, yes, and also in every annual conference we have the special session for the each speaker project to the national project case. So, then the members can understand what they are going on in the big project there. So, in a sense, we support their activities. "
"Sadao Kawamura","Interviewer","And RSJ has advanced robotics internationally."
"Sadao Kawamura","Interviewee","Yes."
"Sadao Kawamura","Interviewer","What kind of impact do you think RSJ has on robotics internationally outside of Japan?"
"Sadao Kawamura","Interviewee","Yeah, not only the many people submit to the papers, so then That is very good as a presenter, RSJ. So, That is very nice I think. So, then I hope in future they the Advanced Robotics, the international journal of RSJ will become much more important journal all over the world. So, and I would like, yeah, make effort there for this. "
"Sadao Kawamura","Interviewer","And what do you think are some of the challenges for robotics in Japan?"
"Sadao Kawamura","Interviewee","Yesterday, the seminars, symposium one, I am not sure there, I explain you there, we run into the original point there that is we should learn from the living things, as I said, so because the now interested in robots, since those numbers are very limited. So, but if we compare with the living things there are many numbers of them. The important point is how we integrate it such that variety of the senses there and how we integrate the many numbers of the actuators there. That is very important there, so once again, I think we can learn from living things there to get the new ideas. So also the second one is the system integration is very important there I think. So, as a science, system integration is very important as well as the technology. So, I believe that the robotics is a very original, independent science. So, not only application of the other conventional scientific fields there, I believe. So then, to establish one field as a scientific field, I think to make real the system integration science as a science, That is very important there. So the, I hope we robotic researchers make real all this results as a system integrated science in near future. And also the hardest thing also will make to establish a new field of system integration. "
"Sadao Kawamura","Interviewer","And in Japan there is always a lot of discussion even in the talks yesterday about robots being in society with people. What are some the directions that That is going in these days?"
"Sadao Kawamura","Interviewee","Yeah, yes, yes. The one people is the professor Kusagi, he presented yesterday and as he said, there is such a focus on the one subject and get the good result. And the other important point is that after getting the good result as such, how we use this results then? So then, in this sense that I think that needed a kind of a sense of the transferability, otherwise they just do result within their limited areas there. So then, what is also is we need such a very wide view point there to actually the good results, the research results there, That is very important now, I think. So, the RSJ, also we would like to make effort for this point there, yeah. "
"Sadao Kawamura","Interviewer","And we ask this usually a final question. So if you were giving advice to young people who want to be in robotics, what would that advice be? "
"Sadao Kawamura","Interviewee","That is very different question. it is not so easy to make good out of it. Of course, depending upon the person, the advice should be different, but based upon my experience there, I am really lucky to keep consider the one things for a long time. So, then I was very interested in some of the relation between the living things and the robots there, so even though I worked there for many projects, many different goals there, but at the same I keep the one direction there, yeah. So, that was very good for me, I think. So, in my case, that was nice. This not otherwise. "
"Sadao Kawamura","Interviewer","The way to keep a good motivational idea."
"Sadao Kawamura","Interviewee","Yes, yes. So, then keep the one idea for a long time. So, not to give up but the step again, That is very important. "
"Sadao Kawamura","Interviewer","Just one thing."
"Sadao Kawamura","Interviewee","Yeah."
"Sadao Kawamura","Interviewer","You said even before you went to school, to university, you were interested in robots. How did you become interested in robots so early?"
"Sadao Kawamura","Interviewee","First of all, I should say the answer was the cartoon. Of course, I watch the TV and the Astro Boy or the cartoons there. Actually, I have an inference there from the cartoon. But at the same time, as I said, I was very interested in the living things, yeah, I played near Lake Biwa also the river near my house and also I watch the some of the animals. So, then in my case, maybe both of them. That is the reason for I entered this department. "
"Sadao Kawamura","Interviewer","Mm-hmm, great. Is there anything you would wanted to add? that is about it for our questions in general, but if there is something we missed and you want in there."
"Sadao Kawamura","Interviewee","That is maybe. "
"Sadao Kawamura","Interviewer","Thank you. "
"Sadao Kawamura","Interviewee","Yeah, we will go. "
"Shinichi Yuta","Interviewer","If we can start with your name and where and when you were born."
"Shinichi Yuta","Interviewee","My name is Shinichi Yuta. I was born in Nagasaki Prefecture in Japan, 1948 and but I was grown up in Tokyo. Then I graduated from Keio University, it is one of the private big university in Japan. And I studied electrical engineering and continued to study at the graduate school and got Ph.D. degree and 1975 from Keio University. And so then I was working for three years at Tokyo University of Agriculture and Technology, located Koganei City in Tokyo. And then I moved to Kobe in 1978 at University of Tsukuba. At that time, I was belonging to Institute of Electronics and Information Science. Then I already stay at Tsukuba 33 years. And actually the system has changed and also I moved to another institute. And now I am working at the graduate School of Systems and Information Engineering, University of Tsukuba. And once I was working as a dean of the College of Engineering Systems for two years, it is for the undergraduate education of kind of applied computer engineering or, but something including mechanical engineering, electrical engineering or even architectural engineering. And also I was working as the chairman of the Institute of Engineering Mechanics and Systems for two years. Then I was appointed to be a vice president of the university for the research and international affairs and the industrial incorporation. And there I worked for two years there and I came back, stepped down to be a kind of a professor but working at a director of Tsukuba industry it is kind of the center to stimulate collaboration between university and companies. And also something for teaching, education for other matters for the students. And then I was working for four years, now I am very free. I forgot professor and okay this is my career. "
"Shinichi Yuta","Interviewer","we are going to ask you go into some details about things that happened over time, so if we could way back to when you just started graduate school. You started university really, how did you decide to become an electrical engineer?"
"Shinichi Yuta","Interviewee","it is interesting question. Yeah, I was interested in mathematics, physics, as well I was interested in social sciences. But maybe my parents are not engineer, my father was working in company and he studied economics and working at a company and but maybe I am interested in other natural science, so then it is very naturally I decided to go engineering, because at that time I was studying at Keio High School, so then even at that time, it was some competitive situation for the examination to enter the university but because I was at the Keio High School, it is not necessary to take examination. So just I have to select which faculty. But at that time Keio University does not have a faculty with natural science, just university had electrical engineering and I am not sure, but young boys is more preferable than engineering usually. But still I am getting interested in engineering and maybe I had no reason why electrical engineering selected. It might be okay to study in the mechanical engineering or chemical applied chemistry or even instrument or other department. But anyway, I am not sure but just I selected without exact reason. So, then actually I enjoyed very much in studying the engineering, but also I was interested at that time on social science, economics or especially economics or ."
"Shinichi Yuta","Interviewer","Could you take classes or did you do things related to social science?"
"Shinichi Yuta","Interviewee","Yes, I took big class but preferably I just made the small group to study by reading a book. "
"Shinichi Yuta","Interviewer","Do you remember any particular things that you thought were very interesting at the time?"
"Shinichi Yuta","Interviewee","No. "
"Shinichi Yuta","Interviewer","I know it is along time ago. "
"Shinichi Yuta","Interviewer","Were there any particular social problems or economic kinds of problems that got you interested in thinking about the social sciences? "
"Shinichi Yuta","Interviewee","Actually, I do not have a particular problem or particular interest. But at Keio University used to be very strong in economic and also so not only by myself, but also the friends are also interested in the mechanics of society. So, actually the economy is one of the key mechanism of infrastructure of the current democratic society. So, and this feeling is not only the school but also my parents, my father give me some basic understanding of that. So, I was interested, for example, so then I was interested to know the more detailed mechanism or history or reason why we have such a system at that time. So, for me rather the mathematical understanding of the economy or social system or decision making was interested. "
"Shinichi Yuta","Interviewer","And so you decided to stay in electrical engineering for graduate school?"
"Shinichi Yuta","Interviewee","Yeah, I like study, so but actually this is very interesting for me, this is very important event. And that when I was the final year, senior of the university, I myself supposed by myself to go some company and not the idea of company, I thought that I would work at industry, some company as not a . I was working in electronic engineering, studying electrical engineering and I had no objection about that. But still, I did not have any exact idea what I would do. But just I liked the electrical engineering theory, that field. And also another issue is I like to travel or I like to climb the mountain or enjoy the other people, friends. So then, I was thinking to extend the chance to enjoy, to travel something, the graduate school was a very attractive for me. And I thought that it not good idea I thought to go graduate school just for to enjoy. At that time, I thought so. So then, actually I thought that I will work in industry. But once my friend who is 15 years older than me, I was talking with him and he told me that I must continue to study at the university because when to make a rich life, most important thing is how good time I have. And especially in a young age or even if it is not effective or efficient or anything, just to spend, even when it is waste, it is okay. Just have a free time, it is very important, he told me. Actually I suddenly decided in my mind to go to Master program in the university and so then I sometime, I never thought to be a professional academia. But while I was not studying, I was enjoying in the Master program. I was recommended and suggested to continue to study at the Ph.D. program with some scholarship. So, anyway, get a scholarship is a good thing. And in Japan, at sometime at the engineering departments, even the Ph.D. program students, their parents should pay the tuition. And it was a private university so tuition is not small. But in my case, some program at the university provided me a tuition and scholarship. So, I decided okay. I will go to a track to be academia. So, but at that time, I thought that it is almost decide the job at that time. That scholarship is to keep some good potential student at Keio University but as it turns out, I am not that bright at Keio. So then, I start work at another university. "
"Shinichi Yuta","Interviewer","Who did you work with when you were a graduate student?"
"Shinichi Yuta","Interviewee","At that time, Associate Professor Takahashi, he is a specialist of the electrical circuit and system theory. Under his supervision, I studied about optimization or electric circuit theory and engineering control systems and such fields. Principally theory and no mechanics. "
"Shinichi Yuta","Interviewer","So no robots yet?"
"Shinichi Yuta","Interviewee","No robot. And interesting thing that, so about the robot. I was working at Tokyo University of Agriculture and Technology for three years and at that time, actually I thought myself that what I can do and but I thought that I got a theory, so then job should be assigned for me. This is a basic sense at the time. So, then I was working as a research associate and some professor who are doing medical application of the control, electrical engineering. So, special in the ultrasound diagnostic equipments. So, I did with ultrasonic imaging system research and development and also just at that time, the so-called computer tomography, CT started. We imported from EMI in England to Japan. So, first I visited some hospital to see it. So then, we did some research of the imaging but not only the results on imaging, but also the CT imaging for the medical application. So, actually I enjoyed and I did some research collaboration with medical doctor in Osaka, but anyway my profession is research associate so I thought I had to, even though it is a tenured position. But anyway research associate itself is not a good position so I applied by chance to Tsukuba University so then I moved to Tsukuba University after a few years. And also, I continued to work in medical imaging. So, actually still I am proud of that. I am one of the first researcher of ultrasound computer tomography in the world. "
"Shinichi Yuta","Interviewer","What were some of the early challenges in medical imaging? "
"Shinichi Yuta","Interviewee","Yeah, to make a good resolution of the image. To provide a medical doctor can diagnose, especially in the cancer. For example, at that time, the key was how to find the cancer one centimeter in the body. So, actually I enjoyed this development but after moving to Tsukuba University, I thought that for me it is okay. But for the students, such a medical application is even when we make some good theory or methodology, but the variation of this methodology can be done only by medical doctor. We can say that, oh this is, I tried to get convince by medical doctor, but medical doctor sometimes very like our results and sometimes not. So, we cannot decide this is good or not. And the other side, for the so then one method to solve this problem is I study the medicine, but I do not have a big interest in that. Just I was interested in the technology side. So then, at that time, I decided to apply my experience of technology not on the medical but rather to the industrial applications. What that thought I had when I moved to Tsukuba from Tokyo University of Agriculture and Technology. So but, just after moving to University Tsukuba, Professor Kameyama is not my boss, but I worked together with him and he is ten years elder than me. And he invite me to join to research on the mobile robot. So then at some time, at the University of Tsukuba, you know in Japan, we had chair system. So, very strong professor have several associates, it was a system, usual system at that time in Japanese universities. But in Tsukuba University, it is very like American system. So, I moved to Tsukuba as a lecturer, but lecturer, it is a kind of that assistant professor really. And even the lecturer is very independent. So, I have to manage everything by myself, but I cannot force. I was not forced by other people to do anything. But still, it is not bad to make some group. So, Professor Kameyama invited me to work together on the robotics. Not on that mobile robot. And but at that time, I did not think that I do the research on the robot. But he invited me to work together to develop some small mobile robot for the students and other students project. So, to participate made a contest. It was just started and it was the one of the target contest was I suppose, I am not sure, anyway, in the UK. So then, I am not specialist on the mobile robot and not specialist on the video circuit system but still I feel some interest and I thought it is a good chance to study for myself. But, so I just study of the motors or circuits or computer and software with students. So then, it was fun and what most interesting and most exciting thing for me was I was an instructor-teacher, but together I work with students and all at the same level because some of them have some experiences and I did not have experience. So but, actually I knew the theory of control or circuit or some basic structure of the software so then I can give them a very good suggestion in to working with the other. So then as a result, it works, not completely, but something it works. It gives me a very big impression that. And this such a thing is very good thing for student to study and I can have some effective work for them. And also and most important thing at that time for me, is when I was at graduate school or especially when I was graduate school, when I doing the theory, I just make a paper. And at first we say that recently, some requirement from industrial or something like that. So then, such a kind of constellation is necessary then blah, blah, blah. it is a style of writing a paper but I did not believe that. Actually I did not think it is true. But I was forced to write and I thought that this is a manner, just a manner. But so it is a manner, so it is okay for me, but I did not think that I do not wish to force the student to . But in the case of robotics, it is not a paper, and also for the robot it is very clear let us make such system to work something in such environment. it is very clear to understand and I thought that it is possible to have a same direction, same purpose, same mind with me and with the other professor and with student. So, I thought that this a very, very good subject to other research, very, very good research subject in case to do at the university as a part of education. So, actually, at that time, I thought that I am getting salary from university for teaching, I thought, not for research. So, then it is very natural for me to select research subject for the education. So then, actually at that time I thought that this is a very good subject for education. So, then at the other side, in this point of view, to make a paper, the efficiency of, the productivity of the research paper was not good. But actually, it does matter. Because I was working medical imaging and I had another group, I was involved in another group some company and Keio University research group and I still be involved in that group. But they write many papers including my name. So, the research paper is a kind of automatically made in this project. So, in the robotics project, it is necessary for me to produce a paper just for me, just to give a good information for student, good subject, good chance, good opportunity for student is the purpose of my own involvement in robotics. That is the reason why I started the robot. So, several professors, especially in Japan, some of them are very much interested on robotics from the childhood. But I never interested in robot when I was child. Just I started to be interested in robotics as a standing point of teaching the student. "
"Shinichi Yuta","Interviewer","That is really interesting because now people talk more and more about how important robotics is for education in these kind of science and technology fields. it is really interesting that you have that insight so early. What kind of robots were you using? What kind of technologies did you have to put the robots together?"
"Shinichi Yuta","Interviewee","Yeah, at that time, just electronics. But including how to rotate, how to control the motor. So, what we did is small size mobile robot is two motors, two wheels. And actually mechanics at that time is made by other and not by me. By other people or other students and after the control using the kind of controls something theory including based on the knowledge of dynamics is my theory at that time already. So, actually then I thought robotics is a very good subject even the research subject doing in university. And at that time, I thought that when I was studying to work at the University of Tsukuba, I thought maybe several years, three, four, five years, I will work at the university. But I do not have a reason, but I at that time, in some feeling, I thought that I will move to industry after several years. But I thought that in this case, I will do image processing or circuit design or control or mechatronics or something or even artificial intelligence. But I will not do robotics, because robot is a very good subject for teaching, but robot is not good subject for to make money. This is my understanding at that time. Still I do not think so. "
"Shinichi Yuta","Interviewer","How long did you continue your involvement with robotics for teaching and how did that develop with your interest in control theory into more research?"
"Shinichi Yuta","Interviewee","Still, I am interested on the robotics situation with education. So, but eventually, gradually changing because I recognize that robotics itself is a good subject, just only for the scientific research. But anyway, as a university professor, I do something by myself but more important your major work by myself is supervise the student to do research. So, give them subject or suggest a subject, discuss a subject and research contents. But what I am doing as a research is not done by myself, rather at least work together with the student. So, then after three, four years, then I recognize that I can some research paper in the robotics field and it may make my career. "
"Shinichi Yuta","Interviewer","What made you realize that?"
"Shinichi Yuta","Interviewee","Just I really got some interesting result, but anyway, for the students, they have to write a graduation thesis. And also, in Japan, we have many domestic conference. To publish a paper is of two pages, for example, and principally it does not have a review. So when we have some good experience, we have some good consideration, then we write a paper and sometimes it is the companies are interested in the result. So naturally, we start to write papers. Then if we have a rather more good result, then submit a paper for the honor, intelligent conferences."
"Shinichi Yuta","Interviewer","What were some of your early interesting results?"
"Shinichi Yuta","Interviewee","it is a difficult question. Actually, as a research point of view, I was interested in autonomous mobile robot, autonomous navigation. Say our autonomous mobile robot to go from my lab to another place autonomously. And this is very simple subject, but it is very clear and so then, for example, so such kind of the definition of that task or mission or whatever it is very good way to have common interest between student and myself even or another visitor. So then, I decided as a research subject to realize autonomous robot to move some other place autonomously and how much reliability it has. it is important and to make the robot to move in the real world and so I cannot control the environment. So, it should move in the real environment. So but, I cannot control the other environment, so the 100 percent of the reliability is impossible. When that happen when the robot moving, so the robot cannot arrive the destination. So, then how to increase the probability of successful ratio is an important issue. So, to define a more difficult environment or more long distance is we change the subject to more long distance, more general environment, but still very definitive problem between for example from our lab, the goal of our research is to put our automobile robot at some park at Tsukuba City. it is eight kilometers from our lab and fortunately we have a pedestrian street in Tsukuba City. So, the story is the robot should come back autonomously from there to my lab. So, when we put the robot, push the start button and come back by myself at my lab and it is eight kilometers so after two hours robot came back to front of my room. it is a story, for this purpose, actually we had too many things to do for the environment recognition, even just the sensor issue or electric circuit, electronic circuit power, motor drive or management with a battery, everything. So, I thought this is not a good definition of the project. So usually, when I told at that time, it was more than 20 years ago."
"Shinichi Yuta","Interviewer","So, this was the early eighties? "
"Shinichi Yuta","Interviewee","No, mid-eighties, no, end of eighties. So, after that time, I usually tell that our goal of the research is to realize such an autonomous robot. It can come back from Doho Park to university autonomously by itself. That the people from the newspaper or media very much interested and asked me when it is realized. So, then I usually answer oh, age 30 years, wait, 25 years, recently I say oh, 85 years. Anyway, always after my retirement, I do not have a responsibility. it is a story. But actually 20 years ago it was just almost dream but I thought that we have some certain possibility to realize, but now I can say that. It depends on the project. "
"Shinichi Yuta","Interviewer","Did the robot have any accidents?"
"Shinichi Yuta","Interviewee","Yeah, of course, even the people may have accident. So, the program is to just increase the probability to come back safe. So, the 99.9 percent of a probability, it is okay. But usually, besides people say that. We success this motion, this reaction, this behavior, but the success ratio is best on 10 percent for example. So, to move autonomously for a longer distance, it is a key, because in case of the success ratio of navigation in one kilometer is fifty percent, then the success ratio of ten kilometers is less 0.1 percent. So, to realize longer distance, it is very simple explanation to realize the high reliability. So then, actually recently, five years ago something I gave up to realize by myself, but I realize the Tsukuba Challenge. it is a kind of open experimental event to make one kilometer autonomous navigation in Tsukuba City and other people are moving, working, bicycle is moving. So, in Japan, we have more 70 group participating every year in these years to try to realize such an autonomous navigation. So, of course, the team from my group, my lab participate and sometimes success and the other side. But anyway, to realize eight kilometers including observing go stop signal or some other steps or something, it is not completed yet. But, this is the kind of research purpose. So, it is okay for me. Another interesting thing is to come back from Doho Park to University it is eight kilometers. it is just same distance from Shinjuku, do you know Tokyo? So, it is eight kilometers. Of course, it include many street, but if the robot has mechanism to climb up over street breach, then the difficulty's almost the same, I guess. it is a rather big subject and to maybe good for to understand. Not only the researcher but also the student but also by the newspaper people or any people. "
"Shinichi Yuta","Interviewer","What were some of the different approaches and different robots that you used while you are trying to solve this big navigation problem? "
"Shinichi Yuta","Interviewee","Different, you mean, for example original thing or very different something. I do not like it. We have to find a good way, if some people propose a good idea, then we should use that. So, actually in my theory, our methodology is very simple and almost obvious method. So, principally no special idea. it is my own theory. But still, we believe that a kind of a position estimation is important and estimated position based control is also important. And some kind of the quantitative map expression is important and quantitative understanding of the sensor information important. So, it is not special, but to realize such a system and we have many experiences on that. And so the technology about that, we actually believe that we integrating the technology. So, the companies, I have several friends with companies who are interested to know our experience."
"Shinichi Yuta","Interviewer","So, it is really a question of putting all the different systems together and figuring out how They are going to interact to make the robot do something? "
"Shinichi Yuta","Interviewee","Yeah. And, of course, not only this subject, we have many student in my lab now, 40 members we have including the major part is the Master program student. After getting Master degree, they will work in industry. So, how to give them a good subject to study with is very important. So, we cut something from this program or find some relating problem to give them to work together with them on some research. And also some other application of related work for the construction machine it is also done. But relating with this subject is a key of the research theme of ours. And then, it is a mobile robot autonomous navigation issue, SLAM very important issue. SLAM, the concept of SLAM is how to relate the human understanding of the geometrical environment. To make a map and localization, to do it together concurrently is a basic idea. it is a very interesting subject. But the other side to just realize such a robot, if the robot has no idea of the environment. So then, this robot cannot come back because the robot cannot understand the destination. My idea we can give the map or environment information as much as possible, but possible is important because for the student, in case we make some system, we will give the information as much as possible, but possibility is just one under one week for example. Then another date, efficient information is very important. But anyway, we give the information. So, not making map, but rather using a map for the localization is more important. And to make a map is another issue. it is to make a map in very efficient way is also important issue. So then relating with SLAM is very interested and common subject. So, the word SLAM started, it was beginning of this century, yes. And I feel myself that I was working together with another researcher, I was observing the start of the SLAM. And also before we invent a word SLAM, this subject is already existed. So, one of my colleague in Japan did research to make a map using some vision in some constrained environment and using this vision and make a map and estimate its own position to extend the map. His Ph.D. but he got the Ph.D. in maybe 1990. And historically maybe thesis at last is some issue, I think."
"Shinichi Yuta","Interviewer","Who was your colleague in Japan, who did the Ph.D.?"
"Shinichi Yuta","Interviewee","Okay, first Igima, so actually such issue interested and then usually we use electrical sensor from the first because it is a most simple and robust and easy to get at the university. But, the shortage of the environmental recognition, environment sensing ability, we did some research to realize more good autonomous sensor, the problem is wavelength problem to make a good resolution. So, obviously electrical sensing is better. So, we did vision or another sensing, but as a part one of this sensing, I used something collaboration with a company, optical range sensing, so then by the proposal by that company, I collaborate with them and helped to develop Hokuyo sensor. And Hokuyo provide small size of scanning range sensor and now it is a very famous and very much used in the robotics research field in the world. I some observation, I, from outside of myself, the biggest contribution is the development of this range sensor. But the reason I am involved in this sensor is I was interested in autonomous navigation and I knew that the necessity of this type of sensor. "
"Shinichi Yuta","Interviewer","Did you also do biologically inspired navigation?"
"Shinichi Yuta","Interviewee","Probably no. Actually, to realize good navigation system, to study how the human do it gives very good information. And also, not only the human but also how the dogs or other animals doing this task. Usually gives a very good information, we do not have enough good way other than thinking a human or animals. So then, actually we think in my case what I observe or what I think is I usually analyze about myself, the human. To understand a human behavior or human thinking is out of my interest. The purpose is just a kind of a methodology. This is interest something about myself, I like animals. I like biological matter. So, once I had 14 dogs at my home, 8 cats at my home, I had a goat at my garden and almost 50 chickens in my garden. "
"Shinichi Yuta","Interviewer","In Tsukuba you must have had a bigger house?"
"Shinichi Yuta","Interviewee","Actually, I have a rather bigger garden. I enjoyed very much with animals, but when I observed animals, I usually think that it is almost impossible to make a copy of them. But the other side, we can apply our technology to make some useful machine. it is rather lopsided of a thing. So what I am doing is research, just I am enjoying to observe or interact with animals. For example, I have, at this moment, of course, dogs died after ten years or fifteen, twenty years and a chicken was taken by the small natural animals, so fifteen chickens disappeared for half year. But now, I have in my home we have three kitty cats and three dogs and one cat does not have an eye because of the injury, we removed her eyeball. So, he cannot see by eye. But he can survive, that he living very usually, looks no problem. Observing such action is very, very interesting and from the point of the robotics researcher, so I sometimes analyze what kind of sensor is most effective on them. Well, also such a flexible soft mechanism or body looks very important. So, I can explain something on them from the viewpoint of robotics research. But I have no idea to apply them as authority or such idea to my research. "
"Shinichi Yuta","Interviewer","When you mentioned the Hokuyo sensor and that it was very popular, could you tell us just a little bit about why it is so special and why it was so useful for robotics?"
"Shinichi Yuta","Interviewee","Yeah, do you know Hokuyo sensor? "
"Shinichi Yuta","Interviewer","Mm-hmm."
"Shinichi Yuta","Interviewee","Actually, we already had the similar sensor by Jeek Corporation or other some companies. So, the big difference itself is a small size lightweight. And withdrawal cost and the other side, just from different point of view, the experimental base robotics research in experiment is very, very important. To know that your problem, even to know the real problem. But to realize a safe experiment, the small size platform is very important. So, then small size platform, for the small size, the bigger, heavy sensor is not good. So, maybe the point is sensing, I will tell about why the Hokuyo sensing is useful but comparing with previous, existing sensors, Hokuyo sensor is small size, small weight and low cost is a key. And so for this purpose, Hokuyo develop some new methodology in the sensing measurement technology. But the function itself is almost same, just small size. Even now, of curse, Jeek has a very good technology, so I think there is no good idea to overtake already existing good system. What Hokuyo did is limited the distance of measurement and principally limited the distance of measurement. Then they developed was new methodology for this specification and realize a very small sensor. it is less than 200 grams and so it is almost one-twentieth comparing with the Jeek sensor. And next is effectiveness of such optical range sensing. Anyway for the robotic application the shape of the environment is very, very important to move. So, for example, stereo images a depth map and gives, of course, shape information, but in case of the talking about a shape, the resolution or accuracy is also important. So, for the robot to move in such an environment, maybe they do not need one millimeter accuracy. But ten centimeter accuracy is obviously not enough. So, to realize one centimeter resolution or accuracy is reasonable requirement. So, then to realize one centimeter accuracy or resolution in ten meter or ten kilometer, five meter, ten meter, twenty meter region is most useful information for the mobile robot or even when manipulated. That reason we people use this sensor. And then some strong point of the Hokuyo sensor is a small weight. Low cost, small power consumption. "
"Shinichi Yuta","Interviewer","And you mentioned that you have always been interested in industry and that you worked with a number of different companies. Could you tell us a little bit about the different companies you worked with?"
"Shinichi Yuta","Interviewee","Actually, the basic idea, the funding is the most important issue, usually. But, I am very happy, I am getting salary from the university and in Japanese university, university provide a small amount of money for research. Not enough and also I can get fund from Ministry of Education Science Education Japan as a science research grant. So, then the funding from industry, especially nowadays, funding from industry is not so big part of our research support. Still, I believe that what we do our research, my main purpose with research is education. Using this opportunity, the second purpose with research is apply our result to help the industry to make something for their own purpose. Maybe that is write a paper to be famous in the world or something. So then, I am very happy to give any information to industry. Sometimes, it is better to give exclusively our experience or technology or sometimes it is more effective to give any company. So, exclusive transfer, the purpose is how give them information or technology is used, how much it is used is important. For this purpose, sometimes we open it, sometimes principally open all the information. But sometimes we keep some special information exclusively for this company. In this case, when I think that this is more good to be used. In this sense, it is not for the financial support. Fortunately, we can get money from government. So, we should give them the research for the society. it is our duty. But this is one of the point for the communication or cooperation with industry, but the other side, for me, more important thing is our student, in my class or in my lab will start work in industry. So, teachers, professors should know what kind of technology is required or what kind of technology is necessary for them. This is very important information. So, for this purpose or for to decide subject of ours, also important information what they are interested? I actually I feel I need the information of the companies. So, to get such information, we have to have a very kind of a close relationship or a friendly relationship. This is more bigger purpose for myself to communicate with company. But when I just tell or wish to know what is your problem, what part are you interested, the company will not give good information. So, to make some give and take relationship, we should be able to provide some good information for them. So then I use our research result to provide them as information to make a good relationship. But important purpose is get the information from the company, necessary information from the company to teach the class to give the information for student. So, for this purpose I am very active. I am always trying to make a good relationship with these companies. And of course, it is fun when our result is used by company, but usually it is very difficult. But still, many company has interest on the research result of the navigation or just the motor control or autonomic sensing or just a motor drive. We have many things we have so we provide them. So when I contact with the motor company, then we tell them what we are doing related with the motor control or how the motor is used for something. So, we will give them a very detailed information about that. So, then I usually ask this what kind of student do you wish? Or when in case a student working in company, what subject they should have studied or what kind of research do you wish us to do? I ask them. So, actually one company just produced a copy of our motor drive circuit. It is not a special one, but for them even as the circuit and the printed pattern on the circuit is working in this condition, such information is very important. When they wish to make some special purpose motor driver, for example, so we provided the circuit information or source code of the many parts of the subsystem of the robot. And also, we gave information of our navigation system for the security guard company for developing security guard robot. And also once Mitsubishi Heavy Industry made a wakamaru robot. When they announced the first announcement in newspaper they said that the vehicle control part software is produced by my university. This is the reason why we just provide them our source code and explain very in detail. Unfortunately, they give not any money for me in budget. They are very pleased and they promised me if necessary they will think seriously to provide research budget for us. But at that time, also they have a problem with shortage with the budget. We are very happy because it is kind of in the budget. So, I thought that if we have a problem with a shortage of research budget, maybe then I will ask you, but unfortunately, he moved out of the section. But anyway, I got very good information what is a problem of them and what company requests of students, so actually I am proud that my graduation students, not all, but very good part of the students graduated from my lab, especially in the Master program, to working in the Honda, Toyota, Hitachi, Mitsubishi, any company. They are getting a very good evaluation, I believe. This is a relation between company and myself."
"Shinichi Yuta","Interviewer","And I mean having students in the company also probably makes you closer to the company as well, you have more connections or no?"
"Shinichi Yuta","Interviewee","Not much. Some of them we have but so yeah actually kind of the contact person of the company I have several companies, maybe only one-third or less company in 20, 30 person company the contact person is our graduation but it is not usual. "
"Shinichi Yuta","Interviewer","And what are some other companies? You mentioned Mitsubishi, and . What are some of the other companies?"
"Shinichi Yuta","Interviewee","Other companies, , or I am not sure I can tell you or not. "
"Shinichi Yuta","Interviewer","That is fine. Only the ones that are okay to know. And so when you-"
"Shinichi Yuta","Interviewee","But the other side as a result I sometimes ask the company to support the budget, not as a contract, just by donation so in this case we do not have any obligation in this budget. Still then it is very free to use, so this is very, very good money. Amount is not much but such a donation from the company makes me very big freedom of the research activity."
"Shinichi Yuta","Interviewer","And I also noticed, I was just reading one of the kind of bios online for you and I noticed that you were interested in modeling the evaluation structure of Kansei."
"Shinichi Yuta","Interviewee","Kansei yeah. "
"Shinichi Yuta","Interviewer","Kansei is a very kind of specific term for Japan so I was wondering if you could tell us a little bit about that. "
"Shinichi Yuta","Interviewee","Okay yeah. Actually it is not my own interest; it is not my own interest. Rather one of the famous researchers who is doing industrial design in our university. He did not only industrial design are usually kind of the artist but he thought that not only the artistic thing the other or technical thing. Even artist should understand about the audience or even when he draw the picture. Usually the artist just draws the picture, that is all. But nowadays even the artist should know, should think about the people who see, who enjoy this picture. So for this purpose the artist or more principally the designer wish to know the how their design picture observed or how they are impressed by some people in as much as quantitatively. That was his interest, not my own interest. So then he requested me because we are rather some good friend then he requested to me to join his project to use robotic interface as a tool of measuring the user. So actually for example then what we did is we develop robot who are which is remote controlled to move in the floor of the museum to get the image to send the people. Who are enjoying this museum remotely. So just provide such a system using your technology web as a communication path. And this is a simple idea or application of the mobile robot, but the real purpose is when you we use remote mobile robot as avatar myself to move in the museum, art museum, then we can decode the look or the motion, or how many seconds, now many minutes stop on the picture or which path of the picture is observed. So we discuss with this professor of art school and industrial design that we can make such a robotic system as a tool of the measuring of the audience interest. So he is very pleased and interested. So we did some and as a result I have to be some kind of a spokesman of this result from the point of view of the technical side. So then and so it was one of the university projects so I had say, I had to say that I am doing the concept project. that is all is. But actually this is for me. This is relationship. it is of course it is as interesting for us to apply our technology and our technology is used but it is a kind of the user technology is not only the industry but also I found user technology inside of my university."
"Shinichi Yuta","Interviewer","Who was your collaborator?"
"Shinichi Yuta","Interviewee","Okay Professor Harada Akira Harada Akira. He is now a president of Sapporo Municipal University. "
"Shinichi Yuta","Interviewer","But I have heard also in Japan Toyota also talks about Kansei design."
"Shinichi Yuta","Interviewee","Yeah. "
"Shinichi Yuta","Interviewer","And they talk about Kansei with robotics. "
"Shinichi Yuta","Interviewee","Yeah. "
"Shinichi Yuta","Interviewer","Very much. "
"Shinichi Yuta","Interviewee","Yeah, actually so Professor Harada initiated the Kansei- Academic Society of Kansei Engineering. But this word is not invented by him himself. This word is a bit old but Professor Harada is one of the key persons of Kansei engineering. it is so this project is also advertised in several places but Japanese people, many Japanese people are very much interested to treat Kansei. "
"Shinichi Yuta","Interviewer","Why is it, because it is a very different perspective on engineering in a sense from the efficiency rationality kind of way of thinking? "
"Shinichi Yuta","Interviewee","So but my interest is engineering principally, but also my interest is engineering but my interest is also the how our product by engineering it is used in the society. So then he should know what is a problem, what is a requirement, what is a real purpose to use our technology? So Kansei actually this is not usually it is not my own research subject. Just I wish to know and I try to understand. But in this project I could observe more detail how our technology is used for their purpose. So then I collaborate some something more deep in this project but again my own basic interest is not that part. "
"Shinichi Yuta","Interviewer","Were there any surprising results?"
"Shinichi Yuta","Interviewee","Oh, principally actually for me it was many interesting things but main thing was rather give the- a kind of the foundation of the fact which are already . For example the in the museum, picture museum there is a small explanation card under the picture. So the people in the museum how would you say the people the specialists working in the museum use "
"Shinichi Yuta","Interviewer","Like the museum curator? "
"Shinichi Yuta","Interviewee","Yeah, That is right. They have experienced that. it is a bit easy to change the flow of the people by explanation. But still they did not have any exact numerical comparative decode how the people move or something like that. But actually using this our system as a tool of the measurement of the audience they can get some information about that. So it was very, very much interested by themselves. I was very much interested on the fact that this is interested by them. So it is interesting. "
"Shinichi Yuta","Interviewer","Are there any other projects that you want to mention or things that you would like to mention?"
"Shinichi Yuta","Interviewee","Yeah, recently I as I told you this , this five years I am organizing a special Challenge. it is something similar with Grand Challenge operated by DARPA. We just provide the course and the subject for the mobile robot, the autonomous mobile which moves the pedestrian street and the city plaza or park or the center of the city. One kilometer and the robot should move autonomously completely autonomously from the start point to the destination. While the user people moving, standing who are enjoying playing. So autonomous mobile robot should coexist with for example the wheelchair for handicapped people, or bicycle, or children. So and this the but still the basic point is how to navigate the from on this course and we call and we call it to all in Japan so many researchers even the companies are interested to participate. And what I provide is opportunity to make experiment. So I work together with City local government and I get permission from the police and but to organize experiment in the same day for all people it is very good opportunity for them to observe each other or discuss. So actually in Japan this year 50, 60, 70 robots were developed to come to participate in this technical event. And big difference from the DARPA event challenge is this is not a competition. Just open experiment to work together so we do not give any order. But the people can observe that this robot completed the navigation. And this robot could not complete it but this robot could navigate autonomously after this point, 500 meters or something. But anyway we do not give any order. it is not competition, not prize, not budget support."
"Shinichi Yuta","Interviewer","One thing I have noticed in the past looking at competitions, mainly business plan competitions are the ones where the prize gets higher the more the teams do not talk to each other. So I am curious if you have seen so this sounds like you want to encourage conversation."
"Shinichi Yuta","Interviewee","Yeah."
"Shinichi Yuta","Interviewer","Have you participated in other competitions where they are very competitive? Or do you notice some of this philosophy behind what you are-"
"Shinichi Yuta","Interviewee","Actually principally I do not like competition. "
"Shinichi Yuta","Interviewer","This is a great idea. "
"Shinichi Yuta","Interviewee","But anyway in the case of robots, if we teach competition, still it is very easy to observe. So how this robot move? What kind of sensor it use? But rather provide them opportunity to discuss. If it is a really competition to get some prize then they do not wish to tell their technology. But still I believe that the autonomous navigation is it is a very long years' history of technology. Still it is not enough to realize. So the common understanding is very important. But their robot system, by itself is it is of course it is very good information but it is a bit limited to just to see or just discuss on the front of the robot, it is very important. So actually thank you very much. it is not the it is because it is not competition then we can have a very good opportunity. But the other side, it is partially it is not a competition. Still the not only the definition but also the safety purpose. We have to decide the details of the course for example or a kind of regulation. But to make regulation it is very difficult. And anyway it is real world. So first robot move in some situation. When the second robot start it start to rain. And in the case of third robot there come another cart . "
"Shinichi Yuta","Interviewer","So the environment changes. "
"Shinichi Yuta","Interviewee","So the environment should change. But in the case of the competition organizers should provide some equal condition. But this is nonsense in the problem of the real world. But anyway we have but still we have to give some regulation. But it is very difficult to write the regulation. Then I say that regulation is me pre-task at any time on site. But then but some people from interested to join. Then ask me to send the regulation. Of course we have some, but it is very difficult to write a very detailed definite regulation. So we decided just a regulation is written in Japanese language. And because for us this regulation should be understood by the local people. Not for the specialist. So then unfortunately or fortunately we this challenge is just for Japanese people. But anyway we do not pay any budget. Rather we get registration fee but we do not pay any budget, but registration fee is not so big. But the people should bring their should brought the robot by themselves and should bring robot by their own expense to bring it is about to make experience and discuss this together and bring back. And there actually this is a very I believe this is a very good opportunity and I am very proud that I could provide such a chance for the desired robot researchers in Japan. "
"Shinichi Yuta","Interviewer","What do you think are some of the future challenges for robots in Japan?"
"Shinichi Yuta","Interviewee","Future challenges? Yeah. This is just name is Robot Challenge. But I think of course it is a kind of a challenge but I do not think it is not a grand challenge, not grand. That such opportunity is very important. it is my own mind. So the actually the challenge of the robot is very difficult. Anyway we are challenging to make some good machine which can walk like people. But actually the when we define that task, then it is better to make single-purpose machine so the the grand big challenge is to realize a machine which can walk various wide range of tasks in one wide range of the environment. But still wide range is it is not clear but it is very difficult so for example for me for example to realize the small size mobile robot which can behave just as the same as my cat. For example walk around in the room climb the tree and at anywhere around my house if you can come back to my home to eat and he can recognize people and he can recognize a car and avoid escape from the usually he is sleeping on the street because in front of my house traffic is not much. But when the car come he is usually wake up and come back to my home or something like that period. So to realize that such cat's behavior is very interesting subject or a very interesting target of development. But it includes too many challenges. And also but the other side I am very much interested, but when I give you the proposal over this development we use a very big budget. I will refuse because this subject itself is not worse to use the tax. When I have a very rich man, I have many money I provide then it is okay. This subject interests me. But from the viewpoint of the project or something I believe that interest more important is not interest usefulness in the society. "
"Shinichi Yuta","Interviewer","What do you think are some applications that are going to be very useful for society?"
"Shinichi Yuta","Interviewee","Yeah, then application point of view actually for example the most successful robotic machine in the world first one is automatic clothes washer. Imagine 50 years ago the people should wash their clothes by hand in cool water even winter. But that is and usually in Japan maybe in other country washing your clothes is a task of the woman. So it was very, very hard work. when we in the case if the people say the washing woman or you 50 years earlier after 50 years you just put your wash in the box and push the button and just you can wait the machine call you after washing and and dried until you can just see it and watch picture or drinking tea. In this when this woman will feel that no I cannot imagine such perfect robot. But nowadays usual people have their own robot washing woman robot in each home and also but it is just small box. It does not move. So next generation washing room machine will walk around the room to find clothes when I just removed clothes and throw it, then washing robot come to pick up and wash and fold it to put on the place. But at this moment we can never consider such a system in practically. But so I am not sure such washing robot realize or not. But also another robot system is power shovel, excavator. It can move. It can dig the soil or do many other things. Of course it is control but recent excavator is very much automated. Of course operator is necessary. But it is very easy to operate. And sometimes we can control it remotely so it has a hand. It is a mobility to work what people usually people does not wish to do. Very hard work, it can provide. it is a real robot but we do not say it is a robot. Washing machine, right, we do not say it is a robot because it is really useful. So when for example in iRobot series the Roomba cleaning robot, but at first people feel that it is a robot. But nowadays it is just a cleaning machine. So if we have to say it is a robot then it not only cleaning the floor but also I wish it should for example when it finds something on the ground if it is a robot it should pick up this mobile phone to put on the table or any other it is requested to do if it is robot. So at this moment the cleaning robot out feeling is it is not a cleaning robot anymore. it is just a good cleaning machine. So in the application point of view I believe that. In any situation or any system and a robot technology will be installed in a very wide range. To realize more good performance of cellular phone, electric pot, or even a light or camera or anything. Of course in the automobile so the robot technology will be installed to make it more good performance. But after realizing that they are practical did I maybe we will call it this is just a car and even a good car. For example 50 years later if the taxi in San Francisco usual taxi does not have a driver, just it is a normal operated automatic car just but service area is limited only 20 kilometers or something. Still it is very useful taxi and in such a case it is very good because one more people can ride. So at this moment it is actually it is robot but if we have such a system then we will not . So this is my definition of robot, so that robot is machine, it is a good technology in dream. So what are you doing to realize the dream? But in this sense sometimes I explain that what we are doing is that we are developing machine good machine which is thought as robot now to be just a machine, not a robot. From robot to not a robot is our work, what we are doing. So then the develop a robot it is kind of that means develop a prototype or something. it is my feeling. So it is very difficult to say grand challenge. "
"Shinichi Yuta","Interviewer","Grand challenge means there will be no more robots ever. "
"Shinichi Yuta","Interviewee","Yeah. "
"Shinichi Yuta","Interviewer","So just one final question. We want to have an education component for the website so we just ask everyone do you have any advice for young people who are interested in studying robotics? "
"Shinichi Yuta","Interviewee","Yeah. What I am talking with students who are young people, just think what do you wish to do? Just think what do you wish to do or what are you interested then try to realize your interest. it is usually I am talking with the students but this is a reason why. The reason is I did not have such a sense when I was young a child so I thought that it is rather better for me to have some purpose or direction. Especially in Japan, especially in Korea or China the purpose of young people is just by examination. So my feeling is by examination is not a good purpose because I do not like competition. So what I should say is that try to do a practical, try to do practically and what you wish to realize or what you are interested and integrate many experience is important in the young age. Of course a kind of good consideration or thought is also important but my feeling is more experience is important. "
"Shinichi Yuta","Interviewer","Thank you very much. I hope you are not too tired now."
"Shinichi Yuta","Interviewee","I enjoy to talk. "
"Shinichi Yuta","Interviewee","So but point of view, my point of view, robot cannot be understood because if it is-"
"Shinichi Yuta","Interviewer","it is always in the future."
"Shinichi Yuta","Interviewee","Yeah."
"Shinichi Yuta","Interviewer","that is a great point of view."
"Shinichi Yuta","Interviewer","Yeah, I had not heard that before. I have not heard it put that way before but that makes a lot of sense because there are you get used to a certain technology and it becomes normal and robots are not normal things. It makes a lot of sense."
"Shinichi Yuta","Interviewee","But also from the point of view of academia who are interested to start up a very big project getting a budget from such a sector, some professor told me do not tell. "
"Shinichi Yuta","Interviewer","do not say that. Yeah, no I mean it makes a lot of sense because nobody can really define a robot. it is always very vague but everybody has- the public has an idea, roboticists, professors have an idea, everybody has an idea and everybody is very excited about it, but it is always moving. "
"Shinichi Yuta","Interviewee","Yep, That is right. Yeah, so robot can be defined by any people. For the element that is who can just make a box, add some hand by some branch connecting it by band he can say this is a robot. "
"Shinichi Yuta","Interviewer","Definitely."
"Shinichi Yuta","Interviewee","He can say but we do not say this is not my favorite robot. that is all. it is not. Okay. Thank you very much. "
"Tom Lozano-Perez","Interviewer","Great. So, if we could, can we start? "
"Tom Lozano-Perez","Interviewer","Yeah, I am ready. "
"Tom Lozano-Perez","Interviewer","Okay. So, we can start with you telling us your name and where you were born and when. "
"Tom Lozano-Perez","Interviewee","I am Tomas Lozano-Perez. I was born in Guantanamo Cuba, August 21, 1952. "
"Tom Lozano-Perez","Interviewer","And where were you educated? And how did you come to the U.S.? "
"Tom Lozano-Perez","Interviewee","We left Cuba when I was about ten, moved to Miami, lived there for a little bit, then moved to Puerto Rico, where I went to high school. After high school, I went to MIT. So, I stayed there for my Bachelor's, Master's and PhD."
"Tom Lozano-Perez","Interviewer","And you were always in the computer science department? "
"Tom Lozano-Perez","Interviewee","Yes. Well, at MIT, it is electrical engineering, computer science. It had just changed right around the time I got there. I do not know exactly what date, but yeah, my degrees are mostly in computer engineering, computer science. "
"Tom Lozano-Perez","Interviewer","And how did you get interested in computer science? "
"Tom Lozano-Perez","Interviewee","Well, as a freshman, I thought that I was going to do electronics. I had no clue what that meant, really, but then I took a programming course and loved it and sort of stayed doing that. So, at MIT, they have a requirement to do an undergraduate thesis, and a guy I knew, one of my friends, was working at the AI lab at MIT. And so, my advisor, my undergraduate academic advisor was Patrick Winston, who was at the AI lab. So, I ended up doing a Bachelor's thesis there, which ended up being in computer vision. "
"Tom Lozano-Perez","Interviewer","And was it with Patrick Winston? "
"Tom Lozano-Perez","Interviewee","Yeah. He was the supervisor of the Bachelor's thesis. So, then I stayed and worked there for a year after my Bachelor's, which is in 1973, So, 1973, 1974. And we had a visitor for a year there, who was Hiroshika Inoue, who spent a year at MIT. And he was working with a little robot that we had there, which was called Little Robot. it is a Cartesian arm that he used to doing some assemblies. And I was asked to help him with lisp . He did not need much help, because he is a smart guy. So, but I got to talking to him. I got really interested in the robotic stuff. So, I went to graduate school, you know, after a year there and started working on Winston asked me to work on a language for mechanical assembly. So, you know, I had done his assembly using a very low level, you know, move here, move there, very simple kind of language. And so, the question is: Could you do a high-level language for assembly? And at that time, there was this rash of problem-oriented languages or special-purpose, high-level languages for particular tasks. In particular, there was something called Planner that had been developed at MIT. And so, I tried to start working on something like that and then realized that it kind of did not make any sense, that that kind of a high-level control structures. The Planner had these back-tracking control structures, and that did not seem to be relevant to the robotics programming. So, basically I started doing basically geometric planning instead. Because I figured, like, even deciding where to put the fingers to pick up the objects was a hard thing. So, I started building little object models and trying to figure out how to do the grasping of the and how to move them around. So, around that time in the early 1970s, there had been a thesis at MIT by Terry Winograd , which had built this simulator robot that you could interact with in natural language, you could give a command. So, it was called SHRDLU . And it had a little symbolic planner, you know, and it would pick up these blocks and so on. And in it there were two functions that depended on geometry. One was called Find Space, and the other was called Make Space. So, Find Space is if you are going to put the block down on the table, where should you do it, where is a place That is free, and make space was to move things out of the way to put something down. And they did not know how to do it. They were doing it by picking random positions, which at that time was considered incredibly stupid. Now it is the state of the art, but at that time, random selection was considered very stupid. So, a number people had thought about algorithms for how to try to solve those problems. And so, I got interested in that. And I started is this what you want? "
"Tom Lozano-Perez","Interviewer","Uh-huh. I am taking notes. "
"Tom Lozano-Perez","Interviewee","Okay. I started thinking about how to do the selection of grasping on these objects. I had done it by hand first. I did an assembly of aircraft, little model aircraft engine cylinder, which has a cylinder on a rod. And so, I had programmed the robot to do it. And so, I was interested in how to figure out where to put the fingers when there were obstacles nearby, other objects and so, on. So, I started sort of trying to write programs to do this, and I pit upon the idea of using just the tip of the fingers as a reference point and then characterizing the set of points that were not accessible to the tip of the fingers due to the presence of other objects. So, I built these things that I called grasp sets, which were basically maps of the degrees of freedom and characterizing the places where you can put the fingers and so on. And then, I kind of ran out of time, and I did the design of how I would build a whole system, but the kind of hard-core piece was really a mechanic grasping . "
"Tom Lozano-Perez","Interviewer","And what kind of robot were you using? Or was it mostly simulation? "
"Tom Lozano-Perez","Interviewee","No. No. There was a real robot, but what I did is I did programming on a real robot. Then after that, I really did it in simulation. I did the computations geometrically. We had this robot, which was called Little Robot that was built by a guy called David Silver. And it was a Cartesian arm, which is an interesting set of degrees of freedom. There was a hand that could do Z and Theta, and then a base, which was the little table that did X and Y. So, it had four degrees of freedom but split. It was very cool. And it had four sensing fingers, which was not typical at the time. Inoue had used some early for sensing in Japan, but it really was not widespread. Well, robots were not widespread, but this was. And they have a nice level interface to our computer, so, you could write list programs to run it, which was pretty cool back then. So, I had done a fairly elaborate assembly using that thing. And then I switched over to how do I plan for it. I never really closed the loop to the point of actually generating a plan for that robot. So, you know, at this point really it was a computational question: How do I pick the grasp? So, I got some way along that and wrote up a little paper, which appeared in or something. And then I went off for another year in between. So, I had taken a year in between my Bachelor's and my Master's, So, I went off for a year between my Master's and my PhD to IBM, T. J. Watson, there is a guy there, Peter Will, who was running the robotics group at T. J. Watson. And he'd accumulated an interesting bunch of people. And he used to visit MIT every once in a while. And I said, I am interested in kind of, you know, figuring out what IBM is like, because I thought I wanted to end up working in a research lab like that after words, and IBM was very interesting at the point. It had a monopoly, so it could afford a lab. You know, it is sort of like after the monopoly went, the lab went. But anyway, so I went to T. J. Watson, and they had their project to build a language or assembly at that time they called Auto Pass. So, I started working on that team. there is a guy called Mike Wesley, who unfortunately passed away, a British guy, very, very cool guy. He was working on a modeling system, a polyhedral modeling system. And I started working with him. And he said, Oh, let us kind of try to build an example. And around that time, I ran across a thesis from Cal Tech by a guy called Dupa , who had done a motion planning system using what we would call kind of configuration space ideas at the time. And, you know, I said, okay, it turns out that this is exactly the idea that I had used for grasping, and he was using it for moving the arm around. I said, Hmm, this kind of seems like a pretty general idea. So, we decided to kind of build a whole system that would try to do planning for little assemblies. So, it was the usual kind of, you know, without understanding it, Mike and I split the work. So, we said, Okay, Mike, you write the A-star algorithm, or the grasp search algorithm, and I will write something that computes the ground obstacles in the world and so on. Yeah, of course, that part was ten times bigger than the other one. But anyway, That is the way it works. But we managed to do it by the end of the year. We had a prototype of something that, it had a bunch of typewriter parts that were placed in the environment and the set of obstacles. And we ended up using Styrofoam obstacles because the method that we ended up using was what we later called a visibility graph method, which was an idea that appeared originally in strips, you know, that system. And but they had not known about ground obstacles in the way that we were doing it. So, it ended up clipping the corners of the obstacles, so, you know, the Styrofoam got curvier over time. So, they had a Cartesian robot, too, which IBM marketed for a while. So, we put something together that would build these ground obstacles and then do visibility graft searches and do it over X, Y, Z, and a discreet set of rotations So, it could move those things around. And, you know, we demonstrated it. So, that was, you know, it was pretty cool, I thought. And then I got into a little fight with IBM because they decided that, oh, this is pretty cool. Why do not we make it confidential? So, we had a little disagreement around that point. I ended up talking to the vice president of research IBM about this disagreement. So, we reached a compromise that I could publish it as long as I did not mention that it was ever implemented on a robot. So, okay. So, I wrote this paper, which later appeared in Communications of the ACM, jointly with Mike Wesley. So, it looked like a very abstract algorithm. It was good. The paper became very well known, people in computational geometry, which was kind of being born around that time, got interested in it. And we wrote an IBM tech report, and a guy called John Rife read it, and then he wrote this paper on the complexity of the piano movers' problem. So, it ended up having, I think, a fair bit of impact, people that did not know it. And it was, you know, not mentioned that it was on a robot. It looked like it is an abstract algorithm, which probably was a good idea. It probably would have been a bad idea to kind of present it as a systems paper, as a robotics systems paper. It was really kind of an abstract algorithm, which was good. Later, Wesley managed to sneak in a picture of the IBM, of the path of the robot doing the simulation in one of the papers that he wrote on describing the geometric modeling system that they had built. So, he kind of snuck it past the lawyers. Mike was good. he is a very kind of staid British guy with white hair, but he was funny. Anyway, So, I went back to MIT to finish my PhD, and I wrote this paper and so on. And I showed it to Bertel Horn, one of the professors there, and he gave me a great hint that, in fact, that these volumes that I was building appeared in classical geometry. They are called Minkowski sums. This was actually Minkowski difference. And So, he pointed me at that. That was very useful. We were graduate students at the time then. He said he'd been reading physics, and he said, Well, you know that this space that you are using is called configuration space in physics. So, what you are really doing is building obstacles in configuration spaces. I said, Oh, cool, a brand, a name. That is perfect. So, then what I did in my PhD thesis was really kind of build on this idea, generalize the idea and implement some ways of computing them for bigger problems and so on. So, you know, published a couple of papers on that. And that became what people called, you know, became known as the configuration space approach, the idea of characterizing the constraints and the robot's degrees of freedom due to the presence of obstacles and then, you know, doing planning. And over the next, you know, few years, we showed that it could be used as the basis of all kind of planning for grasping and so on. And Matt and Russ Taylor wrote a paper on how to use it for thinking about uncertainty using an idea called preimage back chaining. And so, computing these preimages into configuration space and thinking about the sensing that happened while the motion was going on, which was kind of my favorite piece of work that we ever did at the time. Because, you know, it was pretty clear and certainly it was pretty important, but it was not clear how to think about it. Now, it turns out that those ideas were also, present in the controls community, but we did not really know about that. there is dynamic programming and space with some idea that was kind of being developed in the controls community. We were not aware of it at the time, but I would say, you know, it is something that I really liked. So, I did not say, but my PhD thesis ended up being supervised by Bertel Horn because he was the more mathematically inclined faculty member at MIT. So, he ended up being the supervisor for my thesis, and Matt's thesis. And Bertel and I co-supervised Matt's thesis at the end, but at that time at MIT, there was this constraint that they were not supposed the government had told them not to support robotics because they go through, you know, eh, you know, they decided no, That is not useful work. "
"Tom Lozano-Perez","Interviewer","When did that happen? "
"Tom Lozano-Perez","Interviewee","This was, I think we had it was ONR . And it was around the time that I was a graduate student, So, sometime before 1980, in the late 1970s or something. So, the AI lab had this money that came ultimately from DARPA the ONR . And somebody had this idea that, you know, that was not a high priority thing. They were funded to doing AI. So, there were a couple of us that were already around, and we stayed, you know. They managed to kind of keep us going. So, I mean, as I remember, there were really only four graduate students in robotics at that time around the AI lab. The one who graduated first was Mark Graeber , and then there was John Hollerbock and Matt and I. So, we all stayed in robotics and are still around. But anyway. So, Bertel ended up supervising at least Graeber, Matt and I in one way or another. Are there any questions that come up out of that? Or I could keep going? "
"Tom Lozano-Perez","Interviewer","I was curious about you already talked about the piston from the airplane and then also, the typewriter parts. Was there any way you kind of came up with those objects? "
"Tom Lozano-Perez","Interviewee","The typewriter parts at IBM were natural. IBM had the Selectric typewriter, which was I do not know if you ever looked at a Selectric typewriter. It was the biggest mechanical kludge in the universe. I mean, the fact that that worked was completely amazing. Because you would see all these parts, the incredibly gnarly shapes. I used them later for when we were doing some computer vision stuff. I used those parts because they were just awesome. They were just, you know, mechanical engineering gone wild over the years adjusting to fit around corners and stuff. So, you know, within you thought about assembling stuff at IBM, it was, you know, the Selectric came to mind. Wesley was thinking about the covers of computers, of, you know, the big machines. And they had cabinets and stuff, and So, he was actually working on CAD for those things. But they were too big, So, we had a robot about yay big, and you know, the things you could pick, the Selectric typewriter parts were the right size. Similarly, with the little robot, we had to look for something. And I think it was probably Winston and Horn who had come up with the idea of assembling a model aircraft engine. I think That is where it came from. So, the size of the piston, which is about that big, was about the right side for the fingers of the robot, perhaps a little small. I have that video some place. it is from 1976, and it was, you know, it was hard, because you know, they were kind of a little too small for the fingers. It would have been better to use something bigger. Even though I had built an assembly out of some ball bearings and a shaft, and those were a little bigger and probably would have been a better choice. I was, I mean, you know, just fresh. I did not take graduate school; I did not know better. But anyway, so, you know, there was not like a whole robotics was very small then. You practically knew everybody, So, there was not that much experience. "
"Tom Lozano-Perez","Interviewer","And was that all funded by the ONR? "
"Tom Lozano-Perez","Interviewee","We were. So, at the AI lab, we never even thought about funding, so, the whole lab was funded by one agency. It was ARP, DARPA, or I guess at that time it was ARPA, then there was ARPA then ARPA, then DARPA then DARPA, you know. And the guy who was in charge of ARPA had this funding model of basically funding labs. So, AI lab and MIT and Stanford and so on were basically, there was the one grant, and they funded everything. So, you know, they wrote a grant every three to five years or something, which was, you know, three hundred pages of stuff and saying all the things we were going to do and all the things that we have done. And we were there, so everything in the lab was paid basically from one place. And I mean, it was a radically different model for funding than we have now. it is much less constrained. So, if something came up that was interesting, you could follow it. It was not like you had to say that you were going to do this: And on the third day I shall have a breakthrough and that was not something I had to say. So, you could just do it. So, you know, Winston was the head of the lab at that time, and he kind of liked the idea of robotics. There had been robotics going on there since Minski started the lab. He was interested in robotics, and they had done some robotics stuff. So, Winston kind of kept that going. There were a few of us around doing it. It was not, you know, the major part of the activity as a laboratory. As I said, there were only, you know, three or four of us doing it. There were some more people doing computer vision and just, you know, basic AI stuff. "
"Tom Lozano-Perez","Interviewer","How many people were around the lab at the time? "
"Tom Lozano-Perez","Interviewee","it is hard to say. I do not know. We had about one floor at Tech Square, So, I do not know, fifty? it is hard to say. I mean, later it grew bigger. I do not remember. You know, there were maybe five or six faculty and graduate students and then some staff. So, I mean, there were, you know, what we called hackers back then, as a compliment, not as a curse. And you know, they had built things like the first, one of the first chess programs that was rated, you know, it was taught by Ray Greenblat , who was a guy working there. And, you know, it was a cool place. A lot of stuff was happening. And robotics was one of the things that we were doing. But there were only a few us who were really working on that. "
"Tom Lozano-Perez","Interviewer","Did you collaborate with people who were outside of the robotics group? "
"Tom Lozano-Perez","Interviewee","Well, we talked to random people in terms of collaborations. I mean, the person I worked most closely with was Matt. We were graduate students together and, you know, we hung around. So, our supervisor, Horn, was like a vision guy. And he appreciated math, but he is A), a vision guy, and B), somewhat reticent, So, he was, you know, it is not like he, Hey, come here guys. No. We barely ever saw him. So, we were kind of our own advisors. So, you know, Matt and I, a little bit more under sometimes with John, We had talk about things and, you know, what is going on, and We had try to read papers and talk about them. But it was pretty much, you know, kind of, we were going. And you would talk to the other graduate students and, you know, other people working on planning and language and all kinds of stuff. So, you ended up absorbing a fair bit of the general culture from talking to random people. It was not as because it was small, you know, you talked to everyone. It was not like when you have a big group, you only talk to the, you know, the people in your group, you know. And they believed in moving your office every year, So, you would talk to a different set of people kind of thing. So, you know, I knew about vision. I knew about language. I spent a year doing linguistics as a graduate student just because it seemed like fun. And you know, Jumpski is around and seemed exciting, So, I did linguistics for a year. Then Jumpski woke up and said, No. that is all wrong. Everything I said before was wrong. it is now this way. Oh, well, I will just go back to robotics. So, I think it was much less specialized, the education, and kind of environment. So, I think That is good. I think students today tend to be rather more specialized. But, you know, in terms of collaboration, I had worked with the people at IBM. Late in my time there, Russ Taylor arrived. He went to work there, and Russ was working on some of those same ideas when he was at Stanford. So, in terms of academic robotics at that time, Stanford was probably the biggest place under, you know, Bernie Roth and those guys there. The Internet started; it was working on there. And so, there was a fair bit of activity. Lou Paul and Bruce Shimano and all those guys. So, and Russ Taylor had been working there. So, I had kind of talked to him, and you know, I had talked to, worked with the people at IBM. But when I came back to MIT, aside from kind of random connections, mostly the guy I talked to was Matt. "
"Tom Lozano-Perez","Interviewer","And you mentioned, I think, , and communications with the AC . What other kinds of conferences or journals were up there for robotics at the time? "
"Tom Lozano-Perez","Interviewee","There was not much. So, it terms of robotics itself, there was this conference, ISIR or can go like that, international symposium on industrial robots? Which was kind of a mish-mosh of stuff. A lot of it focused on industrial it is called industrial robots. So, I mean, there had been kind of a giant disconnect between kind of industrial robotics and academic robotics from the AI kind of perspective. So, industrial robotics was about doing stuff fast and cheap, you know, and so on. So, it really was not a place where you really could present that kind of stuff. Any kind of more high-level AI-ish flavored stuff you would go to an AI type conference. But it really was a problem. So, communications of the ACM was kind of one of the leading journals at that time. Now it is a kind of rag, you know, it is for the news and an occasional random article. But at the time, it was like the leading journal in computer science. So, we were very lucky to get our paper published there, and it was the cover article, and, you know, they had to prepare cover art and stuff like that. So, you know, it was very cool. And I ended up publishing that paper in my thesis, and the IEEE transactions in systems and cybernetics, which was kind of a hodgepodge of stuff. And the paper that, you know, that has configuration space on the title was in the IEEE transactions on computers, of all places. I mean, if you said, What were the leading computer science journals? ACM, you know, and IEEE computers were. So, I was trying to say, Hey, you know, let us try to get wide circulation. So, I aimed for that. There were not very many robotics venues in terms of publication, which was one of the other reasons that it later, you know, a few of us kind of talked about beginning a journal in robotics and, you know, ITRR eventually came out of that set of discussions. Lou Paul and Mike Brady took the lead on that and started that journal. But I mean, there was not I think as far as I remember, ISIR was not really that kind of conference. I do not think I ever went to one of those. It really was not. So, I aimed at whatever random other journals were around. "
"Tom Lozano-Perez","Interviewer","At some point, somebody told us that also, MIT, CMU and Stanford have these reports that they would circulate. "
"Tom Lozano-Perez","Interviewee","Yeah. Yeah. So, those were not a rough read or anything like that. So, in AI and computer science in general at that time, each of the major institutions had a technical report list. So, IBM had one, and So, MIT in the AI lab, there was something called AI Memos. So, you would, you know, write AI memos and then try to publish them some place. That is usually how . The memos were in circulation earlier. So, for example, the delays in publication were enormous, so my paper on configuration space, whatever, took three years to appear. It had three reviews. Each one took a year. So, the AI memo version had been out, you know, long before. So, that was something that people looked at. So, Stanford had a series of technical reports. And they were physical, right? This was before the web, so there was a real use for a library. So, the library at MIT would subscribe to the, you know, CMU and IBM and Stanford and so on, their publications, these technical reports, and then we would use that as a, you know, means of trying to keep up. Because there were not really regular conferences that you could go to, at least, you know, the guys and later triple AIs and so on for a while, were that until, you know, regular conferences in robotics started. Like, ICRA started in 1983, something like that, no, 1985? When was it? I do not know. It was in the early 1980s. I was the program chair for the second one. Lou Paul had been the program chair for the first one. I did the second one. My experience with the IEEE was not the best, So, I did not do that again. But and then, out of the AI lab, we started the ISRR, and they came out as books. At that time, MIT Press was interested in publishing books like that, because there was not a lot in robotics, and they started publishing the IJR journal. So, yeah, so the technical report series played a very important role in all of computer science at the time. But it was especially true in AI, I think. So, you know, the standard thing you do is you at the AI lab, we had the things called the AI memos, which were fairly polished, and then there is something called working papers. And previously they had a thing called vision flashes because they came out of the vision group there. So, you know, stuff that was less polished We had throw in there. So, and then you would publish a thesis that, you know, student theses and so on, so you would get a nice little, you know, bound thing, and people got a hold of those. So, yeah. "
"Tom Lozano-Perez","Interviewer","And how was the communication like in the community, then? Was it, you know, in these conferences that were not so much robotics oriented people but still kind of congregate in robotic circles, or not? "
"Tom Lozano-Perez","Interviewee","So, we are talking here kind of before 1980. I graduated in 1980. I do not remember any place where you talked to people, except by maybe visiting their university. Now, I am sure that faculty at that point and so on maybe had other places that they went and maybe talked to each other, that they probably had traveled more, but I do not remember really talking to people. I remember one time visiting Stanford and missing Russ Taylor but talking to Bruce Shimano kind of thing. And CMU I do not think I ever visited, although they were probably a little less active in robotics at that time. And in the Boston area, it was Draper Labs who was pretty active in robotics, this guy there called Dan Whitney, who had been very influential. So, we would see their reports and theses and so on. And so, we heard about that. And We had look at the Stanford ones, and it was pretty informal. I really was not I mean, we did not have the Internet kind of thing. I mean, we had local e-mail, but not really but there was at the time e-mail between the different, you know, the ARPAnet was in place, So, you could send e-mail to Stanford and other places, but if you did not know somebody already, you know, you did not kind of cold call them. So, you know, you kind of knew who was doing what because of their, you know, the technical reports coming out and stuff like that. And there were not that many people doing anything, so you could keep track of what was going on much more easily than you can now. "
"Tom Lozano-Perez","Interviewer","When do you feel that changed? Because you mentioned your friend. "
"Tom Lozano-Perez","Interviewee","ICRA really yeah, I mean, ICRA and ISRR were really the, I mean, from my point of view maybe other people have other memories but those are the times in which I remember actually talking to other people. So ISR was by invitation at the- when it was created and the first few of us were great. I loved them and the- everybody was there and it was a lot of fun and you would present stuff and there was a lot of discussion. I remember the first one I presented that worked that Matt Mason and Russ Taylor and I were doing on this backchaining stuff or uncertainty and I remember Jean-Claude Latombe getting upset, Oh, this is ridiculous. it is a waste of time. We should not be working on this and Lou Paul came to my defense and it was an interesting discussion there. People went Oh, wow. It was interesting. So there is a lot of sometimes heated discussion about things and it was- that was a lot of fun, but So that was a change starting in the early 1980s when- and when ICRA was put together, it was a fairly conference. The IEEE particularly wanted large conferences. They like large conferences because they make some money out of them so- which is- was the basis of some of our disagreement, but- and so then you started seeing lots of people and talking to lots of people being at conferences and being always- almost never listening to the papers but outside talking to lots of people. So that was a dramatically different experience from my- from earlier on and before- in the late 1970s when- being graduate students basically. You knew the people around you and That is it."
"Tom Lozano-Perez","Interviewer","Do you have a feeling for what factors led to this explosion of interest in robotics, the amount of people, the attention given to it?"
"Tom Lozano-Perez","Interviewee","Well, I suspect that it was the idea that industrial robots were going to be important. I think the funders had this idea that somehow the industrial robots would be important and that it would be good to have academic research. That later led to a bust basically in which- because there really was relatively little connection between much of the work in robotics and what went on in factories, which was very stereotypical repeated kind of stuff. So there was not a great value placed on versatility and so a lot of us were working on that and that did not really connect. So I think later on funding kind of dematerialized and I basically left the field around 1990 partly feeling that some things were stagnant and funding had gotten pretty hard at that time so I think there was the kind of optimism about industrial robots, and I think industrial robots in fact did pay off but the connection to academic research was not as strong as it could be. There are some parts of it that- some of the low-level control and kinetics and that kind of thing so that paid off and- but much of the work that was kind of computer science based there was really no connection. So I think that that led to a kind of drop. The thing that kicked it back up later was mobile robots but that was not for a while."
"Tom Lozano-Perez","Interviewer","What kinds of things were you working on when you started at MIT as a professor?"
"Tom Lozano-Perez","Interviewee","So I was interested in the There were two kinds of things, the motion planning kinds of things that I had a phenomenal group of students. My first group of students was out of this world so Matt We were graduate students together and I happened to be co-supervisor in his thesis at the end 'cause I graduated a couple years earlier. He had taken a couple years off but we were more You could just as well say he supervised my thesis as I supervised his but then I- when I first started out of the blue I had this office of students, John Canny who went to Berkeley and this amazing guy. There was Donald who is now at Duke, was at Cornell for a while, Mike Erdmann who is on the faculty at CMU, and this guy called Van-Duc Nguyen who did not continue to a Ph.D., did a Master's, but his Master's thesis stuff is still referenced. If you look at any work on force-closure grasping and things like that, look at any paper on that now that are around and the odds are you would see V.D. Nguyen as one of the references still today every time. he is amazing too so And then after that Nancy Pollard who is on the faculty at CMU. So I had a really phenomenal group of students and they were working on basically motion planning kinds of things so Canny then developed in his Ph.D. on the first provably singly exponential algorithm for motion planning. he is completely self-taught so he did it all himself and Bruce worked on- first on six degree of freedom motion planning for free-floating bodies and then he did a thesis on error correction and recovery, some interesting ideas, generalized configuration spaces and so on and then ended up working on basically One was the modeling of friction in configuration space and then later he worked on randomized strategies, ended up doing some really cool stuff there. Nancy worked on grasping with three-fingered hand. Ken Salisbury was around and we had his hand and so she looked at algorithms for- finally for three-fingered hands so that kind of stuff. In parallel I was also working with a guy called Eric Grimson who was a vision guy. He did some work on object recognition using contact sensing and vision so we developed this thing called the Interpretation Tree, which is- was an approach- a constraint-based action approach to doing vision and object recognition so that became reasonably well known so we did that. I have always been kind of hands on so I always liked- actually did programming myself. I still do. So Eric and I actually did the coding for that project and we did that so Well, the students were doing a great job with the motion planning stuff. I did some myself also. I came up with an algorithm for doing planning for joint angles and so I- That is one that I did by myself, but I was also doing this stuff with object recognition so I did that through the 1980s, papers in that area. We did a system towards the end of that time called Handey, which was an attempt to put together a lot of the stuff that we had done in motion planning because a lot of that had been kind of independent little pieces so Handey could plan the whole thing, picking up an object. It would do localization using laser striping and then figure out where to grasp the object and then move it someplace and re-grasp it if it needed to and so on so it did kind of the whole thing so it was nice to bring it all together, but then at that point I started feeling like I was not- that we were kind of stuck. Partly the computers were not very fast and we seemed to be reaching our limits and funding was getting hard so at that point somebody came to talk to me about modeling molecules in configuration space and I said, Whoa. that is a wild idea. So then I spent the next kind of- almost 15 years working on- doing discovery so I got- I worked at- with a startup and trying to use machine learning to do discovery. That was before the whole GM thing. So proteins and peptides were the thing of interest so I got interested in that. Then it was good because it got me into machine learning, which I really know at that time. This was also before the machine learning explosion so I got interested in that. And we came up with this problem called a multiple instance learning problem in machine learning, which arose out of my stupidity of I had this representation for these little molecules and so- but the representation was not unique because- and so it was Okay. Somebody must know how to solve this problem so contacted Tom Dietterich who is kind- of reads every paper ever written on machine learning, still does I think. I said, Tom, really how do we solve this? I do not know. that is a new one on me so that was fun so we worked on that for a while, then worked on protein structure and stuff like that, then made the mistake of getting involved in academic administration for a while, hated it, so then decided to take a sabbatical and said, That robotics stuff looks like it might be fun again. So that was around oh, I do not know six years ago or something."
"Tom Lozano-Perez","Interviewer","What was the fun stuff that you were seeing then?"
"Tom Lozano-Perez","Interviewee","Well So one of the things that happened while I was away kind of thing was- had started to happen was the randomized motion planning kinds of things so that seemed to have done extremely well so- and of course the mobile robot stuff had really kind of done a great job so that was It seemed like people were starting to become interested in using robots and for something and- besides industrial applications so might be interested once again in trying to do intelligence kinds of things, and some of the ideas I had always thought that dealing with uncertainty was really kind of the critical thing because That is really where sensing and action come together and so there was a lot of work on using probability methods and so on. So I started talking to Leslie Kaelbling and she is one of the pioneers in POM DPs, which is an approach to doing- dealing with uncertainty and planning, and so we talked about a bunch of things. We also did some vision kinds of things but I said, Why do not we use POM DPs for doing grasping kinds of stuff? and she said, No, POM DPs are too hard I remember, said, I stopped working that. I am doing machine learning now. They are too hard. And I think it might be interesting so we started working on that and it did prove out to be interesting so we are still working on that and we have a couple papers that are kind of outgrowths of that in this conference so that has been very productive. So now we have a joint group and we supervise students together and stuff so That is worked out great so Yeah. So it felt like at least manipulation, which is the part of robotics that I have always been interested in, which is almost dead, so if you looked up robotics in the 1970s and 1980s it was manipulation. When people talked of robot it was a robot arm that had been Hans Moravec at Stanford had built his cart and stuff like that but you did not do mobile robots then. Then for while there was only mobile robots. There were a few people who hung in there like Oussama Khatib and so on but doing manipulation was basically impossible and- but then it seemed like- back a few years ago it seemed like yeah, it might be time to start doing that again. I think I called that one right. All of a sudden there is been a real rebirth of interest in manipulation. "
"Tom Lozano-Perez","Interviewer","What are some of the things that you think changed to make it reborn? Is it technological development? Is it conceptual "
"Tom Lozano-Perez","Interviewee","So computers have- are just Oh, They are a lot faster. that is a transforming issue so problems that used to be- people used to worry about, learning the servo loop fast enough and doing geometric computations and so on. With computers today it is sort of whoof so really- that really transformed the things that were interesting. I think that was probably the biggest thing. I think conceptually the idea of using probabilistic representations and some of these ideas like- that came out of operations research and controls really do give you a kind of- a nice set of tools for thinking about uncertainty and so on so people had been using some of those for mobile navigation, the whole SLAM thing but they really had not moved into the manipulation end at all. The manipulation The problems are somewhat different so there seemed to be kind of low potential for doing that so That is what we ended up doing."
"Tom Lozano-Perez","Interviewer","What are some of the challenges that you are working on now?"
"Tom Lozano-Perez","Interviewee","Well, the thing that Leslie and I are working on is trying to find a kind of unifying way to think about planning, acting and perception so one of the weaknesses- conceptual weaknesses in much of robotics throughout the years has been that these things get compartmentalized partly because of education reasons. So there is the people who do controls and there is the people who do vision and there is the people who do SLAM, and usually what you end up with is solutions that do not play together very well because you make assumptions that are really incompatible with some of the other solutions. So what you really need is some way of really kind of thinking about the things together like AI planning kind of separated from robotics back from- when STRIPS was and they made a set of assumptions which happened to be incidental I think to some of the things that STRIPS- the way STRIPS was doing things and they have stuck with them. And now they consider it anathema to question those assumptions but They are just incompatible with the real world so that you can not have fully symbolic descriptions of the real world. That is not practical and- but They are stuck in that little local minimum and you look at the people who do POM DPs and they mostly- they say, Oh, well, we have to find the optimal solution and you can not find optimal solutions for any interesting problem so you have to kind of fake it so you want to kind of break away from that. And perception once again people were- you make all kinds of assumptions about what it is that you want from perception that it is not clear how it integrates in a task and what you really need. So we have been trying to build- kind of conceptualize a system that- where perception and action and planning and execution are all integrated and trying to see if you can get some leverage on understanding what some of the assumptions were. So for example, we ended up kind of using some of the ideas from high-level planning in robotics but turning it around a bit and we still get into arguments with any- when- we- ever we talk to anybody there because Oh, no, you can not do it that way. Why? And even here when we talked about it today some people says, You can not do it that way. Everybody does it the other way. Right? So I think it- there are these conceptual silos that develop and you are starting to see some cross pollination but it is good to So we are trying to find something that kind of cuts across so recently we were working with our colleague, Russ Tedrake, and a post doc, Rob Platt. we have been trying to understand how the control people think about the world and trying to In fact, the- we had- Leslie and I have been doing a lot of discrete POM DP stuff and the controls is really continuous POM DPs and so how do you put them together and try to understand that so we have been meeting every week trying to kind of figure out how to cut across that boundary so that has been very productive so Anyway, so I guess I am old enough that I can- subject to finding a little bit of funding here and there I can kind of work on stuff that somebody starting their career might think a little risky. So for example, the kind of thing that Leslie and I have been doing some of it has just- she and I have been doing it. We do the programming. there is no student involved because the field has gotten conservative so the review process tends to weed out any idea That is too- that we do not do it that way so we are older. We can afford to have our papers rejected. Younger people get all upset about that but- so Anyway, so we are trying to do something which is cross cutting that really brings together the different aspects of the field and It will take 20 years to get there but it is fun."
"Tom Lozano-Perez","Interviewer","You mentioned earlier that industrial application seems to be this thing that constrains robotics in certain ways and now people are talking even today about a much broader spectrum of applications whether it is in the world or with robots or CoroBot thing and things like that. Do those kinds of concerns play into your work at all or "
"Tom Lozano-Perez","Interviewee","You need money. Right? So yeah. The problem with industrial robots was not that we felt that was the only thing. it is just that That is what people thought they wanted to fund so you had to kind of at least move in that direction. If you had written a proposal in the 1980s saying that you were going to do robots in the home that sounded a little strange so There had been a little bit of work on medical robotics at Stanford at the hospital there but- so that was not mainstream and it was not funded. Pretty much the funding came from DARPA and some industrial places and so it was not- that was not available. Now there is- it is a little more open. The only bright light for not only one bright light for funding was NSF in the early days. They were pretty open minded but little, tiny bits of money so you could fund one student but So now with the increased- we are on the ascendant again, it seems interesting and there seems to be a broad range of applications and the military's very interested so that makes it easier to get funding to do a variety of things so That is good. If you can not get funding to do stuff, then the realities of the situation are you can not So "
"Tom Lozano-Perez","Interviewer"," feed into things that you are interested in like uncertainty. Being in the home is a much more "
"Tom Lozano-Perez","Interviewee","Right. I was brought up as an artificial intelligence researcher and that is always what interested me is getting robots to be intelligent and so the thing That is interesting is what do you perceive to be the critical blocking factors when you do robotics. So the early days of AI so- what people perceived as a blocking factor was things like planning and reasoning and they kind of viewed the robot as an output device, as kind of a printer on the 3-D world, but then when you start actually trying to do something with a robot then you realize that whoa, it is very hard to do anything and where everything breaks is because your sensors were not good enough and your controls were not good enough. And so you go here and the object's there and you missed or you go and you hit it and everything breaks. So once you start doing things in the real world then you immediately realize that uncertainty and- which brings a combination of sensing and acting is really a big problem. And one way to try to improve on that is by doing better sensing, right, and- or better control, and in fact those are kind of dominant lines in robotics so that my little take on it was that yeah, okay, you do better sensing, you do better control but ultimately you also have to reason about how you should act in the presence of uncertainty. So that was my little niche there for a while and roughly it still is. Thinking about that is kind of how do you it is practical intelligence in some sense. it is not just abstractly reasoning about chess but it is producing actions that are effective even in the presence of uncertainty. That is the kind of area though where I got interested in. "
"Tom Lozano-Perez","Interviewer","What do you see as the current obstacles in the direction of where the field is going? "
"Tom Lozano-Perez","Interviewee","There are still hardware issues and that will always be but- so the hands in particular are problematic. There are some really good ones around but They are very expensive for example so we- a couple years ago- I guess a year ago we got this PR2, which is a Willow Garage thing. They gave out 11 of them or something and it was- it is an awesome device. It literally arrived in a big box and we pushed the box in, opened it up, pulled it out, and it works and it had sensing and control and everything but wow, this thing is great but the hand is really stupid. It can only open eight centimeters and so it is a limiting factor of this really cool- otherwise really very cool device. Anyway, so I think hands are still a problem and cost. It still costs hundreds of thousands of dollars to get one of those robots so I think as people get more interested in it somebody eventually will come down with something That is lower priced and more people will be able to work on it. That is what happened with mobile robots. Right. Initially, they were really very expensive and then I remember when Rod first started at MIT. I was his supervisor so he was a post doc for one year and so he was working with me on some manipulation stuff and- but he really always wanted to do mobile robots. And I remember one time this kid showed up. He was a 16-year-old who had built his mobile base, eventually started a company called Real World Interface, which actually sold those circular robots to everyone. This kid was amazing and so I remember he showed up at the AI lab and my office was close to the door and he said, Hey, I built this thing. Would anybody be interested? and I went Ooh, yeah. He had built it in his basement and it was cheap. You could produce lots of them. It really changed the face of the Anybody could work on mobile robots at that point. You had in your computer one of these little bases and you are off going so- whereas if you do manipulation it is a huge investment."
"Tom Lozano-Perez","Interviewer","What was the kid's name?"
"Tom Lozano-Perez","Interviewee","I am having trouble with that. Rod would know I think "
"Tom Lozano-Perez","Interviewer","No problem."
"Tom Lozano-Perez","Interviewee","Yeah. I can not remember his name. He turned out to be important. He really did this company and was eventually bought out by somebody at It was very cool. So Rod used that base for some of the early work he did in mobile robots, yeah, because a lot of us were gifted mechanical designers. For a while Ken Salisbury worked with us at the AI lab and he would always produce these beautiful pieces of hardware and it was sort of like Oh, that is amazing, but once everybody else produced these kludges that did not work very well, no. So I think we still have a little bit of a hardware problem. The PR2 has been kind of a great experience. It kind of works and the students can work on it and it is- it- so we need something more like that, maybe a little cheaper, and I think that that will help bring more people into the field."
"Tom Lozano-Perez","Interviewer","Four hundred thousand dollars is not exactly affordable."
"Tom Lozano-Perez","Interviewee","No. No, I- but I think that is a temporary state of affairs because there is another Mecha Have you Mecha Robots. They produce a really cool platform now. They also are charging $300,000 or something like that but that means we know how to do it so somebody's going to figure out some way of making them cheaper and so I think- just in terms of community I think that the two issues I see are One is the hardware at some level and then the perception just got a lot easier because of the connect. Right. That is going to be- make a big difference. The other is I think education. I do not think we are going to make progress by being compartmentalized the way we are now. We have to figure out how to get out of that. I do not it is hard just You have to learn a fair bit but I think if we could decide and agree that that was an issue we could construct a curriculum and there is- there are stuff around that you could know and so that people are aware of at least They do not have to be an expert in everything but they should be a little more aware of the broader picture so I think that That seems like an odd thing to pick on but it- I kind of feel like there really is an issue there. there is a lot of stuff known but not by many people that know all of the pieces or even some subset of the pieces. I am always learning. I have always loved I have Every time And it is good to kind of learn about what the other people are doing and I think it is kind of important just to formulate the problem in a way that makes sense so—"
"Tom Lozano-Perez","Interviewer","You mentioned education. If you could give advice to young students, people who are interested in getting into robotics, what would it be?"
"Tom Lozano-Perez","Interviewee","Go west, young man? Oh, no. That was No. Go east. Well, I think spend some time learning about all the aspects. There is this thing That is happened in recent years with the advent of all these competitions in robotics, the FIRST and all those things like that, is that students come in thinking that robots is about hacking. You slap a bunch of things together and you can just go out there and do it so the idea that there are kind of principles and That is not something that really gets highlighted there very much. So it is really- there is a scientific- set of scientific principles that are good to understand and it is good to learn broadly before tackling it so That is probably the At some point you want to actually do something but you also want to make sure that you are working on something that makes sense."
"Tom Lozano-Perez","Interviewer","You mentioned early on Did you have other connections with him or any other Japanese labs or other labs around the world or labs in the U.S.?"
"Tom Lozano-Perez","Interviewee","I kept in touch with for some years on a personal level but I- not really much connections with the Japanese. I did have more connections later with LAAS in France so Georges Giralt used to visit. He used to take this pogaminch throughout all the places that did robotics and so he kind of knew everyone. So I had met him and we got along. We used to talk in Spanish. He was Kavalan but in the French side and so we had that in common and so he always invited me to go over and visit and so I did. I spent some time there at LAAS and met who was there and a number of other people and we kept in touch and I had a number of French students in the lab over time so I think that that was productive. They later became one of the prominent centers in motion planning. I think I might have had a little influence in that. I do not know. I used to keep in touch with them and talk so they really kind of took to that stuff and did very well with it so Yeah. So I think from international places I had some friends in Barcelona also but they were really working on other things but I spent there- some time there. In fact, I did my sabbatical six years ago, whatever- eight years ago at- there- Barcelona but not a lot. I used to travel around and visit labs but I did not have a really close connection with them at the time. Anything else?"
"Tom Lozano-Perez","Interviewer","No. I think those are most of the questions. Is there something you would like to add?"
"Tom Lozano-Perez","Interviewee","it is 30 years' worth of stuff. Okay? "
"Tom Lozano-Perez","Interviewer","I know."
"Tom Lozano-Perez","Interviewee","But no. I am fine. I think you got some idea."
"Vic Scheinman","Interviewer","Why do not you just tell us your name and where you were born and where you grew up?"
"Vic Scheinman","Interviewee","Okay. My name is Victor Scheinman. I was born in Augusta, Georgia, on December 28, 1942. My father was in the U.S. Army at the time, stationed there, and so That is what brought me to Georgia. But at a young age, when the war was over, World War II was over, and we moved to Brooklyn, New York. And I lived there in Brooklyn until I was about 12 years old. And I guess if you want to call it (TAPE CUTS OUT) space and rockets and things like that, and science things, I loved it. And I would say my first contact with robots occurred when I went to see the movie The Day the Earth Stood Still, as a kid maybe about eight years old or maybe nine years old. And I was terrified by the robot in that movie and had nightmares over it. In fact, one night I woke up and saw the robot standing in my room. I am convinced it was there. So I hid under the covers after that for many weeks. And as part of that process, I remember my father encouraging me to maybe make a wooden version of the, what was it, Tobar or whatever his name was. "
"Vic Scheinman","Interviewer","Kind of as therapy?"
"Vic Scheinman","Interviewee","Yes, kind of therapy, right. My father was a doctor and so I did that. I remember it was all silver and it was made out of wood and about this high, and it had a little shield. He had this shield over his eyes and I had a little string I could pull in the back, and the shield would go up and down. And of course, I was always into trying to build spaceships and things in the backyard that we would climb into and things of that sort. I remember in fifth grade, I had a friend who liked trains a lot, model trains, he was into trains. And I remember talking with him one day and he says, When I grow up, I want to go to MIT. And I said, Well, what is MIT? And he explained, he gave me the initials of Massachusetts Institute of Technology. Then he started to tell me a little bit about it, and the only reason he knew about it was his father had gone to Harvard and had mentioned MIT, and his father was a Harvard man. I had never heard of MIT at the time, but he did. And so, I said, Well, I want to go there, too. So ever from the fifth grade on, I sort of dreamt about, Well, That is where I want to go. I went to a private high school in New York. We moved to the Bronx. It was a small high school, and it had a science program, but not an intensive science program. It was more of a liberal arts school. And in fact, I did go to MIT and I was the first student in this school ever to go to MIT, so it was sort of unique for them. And in fact, I do not think any other kids in the class went to what I would call an engineering science school. The first years were hard for me, the first year was just because I did not have what I would call the AP courses that they have today. This was in 1959 when I went to high school. When I went to MIT, I was 16, I was young, too, when I started. But I liked the environment and I liked the science and I liked the labs and I liked just wandering around the campus and talking to people, researchers, faculty people. I felt very privileged that I could talk to professors as a young kid and they would talk to me. And in fact, the early professors, my first physics lectures were all taught by full professors, not grad students. And I still remember them being very influential and just how I thought."
"Vic Scheinman","Interviewer","Did you know at that time you wanted to do robotics?"
"Vic Scheinman","Interviewee","No, no. And in fact, generally at MIT in those days, you spent the first two years taking general subjects, math and chemistry and physics. But I actually was more interested in aerospace at the time, and I actually went and became an aeronautics and astronautics major. And in fact, my Bachelor's degree is in aeronautics and astronautics, not in mechanical engineering. And I was in aero and astro, and That is really what I enjoyed. I had my first summer job, I had between my junior and senior year. I was just 18 at the time and I worked for Sikorsky aircraft in Stanford, Connecticut on their helicopters. And it was a very nice, interesting job. More data processing and things of that sort, but I got in experience of being able to wander around the plants where they were building the helicopters and got to ride in. I was not allowed to fly in a helicopter, but I was allowed to get into the helicopters while they were doing ground taxi tests and things like that. So they would run me around on the field, and while we were getting ready to take off, you have got to get out. But it was a good experience, a great experience. My senior year, I did a research project. We had to do Bachelor's thesis in those days. My senior year was my Bachelor's thesis, it was on hydrofoil boats, fully submerged hydrofoil boats, and I did tests in the towing tank at MIT, and also worked on control systems for controlling hydrofoils, and built an ultrasonic height sensor for looking at wave heights and allowed the foils to run at a fixed distance under the surface of the water. I had an interest in electronics at the time, too. I was a Ham radio operator. I got my Ham license in high school when I was about 13 and I had a little Ham radio station at home. I was not gung-ho Ham, but I did have this radio station, and so I knew about electronics, and got interested in control systems at the time. I was very much a hands-on guy, I was president of the model airplane club, if you want to know that. And in fact, it was not then just about building model airplanes, but we did do work on radio control and other control methods for model airplane. In the winter at MIT, you can not go outside, so we used to fly planes indoors in the armory there. And we even had worked on light controls where essentially you could flash a spotlight on the airplane, and then the photocell sensor would allow you to control the direction of the plane. let us see, for my work on my ultrasonic sensor and the hydrofoil stuff, I was always interested in tinkering and building things at MIT. I was active in the hobby shop and learned how to use machine tools. I did win, it is called the Louie de Flores Award. it is for outstanding ingenuity or whatever, I can not remember what the title is. And the $500 was a very significant amount at that time. It was essentially a semester's tuition, and it was one of the larger undergraduate awards that you could win, and so I felt that was a nice going away present from MIT. I graduated in 1963 after four years. I went to work for Boeing for a short term, for several months. And my faculty advisor at MIT actually guided me, his name was Holt Ashley. He was a professor of aeronautics and astronautics. he is not alive anymore, but he kept telling me, he said, Vic, he says, what do you want to do? I said, Well, I am not sure what I want to do. He says, You know what I want you to do? I want you to go work for Boeing for a while, and then go to Stanford. I said, Well, why? He said, Just trust me, just do that. So what I did, I was young, I was only 20. I was very lucky that I was young enough. And we had the draft at that time, military service in the Vietnam war was building up at the time. And all of my friends knew that they either had to stay in school or work in the aerospace defense industry to keep out of the draft essentially. And we had a test, you took the Selective Service test in those days, and if you got above a certain grade, you got so many years of graduate school deferment. And I got high enough grades that I had the graduate school deferment, if I was in grad school. But what I did was I took a year off from my studies. I went to Boeing, my faculty advisor, Ashley, had gave me a good letter of recommendation, and I sent it to the right people. And when I arrived at Boeing, I mean I was this young kid. They put me in an area called Mahogany Row, which is, in those days, they had bull pens where they had hundreds of engineers working in these big, open office areas. And around the edge were all the managers in their mahogany wood-paneled offices, and I was in the wood-paneled office area, looking out. And a couple of the people in the group there had added me to the Boeing employee chart, which is this sort of pyramid, and of course at the top was the president. And I come in there and I look at me, where am me, I am just this little name third from the top of Boeing. My boss reports directly to the president of Boeing. And he said to me, the first day, Well, Vic, here is what we are going to do with you. here is my card. You have a budget which pays you for whatever you want to do. Take this card with you and wander around anywhere in Boeing. I will give you some people to talk to. And if you like what you see, go work with them. And I was not there permanently, I spent about four months just going from group to group, working on projects that were interesting to me. And it did not cost the groups anything, because I had my own funding. It was sort of like your own funding and you could just go around, and it was very interesting. I worked on them, let us see, I worked on a lunar gravity simulator, which is a giant elevator, and did some analysis and studies on that. And in fact, got familiar with programming analog computers, where the programs were essentially done by adding resisters and compacitors and things like that in chains essentially to process or to do computations, analog. I worked on missile-carrying submarines, aspects of that. Mostly these are sort of advanced proposals. The group that I was in at the time was advanced ballistic missile systems, and I worked on some rockets. But I learned a lot, and I sort of saw what the aerospace was like. And after that, I decided I wanted to take a trip. So I took a trip, I took my backpack and I started out around the world, visiting MIT alumni in various countries. And my first country was, well, it was not MIT alumni, I ended up going down to Tahiti and New Zealand and Australia and Philippines and Thailand and Malaya. And I essentially spent most of the year doing that, visiting some alumni in various places, and seeing that they were doing in their countries, and getting appreciation for the breadth and width of engineering around the world. I was in India at the time and I got called up for my pre-induction. My draft status was 1A at the time, which meant that I was eligible for the draft, but I was too young. Unfortunately, they started lowering the draft age because they needed more recruits, and I was called up for my physical exam when I was in India, and I realized I had better come back to the United States soon and go to grad school. So I was out a year. I had been previously admitted to Stanford, but I had asked for a deferment for a year. And they had said, Well, we can not guarantee it, but chances are good you could come a year from now. And so what I did is I came back to Stanford and I started Stanford in the aeronautics and astronautics department. And rapidly realized that since they did not have an undergraduate program at Stanford, they had only a graduate program at Stanford in aeronautics and astronautics, I had a lot of the coursework already. And I really was interested in taking more courses in the mechanical engineering department. And so what I did is I asked Stanford if I could switch departments. And mechanical engineering said yes, you can join in any department, so I did that, so I moved into mechanical engineering. But I took a lot of courses in aeronautics and astronautics, and my Masters degree is an ME Masters, but I had a lot of fluid mechanics. In fact, they took propulsion courses, I was really interested in rocket and electric and nuclear propulsion in those days. And so I did a lot of course work in the aeronautics and astronautics, but got credit in mechanical engineering. I guess I missed a couple of summers, I had some summer job experience, I worked on the Apollo program, which was the moon mission. I spent two summers working on that, one when I was at Stanford. Again, so I was in aeronautics and astronautics, sort of in the summers, working on the Apollo program and building the Saturn rocket and also the lunar lander. One summer was in the theoretical aero thermal dynamics group, which was looking at the heat shield on the Apollo reentry module. And another one was in the Saturn rocket group, where I worked on turbo pumps for powering the rocket engines. Both were very interesting jobs, and again, I really got a sense of what the whole process is, not just the engineering, but the making of the system, in other words fabrication. And on lunch hours, I had spend my time wandering through the factories, the manufacturing areas, and just talking with the people. But the trip around the world convinced me that I really should be more in mechanical engineering, where I could do projects where an individual could make more of a difference. I always felt in aerospace that you are one sort of small tooth in the giant gears of industry. And after I got my Master's at Stanford, I got my Master's in one year at Stanford, I stayed on and started working on the engineer's degree. I really was not focused on the PhD at the time. And the engineer's degree is sort of a post-Master's degree at Stanford. And I got a research assistantship, working in the artificial intelligence lab, the AI lab at Stanford. I worked with Bernie Roth, he was associated with the lab at the time in the group that was sort of looking at hands and arms for the computer. And my work started to be into robotics at Stanford."
"Vic Scheinman","Interviewer","At that time, did they already have a mechanical arm and hand?"
"Vic Scheinman","Interviewee","Yeah, they had a mechanical arm, which they had bought, and in fact, some of the work that I did early on was maintaining that and keeping it running. It was called the Rancho arm, which they had obtained. It was a prosthetic arm that had been converted, from Rancho Los Amigos Hospital in Downey, California. And it was an electric arm, which was essentially made as a prosthetic arm for a person, originally controlled by tongue-operated switches, among other things. It did not really have any computer interface. And essentially what we did was, when I got there, they had started work on getting it interfaced with the computer, and much of that work on that arm was done. But it was not an arm that was easily. It had all sorts of problems, it was not very accurate. You could move it around, but as far as doing tasks of manipulation, it was very difficult to use that, even with the computer. And there was some other issues that we learned very early on. We learned about the importance of simplifying the arm solution, the computations required to deal with this arm, which did not have orthogonal axes and the kinematics configuration was not ideal for computer control, especially in those days when the math was not as well developed as now and the computation speed was slower. And so I was involved in working on some new robot designs. One was what is called the ORM project, which was like a little snake robot. I worked on it with another grad student, who was a little bit ahead of me, Larry Leifer, who is a professor at Stanford now. And this was a little snake-like arm. Essentially, the idea was that this was a digital arm to be controlled by a digital computer. And design involved a stack of plates, you can see that arm at the Computer History Museum in Mountain View, California, right here. I think it is on display now. I do not know if you guys have been there?"
"Vic Scheinman","Interviewer","I have seen the museum."
"Vic Scheinman","Interviewee","Yeah, right. it is a stack, it is only a stack about that high. And essentially what it was is a pneumatic arm. It had a bunch of plates, and these plates were controlled by essentially inflatable actuators, which could either be inflated, call it a one, or deflated, a zero. And there were four actuators between each set of plates. So imagine a stack of plates, with four actuators between it. And so imagine a four-bit word positions, although there was some amount of overlap there. But you could have a four-bit word theoretically defining the positions of each plate. And this arm, the goal was originally to make a big stack and maybe have it do things, and being controlled directly by the computer, direct digital control. It carried a little light bulb at the end, that was the target, that was the end effector, if you want to call it that, and a camera could look at that. The programming of that and description of that is written up in Don Piper's PhD thesis, Donald Piper. These were still all in the 1960s we are talking. And we rapidly learned that there were some problems with dealing with this arm. First of all, it was one where the path control was very difficult because in going from one state to another, there is an indeterminance condition as the actuators inflating and deflating. it is sort of like in electronics, when you have a digital component, there is a data ready line usually, which essentially says I have switched and now the data is valid. So there is an invalid state, and during the invalid state when it is switching from zero to one, the arm could flail around in random positions. Not only that, in binary words, the states of many of the bits have to change, to go from one number to the next increment. And of course, gray code coding is a way of coding words such that the state change is only one bit at a time. Unfortunately, in the real world, it is very hard to have what I would call a truly great coded arm, such that it has very discreet changes from one position to the next. And so we had problems in controlling the arm. Then, we said, Hey, computers are fast, let us build a fast arm. So I worked on what is called a hydraulic arm, there is a write-up on that, as well. And we spent a fair bit of time working on the hydraulic arm. The hydraulic arm is also at the Computer History Museum. That is not on display and they do not really have much documentation on it. But I found it while rummaging through their inventory and it was sort of stuffed into a barrel, and it might still be there. I should get over there and give them more documentation on it. This was a high-powered arm that was supposed to be very fast. We spent a couple of years working on that, and it ran at the AI lab. It was so powerful and had so much power to it that it would shake the building when it ran. And we ended up having to actually build steel structures into the floor to hold the thing up, because it was originally built on the computer floor. The mainframes had special floors for them, where you could pump cold air around, underneath the floor and then into the machines, which are generating a lot of heat. Any event, we used that, we learned a lot about that. It was a robot that ran in what is called space war mode, which is it needed real time computer control. And running it with a timeshare machine was very difficult, because a timeshare machine does not necessarily give you guaranteed real time, except if it runs in what we call space war mode, which is where it is dedicated to you. And That is because the servos were all dual-loops and the servo mechanisms were closed within the computer. The PDP-10 at those days, early on we were using a PDP-6, and then we went to a DEC PDP-10. And it was not compatible with the computer environment, because it had hydraulic oil, it had leaks, and the floor got sticky. We had to keep it in a separate room to keep people away from it. It needed this real-time full-time control to run it, but there were a number of problems with it. But it was an arm that could be controlled. Then, I was asked to design an arm that really could be used by the computer, and I designed an electric arm. And essentially, I was given sort of cart blanche to do something, and this arm here, the Stanford arm was the sort of product. And I did that as my engineer's degree thesis, just the design of the arm. I did not build it at the time, or I started to sort of build parts of it, but it really was not building it. And of course, it had the efaginal axes. I tried to incorporate various other features, which were interesting to me. I was a prismatic axis just so I could design that, and a revalu joint degrees of freedom. it is a six-degree or freedom arm, with a one-degree of freedom proportional hand, so it is a seven-degree of freedom robot, all electric. And it had brakes on the joints, such that we could run it in space war mode, but then you could turn it off and then the arm would sort of sit in a static position until you have finished your computations for the next move, and then it would go on. Whereas the hydraulic arm, if you turned off the computer, it would collapse. This one did not. And it sort of became a sort of a workhorse. I left Stanford at that time after my engineer's degree in 19, I do not know, 1969, I think it was. I left Stanford and went to work at a company called Raychem in Menlo Park in automation engineering. And at that company, I chose that company, actually I committed myself originally to go work for IBM at their research centers in Los Gatos, California. And I said, Well, look, I need several more months to finish my work at Sanford. When those few months were up, I called IBM and I said, I am ready to start. They said, Well, we have a complication. The fellow you were going to be working for is on sabbatical for the year, and so we are going to have you work with another person directly. I talked to that other person and I was not as excited about what his group was working on. And this opportunity to work locally without having to move at Raychem came up, and so I went to work there. And our job was to essentially design automatic machinery that would use Raychem products, which were essentially shrink plastic products, like shrink tubing. you are familiar with shrink plastic tubing, you heat it up and it shrinks? Well, they had a lot of products that were based on that, and they were the developers of this shrink tubing. it is a radiation cross-linked plastic product. And our job was to develop machines that would use Raychem products, which we would give or sell to companies so that they could incorporate Raychem products in their finished assemblies. And I essentially, since I had an electronics background as well, I did a lot of the controls for these machines, as well as the mechanical engineering designs. And I got to work with some very experienced engineers, learned a lot, spent a year there. Stanford asked me to come back after a few months and said, Hey, we want to build this Stanford arm. So I went back to Stanford and I started building that arm."
"Vic Scheinman","Interviewer","Who contacted you about that?"
"Vic Scheinman","Interviewee","Who contacted me? Well, at Stanford, I would say I had always been in contact with people at Stanford. I worked with John McCarthy, of course, was running the AI lab at the time and I was very close to him. Who contacted me at that time directly, I would say Lester Earnest. And you might have met Les, I do not know. He was sort of like the administrative director of the AI lab. McCarthy was the faculty director and he was the sort of faculty head of it. Les was the administrative head, and I guess Les might've done that. I remember at the time sort of discussing, Well, what is my title going to be, and a few other things. And I have kept close to him, he is retired now, of course he lives in Los Altos nearby. So I came to the AI lab and I started working as called an employed of the AI lab. I also went back and started taking some courses on the side. At that time, I thought, Well, maybe I should work on a doctorate. I was not that enthusiastic about it, but it seemed like a thing to do. And so, I started working on a PhD, in the sense of just taking some of the courses. And I built this arm, I also worked on other aspects at the AI lab. But the thing that happened is that, we got this arm working, the gold arm, the gold version of this, and then Stanford said, Well, we need a second arm, so I built the blue arm. There was a third arm that was started, but never finished, a red arm, because we decided we do not really need three arms. Other people got interested in these robot arms, because papers were starting to come out based on projects which Richard Paul, Lou Paul, have you talked to Lou Paul yet? Richard, you know the name? He lives in the Santa Cruz area, not far from here. "
"Vic Scheinman","Interviewer","he is in Fresno."
"Vic Scheinman","Interviewee","he is in Fresno now, well, he was in Santa Cruz and now he is in Fresno. So you are going to see him there?"
"Vic Scheinman","Interviewer","Yeah, we have been talking to him."
"Vic Scheinman","Interviewee","You have, okay."
"Vic Scheinman","Interviewer","Just on email, yeah."
"Vic Scheinman","Interviewee","Yeah, okay, all right. He insisted he is out of robotics, or at least maybe he is said that to you, right, okay. Anyhow, Lou wrote his book and sort of described the Stanford arm and the computations and the math and all of that. Other groups wanted that arm and so I made some kits. Again, I am trying to remember now, I am getting a little bit out of phase here maybe. But anyway, at some time around that time, I made an arm for SRI. SRI wanted an arm. This is the one for SRI. I did not actually physically build this arm, I did not have any way of building it outside of Stanford at the time. And so, SRI found a small company locally who had a machine shop and they built the arm physically. So I worked with them and gave them my drawings and all that, and they made the arm."
"Vic Scheinman","Interviewer","Who at SRI wanted the arm?"
"Vic Scheinman","Interviewee","It was in Charlie Rosen's group. This was Charles Rosen, the AI lab and Davad Nitsen . Neither of them are alive now, but it was the AI lab there. And at the time, Charles Rosen was the director of that. Also, JPL wanted an arm and so I worked with them. Again, they built the robot, I did a lot of the drawings, they did some of their drawings to adapt it, and they mounted it on a mobile vehicle for a lunar rover simulator. And there were a few other people who wanted some arms, and I made some kits. Boston University, actually, I can not remember at the time, so there was a time there also. This was in the early 1970s now, and in 1970, 1972, I think it was, Marvin Minsky at MIT said, Hey, you know, we want an arm, too. And he had had some money to do his own robot from DARPA, DARPA had given him some money. So I went to MIT, essentially Stanford loaned me to MIT, but I worked at MIT for a few months in the summer. I think it was in the summer of 1972, something like that. And Marvin said, What we want is we want an arm, and he had some specifications. It was sort of like a mini-robot. He said, Make the smallest robot you think you can make that can do some of these tasks, and he had written up this proposal, a multi-page proposal, which he showed me. And I have it somewhere in my files, but I can not remember where, which described tasks like doing remote surgical procedures, where essentially you would take this robot and you would put it into some clinic thousands of miles away and maybe have a nurse or somebody like that with the robot and a surgeon hooked up in the Unites States could run this robot arm. And it would be able to do some simple procedures and other tasks of that sort. That was his idea. And so, I sat down and I started designing another arm, and that was the little 260, well, it became the PUMA 260, but it was the one that you have on the dining room table there. The prototype actually was a little simpler. Well, That is the second batch. The first prototype, MIT got a couple of those. And I think I built three for MIT eventually. So I designed that arm at MIT, and essentially my whole process of design was not to design a part and build it. It was like I sat down and I spent several months designing every part of the robot, from beginning to end, all the calculations, all of the studies, all the detail drawings. And in those days, we did not have CAD, so I had either a drafting table or I would work at my desk on vellum and do all the machine drawings. And I sort of decided that was the smallest arm I could build that was practical, or at least that I felt that I wanted to build at that time, and would fit this task. And that was the configuration that I chose. He was not specific about what it had to look like or anything. And it incorporated a number of features that I wanted to try out. It was sort of like it was an opportunity for me to experiment with what I could do. It had a shell structure, which was like most robots in those days had sort of like solid beams and things of this sort. This had a shell, which was a thin sheet metal structure, lightweight shell. It had a number of other features in it. Backlash was an issue, it had some interesting ways of controlling backlash and it had a lot of other features that I felt were new to me. And it gave me an opportunity to design gear trains and work with frameless motors. In other words, I was not buying motors off the shelf anymore. I was actually buying components of motors and designing the motors themselves. "
"Vic Scheinman","Interviewer","So what was the problem with backlash?"
"Vic Scheinman","Interviewee","Well, it affected the positioning accuracy and the repeatability of the robots. And it limited the ability to do fine motion tasks. And in addition, it was not just that, but that was the main reason for backlash control in gear trains. But I did want to have a six-degree of freedom arm and a proportional end effector, if you want to call it that, an end effector that was not just pneumatic open and close. Although, if you notice on these arms, there are some pneumatics here, because for industrial applications, people want sometimes pneumatics, although the original one had proportional end effector. The other feature of the arm, the original arm, was that I knew that it was going to be used in a setting where vision was going to be involved at the time. And vision in those days was more binary vision, and the feature extraction capabilities of vision were somewhat limited. So I wanted simple features to look at in the arm, so the vision system could actually look at the robot and determine its position and orientation by just looking at it, rather than having this very complicated thing with the wires and cables and things dangling all around. I wanted everything inside, so that in the case of having a camera, look at the end effector at the robot itself. It would have a simple image, which could be processed quickly. In any event, I did that at MIT, I started designing that. I came back to Stanford, got cold, I said, Hey, I want to go back to Stanford. So I came back to Stanford and continued to work at Stanford. MIT says, Well, we want you to build these robots. And actually, while working at Stanford, I was able to build some of the robots on the side. And I actually realized that to build them for MIT, it was not practical to build them at Stanford, I had to do it on the outside. So I found some outside people to work on making parts, but I also bought a small machine shop. And I actually started a little office in Mountain View, California, and I called it Vicarm or Vicarm. I started saying Vicarm, but then people said, Why say Vicarm? We used to say Vicarm so that the would not associate it directly with my name. But I had a little machine shop and we set up electronics, I had everything there. After a while, I hired Brian Carlisle to work for me, and Bruce Shamano , both of them. Bruce was working on his doctorate at the time. By then, I sort of kept putting off the PhD more and more and more, and then eventually never finished it. And I had actually given a couple of papers based on my PhD at that time, but never handed in the thesis. Bruce was working on his doctorate, and one the side in the evenings, we would work on the software and the control. And are you going to talk to Bruce at all?"
"Vic Scheinman","Interviewer","We talked to him, yeah."
"Vic Scheinman","Interviewee","You did talk to Bruce, okay, all right. Well, he might have stories about working on the floor at my house in Palo Alto, in the days of paper tape and all these other things. But Bruce developed most of the software, and Brian's job was to help to make the robots and get them delivered. And I guess in the case of Bruce, he had been working at the AI lab. In the case of Brian, he was one of Bernie Roth's students, and Brian had no real experience in robotics, prior to coming to work for me, and so I sort of started him out, I guess, on the right track, because he kept going. All right, so much for Brian and Bruce at that time, but they worked for me. And then, we sort of grew. I got in these orders to make robots this size arm and the Stanford arm and the MIT arm for various people, mostly research organizations, General Motors, National Bureau of Standards, AT&T, some universities. Naval Research Labs bought a little MIT arm. I had a little brochure, I do not know if you have seen that, somewhere I have the Vicarm literature, and it shows the arms and describes them."
"Vic Scheinman","Interviewer","How much did they cost?"
"Vic Scheinman","Interviewee","Well, the very first arms that I sold, I started out at the very beginning just selling the robot with the software, and the customer had to supposedly had to build the computer interface, because it needed a mainframe computer. So I showed them how to do it with PDP-11 mainframe computers. And I think the very first one, it was $4000 for a little MIT arm, I had said something like that. But that rapidly went up, I started realizing what it really costs me to do these things. And once I had hired Brian and Bruce, and they were working full-time, Brian was full-time, I started realizing the costs involved and I had the little business there. It got to maybe 15,000 or something like that, I can not remember. I have the price list somewhere from years ago. And then I started offering the controller. When DEC came out with the LSI-11, which was essentially a PDP-11 mini computer on a one-board on one or two boards, I started designing controllers that would have that all incorporated. So not only did it have the micro processor, the processing capability on it, it had the software and everything, so I could deliver the whole software package. And That is when we started developing VAL. It had, let us see what else, and of course, I got carried away and we started having not only that, the micro controller could not do the servos, it was not fast enough to do the servoing in real time on its own. And so, we actually made software servos and we used these little 6502, it was an 8 bit microprocessor, single chip microprocessor, that was used in the first Apple 2 computers, not in the Macs, but prior to that, and a few other things. It was made by this company called MOS technology back in the 1970s, a one chip microprocessor. It was sort of like the Intel 8080 or Zilog Z80, but it was a 6502, and we used one processor to do the servoing for each joint. So the first arms in there, there was essentially eight microprocessors, one for each joint and one for the end effector, one for each of the six joints, one for the end effector, and then the LSI-11 for doing the trajectory and the path control and the arm solutions"
"Vic Scheinman","Interviewee","Okay. So I started making some arms. I made some robots. We made a bunch of these- of those over there. By that time General Motors had been playing with my Stanford arm and there were various people there at GM. I do not know if you talked to- if you talked to Steve Holland at all. Has he come up? he is "
"Vic Scheinman","Interviewer","He has come up."
"Vic Scheinman","Interviewee","His name's came- come up. "
"Vic Scheinman","Interviewer","Uh huh."
"Vic Scheinman","Interviewee","Steve Holland was maybe more recent. There are other people, Mitch Ward. There are a few others but I would say the closest person I have been to in more recent times I do not know what is Lothar Russell- Rossol. He was a name. GM had a- essentially a research group at GM research and they wanted to get into robotics too. Okay. Oh, I have to go back further. I forgot a big part of this whole thing. Can I jump back a few years?"
"Vic Scheinman","Interviewer","Of course."
"Vic Scheinman","Interviewee","All right. I have to give All right. In 1968 or something like that maybe or 1967, 1967, maybe 1966, I can not remember, there were a couple of guys. One was named Joe Engelberger and another one was named George Devol. George was an older man to me in those days I was in my twenties at the time who had a company called the Devol Research Company and he was interested in robots and robotics and so was- and he had funded this company called Unimation which he had been He had a number of patents and things which he had licensed to a guy named Joe Engelberger who had this company called Unimation, and George came wandering around. He wanted to give some money to somebody at Stanford as a fellowship to work in robotics and Stanford picked me so I had a fellowship for a year at Stanford which funded me for a year during which time I got to travel with George and with Joe to Unimation in Connecticut and around the country looking at early robot installations in factories and finding out what was available. Okay. Unimation was- had some of their robots out which were these hydraulic arms. Okay. There were some other robots out there. The Unimation robot was actually sort of somewhat of a digital arm. It had a rotating memory in it; it had digital memory, did not have semiconductor memory. It had actually a magnetic memory if you want to call it that. There was another arm called the Versatran by AMF Corporation and we saw a number of these in the factories and companies were using it and mostly in Detroit it was used, both of these arms for loading machines and unloading machines and material handling primarily. Also Unimation was starting to try and do some welding with it where they were lifting up heavy welding guns, spot welding guns. The—"
"Vic Scheinman","Interviewee","The AMF Versatran was an electric arm and- but it had an analog programmer- controller, essentially a whole series of potentiometers which you would set each joint angle with a potentiometer and then a stepper which would just physically step from one set of pots to the next set of pots to the next set of pots to the next set of pots. And it could go through maybe a dozen positions and that was it, which was sufficient to load a machine or unload a machine, but it was a good experience for me to sort of see that. There were other pneumatic arms that would just load- move in and out or left and right and things of that sort. There were a few other arms. Okay. So there was that. There were But I met Joe Engelberger at the time and I sort of saw the company, Unimation, in Connecticut and it was a good experience for me then and I sort of established sort of long-term contacts with those- with George and with Joe. I guess there is other things that I am forgetting. Oh, I started Vicarm and then in the very early days of Vicarm Once I got my little microcontroller running on this LSI/11 I had this box. it is smaller than that. it is about a third the size of That box is a bigger box 'cause it is running a bigger arm and it was a little more advanced; it had more features to it. I was able to take it places. I could take the whole arm with me, the whole robot, everywhere in an airplane, fly it with me, even carry it on board in those days 'cause the arm weighed 15 pounds, the controller and everything weighed maybe 25 pounds, and so for 40 pounds I could carry it with me and when I made a trip I had take it with me. I went to Engelberger and I showed him in Danbury, Connecticut. I plopped it down right on his desk. This was in the 1970s, maybe a number of years later, but I had these names so I plopped it down on his desk and I programmed it up and had it running, doing real time straight-line motion and all these things that his- he could only dream about with his big robots. They could not do that. And I took it to other places. I plopped it down on the desk of the head of Digital Equipment Corporation, same thing, and brought all his engineers in to watch it- to look at it running, and I also went to the very first robot show I guess it was. I brought it there but I did not have a booth and I guess people I had talked to you about that. I was a little bit I was not a mainstream guy. I had a full beard at the time and long hair and stuff like that and wandering around at GM in Detroit where everybody was very stuffy with their coats and ties was quite a shock to them. And so I came to the robot show and I had my little robot with me, the very first one. There were only seven or eight exhibitors there. This was at University of Illinois in I do not know when it was, early 1970s. "
"Vic Scheinman","Interviewer","In Champaign or Chicago?"
"Vic Scheinman","Interviewee","Yeah. It was in I think No, it was not Champaign. It was in Chicago but—"
"Vic Scheinman","Interviewer","What year?"
"Vic Scheinman","Interviewee","I can not remember."
"Vic Scheinman","Interviewee","Yeah. Right. Right. Right. Robots One I think it was called. Anyhow, and I had this robot and of course these- all the other companies had these big things they were showing and I had this little thing and I- they said, Well, that is a toy. You can not show it here. You can not have it in here so I took it out in the front steps and I had- got an extension cord and I was able to run the whole thing on extension cord and then people would come around. They were all crowding All the young people would be crowding around and in fact the people who were researchers and science- engineers and programmers all came and were interested in it because they realized that it was one- it was sort of one that had this programmability that nothing else- not- the others did not and it had the control and it had the real time processing. It was not just a step, step, step, step thing. It had a whole programming language, which was Bruce's- the VAL language. Joe Engelberger invited me to bring the robot in to his booth. It caused some controversy and I showed it in his booth but it sort of became- it got me into the show. People complained about it, saying, well, it was not part of it and all this, but anyhow it did that and it sort of was my first sort of experience at a robot show. In other years then I had just buy a booth. I bought a booth later on, all of it sort of funded- just personally funded. In this case, I did not have outside financing or anything like that. Okay. GM got a robot, a Stanford arm. They came to me and they said, You know, Vic, we really want to- we have this idea for a- an automation system. we have seen the Vicarm, the little one that looks like these, and what we want is we think we could- we would like to have a bigger version of that which would work on our assembly lines and be sort of like a human replacement, human moves, human speech, human space but we are worried about your ability to make these arms, build them and deliver them to us. So maybe you want to talk to other people and then they had some suggestions. Other people had talked to me about the same thing, Hey, Vic, think about joining with somebody else who can build it."
"Vic Scheinman","Interviewer","How many arms do you think you would built at that point "
"Vic Scheinman","Interviewee","Ten or fifteen and it was not— I was building it for research groups. I was not trying to market to factory floor applications. That is what it was. I built six of the I had the first prototypes of those Vicarms at six. I built six of those and I had maybe four or five or I do not know something like that of these things here. It was a small operation at the time and so I made a deal with the help of Charlie Rosen at SRI, said, Hey, talk to Joe Engelberger at Unimation and I did. I talked to Joe and we talked to GM and Joe of course knew people at GM and they had a working relationship because they were selling robots there, and I made a deal with Joe Engelberger at Unimation where essentially became the West Coast division of Unimation. I sold out to him. I had a royalty arrangement with him on the technology and I also said, Well, I still want to work on my doctorate at Stanford and so I had some arrangement on doing that although unfortunately I spent so much time at Unimation working on the West Coast division. I grew it and so Bruce and Brian Bruce was finishing his doctorate so he came on full time then. Brian was already full time with me and he moved over with me to Unimation. We essentially just changed the name on the door one day but eventually within a few months we moved to a bigger facility and started designing the- I started designing the bigger version of the two- of the robot for General Motors and that was our focus for a couple years to design and build that and a controller and prove things and upgrade it all. And so in Mountain View we had the West Coast division Unimation and we built the prototypes there. We even got in a big hydraulic arm in California and started hooking up the software to that to try and make that into a- and call it a real robot rather than just a stepping simple thing and started working on other technologies, other areas. I started on the direct drive concepts and things of that sort and I did that for a couple of years. I had an employment agreement with Unimation for a few years,maybe two years or so, during which time we delivered the bigger PUMA to General Motors and we started moving the manufacturing of the PUMAs, we- the design to Connecticut and they started building them in Connecticut. let us see. So anyhow, I did that. I guess at that time Unimation was- Bruce was working in Los Angeles. I moved him down to L.A. after his doctorate and he worked down at Consolidated Controls Corporation offices which were part of Unimation and Unimation was owned by- was a subsidiary of Consolidated Controls and Pullman Corporation in those days so Bruce worked down there and he is probably told you that and he worked in L.A. and in fact- and so I commuted down and I had meet with Bruce there. He had been working on his own originally and then he hired- we got a couple other people to work with him in that. Lou Paul got a couple of- Cliff Geschke and there was a few people who came and worked for him- with Bruce and then of course Brian was up here in Mountain View with me and I brought in some other people as well and we were up to maybe ten or so in Mountain View. I then When my employment contract was up and I decided I wanted to move on I had been- I had given the- I had the opportunity to get involved in a startup. Okay. And Unimation at the time I really just had- I did not have stock or anything of that sort. It was sort of owned by these other companies and I realized that maybe I should just try- look at these- this other opportunity and so I moved and got involved in starting up Automatix, all right, and with a fellow named Phil Villers and- but I wanted to stay in California. He was located in Massachusetts and this was sort of a venture capital-funded startup from day one. We wrote a business plan and I helped put him- I helped put the technical team. He had the business team together. Don Piper became VP engineering. Have you talked to him? You have not talked to him yet? Okay. All right. He lives here in California too now down the coast near Santa Barbara and Don came so I talked Don into leaving Continental CAD. He was in Chicago and joining in the startup group. I got Gordon VanderBrug, another He was at National Bureau of Standards essentially. He came on board and I helped sort of put the technical team and made the technical contacts and we started this company with venture funding from the beginning. There was not any sort of personal seed capital or anything. it is sort of like day one we got the money; We will just start doing this. I worked out of my house, not this house, another house down the street here—"
"Vic Scheinman","Interviewer","What was the idea "
"Vic Scheinman","Interviewee","All right. We were going to do everything. We were going to have sort of like turnkey robotic systems and what we were going to do was we were going to do three product lines, welding robots, assembly robots, and vision systems, and we were going to design and build the robots and vision systems and do the applications as well onto the factory floor, turnkey robotic automation and so we started out with the three separate product lines, the welding. We made agreements to buy welding- robots. We bought robots and we were going to do arc welding, not spot welding, which is continuous path motion control, and we were also going to do vision-based arc welding, which was seam welding using vision and sensors or I would say we- you call it vision but it was not just vision but there were sensors to adapt the weld paths to the real conditions, which were- which was a problem with seam welding and that is that the seams are not always identical in production. The material warps and bends and things like that or there is gaps changes, things of that sort, in other words make smart welding robots. In the assembly systems we were going to build assembly robots and we were going to do small part assembly and we had some contracts and business things like making keyboards, putting in keys and keyboards and things in those early days and a lot- other assembly tasks. And then in vision systems we were going to use We made a deal with SRI, which is in the public domain software, to use the SRI vision algorithms and I essentially was able to work with SRI and our first vision boxes were essentially we took a lot of the SRI vision software and a lot of their electronics that they had, which is- you did not just buy off the shelf boards. You had to design your own boards and logic and we built them- I built them right in my house essentially. Well, we contracted out various PC board fabs but essentially did a lot of the prototype stuff of starting to make an industrialized version of that- of their vision system and incorporate that into our vision product and SRI also had There was a spinoff from SRI, Machine Intelligence Corporation, which was trying to do the same thing- which was doing the same thing although they did not last very long. That was Charlie Rosen's thing on the side but they did not- they were not- I think they wanted to go after the research market more but we went after this other market. Okay. So we started doing that so we had the three product lines and we had customers that were buying our vision systems and eventually we moved all the manufacturing to Massachusetts. I was just doing some of the advanced development in California. I did the vision, brought the vision into Automatix, and then transferred it to Massachusetts and they were able to run with it and develop more vision algorithms but we were using essentially the feature extraction capabilities of SRI vision work, which was done under DARPA contracts, and so I had that access and I had been- had a long-term relationship with SRI and so I knew who to talk to and who to work with there. Okay. So we did that and that became one of the product lines. I also worked on assembly and I had some ideas on assembly which I wanted to work on in advanced development and that was the robot world, which was scaling robot tasks- the robots to the size of the tasks. If you were making- doing small part assembly, why not- why have a giant robot doing small part assembly, and the concepts involved As I said, robots work in a robot world and people work in a people world and that was to scale the whole world down to an environment that is conducive to robots whereas traditionally robots were working in people world. They had to have aisles. There were safety issues. Everywhere I went people were Oh, robot hitting a person, things of that sort. In this case here I was able to move the robots, make them really small so that I had robots that if you stuck your hand in there they were small enough that they would not hurt if they hit you, but even then you were not intended- just naturally you were looking in from the outside. The world was a separate world and the heights Why have an eight-foot-high or ten-foot-high ceiling when the robots are working on parts that are only a few inches high. You could have ceilings that are only that high. So I had also been familiar with some other technologies, in this case Sawyer motor technologies which had been used in some plotters and I worked a relationship with a company here in Silicon Valley, Xynetics, which does not exist anymore but it was a company that was making what is called Sawyer planar motors. And I incorporated their technology into this robot world system and we- I started developing that and there was also a multi-robot system, naturally multiple robots working in coordinated fashion, so I had multiple robots. You could put in two robots, three robots, four robots, six robots. It was more of a Cartesian-based system. It was not anthropomorphic in the sense of looking like an arm but the- it was not a gantry type of Cartesian robot. The gantries have some limitations on the number of robots you can put in, the number of arms you can- or manipulators you can have in a gantry system 'cause they start colliding. In this case you could put multiple robots in. It was based on the fact that vision is an integral part of the robotic system. The concept was as you- anything that came into the system could be presented in sort of not a precise manner. Vision would acquire that and determine its location and position and- its position and orientation accurately and you could do precision tasks on non precisely placed parts because you had the vision system that was inherently incorporated to the system and in fact it was a vision system with manipulation capability rather than a manipulator with vision capability. And That is of course because we- vision in those days and still today requires a lot more computation, or call it processing power if you want to call it that, than manipulation, and so I started building Robot World. My first customer was Well, I did it as a research- advanced development here in California, same thing. We grew out of my house. I started having I had a facility down in Redwood City near here down at the waterfront. We had a group of people there working on again the mechanic- the mechanisms, the electronics, the sensors and the software, the whole cross-section, a small development group, and again the goal was transfer the technology to Massachusetts. Our first We did deliver several systems out of California here. Eventually, it moved to Massachusetts, the first customer again General Motors, and they had some specific application in this case here, small part assembly. Most manufacturing Most assembly in car assembly is small part assembly. it is not the final assembly that you see that everybody knows. it is making those subassemblies that is where a large part of the assembly goes, the fuel pumps, the windshield wiper assemblies, the fuel injectors, the distributors, the- all the little parts that are part of the bigger assemblies, have to be assembled in some ways. And so we developed that for- we developed a We sold a Robot World to General Motors and then Hewlett-Packard bought a bunch of Robot Worlds for inkjet cartridge manufacture and it had this- because it had the vision built into it they were able to actually- at HP they actually were able to run these Robot Worlds from Silicon Valley here but they could be all over the world. Because of the high-level software and the communication capability they could see what was going on, they could diagnose the problems, and in fact it enabled them to- they developed their own communication interface if you want to call it that and control interface, which enabled them to run these Robot Worlds remotely. And of course the built- having the built-in vision they could also see what was going on too. This was precision vision and the robot had very good accuracy. It had it is sort of like micron capability from micron resolution and let us see. So at Automatix I had other roles there too. We worked on there is more I have more wrists and mechanical arm parts that developed here in California. I would develop them for Massachusetts and we built some assembly robots as well. let us see. That went on for quite a few years, California, and we sold- eventually Automatix grew. We grew to a company of something on the order of 350 to 400 people in- mostly in Massachusetts but we had offices in France and we had relationships and we were buying our robots' components with Some of the welding robots and some of the assembly robots were coming from other countries as well, Japan, Germany. We would build controllers We would buy the mechanisms in many of those cases and put our own controllers on it which were- had vision capability and they also had this real time sort of high-level control. We had our own operating system but we were spending a lot of time developing our own operating system, which was called RAIL, Robot Automatix Incorporated Language or something. We called it RAIL and at some point we decided we were spending so much effort developing this operating system; maybe we could find and our sort of computer. We were building our own circuit boards, everything maybe we could find some sort of commercial product and we actually did. We made a deal with Apple and what we did with Apple Apple agreed to sell us their processor and the Apple operating system. This was the old Apple, where it was based on the 65, the 6800, Motorola 6800. "
"Vic Scheinman","Interviewer","Pro Dos, was it ? "
"Vic Scheinman","Interviewee","It was operating system six, and five, and four, and three, the early Mac's, you know, Mac's. The Mac, we bought Mac. And essentially they started to try and sell us boards, but it was easier for them to sell us the whole computer as the price of the board, with the agreement that we would destroy everything else. So we would take these Mac 2-ci's or whatever it was. I can not remember what it was, pull the boards out of it, the processor board, which was a mother board, pull the mother board out, and then smash everything else up, you know, just have it destroyed, because that was the agreement. It was cheaper for them to do it that way. So we did that, and we used their operating system. It was embedded in our product for a while. let us see what else happened. So, and at some point, essentially we found that the problem with Automatix was that we were trying to we found that to expand further, we really needed to have people who were going to do system integration as well as us. We could not do all the applications on our own. And so we had this line of system integrators. Unfortunately, the system integrators generally felt that we were competing with them, because we were building all the systems. We were building the we were the supplier to them, and they were doing the applications, but we were also doing the applications. And so we had trouble expanding our system integration, our integrators, and that became a difficulty. And I would say that we started to realize that it was not practical for us to do the applications, and yet the integrators were not willing to come on board as much as we would like, because we sort of had too much control over them. And so after a number of years, we had built the company up to maybe selling a hundred million dollars, or so, of well, I would say, let us say we sold I can not remember what the numbers were, but let us say at some point we had sold fifty million dollars worth of robotics, but unfortunately it cost us a hundred million to do it. And we slowly divested some of our product lines. We sold off Welding. We sold off Assembly, if you want to call it that. We made some deals with Yaskawa, for instance. They bought Robot World, and they bought some of the assembly robots, and Welding, as well, a Japanese company. And we moved more towards Vision, because we felt that that was one where we had more control over it. It was potentially more profitable, and rather than the robotics end. There were too many we were always in the position where we were competing against the low bidders on the applications. And the low bidders, in general, were people who could not do the job anyhow, but they did not know that they could not do it. One of the big problems with robotics has been that in application engineering it seems so simple. And people say, Oh, I can do that. And the customers were not educated enough to realize that the people they would choose would not be able to do the job. it is not a matter of buying parts, and putting it together, and then delivering it. it is a matter of getting it all to work. That is the hard part, on the factory floor, in the actual real world case. And we were always competing against these low bidders, who were other system integrators, who were not part of Automatix, who would say, Hey, I can do that for less. And so it was hard to make a profit in many of those areas, and it still happens today. The cost of an application is, like, four to five times the cost of the robot. The robot's only, like, twenty or twenty-five percent of the typical application. And, in fact, the other problem is, is that we found that in each case, we would do an application thinking that there were additional follow on orders, but they were always less, because people would want to have changes each time. In other words, there was a lot of follow on applications work, which was involved. And the applications were not where we were making our money. We were making it in selling the robot, the basic robots and the systems. In the Vision systems area, we had much better margins. But even then, we found that even if we could make the Vision systems for free, for free, we had to charge ten or twenty thousand dollars for every Vision system that went out the door, just to do the support for the customers, because there was a lot of customer training involved. it is now gotten a lot easier. Now it is twenty, thirty years down the road, and you just buy a board and a camera, and you are off and you are running with some software. In those days, it was not the same. Anyhow, we eventually became a smaller company, sold off a lot of the technology, and the company essentially does not exist anymore, and closed, sold off the West Coast. The work that I was doing became part of Yaskawa. I went to work for Yaskawa as a consultant for a while, and we moved down to Mountain View, where they had a little office. And I worked on some robotic stuff for them, and incorporating the Robot World technology. And Yaskawa, of course, used that, built Robot Worlds, where it has that they go close to seven or eight hundred of them, of these Robot World systems. Lab Automation, a lot of biotech automation, uses Robot World's HP, bought a bunch of the company's for small part assembly, bought them. And if you want to talk to somebody about that, John Payne. I do not know if you have talked to John Payne, P A Y N E. he is at Yaskawa. He lives in the L.A. area, and he essentially he was at Automatix, and he became he moved over to Yaskawa, and he sort of ran the Robot World Division, but now he is doing other things, because Yaskawa, in the last couple of years, they stopped selling the Robot Worlds. They were very expensive systems, but they made them in L.A., in the L.A. area, out near Newport Beach area. I can not remember the town actually, but, yeah. But any event, Yaskawa, and he can talk to you about that. A number of Automatix employees went there. And I worked for Yaskawa for a few years doing that. And then I went to Stanford just on a volunteer basis initially, became a consulting professor there, spent maybe about ten, fifteen years there. I can not remember. And a couple of years ago, I sort of retired. And now I am doing well. I am meeting with I have a high school group that meets. it is a high school robotic's group. I do some consulting, not just in robotics, but in mechanical engineering, and have been working on some other projects. You saw the little mobile vehicle, those little scooter like things there. We sponsor the project at UC-Davis, a student project, to look at characterizing some if the motors and that, and we are sort of looking at some high tech handicap days, and just a number of various other little projects at the moment. I am an investor in, obviously, Unimation. As you know, the Unimation West Coast Division, when I left, Brian took over. He ran it for a while. Unimation sold out to Westinghouse Corporation, which was of course, it did not directly benefit any of us, because we did not have any stock in it. It was only a few guys back in Massachusetts, in Connecticut, and it was an opportunity for Bruce and Brian to spin off and start Adept, to sort of follow on the work We had done in the West Coast Division. And, of course, Adept grew, and I do not know. Have you have been to Adept at all? No. Okay. All right. Well, and they, of course, ran that for a number of years. And, of course, the same thing, you know, the ups and downs of the industry. Adept got into financial difficulties, unfortunately. I would say some people who did not have the same philosophy got involved, got onto the board of directors of Adept, and, you know, Bruce and Brian one day were shown the door, sadly. The company now has gone through some restructuring and, of course, I have still been a stockholder all along, from the beginning to now. And They are in the East Bay. And a very, maybe the largest, still the largest American robotics maker. And they founded Precise Automation. I am an investor in that. And let us see, what else? What else do you need to know? I probably skipped other things. I have given you a long story. I am trying to remember all this stuff. "
"Vic Scheinman","Interviewer","Yeah, yeah. So all these robots that you built, which ones to you think were the most important?"
"Vic Scheinman","Interviewee","Well, the most important one, I guess, became the PUMA Robots, the whole series, Programmable Universal. See, GM had this concept of Programmable Universal Machine for Assembly, all right. And in their case, they had sort of misguided ideas that the robots would be like people, and you could the robot was doing only a task that a person could do. And unfortunately, that is a little bit misguided, because, yeah, maybe the robot can do a task a person can do, but the robot can do many different tasks. And the philosophy for GM was, okay, you have got this seventeen inch, or twenty-four inch, width between workstations, so you have these people all along these assembly lines. They wrote some articles on that. The robot had to fit in this space a certain wide, do certain motions that a person would do. Parts are coming down the conveyor belt, you know. And if the robot broke down, you could put a person in there, and he could take over the job. Right? The line did not have to stop. You just unplug it. In fact, the first robot, you just pull him right out and put a person in there. They did not realize that the person, you would have to have people waiting for these robots to fail. Not only that, they would have to know all the tasks that all the robots were doing, because you never knew which robot was going to fail. Whereas, if you put another robot in there to do the job, would take a few seconds and you could reprogram it to do whatever task was required at that station. And so they started to realize that after they got these robots on line, and they never really made the machine for assembly that was using the PUMA robots, but we called it the PUMA Robot Program of Universal Manipulator for Assembly. But they bought a lot of them, and they used them in dedicated, in various applications. And, of course, a lot of other people bought them. I and we, I would say, were generally pretty open with the software, and the hooks to the robot. And as such it got a wide following in the research community, the university community, the research community, because people could interface to the robot. They could build their own controllers. I did a controller for Stanford a number of years ago, a few years ago, where it is interfaced to a PC. Okay? So get rid of the original controller, just interface it to a PC now, but you could interface it to because the interface was very well characterized, whereas most other industrial robots, it is hard to the companies do not want to talk about it. They do not share it as much. This became sort of more one where people wrote about it. People could learn to use it, and it became very popular among the research community, which is what I felt strongly about, that you want to share. So I am maybe most proud of that. "
"Vic Scheinman","Interviewer","Do you have any idea how many PUMAs were made?"
"Vic Scheinman","Interviewee","Several thousand. "
"Vic Scheinman","Interviewer","How long did the production go for?"
"Vic Scheinman","Interviewee","Well, the production still goes, if you want to call it indirectly. The company that makes what I would call the PUMA follow on, is Staubli, S T A U B L I. It bought the Westinghouse, the Unimation name, and the Westinghouse line of robots. And the robots there use the same, I would say, kinematic configuration. The innards have changed, because it is now thirty years, forty years later, since the 1970s, but they make a whole series of robots, very, very good quality robots. They, for a long while, actually used the Adept controllers in their robot. And they also kept the Unimation name for a while. Now I think they have moved away from that, but they make a whole series of robots, small ones starting about this size, and going up to giant ones, much bigger. And, of course, the PUMAs came in larger sizes, too. There were some big ones that were, you know, big ones, 700 series, sort of like, well, this is the 200 series. The others were the 600 series, 5 and 600 series, and then there was the 700, a bigger one. So Unimation had, you know, we made larger ones, too. "
"Vic Scheinman","Interviewer","Did you have any connection with when Unimation sold some of their line, I think, to Kawasaki? "
"Vic Scheinman","Interviewee","Yes. Well, well, no. Kawasaki was a partner. The PUMAs were made at, I believe, three places. We made them in the UK. We made them in the United States, and Kawasaki had a license agreement and made Unimates, made PUMAs, all right, Kawasaki Unimates. And they also did some of their own engineering, as well, but that relationship was actually pretty long term with Unimation. The Kawasaki became after I had left Unimation was when they started actually making the PUMA robots, but they had the relationship with them, because they made the hydraulic ones, as well, earlier on, in Japan, in the Kawasaki on that. "
"Vic Scheinman","Interviewer","So, you know, the fellowship when you were traveling around the field with Devol, George. Like, what were some of the other places you visited?"
"Vic Scheinman","Interviewee","Well, I will tell you. You know, the one I remember the most was we went to GM. Well, two things I remember. One is, first of all, George always liked to travel first class, so we always sat in the front of the plane. We went first class everywhere, which I liked. I was a little kid, you know, twenty-one, or something, at the time, you know. And so that was the thing I remember. The other thing was that we would always go into these places, and they had the robots. There was always some problem with the robots that he was going to show me. And one day I was there. We went to this plant. I think it was at Ford or GM, River Road in Detroit, and the robot we went in there, and he was going to show me this Unimate robot, Unimation robot. And we get to the plant, and we are going into the plant, and there is this huge stamping press, a big, sheet metal press, what it is, and the robot is supposed to put pieces of sheet metal in there. The press comes down and forms a hood, or something like that. Then it can take it out. And, of course, the advantage of having a robot is some of these parts are pretty big and heavy, and people have to do it otherwise, and the robot can do stuff That is sort of heavier and dirtier than people want to work with, and there is oil That is spraying around. Well, we get there, and the robot's not working, and the press is not working, and all these engineers around it. And what they show me is it is a robot. Something went wrong, and the robot stuck its hand in there, and the press came down and squashed the robot's hand. And I am looking at it, and they have this pile of stuff, which is you can imagine. it is like when you go to a car crushing, you know, they take the whole car and they squish it. Well, the robot's hand has been squished there, and there is sort of this pile of mooshed stuff, metal. You can see springs, and little pieces, and bearings in it, all smashed. The end of the robot has been smooshed in this press, and the press has been damaged. The dye has been scored because of the robot getting stuck in there. I still remember that image of the robot. And they do not know why it is done that, but, of course, they had this little action the night before. So that was one of the things I remembered. The big thing I remembered there was the spot welding. Again, in those days, the advantage of it was just I got to play with the spot welding guns. They are on cables, and They are counterbalanced from the ceiling, so that you are holding this gun, which might weigh a hundred or two hundred pounds. Some of the big ones did like that. it is sort of like holding a big, big machine. And there is the probes at the tip, and you are trying to position it, as the car comes by, to weld, to do spot welds. And although you are not necessarily having to lift the welding gun, because it is on this counterbalance That is holding it up, you have the inertia of the gun, so it is massive. And just moving it, displacing it, accelerating and decelerating, and bringing it to a stop without a lot of overshoot and oscillation, takes a lot of work and planning, and getting an accurate positioning at the tips to do the weld. And so that was an experience for me to see that the robot could actually hold this thing. And, oh yeah, it is big and beefy, but it is stronger and it is got the ability to apply more forces than a human does, and it can position these welding gun tips more accurately, and faster, so it could do more welds in a shorter period of time. And so it was a good experience for me to be able to see why you need, you know, why having a robot helps. In George Devol's case, we had a lot of meetings. He was interested in George had an interest in patents a lot. I did not. I felt that the way to I was not interested in making lots of money, and things of that sort. In fact, when I started Viacom, I did not have business. You know, I did not feel I needed to have business cards and a big name, and all that. I have learned differently since. But in any event, George was very strong on documentation, you know, and always being interested in what can we patent? Everything I looked at, he said, Look for patents. Look at this. Look at what you can do that we can create That is new and proprietary. And so we had a lot of discussions on that, and coders, you know, optical coders, and control methods, and stuff like that. Mostly it was just seeing the applications, but it was not just the robot applications. It was also processes that I got a good experience with. I remember looking at making car instruments, like the gas gages and stuff like that, everything from that to big presses. And just my opportunity to work on the assembly line and get a sense of what people were doing, and then how to convert that, how a robot might be able to do that, what I would say, with better quality control. And that was a big issue, and that is the repeatability, you know. Always used to be you do not want a car That is made last thing on Friday night or, you know, or Monday morning, when people are not showing up for work, and They are putting substitutes in, you know. And I learned that. So robots are not just for human replacements, I learned. They are really doing the work that humans can not really do well. "
"Vic Scheinman","Interviewer","Okay. we are almost out of time here, but any other people we should talk to?"
"Vic Scheinman","Interviewee","Well, I mean, there is millions of people you could talk to. you have talked to Joe Engelberger, have you? "
"Vic Scheinman","Interviewer","No. we are going to do that."
"Vic Scheinman","Interviewee","you are going to get Joe. Good. That will be good, you know. he is getting old, and it is very important to get to him soon. I have not talked to him. I was at his house maybe two, three years ago. Are you going to see him at his house? Try and go to his house if you can. All right? it is a museum. it is a nice thing. And do not feel guilty. I photographed all his plaques and everything around. I have just gone around with my camera, click, click, click, click, click, click, click."
"Vic Scheinman","Interviewer","We can get back to you, since you seem to have also a lot of, kind of, documentation on various things."
"Vic Scheinman","Interviewee","Yeah, yeah, right, right, yeah. For the PUMA robot, the first one, those documents, a lot, a number of my design calculations, I gave them all to the Smithsonian, or at least not all of it, but a number of files. And they hired some college student, who spent a summer as an internship. I think she was at University of Maryland, to work at the Smithsonian one summer, to sort of organize some of that. there is some errors in that. I have seen the report, the story, but there is errors in it, but I am not particular about that. Errors are errors. So go see Joe Engelberger. I would say That is that. You might want to see some people at GM."
"Vic Scheinman","Interviewer","Yeah. And we have Steve. "
"Vic Scheinman","Interviewee","Well, Steve Holland would be now, Steve Holland came to Stanford. He actually got his Master's at Stanford. GM sent him there for a year. he is a little later, but he would be a person to talk to, and he is at GM. I think most of the other guys might have left GM by now. The original guru there was Lothar Rossil, R O S S I L, Lothar. he is older, and he would be a guy to tell you sort of like the early days, and he sort of founded the AI group at GM. Steve Holland was a little bit different. He was more in manufacturing development, but he did some of the work with the GM versions. I mean, at Unimation, Joe would be the big person to talk to if you are going to talk to one. I mean, there is a bunch of other people, but I do not even know if They are alive anymore, you know. But get Joe, if you can. he is good. You know, then Marvin Minsky. Well, maybe, you know, John McCarthy, he is more of an AI guy. he is here at Stanford. I see him regularly, but he is failing right now. I mean, he can talk to you, not about robotics as much as just sort of AI history, and all of that, but you are in computer science. You have not talked to John, huh? "
"Vic Scheinman","Interviewer","No, not yet. "
"Vic Scheinman","Interviewee","Yeah, right. you will have to do that probably in his house. He got his little oxygen, and stuff like that. He has a walker. "
"Vic Scheinman","Interviewer","Right. We heard it was right now, so."
"Vic Scheinman","Interviewee","it is not yeah, right, right. Well, I mean, I meet with him. Actually I have gone over for lunch a couple of times recently. Maybe about two months ago I was at his house, just he, and I, and Lester, and this other person. You could talk to Lester, and he is not a roboticist, or anything like that, but he was in Los Altos, and he can tell you the early days of the AI lab."
"Vic Scheinman","Interviewer","That would be great."
"Vic Scheinman","Interviewee","And he can talk to you about some of those things. And he could say a lot about he can talk more in terms of what John's thinking. I mean, John was a guy who he dreamed of all sorts of things, and he was a little less flighty than Marvin Minsky was, but you should see if you can get him, Marvin. "
"Vic Scheinman","Interviewer","Yes. he is on our list. "
"Vic Scheinman","Interviewee","Yeah, right, right. They had different approaches in general. We were very deterministic type of approach here. In other words, all the motions of the robot were calculated, mathematically developed motions and motion capability. Well, Minsky did not think about that. He said, let us build something and figure out how to make it run. And he wasted a lot of money trying to build a lot of hardware that never really ran, because he could not figure out how to control it, you know. They got into adaptors, and neural networks, and stuff like that, and with limited success, whereas we early on at Stanford realized that we could, if we designed the robots right, we could control them to do this real time core transformation and motion control. I would say that was, I think, a key to."
"Vic Scheinman","Interviewer","So combining those kind of control."
"Vic Scheinman","Interviewee","Yeah. The planning."
"Vic Scheinman","Interviewer","The planning of it."
"Vic Scheinman","Interviewee","Yeah, right, right, right, right, right. And early on the problem with the planning was that it took a while. Now, of course, it can be done in real time, a lot of that type of motion planning, and That is what the PUMA, the little Viacom, this is sort of like one of the first ones to really do a lot of real time. There was another company that also did I can not say."
"Vijay Kumar","Interviewee","You want me to just go down this list or are you going to ask these questions?"
"Vijay Kumar","Interviewer","I can ask you questions. "
"Vijay Kumar","Interviewee","Okay."
"Vijay Kumar","Interviewer","So if we could first start with where you were born and some of your early educational experience that would be great."
"Vijay Kumar","Interviewee","Okay. Should I look at you or look at the camera?"
"Vijay Kumar","Interviewer","You can look at either one of us. You do not have to look at the camera, whatever you are comfortable with."
"Vijay Kumar","Interviewee","You guys are easy. Sorry. "
"Vijay Kumar","Interviewer","So where were you born and your early education."
"Vijay Kumar","Interviewee","Okay. So I was born in India in a town called Patna which is in Eastern India. And I spent most of my life in Central India and then in New Delhi and I went to school in Central India and then in New Delhi and then I"
"Vijay Kumar","Interviewer","The question that we usually finish with is could you give some advice to young people who are interested in robotics?"
"Vijay Kumar","Interviewee","How young are these people that you are"
"Vijay Kumar","Interviewer","It can be any age that you think. Of course now it is from K to whatever."
"Vijay Kumar","Interviewee","Well okay. So here is my so from the standpoint of education, I think I often call robotics the knautical [sp?] engineering discipline. And the reason is it is a) it is synthetic. Unlike many engineering disciplines where you analyze things, here the whole goal of robotics is to build things. And it forces you to learn the signs that you need to build these things. So if I was to restructure engineering programs, I would simply have the very first course be a robotics course and from that build engineering science courses that could help students build better robots. So this is sort of a top-down way of doing robotics. But getting off that soapbox, I would tell students that this is a good way to learn a wide variety of techniques that are used in engineering. Well today, robotics does not include biology as much as it could so bioengineering and biomedical engineering is not really a central part of robotics but That is just a question of time. I mean that will also creep in. Likewise, it may not include chemical engineering or material signs, but I think again it is a question of time. we are going to be looking for novel materials and so it is really the best way to learn about engineering. So if you are interested in creating anything in an engineering-type setting, building physical devices, robotics is the discipline to get interested in. I would also say it really has a truly transformational ability here or potential here. So if you look at so the U.S. is not yet doing this but if you look at, for example, Japan, Korea, Europe, many countries in Europe, in a handful if you were to single out a handful of technologies that They are sort of emphasizing, robotics is one of them. I think we are a little behind the curve, but I would tell people this is where the action is and this is where you need to be."
"Vijay Kumar","Interviewer","Why do you think the U.S. is behind the curve?"
"Vijay Kumar","Interviewee","I think we are a lot more careful about adopting new top-down initiatives. I think we are a lot more free spirited and I think That is good, That is why I think we attract the best talent. But if robotics were a social movement then I think everybody would buy into it in a heartbeat. But I just got off my soapbox but when I was on my soapbox I am preaching to you and you are not going to accept that, right? you have got to believe it. So I think today that kids are believing it. I mean you see we run the first legoly [sp?] competition out of Penn and I was the head of all judges. So I am looking at these third graders, these fourth graders, these fifth graders and They are trying to explain to me the basics of control as they see it in the robots and you know that we are connecting with them indirectly. So I think this is really the discipline to be in that sense and so I think it is a question of time before we buy into it at the level of Washington and below. And the new robotics 2.0 initiative hopefully will reinforce that. "
"Vijay Kumar","Interviewer","Thank you."
"Vijay Kumar","Interviewee","Did that help?"
"Vijay Kumar","Interviewer","Thank you so much. Yes, no That is great. "
"Vijay Kumar","Interviewee","Alright, I am sorry I did not"
"Vijay Kumar","Interviewer","It was not so painful right?"
"Vijay Kumar","Interviewee","No, but I had no idea what I had signed up to. I thought it was just a bunch of questions."
"Vijay Kumar","Interviewer","The other thing would be any people you would recommend that we interview that may not already be on our list."
"Vijay Kumar","Interviewee","Well her husband still lives here in Philly."
"Vijay Kumar","Interviewer","Okay. Also, any students you have had who have moved on to be professors."
"Vijay Kumar","Interviewee","Oh, I mean I have lots of students. How much time do we have? I have to say That is the one part of my job that I really enjoy which is working with doctoral students. When you we work hard at recruiting doctoral students and I just enjoy the process because you try to track the top people and their like uncut stones and all you have to do is home them like until the stones become gems. And so this is a part that I enjoy a lot. I have had close to, I think I would say 30 PhD students and a good fraction of them are in academia themselves and several post-docs too, I think close to maybe 20, again many of them are in academia. And the reason I single out the ones that are in academia actually I have not singled them out, but I mention that is because I think they I think I have transmitted my love for sort of supervising of the students to them and I think it is good that They are going on doing the same thing. So you asked who are so just most recently I had let us see, the last student to graduate was actually last week, Nurul Amin [sp?]who is she is still here. She is wrapping up her PhD student PhD thesis, sorry, and she is looking at academic positions, postdoctoral opportunities. The one before that, Mahmood Salman Sacar [sp?] is a postdoc at MIT. And then before that, Spring Berman, she is a postdoc at Harvard. I can go on and on. I can give you all kinds of names. "
"Vijay Kumar","Interviewer","What about the early ones from the 1980s?"
"Vijay Kumar","Interviewee","So my very first PhD student, Nathan Ulrich, was probably the smartest mechanical designer that I ever had, very creative guy. He ended up doing a postdoc at Woods Hole Oceanographic Institute and then he ended up establishing his own company called Technique. So he really wanted to create new robots, build new robots and I think he continues to do work on novel devices at this company. Actually, he and his brother started this company that manufactured high-end scooters. This is when when did scooters become a rage? Not yeah, the push scooters, thank you I was looking for so they produced what they called the Rolls Royce of scooters. So this was people like you and me. Actually, I have one at home. So really nice scooters made out of solid stuff, not this Made in China kind of production models. So they made those, they made electric bikes long before electric bikes were a big thing. Now, of course, you go to Shanghai and any snapshot you take will have seven or ten electric bikes in it. So he continues to do these kinds of things, creating novel products and bringing them to market. "
"Vijay Kumar","Interviewer","Where is that company?"
"Vijay Kumar","Interviewee","it is based in Boston, actually I do not exactly know where but he is in the Massachusetts area."
"Vijay Kumar","Interviewer","Some of your work, has it gone towards particular applications?"
"Vijay Kumar","Interviewee","Well, I mean when you do research obviously you want to be aware of applications and be guided by them but it is a little dangerous to be obsessed about applications so we try not to do that. I mean, ultimately, the work that you do even though it is an engineering thesis has to stand on its own, so no we do not particularly think about real applications. Although, I have to say most recently the project I am most excited about is one that is really motivated by applications. So I am sure you are all aware of the tragedy in Fukushima and it is ironic that the tragedy happened in Japan, a country which is known for its robotics work and yet there was very little that the experts could do. And there are many reasons for that. So one of the things we are really interested in doing is to bring aerial robots and apply them to this setting. And we also want to think about autonomy. So one of the difficulties in these kind of settings is you cannot peli-operate [sp?] these robots. you are not allowed to come close to the actual reactor building because of radiation dangers of radiation. Second, even if you come reasonably close, the communications link is greatly impaired because of electromagnetic radiation. So what that really means is you want a robot that goes autonomously, gathers data, comes back to you and reports. Well, it may not come back to you, chances are that robot is lost forever, but it has the data, gives you the data and then it dies. So we are trying to explore this paradigm in the setting of buildings in the Fukushima area. we are going to start with Sendai this summer, send our robots to some of these collapsed buildings. And so here is a project where we want to solve this problem, we want to attack this application area and we think there could be obvious benefits here. So we are doing that. But, in general, we try not to do things like this."
"Vijay Kumar","Interviewer","Do you work with any Japanese collaborators on that?"
"Vijay Kumar","Interviewee","Yes. So we have just started this collaboration. We have a pile of grant from NSF to go visit Tohoku University in Sendai and we are going to perform some preliminary experiments this summer. "
"Vijay Kumar","Interviewer","So besides your own work, we talked a little bit in the beginning about the GRASP lab and you have also directed the lab for an extended, so we were wondering if you could tell us a little bit about the development of the lab, what it was like when you got there. Why do not you mention a bit what it was like when you took over the directorship and how it is developed through the years. Robotics as a program at Pennsylvania."
"Vijay Kumar","Interviewee","Yeah, sure. I mean I think when Rhishna [sp?] was there, she really had the vision to set up the lab. She also acquired, some really good space for us and helped nurture the lab during its early years. But when she left, there was a big leadership vacuum and that was pretty challenging to sort of step in, and as I said, they were mostly computer scientists and I was a lone noncomputer scientist yet running a lab which really was part of the computer science department. I mean That is not to say that my colleagues made me feel welcomed but still it was a challenge. I think the one big change during my tenure as the director was to take the lab and to bring in more participation from other departments. We recruited some top notch electrical engineering professors. And so right now you look at the lab, whether you look at faculty or students or postdocs, it is roughly one-third mechanical engineering, one-third computer science, one-third electrical engineering. And really, that reflects the true nature of the discipline. So I would say that it shifted the overall research, if you looked at the lab, it moved more from the perception centric programs research programs that Rhishna [sp?] was more interested in and obviously she was the person in the world in that area to, I think, more broad-based programs which brought in control, coordination, communication, design and I think that was a big shift. "
"Vijay Kumar","Interviewer","How did you come to be the director?"
"Vijay Kumar","Interviewee","I do not know."
"Vijay Kumar","Interviewer","how does this happen."
"Vijay Kumar","Interviewee","Suddenly I think it may well have been that I mean I was pretty junior at that time but I was the next most senior person after Rhishna [sp?] and I guess it fell into my lap. "
"Vijay Kumar","Interviewer","Do you have any favorite stories from the lab or its development?"
"Vijay Kumar","Interviewee","You know, the one thing that I remember is that so from my really early days I remember that I used to come in on Sundays. Rhishna [sp?] was there on Sundays and all her students were there on Sunday. And they would all have their weekly meetings with her on Sunday. And if she was there they were all there. It was just amazing and I have never seen this culture elsewhere. That was the one thing that I could not sustain mostly because of me, once I had a family and so it is hard to do. But that did not happen so that was somewhat funny. The other thing that was actually she had this T-shirt, this sweatshirt which had the word results printed on the back and That is how she wanted I want results and she would turn her back and walk away to her students, that was funny. But those Yeah. And I still tell my students this so they say, Well I can take this time off? And I said, I do not care as long as you deliver the results. And That is what it should be about, right? "
"Vijay Kumar","Interviewer","How do you see the strengths and ams [sp?] of the robotics program in relative to some of the other robotics programs at MIT or Carnegie Mellon?"
"Vijay Kumar","Interviewee","So yeah I think there are many outstanding programs. I would say we are among the top five if not the top three. I think in terms of size, I think Carnegie Mellon is the big outlier, They are about, I would say, 10 times our size. But I think in terms of I think they have a culture of going after big projects, like Grant Challenge for example, while we probably do not. I think we pay a lot more we are probably a lot more academic in nature. I think we spend a lot more time thinking about doctoral education, not to say they do not, but I think That is one big difference. Mit is great. Much of Mit is program is anchored in the artificial intelligence laboratory. it is sort of computer science and artificial intelligence. So I think That is the difference. I think this is sort of unique in the sense that it is common space That is shared by three different departments. And to this day, you walk into the lab and you have no idea which space belongs to who and to what department. You walk into the lab you will see lots of students and I guarantee you will not be able to identify who is a mechanical engineer, who is an electric engineer, who is a computer scientist and I think That is very unique of Penn. we are also incredibly collaborative. I think it is I am really amazed by how students write papers together and often times the advisors do not even know that They are collaborating with other students and That is great. So I think that culture is part of who we are. "
"Vijay Kumar","Interviewer","How do you think robotics, just particularly the fields that you have been interested in, have changed through the years and what are some of the future challenges?"
"Vijay Kumar","Interviewee","let us see, if you look at cooperative robotics, I think one thing that has happened over the years so robotics, like many other sciences I think has been greatly influenced by technological advances. So I think the biggest technological advance obviously is processing, right? You know about Morris [sp?] law and all those things. I remember when I was a doctoral student and when we were implementing code we actually had to worry about the number of adds and multiplies in our code to make sure that we were not overloading the processor. Again, to put things in perspective, back then a program with 80 86 Intel Processors, if you do not know what that is you have to go back from a Pentium before that came a 486, 386, 286 and then an 86 so it was that long ago. And so now you do not have to worry about that. In some sense I think we are by the largest but in another sense I think it is allowed us to dream and do things that we would have thought to be completely infeasible back then. I think the other technological change that has happened is I think if you look at the price to performance ratio of sensors That is fallen dramatically. So we now have a lot more data than we could have hoped for. And, again, that has influenced how you think about problems. I think the third thing that I would say is that in going back we just did not have a critical mass of roboticists [sp?] creating robots. Now, it is relatively easy. If I want to make a particular robot with some sort of specification, unique specification, for a particular task it is not a big deal, I can do it. Or, if I am too lazy or if I do not want to spend my energy do it, I can go buy it. That was not the case before, right? So when you think about the work that we do here so for example, one of my most successful students, Nathan Michael who is now a research assistant professor here, he decided that he wanted to build his own robots and he took a combination of off-the-shelf parts and fabricated other parts and he built his own multirobot system. I mean not to take away from his creativity and his novel designs but this was much harder to do a while back. So I think these technological changes have influenced the way we think about problems and the problems we think about solving. "
"Vijay Kumar","Interviewer","So what are some of the new problems they can now think about solving ?"
"Vijay Kumar","Interviewee","Right, so for instance now we are thinking about deploying 10s of robots in a building in this engineering complex. So for instance, last year we so I told you about Nathan, he was involved in this too. We did an experiment where we had we told the robot to go not just into the next building but the building adjacent to that and to a corner of that building and to get there and tell us what was happening. And so this robot was able to recruit other robots that acted as relays and they set up their own wireless ad hoc network. And so I am sitting here and I could actually in principle observe what was going on in a corner of the town building. So you need lots of robots to do things like this. And, again, often times we do not attack these kinds of problems unless we know that these problems are doable in the real world. So that is an example of something we would not have attempted 10 years ago. "
"Vijay Kumar","Interviewer","What do you think are some of the coming challenges in robotics or some of the coming new problems?"
"Vijay Kumar","Interviewee","I think one huge change I think is our ability to really develop three-dimensional autonomous flying robots. The UAV industry is huge mostly because of these big drone aircrafts that fly at really high altitudes and do bad things that I do not care about. But I think and They are very expensive. But I think the time has sort of come that you can take those big objects and scale them down to really small objects and then make them completely autonomous. So if you do that, I think the third dimension adds so much to robotics and if you look at the number of aerial robot sections and conferences, it is exploding. I think so that is a big change in the next four to five years that We will see coming. "
"Vijay Kumar","Interviewer","What do you see is the social or societal role of robotics if any?"
"Vijay Kumar","Interviewee","You mean what role society has to play or the other way around?"
"Vijay Kumar","Interviewer","Both, if you could answer both that would be great."
"Vijay Kumar","Interviewee","So I think the one thing so you may or may not know about this but there is a new robotics initiative that we are helping push through Washington and we hope they will be funding for all kinds of new interesting projects both in academia and also in industry. So this is called robotics 2.0. So, as opposed to 1.0, 2.0 now acknowledges and emphasizes the role that humans play in a robotic society or the other way around, robots play in a human society. And so the increasing the realization is that no matter what the application you want humans and robotics to work together and I think that is going to you are going to see more and more of that. Already it happens in for example in the operating theatre where surgical robots are operated by surgeons and there is things happening together. I think it happens a little bit in factories where you have humans working next to robots and the kinds of missions that I was talking about. In Fukushima it is hard for humans to do it alone so they will need robots. On the other hand, robots will need to compliment humans and I think that that is going to you are going to see more and more of that. And right now the only robot we have in our homes are vacuum cleaner robots partially because of economics, partially because of what society is willing to accept. But I think you will see a lot more of these kinds of robots in homes and I think It will bridge the gap between humans and robots and I think you will see a lot more of robots everywhere. "