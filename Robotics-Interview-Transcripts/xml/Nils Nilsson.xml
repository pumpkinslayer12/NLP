<?xml version="1.0" encoding="UTF-8" ?>
<subject>
<name>Nils Nilsson</name>
<interview>
<interviewee>As a matter of fact, he served mainly his tour of duty at ARPA and he was an assistant to Larry Roberts who was the head of an ARPA office of information processing techniques office.  And it was Cordell Green who was assigned by Larry Roberts to look into whether or not it would be a good idea for ARPA to support research in speech understanding.  Turned out it was a good idea and they did.  And that's all mentioned in my book also.  So, then Green started a company that is still in existence as far as I know, what's the name of the company, it may come to me.  But, it's a company in Palo Alto that did work on software engineering.  </interviewee>
<interviewer>Cordell.</interviewer>
<interviewee>We had lots of students come from Stanford to SRI.  And I learned a lot from the students because my background, I didn't know what a compiler was.  I mean, I didn't have any background in computer science, and so these students would read stuff and tell me how to go learn it and I did.  </interviewee>
<interviewer>Did you have my much interaction with the people who were working on manipulation and grasping?</interviewer>
<interviewee>Well, I knew about Vic Scheinman, I knew about his arm that he developed and designed at Stanford.  But, I didn't personally have any interaction with him.  I wasn't so interested in arms at the time, Shakey didn't have arms.  Although we designed a system that we had proposed to ARPA that would have arms.  But, they ended up not funding it.  </interviewee>
<interviewer>When did you make that proposal?</interviewer>
<interviewee>Oh, I don't know, probably in the early seventies.  </interviewee>
<interviewer>And did you have much interaction with Bernie Roth?</interviewer>
<interviewee>I knew who he was, but no professional interaction.  I mean, we didn't work together on anything.  </interviewee>
<interviewer>Okay.  And then, at what point did your work ever come back to robotics?</interviewer>
<interviewee>Well, so I go over to Stanford and first thing is well, I had to learn about how you become a chairman.  The atmosphere was a good deal different than it was at SRI in a number of ways.  First of all, the people in the department don't actually work for you.  I think their idea is look, you're in charge.  We're passengers on your ship, we'll tell you where you want to go.  Your job is to keep the engine running and do all the things that you need to do.  And so, that was a bit of a change, but one that I didn't mind, had a lot of smart people at Stanford.  There were occasional things we had to solve problems as any manager does.  Sometimes there are things that happen on the tail of the distribution that you got to go deal with.  The other thing is whereas at SRI you could work at night if you wanted, but largely you'd get there in the morning and you might leave at six o'clock at night and that was the working day.  But, at Stanford really your work is never done.  People are emailing you, they got problems some of them in the middle of the night.  And they need things done plus the fact that there's this level above the department chair, the deanery, and deans have various demands.  I mean, they want a vision statement every now and again.  Where's the department going?  We have to have tenure cases.  So and so is up for tenure, you have to make sure we get all kinds of letters written.  And you have to present the case for this particular person's tenure in front of a committee.  We need your budget and oh, by the way we're going to have a special committee in the university to look into how we can better use computer science in civil engineering.  Would you be on that committee?  And so, there's all that kind of thing that happens more at a university, I think, than a place like SRI.  So, it was a lot of work and the first thing I discovered there was quite a bit of work.  But, it was all very exciting and challenging so I liked it.  I did get involved right away with a bunch of students and I had four or five of them, Ph.D. students.  One of the difficulties was that they all came in at the same time so in our little group we had weekly meetings.  They didn't have anybody, any kind of mentors, people who had gone on before them.  People they might work with, so they're all starting from scratch and that made it kind of difficult probably for them and for me, but they had some very good students.  One of whom, by the way, did end up at SRI.</interviewee>
<interviewer>Some of your Ph.D. students and one in particular.</interviewer>
<interviewee>Yeah.  One of them named Karen Myers went to SRI and played a leading role in the project at SRI called CALO which stands for cognitive assistant that learns and organizes.  It was a multimillion dollar project.  And it actually led to a start up company called Siri, S-I-R-I, Siri, which has an application, free app I think, you can get on your iPhone that will give you advice about where to go to dinner and making reservations for you, things like that.  </interviewee>
<interviewer>So, I mean, did you do any specifically robotic work after?</interviewer>
<interviewee>Well, let's see.  In terms of robots after finishing being chair I took a sabbatical and went to, had half a year at MIT and Harvard, some combination, and I was in Rod Brooks' lab and I would teach a class or two at Harvard once in a while, not a class, but I'd lecture for someone who was teaching a class.  And half a year at Santa Fe Institute in Santa Fe, New Mexico and during that time one reason I wanted to go to Rod Brooks' lab is I began to be interested again in these intermediate level style programs which were very robust.  And I was developing a formalism, a style of programming that I called teleo-reactive programs.  And these teleo-reactive programs, I called them teleo-reactive because first of all the teleo part was they had a purpose.  And the reactive part was how they worked toward that purpose depended upon their particular reaction to the current situation.  So, however they decided to achieve the goal depended upon where they were at the moment.  And if where they were at the moment suffered a setback as on their way to the goal something untoward would happen, well they would react to that and carry on.  So, I had some students at that time who were developing in software simulated robots which we called bots.  Well, I did have one student who actually programmed a little NOMAD robot using this teleo-reactive formalism.  Tom Willicke, yeah, I think his name was Tom Willicke.  And another student named Scott Benson who used this particular formalism to program simulated devices that would learn the effects of their actions.  So, he was able to develop a system that could learn to fly a simulated airplane, they have these flight simulating programs.  And so, his program could learn by watching and instructor how to take off and how to land.  And it would learn that by noticing all the conditions that preceded a particular instructor's action, all the readings and all the dials and everything, and the conditions afterwards and then it would deduce or adduce that that particular action that the instructor performed would, in fact, take the situation from the before to the after.  So, it would develop a whole set of these operators which were very much like the strips operators that I talked about earlier, the strips rules.  So, he was able to do that.  We never made a movie of it, but he wrote a dissertation and I think has had some impact. </interviewee>
<interviewer>That's Ben?</interviewer>
<interviewee>I wouldn't close that window again.  We won't tell Grace.  </interviewee>
<interviewer>And what year was the sabbatical?</interviewer>
<interviewee>You set, all your wires?  </interviewee>
<interviewer>It's just the headphones.</interviewer>
<interviewee>That was in 1990.  I went off in the fall, summer of 1990 and ended up in the summer of 1991.  And so, I had another student who programmed little tiny robots that would wander around on a screen, these were simulated robots, using teleo-reactive programs that would accomplish various tasks.  Another student who I'm still in touch with quite a bit was able to program some simulated soccer players using teleo-reactive programs.  So, soccer player, although might make a plan for doing something, the plans don't always develop the way you think they're going to because there are other players, other things happen.  And so, but you always got confronted with a certain situation and there's always some best thing to do in that situation.  And so, these particular teleo-reactive programs would try to do that.</interviewee>
<interviewer>Do you know if that strategy has ever been used for the Robo Cup competition?</interviewer>
<interviewee>Not that I know of.  However, I think that the idea of these kinds of reactive agents, I mean, I certainly wasn't the only one pursuing them.  As I mentioned Rod Brooks was doing similar things.  There was a man at JPL, Aaron Gat, G-A-T, who had some programming ideas that were quite similar.  There was a man named Firby, F-I-R-B-Y, at University of Illinois, I think, was he?  And I think he had something called reactive action packages.  </interviewee>
<interviewer>And would you say there's more similarity or more difference between say the subsumption approach of Brooks or some of these others to your own?  </interviewer>
<interviewee>Well, the subsumption architecture, I think, was quite a moving target.  I wasn't too sure exactly what it was.  It was anything Rod Brooks was thinking up at the time.  I think the main thing that motivated Rod Brooks was that you could use the real world itself instead of a model.  One didn't have to make models and work plans out in models.  Let the world store itself.  And so, most of his ideas on subsumption capitalized on that notion.  To a certain extent we did also with the teleo-reactive programs although you could also make plans stringing together these teleo-reactive programs and then proceed from there.  So, I think my idea was that yes, the world can store itself, but you people do use models.  You have to remember where you parked your car if you're going to let the world store itself you'll eventually find it, but you got to look at a lot of places.  </interviewee>
<interviewer>So you've used both statistical and logical methods, models and representations as well as reactive systems.  But these have often been very contentious debates within the AI community.  How do you see that?  </interviewer>
<interviewee>Well, I think it's kind of working itself out now.  I think that if one knows something for sure, I mean, statistical techniques, well, one way in which their used in these so called belief networks in which more or less you have propositions and propositions sometimes can be the cause of other propositions.  And each one might not be known with certainty, you have various probabilities.  And there are techniques for propagating probabilities throughout the network.  So, if you learn something new that affects the probabilities not only of the new thing you've learned, but all kinds of other things that might be related.  However, it is the case that sometimes you absolutely know pretty much with certainty or at least if it's 95 percent certainty you may as well take it as certain and then in that case, probably ordinary logical reasoning might be more appropriate say than trying to do things with probabilities.  After all, when you have the probabilities if you're going to do everything exactly with probabilities there's a good deal of computational burden that not having certainty adds.  But, if you do have certainty you ought to be able to capitalize on that extra knowledge.  So, I think that there's a role for both techniques.  </interviewee>
<interviewer>Looking back what would you say were the most challenging problems in pattern recognition and what were some of the biggest breakthroughs that you had? </interviewer>
<interviewee>Well, in pattern recognition one of the problems that was recognized from the very earliest days was separating the figure from ground.  So, if you're looking at something well even today in face recognition you have to be able to isolate what the face is first and where it is before you can decide to apply the various techniques that you might be able to apply to decide whose face it is.  So, picking out a face from a crowd, I think that's largely been pretty well solved.  I mean, everybody's personal computer if it has Picasa has a way to recognize various faces and isolate them.  Cameras have face isolating mechanisms in them.  But, I think it was thought to be a big problem in the past.  Otherwise, in pattern recognition I think it's still the case that we're not very good at dealing with cursive script.  Connected speech, well, there are various statistical techniques that do a pretty good job with it now.  You can buy commercial products but being able to deal with connected speech and connected writing was an intermediate term problem that I think has largely been solved.  You talk to people nowadays who are prone to use the various statistical methods and I think they say most of these problems that we thought were really difficult can be solved just by having lots and lots of data.  The more data you have the easier it is to solve it and so many of the natural language understanding systems and the, for example, translation programs basically use just lots and lots of examples to help them.  </interviewee>
<interviewer>And what do you see as the big problems in the near future for AI?</interviewer>
<interviewee>For AI?  For AI in general.  Well, dealing with common sense I think is still the big problem.  The expert systems are pretty good in their special domains.  You might say "Well, let's take a look at one of the milestones achievements."  There's been several milestone achievements in AI.  Chess playing was one, the autonomous car is another.  More recently I think the "Jeopardy" Watson, the Watson program of IBM that competed on "Jeopardy" is pretty much a milestone achievement.  However, I think even its designers will admit that when it came to dealing with common sense there were difficulties.  It could get around that for certain classes of questions it was asked.  The more circumscribed the question and the more likely it was that that question was explicitly in its huge database the better off it would be.  However, it made several mistakes and even though it won and I think that a lot of the mistakes would have been solved if it had a better, more encyclopedic, common sense knowledge.  There have been various attempts to try to solve that problem.  Doug Lenat at Cyc is one who thought that "Well, the way to deal with it is to hand code all the different elements of common sense you might ever need," the hundreds of millions of little bits of common sense information.  Well, good luck.  That's a never ending task because common sense changes and culture changes and so you're going to have to have something that can keep track of it and how do you keep track of it?  Well, the internet's a good source.  There's just an awful lot of stuff on the internet.  It's all in English.  So, you have a sort of a chicken and egg problem to recognize something in English you have to have common sense, but in order to have common sense you have to be able to recognize all the things that are there.  But, I think gradually we're making progress on that.  </interviewee>
<interviewer>And what about more specifically in the area of planning?  So, historically would have been the big problems that have been solved and then looking to the future what are the big problems ahead.</interviewer>
<interviewee>I think planning's pretty well under control now.  And I haven't been keeping track of that literature, frankly.  But, there are various programs that win so called ARPA planning contests.  And they put together plans that seem to be quite beyond what humans would ordinarily do.  Planning movement of supplies, doing things like per charts and for a long time I think the problem of dealing with plans which had a big aspect of time involved in them.  Certain things would take a certain amount of time, these things could be done in parallel, these other things couldn't be done, how do certain time dependent processes interact?  But, I think they've made a lot of progress in that although I haven't been keeping up with it.  </interviewee>
<interviewer>And in terms of so this project you did right after Shakey which was a sort of a coaching.  </interviewer>
<interviewee>Coaching, computer based consultant as we called it.</interviewee>
<interviewer>This was sort of a form of human robot interaction, do you see areas in which AI will advance the ability of robots to interact directly with people?</interviewer>
<interviewee>Well, there are a lot of people focusing on interaction between humans and robots particularly the social interaction amongst them.  I think some people are, Cynthia Brazil at MIT and some others, haven't kept up with that either.  But, yeah, I mean, humans are going to have to, well, we hope we don't put too much of the burden on humans, that they have to be specially trained to be able to interact with robots, but robots are going to have to understand humans and so, there's the need for, I believe, robots to have models of what humans believe, what humans' goals are, what it is people are trying to do.  And so, for a long time there was work on what the psychologists might call theories of mind.  How is it that one agent can understand what another agent believes and what another agent might conclude?  And there were special logics designed for dealing with that.  I'm not sure where that's going nowadays, but I think it's an important area for work.  And robots will have to have some idea of what it is that the people around them are wanting to do, what their goals are, how the robots can either get out of the way or help achieve those goals.  </interviewee>
<interviewer>And you mentioned before that a lot of the methods that are successful are the ones that need lots and lots of examples.  Do you think that's going to be a problem for robots that have to interact with the world, that some of their examples might be crashing into things and things like that?</interviewer>
<interviewee>Well, there's no reason why you can't give them lots of examples.  I mean, they don't have to in their life have experienced all those examples.  You can just put them in which you can't do with humans.  So, with humans you actually have to learn by living.  But, with robots you can put the life of previous robots right into them.  </interviewee>
<interviewer>So, in the case of Watson were there specific things you noticed in the kinds of errors that it made that made you sort of think about how it was structuring common sense? </interviewer>
<interviewee>I recorded all of that and I looked at it.  I've forgotten some of the questions that were asked.  Well, for example, on this Toronto thing.  Remember the example in which it was asked, well the clue was World War II aviators or naval battles for which airports were named.  And the answer would be Midway and Chicago and O'Hare.  And it mentioned something in Toronto, I think, even though it was supposed to be a US city.  And I think the people who designed it explained that well, oftentimes the category US city doesn't really mean exactly US city, it's sort of general.  And so, Watson didn't count that as heavily as it should have.  But, maybe it had some inaccurate common sense that allowed it to answer Toronto.  But, anyway it was a failure of some sort of common sense reasoning.  </interviewee>
<interviewer>And do you think the increased power of computing is going to really advance artificial intelligence and robotics at a much faster rate?</interviewer>
<interviewee>Well, if you had asked me that a few years ago I might have said "No," because I think that whatever the power of computing was at the time it was fully able to handle any of the ideas that we had at the time.  I mean, we were idea short, we weren't hardware short mainly.  Now, I'm not so sure because the new idea that's come up, the use of lots and lots of data, well, lots and lots of data requires lots and lots of computing.  And so, the more computing, the faster it can go the better.  I don't know that that's the bottleneck at the moment.  After all if you talk to the Watson people which I haven't, but if you did talk to them and you asked them "Gee, how could Watson have been better?  If you had a computer, this IBM 7000 series or whatever it was, if it were 10 times as fast, 100 times as fast, 100 times as much memory would you have done better?"  I think they'd still answer "Well, not necessarily.  We would need more ideas about how to program all that."</interviewee>
<interviewer>So, it's also about the structuring of the knowledge.  Do you think there's specific problems in AI that aren't going to be susceptible to large corpuses of data or that require new understandings?</interviewer>
<interviewee>Well, large corpuses of data are going to be useful in lots of them.  I don't know that it'll solve all the problems in AI.  I mean, right now we can't do all the things that humans can do.  Look around you and you can see.  I mean, we have office buildings full of people.  And many of them aren't using their hand eye coordination.  It isn't mechanical engineering which is a problem.  You might ask why are they there?  What are the doing?  Well, they're having meetings, they're filling out paperwork, they're doing studies, they're communicating with other humans, they're making plans.  And those are things, why can't computers do all that?  Why is there anybody in those buildings except the janitors and maybe a few top bosses?  Well, and computers would be cheap if we could do it, cheaper than those people.  And so, why are they there?  Well, because computers can't do it yet.  And will lots and lots of data solve that problem?  I don't think so.  Might help, might be part of the solution, but the reason we don't have what you might call human level intelligence yet is that we just don't have the ideas needed in order to write the programs that would allow us to achieve human level AI.  But, we have a lot of smart people and I think we're making some progress.  It will be a problem in the end, I think, for society what happens, what do we do with all the people that computers replace?  And eventually, I mean, right now you need more and more skills in order to have jobs.  But, there's this guy Robin Hansen, you know about Robin Hansen?  Robin Hansen is an economist and he has got this interesting metaphor of sea level rising.  Sea level is what computers can do.  And land and the land that's inhabited, the jobs that require humans to do.  And sea level's been rising.  And on the shore a lot of people are displaced.  Well, they've had to move to higher levels.  But, to move to higher levels they have to have more training.  Now, the fact that sea level's rising itself makes some higher levels.  It's a funny thing.  At sea level build some mountains so people can climb those mountains, but sea level will keep rising.  And the question is will it rise above even those mountains?  And so, what do we end up having people do?  Well, there's certain jobs that only people can do.  You can't have a machine make sweaters made by hand.  And there's kinds of things which involve social interaction which only people can do.  Some of the social interaction maybe machines can do.  But, if you really want a human you got to have a human.  And so, I'm not saying that all jobs will be replaced, but we're already seeing a trend of many and I think that trend will continue and you read people who talk about the current slow recovery, the economic situation, and many people say "Well, we've laid off a lot of people because of the recession, but in the meantime we've found out we could do some of those jobs that those people did with machines and by the way, we're not going to hire those people back."  And so, I think that's going to be a continuing difficulty.</interviewee>
<interviewer>What's your advice for young people who are interested in a career in robotics or AI?</interviewer>
<interviewee>Right now, I don't know, I think I'd try to get involved in the bridge between AI and neurophysiology.  Let's take neural science in particular because I think there's still a lot of secrets about how the brain works that we don't understand that'll be helpful in engineering.  The reason we don't understand them, I think, is we haven't invented the concepts needed to understand them.  I have this analogy with computers.  If you had a Martian coming down looking at computers, measuring all the currents flowing back and forth from the transistors, no amount of all that measuring, no amount of understanding how a transistor works is going to tell you how say an online banking system works or how an airline reservation system works.  You have to have concepts that got invented in computer science to even understand them.  You have to have concepts like lists, programs, data structures, compilers and there are probably a whole set of analogous concepts in helping us understand the brain.  So, yes it's important to understand how a neuron works and a lot of neurophysiologists might complain that models of the neurons that the AI people are cooking up aren't accurate enough.  Well, that might be, but no amount of detailed understanding of an individual neuron or even how neurons get interconnected I think will be sufficient to have a good explanation of how it is that we do what we do.  We have to have some higher level things and there are people working on that.  But, some of it, I think, will get developed by those very people who have one foot in artificial intelligence and one foot in neuroscience to say "Ah, the analogy to these high level programs is such and such to the way the brain does this."  And they will invent concepts that will then help us understand the brain better.  </interviewee>
<interviewer>Okay.  Is there anything you'd like to add?</interviewer>
<interviewee>I think you've got everything.  Well, I think of things after you leave.  </interviewee>
<interviewer>Oh, well, on the wiki page is said that Charlie Rosen started a winery.</interviewer>
<interviewee>Yes, he did.  Ridge Wines, do you know about Ridge Wines? </interviewee>
<interviewer>Yeah.  I bought a bottle on my trip, but I didn't drink it yet.</interviewer>
<interviewee>Uh-huh.  Good wines, I've been up there helping him pick grapes.</interviewee>
<interviewer>In Santa Cruz, yeah.  </interviewer>
<interviewee>Well, in Santa Cruz Mountains.  It's actually in the foothills behind Cupertino.</interviewee>
<interviewer>Okay.  </interviewer>
<interviewee>You can get to it, Ridge Winery, it probably has a website.  It was bought, I think, by a Japanese company, but I think they kept the same winemaker and he and three other people at SRI started that winery.  I think they've all passed away now.  Well, everybody has, Charlie did too.  </interviewee>
<interviewer>Yeah, I saw that.  Is Bertrand still around?</interviewer>
<interviewee>Ravel?</interviewee>
<interviewer>Yeah.</interviewer>
<interviewee>Yeah.  </interviewee>
<interviewer>Where?</interviewer>
<interviewee>I have his email address. </interviewee>
<interviewer>Oh, that would be great.  </interviewer>
<interviewee>Do you want it right now?</interviewee>
<interviewer>Yeah, sure.  </interviewer>
<interviewee>Can I take this off?</interviewee>
<interviewer>Yeah.  </interviewer>
<interviewee>We're done? </interviewee>
<interviewer>Yeah. </interviewer>
</interview>
</subject>
