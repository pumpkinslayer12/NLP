<?xml version="1.0" encoding="UTF-8" ?>
<subject>
<name>Raja Chatila</name>
<interview>
<interviewer>So, if we can start with your name and where you were born and when.</interviewer>
<interviewee>Okay.  So, my name is Raja Chatila.  I was born on January 29th, 1952 in Damascus, Syria.  And</interviewee>
<interviewer>And so then, where did you go to school?  How did you kind of get to college and decide where to go for college?</interviewer>
<interviewee>Yes.  So, I went to school in Damascus.  Actually I went to a school which was French and Arabic school; it was a school run by a French organization close to the French government, actually, in Syria, because Syria during the period between the World War I and II was under French mandate; so there was some relationship with France and, cultural relationships but, of course, at the time I was born Syria was independent.  So, I went to this school.  I, basically it was a school where you go to primary school and then through high school; it was the same place.  And I was always attracted by science and math and so on, so my math professor, actually, when I was 15, 16, who was a French guy, since I was one of the best students in the school, he offered me to obtain a grant from the French government to go for higher studies in France.  And well, of course, I accepted because that was a unique chance and therefore I left Syria when I was 17 after graduating from high school to go for higher studies.  So, in France, of course, the system is always more complex than is elsewhere.  We have a system which is called engineering schools or Grandes Ecoles, a higher-- which is living side-by-side with the universities; it's not within the universities.  And usually, I mean, the tradition in France is that people who are very good in mathematics and physics and so on, preferably go to those schools.  But entering those schools requires first to go to a special preparatory school during two years for, it's called higher mathematics and special mathematics, and then you have a competition.  Actually you take an exam, it's a competition, and according to your marks or the school to which you applied and if you succeeded you go to this during school; so, this is what I've done.  It wasn't the classical university, however, at the same time, I also took some math courses at the University of Paris.  It was in Paris; that school was called St. Louis School.  It's in the Latin Quarter in Paris.  Then I went to an engineering school in the city of Toulouse in the southwest of France; it's the National School of Civil Aviation.  So there I graduated three years later as an engineer in electronics specializing, of course, in electronics related to aviation more than general electronics but it was a general diploma anyway in electronics.  After that, I made an additional diploma, a kind of additional Master's Degree because the Engineering School is three years after the first two years in control science and my dream was always to do science research and not to go to industry that's-- I wanted to contribute to science.  And initially my hobby or my attraction was to astronomy and astrophysics although I went to an engineering school.  I mean, it's not necessary that you do engineering. If you go to those engineering schools in France you can do anything afterwards, even finance, for example, they are very, I would say, you have a general education and you can do almost anything.  Anyway, so after that I went to-- I applied for a grant at a research lab nearby in Toulouse for doing a Ph.D. in space science and astrophysics and that-- first you have also an additional Master's Degree to pass so this is where I started and then something happened.  Actually my advisor passed away, died, and the lab next door was LAAS, Laboratory for Systems Analysis and Architecture which had a different name at that time; it was more close to control science and I had met also someone who is George Giralt and therefore I decided to go and do my thesis on robotics in that lab.  So why robotics?  During my studies in the first Master's in control science I had also a training and a project on machine learning so I had already some knowledge about robotics and some interest about the mystery of studying artificial intelligence and so on.  So it was something that attracted me also but it wasn't as strong as my dream when I was young about astronomy and astrophysics.  However, fate decided that I do this anyway and so I started the thesis with George and that was in 1977.  So, George Giralt was-- actually he's an exceptional person, he was just back from the United States after a sabbatical at Berkeley and there he was completely captivated by robotics research that was going on in the Bay Area and specifically about studying mobile robots; mobile robots as opposed to fixed robots which are arms and, at that time, the main study and the main application of robotics arms was manufacturing.  Mobile robots, on the other side was a different issue; it was about making a machine move in its environment, discover its environment, et cetera, which was a really big question.  No one really knew how to do that.  So he wanted to start this project at LAAS and so it was a good coincidence because he didn't have a student to work on this project so he hired me to do that.  And hence, I was, it appears, I mean, a person doing research on science, not the scientific-- but how scientific research history, told me that according to his own research I'm the first to have got a Ph degree on mobile robotics in France and I got my Ph degree in 1981.  So, that project was called, in French, HILARE, which is the acronym of the robot on which I worked and basically the issue, the study, was about robot navigation.  How to make a robot, a machine, a physical machine move in its environment avoiding obstacles, discovering the obstacles which it didn't know about in the beginning, taking decisions to avoid them and going to a given location.  So that was my thesis subject which was called Robot Navigation Space Modeling and Decisional Processes; and of course, this, today, is quite common.  I mean, you see mobile robots moving all over the place but at that time no one knew how to do that.  So it was quite a challenge and one of the-- I'm happy to be one of the first to have started on this.</interviewee>
<interviewer>What were some of the problems you were working on, the part of making the robot move around?</interviewer>
<interviewee>Well, there were, I would say, different kinds of problems and it's important to say that since the beginning I had to consider them all; and this is very important in robotics to have this system approach, system view, because everything is interlinked.  So, to start with it was a real robot; it wasn't a simulation.  And, by the way, at that time, computer simulation was something not as easy today.  I mean, I'm speaking of times where microprocessors were just starting to be used.  We had mainframe computers.  So, it's not-- and we didn't have computers with an operating system that enabled you to have a good user interface, a mouse; all this didn't exist, okay.  So, to get back to the challenges, to the issues that I was working on, it was the first challenge, the first issue is that it was a real robot that I had to make move; it wasn't a point on a screen, which means you have all the difficulties of real experimentation and all the hassles of real experimentations and the problems that come from that.  The fact that the computing power wasn't so important as today so we had a system which was with very low computing power on the robot itself; it was the early Intel 8080 microprocessor and so since it was not possible to do all the computation on the robot it was radio linked through a very, very slow radio link, 9,600 baud; that's very slow.  And to a small mainframe computer which, itself wasn't sufficient neither, which was linked to a computer in a national computing center, which was in Paris.  So, I was in a lab in Toulouse and this big mainframe computer, which was an IBM 360, was shared with other people, of course, doing something else.  So you imagine that making experiments wasn't that easy and something that you decide on the spot.  So that's from a practical point of view, actually.  And also when I was building the robot, I wasn't by myself; there were other people working and some engineers and researchers to physically build that robot and integrate it.  And so, also there was the sensors that we were going to put on that robot.  At those early times, we were investigating the use of ultrasonic sensors, sonars, and those weren't just manufactured like that.  You can't buy them; you have to make them yourself.  So we made the sensors.  And we wanted to have vision on the robot.  So vision is a very, at that time, it was, of course, a very important issue and an open problem and another Ph.D. student came in to the lab also afterwards, maybe a year after me, to study vision on the robot.  In the meanwhile, because we are naïve and optimistic, we said well, maybe we will leave this guy, do his research on purely on vision and he'll be ready in three years and then vision will be solved.  But in the meanwhile we need to do experiments with other sensors so we also bought one of the first laser rangefinders, which of course, wasn't absolutely used for robotics.  It was used for topography, things like that.  It was just a point laser like the laser pointers you have.  So we mounted it a motor to scan the environment very slowly at that time also.  So, I mean, the experimentation was also to build the robot and the experimental conditions were not, of course, as easy as today.  So that's first set of situation where you had to do the physical mounting of the robot.  Again, I wasn't alone; that was one issue, the computer infrastructure, the program for communication and so on.  And then there was the scientific problem that I was addressing which was robot navigation.  So, question:  How do you represent space, objects in a robot environment?  And it was important to understand that for making the robot move, it was mostly important to present the free space so that the structure, the structure that the robot was going to use to compute its motion was the free space structure, which had to be derived, computed from its perception of the obstacle layout.  So, how to structure free space and it was one of the issues to understand that we needed geometrical representations and we needed topological representations which express the way space portions are connected.  So, one of my contributions was to find a way to decompose free space into regions, geometrical regions, and build a connectivity graph of those regions.  And there was, already at that time, I said we need also a third layer of presentation which was semantics, which was not just the shape of the areas, not just the way they are connected, but also something that designated them in terms of usefulness or dangerousness and so on or any other label, but that wasn't so much used at that time.  Basically we focused on geometry and topology.  And then the second question is okay, once you have this free space presentation and structure, how to move, how to compute the motions of the robot in this space?  And this is a motion planning problem which wasn't formulated at that time.  So, one of the problems was to express how you move an object in a spatial representation and other peoples were working on that, like Tomas Lozano-Perez at MIT, for example, which has written a very seminal paper in 1981; actually we were working on the same issues at the same time but I had dreaded it before that and I had also my own approach and representation of robot and so the issue was to reduce the complexity of this motion planning by correct representations of space and the robot.  So that was the second issue.  And, of course, it meant not just to devise theoretical models but also to implement this on the computer as a computer program and to make this run, of course, debugging the program and so on and so on with the tools that we had at that time and then make the real experiments and make the robot move.  So that's what it was about mostly.</interviewee>
<interviewer>What were some of the specifics of your approach compared to the approach other people were taking at the time?</interviewer>
<interviewee>Well, I think one important point was I wanted to represent space as much as possible close to reality.  So, for example, today it's well known, you can have different kinds of representations, you can have a grid, a regular grid, superimposed on the space and basically the space is digitized into this grid, which, of course, makes you make some approximations of the shape of obstacles and so on.  And if you want to have good approximations, reduce this cretization [ph?] induced by this grid you have to have a very fine grid which means a grid that has small cells which means a high complexity of computation which was completely to avoid at that time.  So, my approach was to say "Let's try to represent space in a way that is, as much as possible, without deforming the shape."  So, I came up with a model which relied on the geometry of objects and acquired by sensing and therefore free space was represented actually by polygons and I came up with an algorithm for decomposing free space into polygons; it was 2D.  Those polygons represented the exact free space shape and it wasn't a grid; it was an actual representation of free space and they were polygons so that those polygons were convex, and that's one other issue, so that in each cell, in each convex cell, the robot can move in a straight line from one frontier to the other and so on, from one cell to the other.  The polygonal shape was, in a way, an approximation, if you had, for example, some rounded parts of the environment but mostly at that time we were working indoors so you had walls, objects that are always, more or less, polygonal in shape.  So it wasn't so bad in terms of approximation.  However, the issue was to represent space as much as possible close to reality.  So that was one point in the spatial representation.  And the other point was right [ph?] to the motion planning issue itself.  So, there were several approaches already known about planning motions and the idea of representing the environment using those polygons was to extract a graph representation, which is the topological representation, and then to compute the motion of the robot using this graph; so, abstracting geometry into the topological structure and then doing a graph search.  And there were some techniques for doing the graph search like the A-star algorithm that was around since 1972 and the graph that I wrote, in a way, was something close to two techniques that were around.  One is called the visibility graph which is a graph that represents the shortest path in free space.  And the other, it's called Voronoi graph, which is a graph that represents, I would say, middle points, middle ways between obstacles so that the robot is not going to hit the obstacles.  So, my representation was closer to the visibility graph but I had to take into account, of course, that the robot had a shape which made it, of course, not go into the-- I mean, taking on the shape to prevent it to go into the obstacles.  So, the configuration space, as expressed by Tomas at that time, was the idea which was very important was to reduce robot shape into a point but making the obstacles larger by half of the robot.  So, I didn't take this orientation.  I made the computation in the geometrical space and not in the configuration space; so that was another difference.</interviewee>
<interviewer>And what were some of the studies that you did; experiments that you did with this robot in navigation?</interviewer>
<interviewee>So, of course, it wasn't enough just to come up with those methods, they had to work, actually, on the machine, right?  So, I made, and with colleagues at that time, so our experiments were making the robot move from one place to another.  We set up an experimental environment with wooden obstacles and so on that we made so that we can give them different shapes and that were light enough so that if the robot collided it wasn't broken.  But the robot was really in aluminum and steel and it was really difficult to break the robot.  And, indeed, I remember on one experiment there was a colleague working on a table and the robot-- well, we made a mistake and so the robot, at full speed, went and collided with the table on which that colleague was working and the robot was so strong that it moved the table and that guy was somewhat afraid.  Anyway, so we had to make real experiments and real experiments mean a lot of failures and what was interesting is to study the causes of failures.  Because when you have a failure in this context what you do, you get back to your programs.  You make some debugging and so on because maybe the failure is due to a bad computation or something and then you get back to experimentation and you find out that some failures don't disappear; so what's happening there?  You could go around those failures by approximating things, for example, because the robot was executing its path and after moving a few meters it started to go into the obstacles, to hit the obstacles instead of avoiding them.  So you could say well, let's make some approximation and artificially augment the size of the robot.  But you could also say hey, what's going on?  Why is it always doing this systematically?  So, asking this question is, I think, a sense of using a scientific method which means you had a kind of theory, your program, your system, your models that should have enabled the robot to go from one point to the other over the obstacles but it wasn't doing that.  So, which means your-- something was wrong.  Something wasn't taken into account in the model.  So, it was a kind of discovery, but that was after my thesis so I'm kind of jumping in time but I'll get back to what I did after the thesis.  So it was that question that led to the discovery of a phenomenon which was that there are-- in [ph?] the robot phenomenon, simple, I mean, today, when you think of it, it's quite simple, but, of course, when the robot moves, well, it's a machine moving; it has wheels; it's moving on floor.  Therefore, there is some slippage.  When we compute the path, when the robot computes the path that it's going to follow, there are some parameters to take into account like the wheel diameter, the distance between the wheels and so on; all those parameters are uncertain but, at that time, in the competition, they were considered as being exact.  We didn't consider that moving was also generating uncertainties on robot position.  So we had to think over and say well, there are problems that you cannot go around with, that you have to really cope with; it's the fact that the robot is generating uncertainties while it moves.  And, by the way, how did we get obstacle positions?  We got them by perceptions by using this laser rangefinder.  But the laser rangefinder provides measurements which means they are also uncertain.  We considered that those measurements were exact, in the beginning.  So, necessarily, we have to take into account, to consider that we have uncertainties on robot motion, we have uncertainties on perception and this should be treated as a problem, okay; that was in 1984.  So, in the meanwhile, after I've got my Ph.D. in which those issues were not considered, so we had made successful experiments and so on but in seeing those issues without really considering them as important.  But then after my Ph.D. I went to Stanford University for a postdoc; so I stayed there for a year with Tom Binford at Stanford at Stanford AI lab and working on a project-- Tom Binford wanted also, at that time, to have a mobile robot at Stanford University.  So there was a precursor a few years ago, earlier, with Hans Moravec who had worked on stereo vision at Stanford University and, at that time, Hans has moved to Carnegie Mellon and Tom Binford wanted to start a project with a new robot in a project with the company is now Adept but at that time it was Unimation.  And so Brian Carlisle was heading, at that time, the company and they built a robot which was omni directional; it was able to move in any direction.  It has special wheels, called the Swedish wheels that enable it to do that.  So, basically, during my postdoc, my job was to procure this robot from Unimation and to set it up and to implement my thesis results on it.  So that's what I started to do, what I have done, during my postdoc at Stanford University.  And then I came back to France in 1983 and I had a position at CNRS, which is the French National Center for Scientific Research, as a researcher and I continued my work as a researcher at LAAS, the same lab where I had graduated with-- in the group that George Giralt was heading.  </interviewee>
<interviewer>When did you get to Stanford?</interviewer>
<interviewee>So, I was in Stanford, basically, in the year '82</interviewee>
<interviewer>Through '84.</interviewer>
<interviewee>No, to '83.  </interviewee>
<interviewer>Oh it was one year, okay.</interviewer>
<interviewee>Yes.</interviewee>
<interviewer>And who was there at the time?  Who do you meet or work with</interviewer>
<interviewee>So, basically, the professor, the leading professor was Tom Binford but there was also there Oussama Khatib, so I'll back to Oussama because we had met before.  Oussama Khatib, there was Harlan Baker, for example, were in this group at-- there was John Craig; there was Ken Salisbury; so very nice people and very competent people; that was a great experience for me to do this postdoc stay at Stanford and the whole scientific environment of the university, of course, unique.  You meet people like also Bernie Roth; so I wasn't working with him but, of course, Bernie is also a unique character in the robotics community and this is where I met him first.  And the environment around Stanford University and the Bay Area, there was SRI.  At SRI I've met people like Nils Nilsson.  So, Nils Nilsson was, for me, a kind of a reference because was the father of Shakey and Shakey, the first paper on a mobile robot, was published in 1969 and was a reference for me during my thesis.  I mean, that was really a marvelous project because first it was really a pioneering project and it, since the beginning, they had the insight and the understanding to consider all issues from higher planning decision making to execution, system architecture and so on.  I'll get back to system architecture as well.  But so that was really a reference because the seminal paper really identified all the issues and solved them in a way, of course, that was enabled by the technology of that time.  But many, many important ideas were invented during Shakey:  strips [ph?], the planner, A-star, the use of visibility graphs for guiding motion.  So it was really a great project.  So, also meeting these people, you know, it's like-- it was really wonderful.  And also I met people at Berkeley.  There had been a mobile robot project also at Berkeley which inspired George but after that they, Berkeley didn't really develop that so people at Berkeley were more AI and control people.  And Lot [ph?] Freezad [ph?] was at Berkeley also at that time.  So, names.</interviewee>
<interviewer>And then you went back to CNRS as a researcher?</interviewer>
<interviewee>That's right.  So that was 1983.  So then I, in a way, I continued to work on the issue of robot navigation and really considering those problems that I didn't completely address during my thesis, now, those issues about uncertainties.  And another issue was about going further in representing the environment.  As I said, there was the geometry, the topology, but semantics; semantics in terms of this is a room, this is a corridor, this is a door and this is-- how to extract those information, how to discover the structure of the environment in terms of its semantics of its structure with those labels from the basic geometrical structure.  So, as I said, I had a basic geometric structure which was the cell and the graph and in work with Jean-Paul Lamont, and John-Paul Lamont had joined the lab at that time, and his thesis was to use those representations to try to organize the graph and from the graph extract the semantic information; so he was working on that, that was his thesis, and I was working with him also on that; so, several topics.  And then, as I said, there was this issue of uncertainties which was important and there was also another issue about architecture.  So, I'll get back to uncertainties but architecture is basically the question of the organization of the robot system.  Since we have programs doing perception, programs doing space modeling, programs doing motion planning, programs doing motion execution; all those programs had to communicate with each other in a timely fashion so that when we issue the command to the robot to go someplace it actually does all those computation and goes there.  And we wanted to add also something which is beyond just using a plan to move; it's also detecting new obstacles like people moving and avoiding them and continuing to reach the final destination.  So there was also an issue about using obstacle avoidance algorithm that we came up with and there were other work on this issue also, of course, by other people and so to take into account also realtime situations like detecting obstacles, avoiding them and so on.  So this made us think about how to organize robot control system so that it can cope with those situation of being at the same time able to plan, execute motion and, at the same time, to take into account unpredicted events, realtime constraints and do that.  So, and this control  issue was also not so much addressed at that time and was one of the directions that I was working on.  There was also another colleague working on that as part of his thesis but I was very much in this; so, different directions.  </interviewee>
<interviewer>Who was the colleague?</interviewer>
<interviewee>His name is Mark Vissett [ph?]; he became a research engineer at LAAS afterwards.  So, those different directions were actually investigated at the same time and to get back to the issue of uncertainties, when we considered that it was a problem that we should really address and cope with, then we started to do some theoretically modeling of that and we understood some thing which was really tricky; it's that we needed to build a map of the environment, that was what the robot was doing to move and we needed, at the same time, to build this map incrementally as the robot moves in its environment.  To be able to build this map incrementally, we needed to put together different views.  And how do you put together those different views?  You need to anchor them in some location, which was the robot observation location, and to connect those different views.  Connecting those different views was using different robot positions but different robot positions were themselves, uncertain.  And the way the robot localizes itself, it's by using its own motion; it's autometry, measuring displacement; and this, as I said, generates uncertainties.  So, the only way for the robot to really localize itself and correct those uncertainties related to its motion was by observing its environment, okay.  But that means that it was correcting its position using the map that it was building.  And, as I said, to build this map it needed the different positions to put the map pieces, the different views, together; so, mapping, putting those views together, and localization, which is correcting robot position using the map itself, were two problems that were linked.  It wasn't formulated this way in 1984-'85; it was more formulated as how to map the environment in the most exact way, taking into account uncertainties, but by asking the question how to map the environment in the most exact way considering those uncertainties, you discover that you had a chicken and egg problem with correcting robot position using the environment and using robot position to build the map of the environment.  This is how SLAM came up.  As I said, at that time, it wasn't called SLAM and one of the first papers about SLAM, again, with a different name and it was more space modeling, uncertain space modeling and so on, was a paper I had written with John-Paul Lamont in 1985.  We had done this research in 1984 already but it was presented at Ecoles [ph?] in 1985 in St. Louis and that was one of the first paper actually dealing with SLAM without using the word SLAM.  I'm getting into many things because there are a lot of connections.  I wanted to say something also; when I was in the United States, actually on my way to Stanford I stopped by Boston and MIT and this is where I met people like Tomas Lozano-Perez, whom I knew before because he came also to Toulouse before that, so I met him for the first time in Boston but we met before but it was also very important for me to see him again, and Rodney Brooks.  Rodney Brooks, who has just finished, just finished his thesis at Stanford, moved from Stanford.  And at that time he was at MIT.  I think in the meanwhile he went to  for some period but at that time he was at MIT.  And so, with Rod Brooks, it was, in my view at least, a very, how would I say it, world [ph?] contact.  I mean, I felt really as like I've met a friend.  So Rod is someone I cherish very much; he's really also an exceptional-- I suppose you had an interview with him or you are going to have one?  </interviewee>
<interviewer>We're going to.</interviewer>
<interviewee>So, he's an exceptional person.  But at that time he was working on also similar issues; motion-- I'm assuming about '82 on motion plan-- applying actually his thesis work, which was about using generalized [ph?] cylinders for object recognition plans basically, on motion planning using.  So we went into some discussions and I've met Rod many, many times afterwards, of course, and the interesting thing that if he was doing work in similar things at the same time, so he also, in the 1984-'85 was working on uncertainties and he wrote a paper also on this issue of modeling space using uncertainty  taking on uncertainties.  So it was very interesting and Rod came to Toulouse also.  At that time we had a conference and Rod, afterwards, worked also on robot control architecture and he came up with the well known subsumption architecture.  At the same time, I was working on a different approach, which wasn't subsumption because I didn't believe in that, and for robot architecture based on sort of layers including planning and realtime control and so on.  But he put planning away.  So, yeah, that was-- I mean, those years, '83, '84, '85, '86 were very rich years where several people were working in different directions with-- in a way, I'm going to make the comparison but it's not, of course, it's just a comparison, on those times, robotics research in this area, I mean mobile robots and so on, made us look to different problems; so, each individual working in mobile robotics.  So taking example of Rodney Brooks, myself, other people was interesting moving to motion planning and to space representations and to robot architecture, how to organize the system and so on.  Nowadays, people are much more specialized.  You have the SLAM guy.  You have the motion planning guy.  You have the uncertainty, processing  guy and so on.  So, the comparison is with the Renaissance as compared to today's scientists.  You know, of course, science has advanced very much and it's difficult to be competent in all domains but when it started people were competent in all domains.  And so, I think, this culture of having a systems view and looking to all aspects is very important to understand that everything is connected.  You cannot solve a perception problem on a robot without considering that this perception is not made by just for itself; it's made to be used; it's made for motion, for action.  So there is a connection between perception and action and this connection has to be at the core of the way you process the sensor data.  It put constraints on sensory data and the action is the connection between the robot and its environment.  So you have to also take into account at the same time the continuum perception, action, and the interaction with the environment and, of course, this puts constraints on the decision making processes which have to be able to cope with realtime constraints, unexpected events but, at the same time, enable the robot to take decisions at the long term, to anticipate and so on.  So, if you don't have this, you miss the global picture and therefore, the solutions that you are going to come up with won't be the right ones; they won't give you the possibility, really, to have an integrated systems working together.  </interviewee>
<interviewer>At some point you also became interested in learning, right?  </interviewer>
<interviewee>Yes.</interviewee>
<interviewer>More deeply in learning.</interviewer>
<interviewee>Well, yes, actually this is interesting because I started with a project before my thesis; it was during, as I said, my Master's in control.  I had a project in machine learning; it wasn't robot learning, it was on machine learning, so I've worked somewhat on that.  And then this was just a kind of problem, still open problem that I didn't address for some time.  Then it was addressed again when I worked with John-Paul Lamont on his thesis about learning environment structures, but that was a different kind of learning.  It was actually structuring the data that the robot had already or the representations that it had.  It was more a way of extracting information from data structures but I didn't get back to learning in terms of-- so that's where it was in the '80s also.  I didn't get back to learning, as such, until many years later in, actually in the years 2002 with different work which was more related to trying to learn almost from scratch the sensory, motor representations that are related to representing objects and actions.  So the idea-- so we are jumping a long period here.  We are jumping a long period.  In those years, I had a student who was very, very excited about that; William Pakee [ph?], actually he's in San Francisco now; he has a small company in San Francisco; so he was very much excited about the issue of learning representations from scratch.  What does this mean?  It means that the robot initially has very, very little knowledge about everything; about its environment, about itself; it has just simple processings.  For example, in an image, it would just extract gradients and edges, spatial directions, and so on; very simple stuff.  In terms of its actions, it only knows about controlling for example, if it's a wheeled mobile robot, controlling each wheel separately; just making small motions.  Consider that if it was an arm, it has an arm, it was just moving fingers like that without controlling the whole action.  So, the challenge was how to-- I mean, consider that a baby just born just knows how to move his limbs or her limbs and doesn't know-- and just perceive vaguely some shapes but no connection between those; so the idea was how to make those connections.  So that was another issue that I worked on with William and another student who came up afterwards, Nicole  on developing a system that would learn sensory motor representation.  As I said, the representations of space, objects and so on are going to be linked to what the robot is able to do with them so that it develops its representations at the same time that it develops its own actions.  It learns to control its motion by and through developing more sophisticated representations of its space and this is guided by a learning process with some motivation, some values, some value functions that start with very simple values and also themselves become more complex as the robot knows to do more complex things.  </interviewee>
<interviewer>And you mentioned kind of a human baby is something that learns in this fashion in testing the world; did you have any theories of that sort in mind while you were coming up with this robotic learning mechanism?</interviewer>
<interviewee>Yes, of course, I mean, again, we are speaking about the years 2002, 2005 and so on and, in the meanwhile, there has been a wealth of work in robotics inspired by biological systems, neuroscience, and so on and neuroscience researchers were coming up also with a lot of theories about how we develop our abilities, how we learn and so on.  So there was, and there is today, a very rich interaction between those areas; neuroscience and robotics.  So there is inspiration, of course, because the only working system that we know about is biological, human beings or animals, but my view is that it doesn't necessarily have to be that way.  It's not, and in a way, you can say </interviewee>
<interviewee>and so on, an instance, in biological systems, s, but it's not necessarily the only instance of achieving intelligent systems or systems able to interact with their environments to learn and so on.  If there is a general theory or theories of intelligence and learning and so on, then this general theory could be applied to different instantiations, different ways of doing it.  So, basically, we do it by using our neural net, which is our brain.  We do it by having a mechanism for learning which is encoded into the way the neurons interact together and integrate information and, of course, the studies from neuroscience and the mathematical models of neurons explained to us how this works.  But, at the same time, when we do artificial neuron nets, for example, this is implemented on computers, on  machines, on a general model for computation.  So, is the brain amenable to a touring [ph?] machine?  That's, of course, an open question and if yes, it means that there is, indeed, a more general model of computation that you could use and not necessarily using just neural systems to learn.  You have also other theories for learning, other methods for learning, which are based on mathematical models.  For example, you take reinforcement learning, which is based on  processes at the end, if you wish, because they are using  built [ph?] on equation [ph?] and not integrating neural signals.  So, I think, I believe, I mean, this is my view, we can achieve artificial intelligence with robots not necessarily imitating biological systems but we have to really seek this general theory of intelligence that can be implemented in different ways.  Natural intelligence evolved with a lot of constraints that have been taken into account by evolution and we can probably build systems that have maybe a different approach but, again, which are as intelligent as natural systems.  So that was my view.  Hence I'm not advocating-- I didn't do it with my students either, to imitate exactly what's happening with the theories that come from neural science.  There were a source of inspiration and proof of concept, in a way, that you can do that but you don't need to really implement it the way it's done in nature.  Although most that, at a given moment in time, we have only models of what's happening in the brain, approximate models, false models, controversial models proposed by neural [ph?]  and so on.  So, of course we could implement those models to help neuroscientists to maybe prove that this model is working and this model is not working, computationally speaking, but it doesn't make sense to have a kind of religion [ph?] which is the only way to go is to make it nature.  I don't believe that.  There are many ways to go and nature is one of them, a great one, a source of inspiration and a proof of concept again but I think we have to seek the more general theory anyway.</interviewee>
<interviewer>And I think one of the things that I skipped over was your Eden project.  </interviewer>
<interviewee>Oh yes.  Thank you, I wanted to</interviewee>
<interviewee>Yes, so the Eden project.  Actually, in the meanwhile, as I said, I worked on this issue of uncertainties in 1985 but then came several projects that, more or less, oriented my research.  So, one issue, one problem, was related to, for example, using mobile robots in warehouses; it was funded by IBM France.  So we built a small model robot, smaller then the initial one, and worked on that for doing some indoors navigation in warehouses and automated docking of the robot and so on based on the research I've done before and developing also control architecture.  So each time we had projects, they were a funded project, they were addressed but at the same time they served as a basis or as a means to develop more profound or more general scientific questions, not just do the project as an engineering project but as a scientific project.  So I had students working on that, one of my students, Fabrice [ph?] Norace [ph?] was working on this issue and at the same time working on the issue of architecture because we had to cope with that.  So, then came the time, in the mid-'80s of European projects; that was a great thing because the structure that each European nation was doing research and we met as scientists, as colleagues, in international conferences.  We almost never worked together in Europe and the European projects were those projects funded by Europe, by the European Union; at that time it wasn't the European Union, it was the Common Market or EEC, European community, with the objective of making different European nations working together on joint projects.  And there was this project called SKIDS [ph?] with different European participants.  There was Germany, France, United Kingdom, Greece, and the problem was about fusing sensory data; having different sensors, cameras, fixed or mobile, mobile robots; observing a situation and trying to understand the situation by fusing all these datas.  At that time, our partner in the United Kingdom was the University of Oxford, Mike Brady, who is another exceptional character, and he had someone working with him, and that guy was Hugh Durrant-Whyte.  So this time of Hugh had actually had his thesis in the United States with Rozeena [ph?] Bakshi [ph?] at U Penn.  And I met Hugh the first time at Rozeena's.  She was giving a party in 1985 when I came for this conference at St. Louis with the paper on mobile robot-- on coping with uncertainties for  modeling and Hugh had read my paper and during the party he discussed with me about it and he pointed out that there was a mistake at some point; he was right, but it wasn't important but whatever, so and this is where I met Hugh and he was also someone I appreciate very much, a real friend.  So, we worked together with Mike Brady's group and Hugh, specifically, on this project and this project addressed the issue of fusing sensory data which was exactly the problem that I started to address with the processing of uncertainties and so on but in a different context; but that was also a very exciting period.  I think the project started in 1986 for four years and so I met Hugh different times in that period.  And also another project came up at that time; it was a European project as well, a different kind of European project called Autonomous Mobile Robots, AMR, and here, for the first time, the issue was to study outdoors, robots; robots for intervention outdoors.  So, and there was some industry involved in this project.  French industry, for example, Matra was involved and I'm going through projects in time very quickly</interviewee>
<interviewer>So we went to AMR</interviewer>
<interviewee>Yes, and in 19-- so it's working?</interviewee>
<interviewer>Yes.</interviewer>
<interviewee>And in 1989, if I remember, there was big excitement about planetary exploration, Mars, and the French National Space Center, CNES, which is our NASA, asked us to come up with a project for Mars exploration.  So what they did was a very interesting thing.  They made a kind of national project and they asked different research labs to come together to study all the aspects related to sending a model robot on Mars.  I'm speaking about the robotic side of it, of course.  And George Giralt was the coordinator of this project; so he was, again, very instrumental in making things well coordinated and advancing things.  So we had many partners from France working on different aspects and we had the responsibility, basically, in my lab at LAAS of navigation over rough terrain and the other aspect was about control architecture and general planning while other worked on locomotion, wheels or other systems; tracks; others worked on divisions specifically; others worked on communication and on the interaction with the ground station and so on.  So, at that time also, we studied how to have a kind remo-- a kind of theater [ph?] operation but we called it theater robotics which means the system has-- the remote robot, because of the time necessary for communication, has to be autonomous enough to do its tasks and to not put itself in danger taking into account that you cannot just  operate it with like 15 or 20 minutes delay between Earth and Mars.  So, we also developed architectures for having these disconnected systems where you had a planning system on Earth and a supervisory and execution system on Mars to achieve this capacity because, of course, sending a robot to Mars means robots that don't have much computing power; so this is why the planning was on Earth.  I mean,  task [ph?] planning and we wanted to have the motion planning and navigation issues on board the robot.  So, starting in 1989, we had this project and what we did, what I did, is that to organize internally in my lab using-- for selling [ph?] all this with the external partners, I've started a project called Eden.  We had, now I'm saying about 1992-'93, there was an event in that period which was the collapse of the Soviet Union and the opening, actually, of the Soviet Union of Russia to the western world and actually the Russians were very much advanced in developing robots and structures, I mean machines, able to move on harsh terrain.  And one of the robots that they developed was used actually in Chernobyl in 1986 to remove debris and rubble.  And just after the collapse of the Soviet Union there was-- some French industry, I'm speaking about Matra, , had bought, from Russia, one model of those robots and this robot was called Adam.</interviewee>
<interviewer>Adam.</interviewer>
<interviewee>And hence the Eden Project, of course, had to use this robot for testing our work on mobile robot navigation in natural terrain.  So Eden means actually this; it's Experimental Displacement in Natural Environment, in French, and the robot was Adam that we used on that.  And so, that was the early '90s, '93 and so on that we really developed a full working system with novel techniques, novel algorithms, novel approaches for perceiving and modeling natural terrain and planning motion on natural terrain taking into account the fact that on natural terrain you have slippage; you have stability problems; you have to actually cope with different kinds of situations.  You have sometimes flat terrain, sometimes slopes, sometimes very uneven terrain and  terrain; all this has to be modeled taking into account devising specific algorithm for navigation, in this case.  So that was a great adventure of coping with a novel issue, and very exciting one, because the purpose was to go to Mars.  And, remember, I was-- my initial excitement about astronomy and so on, so it was a dream come true to work on that.  And so, I think that was really successful because we came up with really seminal results on that and, of course, others were working on that in the United States mainly at JPL, at CMU and we had many exchanges and meetings and discussions in international conferences and so on with the people at CMU, people at JPL.  It wasn't a joint project; everyone was working for himself but, of course, scientists meeting, that was very exciting.  Unfortunately, in a way, in 1994-'95, the French decided to stop this project because the European Space Agency, at that time, put the emphasis on Earth observation and not on planetary exploration.  And so, the money went to developing first a European shuttle, which was called Hermes, which never was really developed and then to programs on Earth observation, which finally ended up in the International Space Station and so on instead of planetary exploration; and the United States, a project of Mars exploration has continued; in the former Soviet Union, also, and I will get back to that in a second; and finally we had Sojourner on Mars in 1997, '96.  So that was, I think, a great thing.  In the meanwhile, as I said, the Russians were also continuing and another robot was bought from Russia by another French company called Alcatel, at that time; it was the Matshokhod model, which has conical wheels and which has an articulated body; a very agile robot, and we had it at the lab.  We worked with that robot; it was called Lama because it was able to really move anywhere.  And on that robot we had-- also it was part of the Eden experiment and we were able to do a lot of interesting things on, again, agile motion planning on uneven terrain and coping with sandy or gravel dunes and so on.  And another model was bought also and was used on an experimental terrain at the Space Agency in Toulouse, the French Space Agency in Toulouse, and that one was called Eve.  So we had Adam and Eve at the same time.  Yes, so those were very exciting years and then kind of disappointing because we never went to Mars but we were ready.  We had everything running.  It wasn't space ready but in terms of the results, the systems, we were really ready; so, yes.  </interviewee>
<interviewer>Who were some of the people who worked with you guys?</interviewer>
<interviewee>So, in the Eden project, and more generally on the project of the Mars exploration, at that time I had a student who then became a researcher at LAAS, Simon Lacroix, who started working also on SKIDS, by the way, on the SKIDS project I mentioned.  Well, as I said, George Giralt was the coordinator of the project.  Also Rashid al-Ami [ph?] was working on that; he was more working on the issues related to planning and control architecture and I worked a lot with Rashid al-Ami on those issues afterwards at that time and afterwards.  In the late '80s, early '90s we'd developed control architecture general enough for mobile robotics which was used in all our mobile robots and that was also an important work in the area and also another person, Nick Sameo [ph?] who was the motion planning guy I would say on even terrain he came up with very clever algorithm for taking into account the terrain configuration and he has made very, very good work on that because we were able to experiment early on even terrain.  Now Nick is working on other topics in motion planning as well.  It's on medical motion planning studying how molecules form, how we can combine proteins for example.  This is also one of the great applications of robotics motion planning into biology he's working on.</interviewee>
<interviewer>I think that's going to have to change this thing and think about if we've missed anything and then I'm going to ask you one last question about advice for young people.</interviewer>
<interviewee>Okay.</interviewee>
<interviewee>Too long?</interviewee>
<interviewer>No, no, no.  This is normal.</interviewer>
<interviewer>We don't start always with a new tape.</interviewer>
<interviewer>It's amazing how easily immediately it becomes deserted because I went into the room that was the conference room and maybe an hour after and it was all disassembled.</interviewer>
<interviewee>Yes, moving to something else.</interviewee>
<interviewee>Anyway--</interviewee>
<interviewee>It won't be complete because of course a lot of things won't be mentioned, but that's fine.</interviewee>
<interviewer>I think only when you start explaining what happened do you realize how many things actually happened.</interviewer>
<interviewee>Yes.  It's amazing.</interviewee>
<interviewee>Yeah, I want to mention two other projects.</interviewee>
<interviewer>Yes, so other projects.</interviewer>
<interviewee>Yes, another project I would like to mention was the COMETS project.  That was in 2003, 4, 5, and so on.  It was about aero-robotics, drones.  It was a European project with Spain mostly and Portugal and at that time we became interested in robots that fly and so don't forget that I've made my engineering studies in these aviation school and my master's in control in the engineering school which is called National Aeronautics and Space School.  So I had also this tropism to aviation in general and so it was very interesting for me to move into aero-robotics and that project was very interesting.  It was about cooperation between different flying robots.  Germany, University of Berlin was also partner.  The idea is to have different robots.  We had plane, helicopter, and so on, cooperating together.  Of course controlled and cooperating together autonomously for some task and the task was detecting forest fires and we made a lot of experiments in Portugal also.  The team went there and __________ was one of the most active in this project to build the understanding and the control system for both the control of individual aero-robots and our case we had this blimp and which was called Karma and the other, the coordination with the other flying robots and there are some projects continuing on this issue coordinating with ground robots, aero-robots, and so on, but that was one of the first project actually in aero-robotics that we have done.</interviewee>
<interviewer>_____________ funded.</interviewer>
<interviewee>It's EU funded, yeah.  EU funding was very, very important and still is.</interviewee>
<interviewer>And they seem to do very large projects.</interviewer>
<interviewee>Yes.  It depends.  I mean it depends because there were times where we had small ones, then they grew up in terms of funding and then Europe is really now putting very much the emphasis on having both smaller projects like two or three partners, three partners, working on a three-year project, pretty small, but and large integrated projects with more partners, maybe longer, and in the future what is planned is what we call flexion projects, ten years, with enormous amount of funding, but many people of course participating in that.  So it's yeah, I think this will push research and European integration much more.  Another project I want to mention, maybe this will be the last one I mention, but it's a very important one.  It's the commune project.  So in that time I mean ____________ about 2002-2003, one of the branches at the European Union which was called Future and Emergent Technologies launched an initiative called Beyond Robotics.  The idea was to study robots with advanced cognitive capacities, advanced interactive capacities and so on and I have coordinated a project called Cogniron which run between 2004 and 2008 with partners from Europe like Henrik Christensen who was at that time in Sweden, Kerstin Dautenhahn in England, Rudiger Dillmann in Germany and many others.  Cogniron means the cognitive robot companion so the objective of the project was to study cognitive functions of a companion robot.  What is a companion robot?  It's a robot that interacts with people, assists people, just do tasks for people and this was a very important project to study the issues related to human-robot interactions, how to model humans from the perspective of the robot, how to jointly do tasks with humans, but also on the more robotics aspect of cognition which are autonomous decision making, planning, cognitive architecture, how the system is organized, learning.  Learning was one important issue there and this is where I mentioned what we have done on that with some other partners working on other aspects of learning.  For example, Aude Billard in EPFL working on imitation learning was in this project as well.  Roland Siegwart was in this project working on other issues related to perception and navigation.  So Cogniron was really a project that put together many competent researchers from Europe working on those issues about learning, decision making, cognitive architectures, human-robot interaction, and communication dialog.  It was the University of Bielefeld and that was an entity graded project, a large project, and I think that is was really very seminal and yielded a lot of results that are now exploited in other projects, European or national projects and so on.</interviewee>
<interviewer>Do you have a feeling for why there was such an interest in developing a companion robot?</interviewer>
<interviewee>Well, yes.  I think what happened over the years if you wish was that in the beginning we were-- in the beginning of robotics 50 years ago, mostly the motivation for robotics was manufacturing, was automated manufacturing.  So people wanted robots in the factory mostly I would say at that time to replace people, to make a work faster, more productive, more precise, and so on and so on.  So it was robots without people.  When we studied which was a different thing at all-- when we studied mobile robots and so on, the emphasis was on autonomy.  We wanted to study autonomous robots, how to achieve, how to build a machine able to make decisions by itself, to move by itself, to avoid obstacles by itself, to go places by itself, to do things by itself without any human intervention.  The human intervention was just in the beginning to give a goal and when we studied Mars rover, of course, it was again autonomous robots on Mars, no people, and again the emphasis was on autonomy.  Some ________ operation which means there is a person, a specialist, doing some control remote control, but very light control, but the robot is basically autonomous.  As those autonomous functions were developed, at the same time came up some issues in society and basically in the industrial world it's the aging society where people started to address the problem of what is going to happen when everyone is going to get older, so we needed some more maybe some assistance or some help from machines.  So the issues came up and mostly I think Japan was very driving on this to study robots for assisting humans.  So in a way there was some maturity in understanding some basic autonomous functions which are necessary for robots to interact efficiently with humans without the humans controlling every motion and so on.  That was a necessary step and there was a kind of need.  I don't believe it was an expressed need and it is still not an expressed need, but there is I would say an anticipation of the fact that we are going to need robots in our homes.  So this convergence of this potential need and the capacity to achieve enough autonomous functions so that the interaction with humans could be easier for humans started this issue of robot companions, I think, and made it possible and there was a potential need.  So it was-- the __________ was mature to study that.  And I believe it's very ________ developing and indeed we have robots with more or less enhanced capacities for interacting with humans.  For example a vacuum cleaner like Roomba doesn't interact with humans, but it's in our homes and we have some experimental devices for very, very simple interaction, but this is probably a great avenue to explore to achieve robots that really are going to share our space for our benefit of course.  So yeah.</interviewee>
<interviewer>What do you think are some of the challenges for robotics in the future the next ten years or something?</interviewer>
<interviewee>Well, I believe the main challenges of intelligent machines are not solved today.  I mean the questions that we try to address in the early days of robotics are still open.  General perception, seeing, understanding, situation understanding, this is not solved.  There are results.  There is progress, but I don't know of any system that you can just put anywhere and it understands meaning, analyses a scene, says well this is a camera, this is a chair, this is a door, and these are two people speaking together.</interviewee>
<interviewer>Must be an interview or like ____________.</interviewer>
<interviewee>So this doesn't exist and this is a very fundamental problem, perceiving and understand what to perceive.  So since the problem was addressed since so many years and we didn't solve it.  It probably means we don't have the proper instruments, the proper theories or the proper processing power or the proper _______________ and so on.  It won't be solved just by chance, by augmenting processing power.  You need to know how to do it.  So I think this is a very important question and a fundamental one, but I want to say that it's not to be addressed by itself.  Again, you don't perceive just for perceiving.  You perceive for action and therefore we have to consider the connection between perception and action all the time, not just perception by itself.  Which means you have to integrate perception with action and this will necessarily be based on learning processes because you cannot imagine beforehand those interactions between perception and action without-- I mean abstractly speaking.  So learning is another issue too that has to be developed.  Learning methods, learning theories, we have a lot of results on learning, but we have big problems with efficiency, with ability to cope with real situations, real problems, dimensionality, not toy problems.  So there is a lot of work to be done there as well, I think.  And too, of course there is the issue of robot interaction, social interaction, but this is more or less this social intelligence issue is important.  I think it would be instrumental in accelerating learning, of course, because you don't learn just again by scratch by observing.  You learn also by interacting with people and learning from people.  Learning from people for a robot or learning from other robots, also this interaction is important.  What I want to say in terms of novel issue to address, I believe that we didn't solve those issues and we should continue and there are mathematical issues.  There are modeling issues.  There are deep questions about how to ___________ those things, but what I believe is that we need to-- if we consider all those things together, there is a point which was not so much addressed until now which is the problem of self-awareness or consciousness.  What enables actually in natural systems also to drive or control or achieve those processes, perception, action, interaction and so on, is related to the fact that I have some awareness of myself with respect to the rest of the world.  Myself is my body and my way of integrating, I would say, the external world with respect to my own existence; my awareness about where I am.  So this is just to say that I believe studying self-awareness for a machine, robot consciousness, we don't have theories of that.  Of course they all have theories of consciousness for humans and so on, but we don't have a theory, a mathematical theory or a computational theory of that.  I think this is probably at the center of those issues and of enabling us to really understand and achieve an artificial intelligence, a human level artificial intelligence.</interviewee>
<interviewer>And just to wrap up, unfortunately since I think maybe they're out there.  I don't know.  Could you tell us if you have some advice for young people who are interested in getting into robotics?</interviewer>
<interviewee>Well, I think robotics is a very exciting field because when you work in robotics, you work in all the other fields at the same time because basically in a way robotics is about developing an artificial being.  So you have of course the issue of sensing; you have the issue of perception; you have the issue of computation; you have the issue of building the body, which means mechanics, material science; you have the issue of studying the notion of mind, which is also related to philosophy; you have ethics; you have interaction.  So really entering into robotics is a wide spectrum of possible studies in all domains.  All domains in conjunction with the science that's going on in those domains, for example independently from robotics.  So it's also a multidisciplinary venue.  I mean you can discuss with neuroscientists, with social science people, with philosopher.  They have interests-- I mean I don't know about any domain which is richer than robotics.  It's really a comprehensive domain.  Of course one will specialize, but what's important is to keep in mind the full picture and a second point is that when addressing a problem, my advice is to never try to solve it by hex [ph?].  Of course hex will work sometime.  They will do great things, but those are hex which means they won't be journal solutions and so on and doing this is missing the real problems.  Again remember the issue of uncertainties and how SLAM came up.  This was because we didn't do hex to solve the problem.  We really tried to address it and we came up with solutions which were developed afterwards and SLAM became a great domain to understand robot navigation.  So no hex.  You can use hex if you want, but you should know these are hex and just for temporarily maybe solving other problems, but no hex.</interviewee>
<interviewer>Great.  Thank you very much.</interviewer>
<interviewee>Thank you.  So what I forgot to mention?</interviewee>
<interviewee>I'm sorry.  What I forgot to mention was my stay in Japan, but--</interviewee>
<interviewer>Maybe we'll catch you at another one of these things.</interviewer>
<interviewee>Yes.</interviewee>
</interview>
</subject>
