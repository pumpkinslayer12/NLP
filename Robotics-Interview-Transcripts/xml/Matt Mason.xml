<?xml version="1.0" encoding="UTF-8" ?>
<subject>
<name>Matt Mason</name>
<interview>
<interviewer>We're just going to start by asking you where you were born and where you grew up.</interviewer>
<interviewee>I was born in, and grew up, in Oklahoma City.  Born in '52.  Grew up there.  Went to MIT in 1970, just a few days before my eighteenth birthday.</interviewee>
<interviewer>What did you study as an undergrad?</interviewer>
<interviewee>I started majoring in physics and math, and shortly thereafter switched to computer science.</interviewee>
<interviewer>And what motivated you to switch?</interviewer>
<interviewee>Well, I had taken a class at Stanford.  So when I was still in high school, I did a summer session at Stanford, and discovered computers there.  There was a very nice class in computer programming that I took that summer.  I had to sneak in.  I kind of crashed the course, you might say, with my brother, who was attending Stanford.  So I knew computer science was cool.  This was 1968 or 1969.  So everybody else didn't know it was cool.  Some people would say, "Well, you know, a computer is just a tool."  Kind of like you wouldn't study calculators.  Telling somebody you're studying computer science in those days might have sounded to some people kind of like you're going to study calculator science or something.  But I think, just from hanging out and studying physics, and seeing some of the things that are going on, it just confirmed what I already knew in my heart, which was that computers really were cool and it was fun.</interviewee>
<interviewer>When did you first become interested in robotics?</interviewer>
<interviewee>Yeah, that's an interesting question.  When did that happen?  When I was at MIT, I came into contact with the people in the artificial intelligence laboratory.  And at that time they had just done something called a copy demo, which was the idea that you could set up a bunch of blocks and then the robot would look at it and build a copy of it.  And so I was hearing some research talks from that, and that's what got me into the lab initially.  I didn't really start working myself on robotics until a few years later, and that came about mostly because I just happened to be sharing an office with Marc Raibert and John Hollerbach, and Shimon Ullman, all of whom were doing robotics of one form or another.  And they were just having too much fun.</interviewee>
<interviewer>Who were some of those first people who did the copy of blocks?</interviewer>
<interviewee>Yeah, the copy demo-- yeah, as I say, it was a little bit before my time, and I'm trying to recover the names now.  Some of them were graduate students or young faculty that were there, and then left before I really got to know the people in the lab.  I think one of them was Eugene Charniak, but it seems like he was doing linguistics.  Yeah.  Well, I don't know.  You should ask Jerry Sussman.  You should ask Berthold Horn.  Certainly Berthold Horn was involved.  Tom Binford, who later went to Stanford, I think was involved.  And kind of along related-- I mean, there was related work going on by-- sorry, I should have done some mental exercises to work through all the names.  There's a very famous guy, another guy who's well known for linguistics at Stanford, who might have been involved.  </interviewee>
<interviewer>What was the first robotic project that you worked on?</interviewer>
<interviewee>I guess the first thing I did was a project in compliant motion and force control.  This was my master's thesis.  So I started working on that, oh, a few months after I started grad school.  So, I started as an undergrad in '70, but I started graduate school in '76, so it would have been right around '76 or '77.  And compliant motion and force control, that means if you've got a hand and you're trying to interact with things in the real world, you have to do it gracefully.  You want to be able to touch hard surfaces, interact with them without hurting yourself or the surface.  So it makes sense to try and control force rather than just controlling position.</interviewee>
<interviewer>What kind of machine were you using?  Was it a robotic arm?</interviewer>
<interviewee>You know what?  That's funny.  We did have machines and I was messing around with them.  My master's thesis was theoretical.  I don't think I did any actual force control until after I finished the thesis.  Immediately after finding out it, I did do a visit, an internship, at IBM Yorktown Heights and worked with Russ Taylor there.  Worked for my-- I think my-- the boss of the group was Peter Will, and another manager was Dave Grossman.  Russ Taylor was the one who I was working directly with.  And I did implement a force control system for their arm that was called-- their experimental system was called the RS1, and they released a product a couple years later called I think the 7565 arm.  The arm we had in the lab-- maybe that gets back to the original question.  Yeah, what did we have in the lab?  We had a-- at that time we had the MIT Arm, it was called.  So this had been designed by Victor Scheinman, I think, at the request of Minsky.  I think the original one had aluminum gears.  There would be a little pile of aluminum dust under it if you worked it too hard.  Raibert did his PhD thesis on that.  And then we had an arm that we were developing in the lab ourselves called the Purbrick Arm.  John Purbrick who was a guy who was designing an arm.  And I actually did the-- sort of the programming and control system for that arm.  And then there was a third system called the Silver Arm.  There had been a visitor at MIT named Hiroshi Inoue, who went on to be a very famous guy in Japan, and he had worked on assembly and worked with Tomas Lozano-Perez, and that was on the Silver Arm, which was-- it's another arm that was developed at MIT.  Any more hardware questions?  </interviewee>
<interviewer>What was your PhD thesis and how did that research progress?</interviewer>
<interviewee>Yeah, so the PhD was on basically how to push things around.  Let's see.  I think maybe the right way-- what's the right perspective for all of this?  So there's a few things going on.  So my advisor was Berthold Horn.  Horn was very well known for using sort of careful-- I'll say mathematical or engineering models of the image formation process and inverting them in order to develop really hard-nosed approaches to constructing the shape-- the three-dimensional shape from an image.  So there were a lot of us that were interested in assembly and using arms, which may seem very distant from vision, but I think I was probably inspired by Horn's work to try and do something similar-- that is, can you, from a very careful engineering model of how things move when you touch them, can you invert that then to come up with the plans and the controls for a robot?  So in the abstract, that seems pretty simple.  Then you start looking at real cases.  So I mean, usually you think of things at a rather abstract level: "I want to put Block A on Block B.  I'm going to pick up Block A."  Where's the subtlety in that?  Where's the engineering model in that?  But when you look at very carefully what happens when you go to pick up an object, usually there's some error-- often there's some error-- and because of that error, you make contact not exactly as you planned.  Things move a little bit, or maybe your fingers deform a little bit.  There's all kinds of little things like that going on.  And from looking at this and sort of thinking about some problems I'd seen over the years, I realized that those little motions can actually be very important.  Maybe the best example-- I have several examples.  The best example was that I had seen a movie that had been made at Stanford called-- I think it's Programmable Assembly: Three Short Examples.  Maybe this is going to show up in some of your other interviews.  I believe Lou Paul, Richard Paul, was one of the others, and Bob Bowles.  I don't know if he's on your list-- at SRI-- and a guy who I never met name Pingle, I think, was part of it.  And they pick up a hinge-- they're going to put hinges together-- they're going to assemble a hinge.  And when they go to pick up the hinge, instead of the two fingers coming down like this and grabbing, like you sometimes see, instead of the fingers sort of start over here, and they came along and pushed the hinge like so, as they squeezed.  And it was like, "Wow, why'd you have to do that?"  Well, that pushing process eliminated the uncertainty, and if you continue to push as you squeeze, you end up with those fingertips right in the corners of the hinge with, I guess I'll say, perfect precision.  Right?  I mean, you're in absolutely mechanical contact with both features of this corner.  So it's a precision that you can't get just by raw positioning.  And you realize when you watch people program arms, you see them doing these kind of things all the time.  Russ Taylor's PhD thesis had a great example, which was that if you squeeze a box and a lid at the same time-- I think he might have squeezed it twice, one in the X direction and one in the Y direction-- then you've perfectly aligned the box and the lid, and then it makes the assembly easier.  So you this stuff all the time.  You watch people work, and if you've got an eye for it, you see people doing similar things, right?  When you shuffle a deck of cards, you don't get the precision with which the card deck is stacked by open-loop positioning.  Actually, if you watch an infant messing with cards, you will see that-- right?  They'll pick up the cards one at a time and put them in a stack, and it's a mess.  But somebody with a few years of experience will squeeze it and tap it on the-- right?-- or tapping chopsticks.  You just see these tricks over and over again and you begin to realize it's actually an important part of manipulation.  So, I guess that's a pretty long answer.  The question was what did I do for my PhD thesis.  So I decided to work on these pushing motions, and that's what I did.</interviewee>
<interviewer>When did you start applying them to robotic systems?</interviewer>
<interviewee>Well, that was from the beginning.  I don't think-- it's not as easy to-- you don't see these things.  I mean, the beauty of robotics is that you're trying to make something happen and you can't appreciate the problems until you're trying to make it happen yourself, right?  So if somebody's out there and they're doing something and you think, "Wow, that looks easy," then you go try and do it, then that's when you discover it's hard, right?  So if you're trying to build a machine to do something, you're trying to program a computer to do something, you really have to understand the something.  And so that's one of the very interesting things.  There's all kinds of problems of a very fundamental nature just in geometry or in dynamics or in simple mechanics that could have been of interest even a hundred years ago, which really never got that much attention, perhaps weren't noticed at all, until they became relevant in the context of robotics.  So I certainly never worried about pushing until I was worrying about how to get a PhD.  </interviewee>
<interviewer>What did you do after your PhD?</interviewer>
<interviewee>Well, there was a few things.  So, there was one project that started before I finished my PhD.  The guys at MIT had this great idea-- they had something called the Year of the Robot-- I think that's what they called it.  And they invited a bunch of people up.  I think John Liu was there.  Mike Brady had been there for some time.  In fact, who knows, maybe the other robot was his idea.  But Russ Taylor came, and so Russ Taylor and Tomas Lozano-Perez and I had a project to try to-- it was on fine motion planning.  There was an idea that had been around a long time, which was that you can sort of divide manipulation into fine and coarse.  So if you're just moving your hand from here to there, that's one thing, but then when you're trying to pick things up, there are these little fine motions that happen that are perhaps more sensor-mediated and more involving compliance and pushing and things like that.  So we were sort of trying to have a very-- develop a geometrical perspective on how this fine motion planning happened.  How do you-- the errors and uncertainty in the task can be greater than the precision with which you can control things.  So then you want to use the compliant motion and maybe force feedback to help you guide the system into the desired goal.  So anyway, that was a project which we called fine motion planning, and later on I think it was Lozano-Perez's graduate students who coined the-- turned it into LMT-- Lozano-Perez, Mason, Taylor.  So a lot of times people called this LMT.  Sometimes they call it pre-image backchaining.  So there was that project.  I put a lot of time into that, some before and a lot after, working with Tomas and Russ.  I don't know.  It's a lot of time after a PhD, so-- -- the answer to that could go on for a long time.</interviewee>
<interviewer>When did you come to Carnegie Mellon?</interviewer>
<interviewee>I came straight to CMU from MIT.  So my first year in graduate school, I mentioned I was in an office with Marc Raibert.  When he graduated, which was just at the end of that first year, he went to JPL at Caltech.  Ultimately he came to CMU around 1980 or so, and then in 1982 he convinced me I should come here.</interviewee>
<interviewer>What was CMU like in 1982?</interviewer>
<interviewee>Well, let's see.  It was an exciting place.  I was firmly convinced it was the best place in the world to do research.  The money situation was good.  Didn't have to spend a lot of time writing proposals, and the main reason for that was Allen Newell and Raj Reddy and people like that were doing a lot of that work for us.  And so-- and there was-- and the teaching load was light.  There was no undergraduate program-- well, we kind of shared responsibility for an undergraduate program with the math department.  So the teaching load was rather light, and the students were awesome, and the faculty that were around were great, and it was just a terrific place. </interviewee>
<interviewer>Was it a full-fledged robotics program at that point, or were you still part of--</interviewer>
<interviewee>Well, it was-- the Robotics Institute was-- had been going for just a year or two.  I identified much more at that time with the computer science department than I do now, and I think I can admit to some prejudices that I arrived with from MIT.  There were people, as I was leaving MIT to come to Carnegie Mellon, telling me to watch out for this guy and that guy, and, "Maybe you should be careful about that Robotics Institute."  But in any case, I mean, it was kind of-- people refer to those as wild and wooly days.  In some ways I guess they were.  There was no robotics PhD program.  The Robotics Institute was just a research institute.  Anybody that had a tenure track appointment was joint with another department.  So I was joint between computer science and robotics.  So, it was interesting.  It brought some great people here.  Hans Moravec was here because of it.  And Marc and I wouldn't have been here without it, I don't think.</interviewee>
<interviewer>Who else was here at that time?</interviewer>
<interviewee>Well, it was a really interesting thing going on.  Ivan Sutherland was here.  So Sutherland was one of these people that had been part of MIT many years before I had been there, and then Raibert got to know him in California, and then Sutherland is an alum of the ECE department here, and he was back here, and he was building a walking machine.  And so he had attracted a really interesting group of people, including Marc, and their walking machine was pretty interesting.  And he produced a book, which I still pull out once in a while.  It's a very unusual book in that it kind of covers everything from how do you create the little fillets in the metal castings, all the way up to how do you design gate patterns for walking machines.  It's very-- it's interesting.</interviewee>
<interviewer>What kinds of projects did you start when you came here?</interviewer>
<interviewee>Well, let's see.  So I told you about the fine motion planning project.  What else was going on here at the beginning?  What was I doing?  More pushing.  I kind of started-- well, I guess probably the most interesting thing was a thing called tray tilting, and that was work with Mike Erdmann.  So he was still-- he was a graduate student at MIT and he came here one summer.  And we were just trying to figure out how far could you go understanding certainty, or eliminating uncertainty in the world, but not by using sensors.  And maybe this just started as a sort of contrarian thing, but I think almost anytime you pick up a paper on robotics research, it might have said, "Well, there's uncertainty in the world and therefore you got to use sensors.  You need force sensing and tactile sensing, visual sensing, etcetera, etcetera."  It all seems perfectly obvious that there's uncertainty in the world; you need sensors to get more information.  And then-- but we knew some examples where people were getting really interesting information without using sensors.  And I'll cite an example from the IBM group.  Peter Will had told me some stories that were pretty interesting about these things, and then Grossman and Blasgen had a paper where if you want to know where a part is in a tray, well you just-- or I'll say it this way: If you want to know where a part is-- and let's say it's kind of an irregular-shaped part.  You have this tilted tray, you throw the part in the tray, and if-- there are no symmetries or anything, and maybe you even shake the tray to eliminate friction-- it's going to settle into one of some finite number of poses, and you can disambiguate that by just having a sort of a cat's whisker.  And so you go in and kind of do a binary search.  You say, "Is there stuff there?  No.  Well, is there stuff there?  No.  Well, then it must be configuration number three."  So that seemed kind of interesting, and Mike and I started thinking, "Gee, I wonder if we could even get rid of the cat's whisker.  Can we actually figure out where something is with zero sensory information?"  So the first idea was to use-- actually to kind of use pushing.  So you could imagine-- imagine you have a part that's like in the center of a table, and let's say you push it like that, and then you push it like that.  And you're not looking at or anything-- you just know if it was somewhere in the center of the table, you do a couple pushes like that, you're going to know approximately where it is.  But maybe you want to do some other things.  Maybe you kind of come in with a needle and do this, or push it this way or that way.  Can you actually get all of the information about its orientation and position this way?  Well, that turned out to be too hard, but there's a kind of simpler version of that, which is you go back to the tray, toss the object in the tray, and now you tilt the tray this way, and then you tilt it that way, you tilt it that way.  The thing's sliding around.  You make it slide from this corner to that corner, back and forth a few times, and at the end of that process you know its position and its orientation.  So, I don't know.  That's a long answer.  Are these-- should I be-- </interviewee>
<interviewer>No, those are great.  No, the detail is great. </interviewer>
<interviewee>Okay.  Well anyway, yeah.  So that was one project.  That was with Erdmann and, I don't know, that one, actually we still pull it out and show it to people a lot.  Erdmann had just done some work where he could automatically predict the behavior of rigid bodies under frictional contact.  And so he had a system more or less lined up ready to go, and so he could basically simulate all the actions that you might contemplate in order to give you the information that you need in order to do automatic planning of that.  But I think maybe the most interesting bit was that you could identify a finite set of actions.  So, subject to some-- these things are always full of assumptions to try and narrow things down-- but subject to these assumptions you could show that there was a finite set of actions that covered everything that you could possibly do, and so that made an exhaustive search actually feasible for that tray-tilting problem.</interviewee>
<interviewer>What other kinds of main questions were you interested in solving?</interviewer>
<interviewee>You know, that's a good question.  You know, a lot of it was-- I mean, it gets back to that original inspiration from Horn.  I guess I've always said sort of that maybe the main thing I'm interested in is the mechanics of manipulation.  I think the work on how things move when you push on them got enough traction or I got enough sort of positive encouragement from people, and you could see there's a lot of interesting things kind of along those lines.  So that was something that-- and of course I'm working with graduate students who are doing most of the work by that time.  So, Randy Brost, Ken Goldberg.  Probably Ken's thesis was the one that was the most noticed out of that whole body of work that was going on shortly after-- I'll say-- shortly after my PhD, within the first ten years or so.  So yeah, mechanics of manipulation, that was one element.  Uncertainty-- how to plan for uncertainty and how to eliminate uncertainty with-- I don't want to say without sensors.  It's not that-- it did get to be a joke for a while that I hated sensors, but on the positive side, the truth of it was that we were interested in getting rid of uncertainty by knowing how the world behaves and what you've done with the world.  And then there was a time when I started working on learning.  So at some point Raibert left and Tom Mitchell showed up-- -- and it's not exactly a coincidence I got interested in machine learning.  And Alan Christiansen, another graduate student, did some work there, and just recently coming back to that.  The original idea was that we've been doing this work in mechanics as if we were-- oh, what's the right word?-- as if we were 19th century philosophers trying to prove everything from first axioms.  And it became an interesting question-- instead of trying to create a model of the world that was based on Newtonian mechanics, could you do similar things with a more empirically derived model of the world.  So could you just watch how things proceed and abstract from that, and develop models of how the world works with which you could then construct plans automatically?</interviewee>
<interviewer>What were some of the important projects that you worked on?</interviewer>
<interviewee>I don't know, let me think.  Maybe there aren't any.    The important ones?  That's a tough question.</interviewee>
<interviewer>I mean, maybe important.  Since there are so many-- often people work on so many-- so some that you think were particularly interesting.  You mentioned Ken's.</interviewer>
<interviewee>I don't know.  I think the more important, the more on the periphery.    I mean, most recently the Urban Grand Challenge.  And I was just on the periphery of that.  I probably wouldn't have been involved in that if I wasn't the director of the Robotics Institute.  But certainly that was I think one of the biggest days in the history of robotics.  And I got to be there, but it was mostly just kind of supporting in an administrative way, the work of Red and his gang.  Gee, I don't know.  I mean, some of this stuff is-- it's hard to say how the technology gets into place.  I mean, when I started, it seemed like there were a hundred different companies that were talking about doing manufacturing-- building manufacturing equipment.  I remember we went out and consulted once with Bridgeport, who were working on building a robotic arm for manufacturing.  And some of the things we were doing-- but I'll say kind of-- what seemed like mundane things, like, "Gee, why don't we have robots whose control computers include the ability to have subroutine calls, or functions with parameters?"  Very, very mundane things.  Some of that stuff-- you never know how it got to where it got in most cases.</interviewee>
<interviewer>Who are some of your PhD students?</interviewer>
<interviewee>Let's see.  This is going to be really bad if you put this online and I forget anybody.  So, Yu Wang, who was actually the first person I ever met from mainland China.    So.  They were pretty rare in those days.  He sometimes goes by Michael Wong.  Randy Brost.  Ken Goldberg.  Alan Christiansen.  Kevin Lynch.  Wes Huang.  Garth Zeglin.  Devin Balkcom.  Amir Degani graduated-- he got his PhD like two days ago.  And so now, let's see.  Who have I forgotten?  I'm really sorry.    Do you have a list?  </interviewee>
<interviewer>We'll find one.</interviewer>
<interviewee>Was it a test?</interviewee>
<interviewer>No, no.  No right answer.</interviewer>
<interviewee>Yeah, I know I have forgotten somebody.  </interviewee>
<interviewer>Where have they gone on to work?</interviewer>
<interviewee>Well, Devin right now is at Dartmouth, and Kevin Lynch is at Northwestern.  Ken Goldberg is at USC.  Alan Christiansen is at MITRE.  Randy Brost-- I've forgotten the name of the company.  They're working on solar mirror technology.  He worked for quite a while at Sandia National Labs, and then worked for Kodak.  Yeah, see I'm forgetting even more people now.</interviewee>
<interviewer>You spent some time at Sandia as well?</interviewer>
<interviewee>I did a couple of summers.  I went there for a couple summers, yeah.</interviewee>
<interviewer>What kind of work did you do there?</interviewer>
<interviewee>I was trying to help Randy Brost and his group.  One summer I added some simulation of pushing to a system that they were working on.  And what did I do the other summer?  I don't remember.  Must have been wasted.</interviewee>
<interviewer>What are your projects right now that you're interested in?</interviewer>
<interviewee>Well, simple hands.    There's our whole plan and all kinds of crazy ideas, most of which aren't going anywhere, but maybe a few will.  When is this going online?  I got to publish everything.  Got a new deadline.</interviewee>
<interviewer>At least a year.</interviewer>
<interviewee>Oh, great.    I'm planning to do this the rest of my life.  Yeah, the simple hand idea is that-- well, it's interesting.  If you look at how people design hands, there's a few ideas that dominate.  So one idea is that if this hand works pretty well, let's build something that's kind of like that-- so the anthropomorphic idea.  And I don't want to make it sound superficial-- I mean, obviously people know a lot about the human hands and everything we learn about it can inform the design and the people that are designing those things have done some really amazing things.  There's another idea, which is that maybe we should be able to manipulate something just using the freedoms of the hand.  So if you're going to do that, you sort of need to have at least nine motors, because if you just grip something at two points, you can't very well control that rotation, whereas if you have three fingers you can.  Well, if you want to give arbitrary motions and do this thing with three fingers, then you need to be able to give X, Y and Z motions to each of the fingertips, and so three times three gives you nine motors.  So both of those stories give a very tidy approach to the question of how do you do manipulation in general.  If you can grab an arbitrary shape by having an anthropomorphic hand, and even have some general-- I'll say fine motions again, using the fingers-- and then if you've got a general purpose arm, meaning it's got like six degrees of freedom or more, then that seems like you've got a general purpose manipulation system.  And that's pretty tidy, right?  I didn't give you a lot of assumptions or anything.  But there are a lot of hidden assumptions in there.  Like for example, the world isn't composed of rigid objects.  There's lots of soft things.  In fact, maybe most of the things we want to work with are soft.  And there's liquids.  There's bulk things.  There's just multiple manipulations.  There's all kinds of stuff like that.  But then-- I mean, the other thing is that these hands are really complicated, and we really haven't mastered them.  I mean, I've mastered that one, and you've mastered yours, but we roboticists haven't mastered the robotic copies of these hands.  And why is that?  It's a funny thing, which is that if you look at practical systems, if you ask what's the most sophisticated autonomous manipulation system that's been developed-- it's a pretty hard question to answer-- but I'll just say I think one of the most impressive ones is a system that Mike Erdmann did one time, which involves two arms.  Each arm has just a palm, and by varying the angles and pushing this way, and it's automatically reasoning about lines of force and where the gravity is and how much friction there is and what the shape of the object is, and it's able to do manipulation of objects, all reasoning, and just using palms.  And you can look at some other systems-- a system done a long time ago by Lozano-Perez called HANDY; a system done at-- called FREDDY at Edinburgh University many years ago.  Both of those had relatively simple hands.  Well, HANDY-- actually I guess HANDY might have had .  Well, I don't remember about HANDY.  But anyway, and then if you look at what people do, you think, "Well, people have these kind of hands."  But look at somebody that's lost their hand that has a prosthetic hook, right?  They've got a very simple hand and they're still doing all kinds of stuff-- not as well, but they're doing pretty well.  Or you can look at a human being using a tool, a simple gripper, pair of chopsticks.  Or one of the most interesting things to look at is if you look at a surgeon using a da Vinci surgical robot.  Those grippers are very simple.  There's almost no haptic feedback; I think for all practical purposes there is no haptic feedback.  That's what people have been telling me.  There is visual feedback.  They do really interesting things.  They're folding-- you should YouTube Robotic Origami, and you'll see somebody folding a paper crane with two simple little grippers-- as simple as alligator clamps, really.  And so what we're trying to do is to say, "Well, let's look at devices that are so simple that they're very affordable, they're very light, they're rugged, we can use them, but maybe more to the point, they're so simple that we can understand them."  And then try to build up the autonomy from that understanding arising from the fact that we're using such simple devices.  Now, it makes a lot of things a lot harder.  I mean, the tidiness you have with saying, "Well, I'm going to have a device that's so complicated that I can conform to the shape of the thing no matter what shape it is and no matter where it is"-- right?  We don't get that tidiness anymore.  So if I have a very simple gripper that's going to go pick up, let's say, a bottle of apple juice by just squeezing it good and then picking it up, that's something a human being would do like that-- .  But our theories of what constitutes a stable grasp don't work for that, because the pose from which that grasp would be stable may not be available with a very simple device.  And what you see the human doing is to grab the thing-- even though it's not exactly stable where it is right now-- but you just squeeze it anyway, and when you pick up it adjusts, and you've got it, and it's not a problem.  So that's what we want.  We want something that I guess in a way has to be smarter, but can use simpler devices and develop an autonomous manipulation ability that way.</interviewee>
<interviewer>So you have a book with Ken Salisbury on manipulation?</interviewer>
<interviewee>Yes.  </interviewee>
<interviewer>Have you done-- collaborated on other things apart from that book?</interviewer>
<interviewee>With Ken, that's interesting. Ken and I have been such good friends, and we really worked together. I mean, even that book wasn't much of a collaboration, it was kind of a staple job. It was Ken's PhD thesis and mine, and then Ken tossed in some of his papers as well. I don't even remember if we wrote a forward for it or not. That book has been very good. There's lots of great things that Ken did in his PhD thesis, and sometimes when people cite it, it's cited as Mason and Salisbury, because M comes before S, so thanks, Ken, that was very nice. You can see some people who absolutely don't want to cite me for Ken's work, and they'll cite Ken's TR or something else instead, just to make sure that's understood. But I'm sorry, to your question about working with Ken, you know, I had an opportunity and when he first did the whole arm, the WAM Arm, you know, because I had kind of been working on related things. We talked about it, and I couldn't really figure out any way to help. Let me think about other things.</interviewee>
<interviewee>Yeah, but with Ken, we were talking about collaborations with Ken Salisbury. That's funny, I don't remember-- I don't remember ever actually doing something professionally with him, but I remember always visiting him at MIT when he was there, and we used to-- we did used to hang out together, so there was, I think there was a group that was a bit more fun and I don't know if this was a Stanford thing, or was it a west coast thing, or something, but all of a sudden I fell in with a gang at conferences that were going bar hopping, so I think I can tell you at least that much.</interviewee>
<interviewer>Yeah, who else was in that group?</interviewer>
<interviewee>Well Salisbury was in that group, Mike McCarthy was-- maybe I shouldn't be telling these things, huh? Mike McCarthy, I met him at a workshop in Minnesota, and I had no idea that, in those days, there was this really awesome music scene in Minneapolis, and Mike knew about it, and I think I met him and then five minutes later, we were headed down there to check out some of these bands. So it was a lot of fun. So I don't know if Mike is on your list or not, but he was a student of Bernie Roth's I think, and it was a lot of interesting history around, you know, mathematical kinematics, you know, which, I assume Bernie gave you all of that. Let me think, what's the question, other collaborators?</interviewee>
<interviewer>Yeah, and other people, the kind of social network as you were a student, and then that's also very interesting. </interviewer>
<interviewee>Yeah. Yeah, there was this group of people at MIT, so when I got there, Marc Raibert and John Hollerbach, and then Tomaso Lozano-Perez was doing one year at Yorktown Heights, and I believe he came back after-- halfway through my first year in graduate school. And between them and Eric Grimson, Ellen Hildreth, it was quite an interesting group. There was also ________ Robinstant [ph?] that showed up from Australia, visited for a while, and a Japanese visitor, Koji Fukumori and I'm going to be forgetting a few people. There was something going on, I guess, not that you would know it necessarily at the time. I mean, who knows, maybe you suspect it, but you wouldn't really know, or maybe the people that are kind of the more arrogant or, you know, or visionary, you know, actually believe it, but it did seem like maybe there should be a field of robotics, and maybe there was something new going on. There was, you know, in the way of publications, there weren't many, so my Masters thesis was published in the IEEE Transactions on System, Man and Cybernetics. There weren't any robotics journals, there wasn't really a conference, there was the-- there was an industrial conference. Mainly we were trading technical reports, we were reading the technical reports from Stanford, and we were reading our own technical reports and PhD theses. We actually put a book together that was a bunch of reprints. We kind of thought, well, you know, we're just trading these things among ourselves, if you don't have the good fortune to be-- to have landed in that group or a similar group at Stanford, how would you ever hit on this stuff. So we created a collection. Now I should say at that point, Mike Brady had showed up, and he's a real doer, I mean, he's somebody, when a lot of people are thinking, maybe we should do this, maybe we should do that, he's, you know, he's like, okay, I'm doing it. And you better jump on the bandwagon if you want to be part of it, because he didn't waste any time. But man, I mean, that combination really worked. I mean, Mike, and I wasn't really privy to the inner dealings of this, but Mike, together with Lou Paul, put together the "International Journal of Robotics Research" within a few years, and the International Symposium on Robotics Research, which was certainly at that time, the premier conference in robotics. And then I don't know exactly how it came about, but then it wasn't that much longer afterwards, that the IEEE International Conference on Robotics and Automation came along, and you know, so things kind of did evolve in the way that you kind of-- I guess you sort of imagine that we had an idea that maybe something like that was in the offing. But I don't think of it as the birth of robotics. You know, it's a certain step in the maturation of robotics, where it becomes, maybe more academically conventional and people can have, you know, conventional tenure track positions, and succeed. And before that, you know, an awful lot of the work that was being done was things that you heard about. Yeah, this guy had an AMF Versitran arm, and, you know, and all the things that they did with it. It's not written down anywhere, or if it was, it was hard to find. An awful lot of those guys were just these, you know, were people without PhDs, without academic positions, kind of, you might say kind of, you know, moving around from one group to another and so that's-- I mean, that was a real change, it was a change.</interviewee>
<interviewer>And concurrent with that, how did the Robotics Institute at Carnegie Mellon evolve? </interviewer>
<interviewee>Well, let's see, so I got here in '82, so it had started in '79. When I got here, Raj [ph?] told me that, you know, I mean the question is, I think, you know, everybody recognized at that time, that MIT and Stanford were, at least as far as academic institutions, sort of the two that were doing robotics in a big way. There were some other places, the Draper Labs in Boston, close to MIT, SRI, JPL, and then in the academic circles, there was some stuff going on at Illinois and Purdue, but you know, it seemed like Stanford and MIT, well, okay, I was at MIT, what do I know? I had my, you know, my-- maybe not the best vantage point, but that's the way I understood it at the time. And when I got here, Raj was saying, well, CMU is a more systems oriented place, a more-- less theoretically oriented, and you know, we're going to make things that work, focused primarily on manufacturing systems. That's kind of what I heard, and I-- you know, that may not be accurate. I don't know if you're going to interview Raj or not. You should get the original vision from him, I think. But it really changed, if it really did start that way, it changed quickly. When Moravec came, and when Red Whittaker, joined up, and when Marc Raibert showed up, I would say within a few years, we're already the number one place in mobile robotic systems. And with Takeo Kanade coming here, we're, you know, one of the top places in computer vision. And these guys were doing work, not just with industry, not just manufacturing applications, but also doing work with DARPA, and so with the Defense Department, and with the National Science Foundation, and then very strong sponsorship from NASA over the years, and the Office of Naval Research. So our kind of manufacturing orientation was a very strong element of the Robotics Institute for a long time, but it started broadening out right away.</interviewee>
<interviewer>And how did you decide to have a robotics PhD as part of the institute?</interviewer>
<interviewee>You know, that's a good question. And you know what, I don't really know the answer. I can only speculate. There are a few reasons. I guess, you know, things have to come together. All the reasons have to be right. So I mean, it's got to be intellectually right, and it has to be-- and you have to be able to solve kind of the kind of logistical, financial, structural issues as well, and in this case, everything was just right. I think people saw robotics maturing and were excited about it as a field, and that goes back to the origins of the Robotics Institute. There was a very strong support for it from our most valued leaders, Allen Newell in particular, and then the president of the university and so forth. So intellectually, it just kind of worked. I think we've always had people who were interested in new things, you know, in creating new enterprises, and so that certainly fits, and then on the structural and financial side, it just kind of works better-- worked better for us to have our own PhD students, rather than to be borrowing, so to speak, PhD students from other departments. So-- so-- but I don't know the details. Raj would know.</interviewee>
<interviewer>When did you become director, and then--</interviewer>
<interviewee>About six years ago. How did that happen?</interviewee>
<interviewer>How did that happen, yeah.</interviewer>
<interviewee>Yeah, well that's interesting. Most of my-- I think people would-- I haven't been in close touch with year by year, may be shocked to discover that I was doing this, because in the old days, I always kept my head down. I thought you had to be insane to want to be a department head and so I was always the guy who would try to duck out of every administrative job, you know, committee work and so forth. I really wanted to focus 100 percent on research and well, you know, you want to do a good job teaching, so I would try and do all right with teaching as well, but I had no interest in management. And so what happened? Well part of the problem is that Pradeep Khosla I used to hang around a lot with Pradeep, and he was always talking to me about this. Obviously he saw things in a different way, as you might imagine, from his rise in the academic administration, so actually he did have an influence on me. Takeo tricked me into running the robotics PhD program, and you know, and that has its rewards, so I guess I fell in, over to the dark side, bit by bit, influence of former friends, good friends, and then, I don't know, as far as the actual event, you know, it's funny, because Chuck Thorpe was the director just before me, and I imagined that Chuck would be the director for ten years, so I wasn't really thinking about it at that time. I mean, I had, when Takeo first stepped down, I thought, well maybe I do want to do this. But when Chuck, after Chuck had been director for a year or two, he announced he was going to step down and go be the dean of the Qatar campus of Carnegie Mellon, and then at that point, well you know, it's more or less the faculty voting on who's least likely to give them trouble, so that's not an actual vote.</interviewee>
<interviewer>What's your vision for the future of the institute?</interviewer>
<interviewee>Oh boy, I should have prepared for this question, huh?</interviewee>
<interviewer>Where do you see robotics going? </interviewer>
<interviewee>Well robotics is-- let me try that one. That one's easier. Okay, so here's my view of robotics. Robotics is about the idea that a machine can do the kind of things that people do. And you might extend that and say, well people and animals, depends on, I guess, what you think animals are doing. You know, can a machine have purpose? Can it be perceptive, can it be aware of what's going on around it? Can it actually interact meaningfully, purposefully with the physical world? It's a question that has actually been on everybody's minds for centuries, right? This isn't a new question. There are stories about the Gollum being made from mud, and you know, machines that have been built through the ages that have mimicked living things, one way or another, somewhat superficially I would say, but now we're trying to do it in a much deeper way, right, and maybe the most, kind of profound way. Can we do the things that people and animals do? And robotics, what makes robotics different, and this is-- I guess this is the 50 year thing that brings this up. I mean, I think what happened 50 years ago, was that the final pieces were in place, where you could see that this might really be possible. The final pieces being, well computers, electronic cameras and intellectual elements, feedback, control theory, and so about 50 years, I think, about 50 years ago is when there comes the first plausible idea that we might actually have the kind of technologies we need. And I think that's actually been proven now. So if you watch a RoboCup soccer, you know, if you watch a bunch of little Sony Ibo robot dogs or cats, whatever they are, playing soccer, they're-- they know where their players are, they know where the ball is, they know where they are, they pass, they shoot, they play defense. I don't think it's possible in ordinary-- in an ordinary sense, in a common sense way, to watch that and without getting the sense that machines can be aware of their surroundings, right, and it's easy to forget that, you know, it was not at all clear that a machine was-- that a machine could do those things. And now I think it is clear. It's not that they're as good as humans, you know, humans are still way ahead of them, and cats and dogs are still way ahead of them, but I think they've crossed that boundary where you could say, yeah, you know, you've got to admit, machines can be where they do perceive, they do have purpose, they do act purposefully. So that's where I think we've gotten to. Where is it going, well one thing--</interviewee>
<interviewee>Well let's see, yeah, I was onto the spiel about robot-- about Ibo and RoboCup and--</interviewee>
<interviewer>You were going to say where it's going.</interviewer>
<interviewee>Yeah, well so one of the things that's happened is that our sense of what use this technology can be, has also changed. It's a strange thing, when you start out, you start with, well we want to build, you know, we want to build a dog. Well you've got to be able to see, you've got to be able to run around, you know, so let's work on seeing, let's just take seeing for an example. We need a vision system, right? You build a vision system, and well, in the process, first off, you discover that it's very, very-- it's a rich problem, there's numerous different technologies that can come together or be used independently, and then you start looking at all the applications of them. So right now, we have machine vision systems, but mostly they're not in robots, right, mostly they're out doing other things. Probably the most common thing for a machines vision system to be doing is the systems that recognize faces in your digital cameras, to do the auto focus, to help with auto focus, right? People look at that, and say, hey, they don't think of a robot, right, there's nothing in there that's necessarily a robotics technology, it's a technology that might have been inspired by trying to emulate what animals and people do. And it has this other use. Well, I mean, that's just the beginning. The most-- some of the most interesting ones or mind bending ones that I'm aware of is for example, teaching kids to read. So there's a project here called, Project Listen, that Jack Mostow [ph?] is involved in. And it's simple, they're using voice recognition software, to build reading tutors. They're using the kind of cognitive models that our psychology department has come up with over the years, there's an algebra tutor program. Well they developed a reading tutor program. The program knows what the text is, and it has models of how humans, you know, of how kids learn, and what kind of issues they're dealing with as they develop. And so with that, you can have an informed interaction with the student to teach them to read. I don't think, you know, I don't think people ever really thought that much about how profound that kind of thing could be, a long time ago. I mean, when you start having the technology available, you see these things. The excitement in it is not that you're doing within that wasn't being done before, I mean, a human teacher, at least a skilled human teacher is still better than the computer, but the computer doesn't have to compete with a human being, right, most of the kids, if they're learning to read at all, they're reading in classrooms where generally, they're reading alone, to themselves, right, and the teacher is maybe going from student to student, and they're interact-- individual interaction with the teacher is rather rare. The computer is competing, not with humans, but it's competing with inattention, right, and computers are very cheap, they're getting cheaper all the time. Microphones that you can do speech recognition is very cheap, so it's an opportunity to provide a service, namely, I mean, a really important on, namely education, in ways it couldn't be-- and to people where it couldn't be delivered before. So you know, another example of that would be-- another, I'll say kind of unexpected application, would be watching mice. The-- there's a company in Manhattan, called, PsychoGenics. They test drugs by giving them to mice, and watching to see how the mice behave, right? So ordinarily a human being would be doing this with a clipboard and watching what the mouse does, and writing it all down and so forth, and it's very expensive, not because of the expense of the mouse, but of the human being. Well, they came to us, we built some instrumented cages for them that can measure, I think there's a force plate on the floor, I believe there's a puffer that can blow air at the mouse, there are cameras so that it can see where the mouse is in the cage, and behavior recognition software that classifies the mouse's behavior tick by tick, and then machine learning software that's classifying the behavior of the mouse and running the drug testing protocols. And all of that can happen now autonomously. The point of this is, again, it's not that it's doing something that you couldn't do before, but it's-- it can do it-- it transforms the economics of these experiments, which in turn, has the potential to transform the economics of drug discovery. So these things weren't on the list. Right, what was on the list before, home butlers, right? This seems-- I don't want to say irrelevant, I'd love to have a home butler, you know, but compared with delivering education across the digital divide, or dramatically changing the cost of lab experimentation, right, those things seem very small. So that's one answer. It still doesn't say where it's going. </interviewee>
<interviewer>Well how do you see the Robotics Institute's role in the future of robotics? </interviewer>
<interviewee>Well, let's see. So let me give you my excuse, first, my non-answer. The Robotics Institute, you know, we're a university department. We have, depending on how you count, somewhere between 40 and 100 faculty, and none of them are looking to me for direction, so the title, director, is more of a courtesy title. So they're all doing their own thing, they're all visionaries. A lot of times, strategic planning is more a sense of looking to see what they're doing, and maybe trying to extrapolate a little bit, connect the dots, and then run out in front, you know, grab the flag and run right back out in front of the mob, and then pretend like you're leading. So you know, five years ago, we went through one of these exercises and we discovered there had been a big transformation, which is what we call Robotics and Life. [ph?] So in the old days, when the Robotics Institute started, we were focused on motivating robotics by looking at things that people wouldn't want to do, or couldn't do. So space exploration, you know, hard vacuum, long distance, cosmic radiation etcetera, etcetera, right? It makes a lot of sense that we should send machines to space. Mines, mining, even manufacturing a lot of times, is very tedious and dull, and people would rather not do it. It's hard to sometimes fill some of these jobs. Agriculture would be another example of that, right? So this is what people called the three Ds, dull, dirty and dangerous jobs, right, and that's how we used to motivate robotics. But you know, implicit in that is the idea that we're replacing, you know, we're trying to figure out how to get machines to do things that otherwise people would have to do, replacing humans with robots. And what we've figured out within the last five or ten years or so, is that the most exciting applications in robotics are working with people. So medical robotics, socially assistive robotics, quality of life stuff, helping elderly stay out of the nursing homes, live independently in their own homes longer and longer, rehabilitation, education that I was talking about. So there's a long, long list of these things, and that is, I think, where the most rewarding applications are, and where some of the most exciting work is. So this is what we figured out about five years ago. The advisory board came, there was an interesting faculty meeting one year, where-- this was when Chuck was director, and he said, well-- oh yeah, and the president of the university was visiting, and Chuck, without having prepared, just said, well let's have a show of hands, how many of you are doing right now, some application that involves human interaction or human robotics, or something like that, and we were all stunned, because more than half of the hands in the room went up. So this is an interesting change, and not just at CMU, all over the world of robotics, very interesting stuff. Now did you ask me about five years ago, or about now? </interviewee>
<interviewer>The future.</interviewer>
<interviewee>The future. Yeah, I don't know, it's interesting. I don't know, is Maja Mataric on your list? I heard her saying that socially assistive robotics might end up being the most significant application. That, I think, is a really interesting idea. Where is it going? I guess what I've-- maybe my conclusion from all of this, kind of the proliferation of applications, you see the appearance of applications that are completely outside of what anybody imagined. I have a pretty humble attitude, I think, about trying to project what's going to happen in the future. If you ask yourself, what are the applications of robotics, well let's see. So if you just think back a few years, in fact, maybe this hasn't really changed. I mean, if you just look at a computer, and you ask, you know, what are the applications of a computer? Well it's a lot, but you know, still, you look at it, and how does it get sensory information? Well, it's not that much, you know, it's getting stuff over the internet, but other than that, it's keystrokes. You know, what kind of actions can it take? Well it can't do much. You know, if you imagine that you, yourself, are in that situation, you're locked inside of this box, you know, interacting by putting pictures up on a screen and getting keystrokes, well you wouldn't really be able to do much, right? So comparing an animal or a human being with that, is, I think, really mind blowing. What are the applications of a human being? Isn't, you know, if that's what we're doing, if we're finding machines that can do the things that human beings do, it's like asking, what are the applications of a human being? But without all of the constraints, right? So I mean the reason that the reading tutor works is because they're so cheap. I mean, they're just impossibly cheap, right, you can't train the human beings and get the human beings in place that can do that. It's the same thing with the mice, right? Why are they successful in space? Red-- I think I've heard Red say, every space mission, every robotic space mission is a suicide mission. You know, you can do things in space, obviously, you can't do with human beings. They can be small, they're not all soft and squishy, right? So well, okay, so that's just another excuse for why I don't have an answer, but immediate future is great. One of the best arguments I have for the future of robotics is just to show people the level of activity in the Robotics Institute, which started at a million dollars a year, in 1979, and it's running at 63 million dollars a year right now, and almost without exception, it's been exponential growth through its whole history, despite the so-called failure or disappointment of robotics in the '80s, despite ups and downs, the trend seems very obvious. And it's an interesting phenomenon, it depends on several things working right, but one of them is that there's just no limit in sight, to the applications. </interviewee>
<interviewer>Do you see any limitations to where robotics can go? </interviewer>
<interviewee>I mean, not fundamental, no. No. Everything looks good. People are excited about it, that's the main thing. The excitement is justified.</interviewee>
<interviewer>What would be your advice to young people who are excited about robots and are thinking about a career in robotics?</interviewer>
<interviewee>You should do it. </interviewee>
<interviewer>How would they go about it?</interviewer>
<interviewee>Sometimes they're slowed down. So you know, we do have people that come in and say, well, I don't know, is the robotics industry really going to take off? Are there going to be jobs? And that's too narrow a way to look at it, right? If you say the robotics industry, well there is a robotics industry, and it's doing great, but that's just the tip of the iceberg, right, the real payoff is in how it permeates all industries, and so if you look at where the robotics PhD students have gone over the years, and most of them haven't gone to places that you think of as a robotics place. A lot of them are at Microsoft Research, they go to Microsoft, Google and Intel, financial companies, all over the place, NASA, of course. And you asked, how do they get started? Well, we're again having-- we're going to have a problem, because it is so broad, right, there's many, many different thing to do in robotics. If it's your aim to do a PhD in robotics, then you should study hard, you should get good grades, you should study math, and you should go home and build stuff. And what stuff, you know, in my day, people were working on their cars. That's not as easy as it once was. I started building radio controlled cars about ten years ago. That's pretty great. Radio controlled model airplanes, some people I know used to build helicopters, and then these days, the really amazing thing is, suddenly, robotics as a hobby has developed into something really interesting. Subscribe to Make Magazine, learn to build flame cannons in your back yard. Don't tell the CMU lawyers I said that. </interviewee>
<interviewer>You mentioned the failure of robotics in the '80s, or the discord of the--</interviewer>
<interviewee>The so-called. The so-called.</interviewee>
<interviewer>Yeah, yeah. Could you just tell us a little bit about that, and how actually people managed to kind of, in a sense get out of it? </interviewer>
<interviewee>Yeah, I don't know, you know, it surprised me when I was looking at our charts and I realized that you didn't see a dip in the funding because of that. I mean, what happened was that in the '80s, or late '70s, the hype about robot-- the robotics revolution, about it revolutionizing manufacturing, was really over the top, and a lot of venture capitalists and others, got excited about it, and there were many, many companies building, basically arms and hands for manufacturing. And at some point, the floor fell out and almost all those companies went belly up or-- a lot of them were companies that were trying it, and had other things to do. They just stopped. Why-- why did that not have a serious impact at CMU? I think the reason is because-- well there's two reasons. I mean, one reason is because the technology is so fundamental, I don't know if that's the right word or not, so basic to so many different applications. I mean, the ability to perceive your environment, you know, if you put it that way, it's like, does that have anything in particular to do with manufacturing? No, that's just everything, right, it has to do with everything. So there's that. And then there's the fact that the faculty here are extremely agile, adept, even proactive at anticipating downturns. I'll cite another example, which is that we were-- we did have an enormous run up in funding from the defense department for unmanned ground vehicles. And when there was a downturn, the faculty had basically anticipated it, and have replaced that with funding from other sources, mining, agriculture and other things. So you know, I guess one way of looking at it, I mean, I look at this as evidence that there's an untapped reserve, that there's, you know, we haven't seen the bottom of the resources that are available for developing the technology. </interviewee>
<interviewer>Is there anything that you'd like to add, that you think we missed, or-- </interviewer>
<interviewee>No, history of robotics and 50 years ago and stuff like that. Oh, I don't know. I'll say this. Yeah, I'll say something, which is that I think the most important thing robotics can tell us is about ourselves, and this gets back to a question that was asked earlier, you know, did I-- had I pondered the mechanics of pushing, or trying to do it with a robot, and the answer was no. I don't think we have a sense of how hard it is, what we do, or even in detail, what it is that we are doing, until we try to do it ourselves. And you know, when people ask, well what's the number one lesson that we've learned from robotics, maybe it's, we've learned just how hard it is to do these things. So you know, wasn't so long ago, everybody was impressed with how difficult chess was, and then you know, computers started competing at grand master level in chess. Well, we're still not competing with humans in what we generally regard as the most trivial of physical tasks, and as you ponder that, and you start asking questions like, gee, how hard is it to, let's say, figure out what's the best way to jump, you know, how high could a human being jump, what would be the best strategy to jump? These are really hard questions, right? I mean, the world of jumping was transformed several years ago, you know, with the Fosbury Flop. You think, wow, you know, after being in these bodies for, I don't know, somewhere 500,000 years or five million years, we're still discovering how to operate them, you know, in fundamentally different ways. That kind of fits in with robotic experience, which is that motion planning and control and so forth, that these problems are fundamentally very difficult. So our progress, you know, with robotics, I think, not just at such an overall level, but, I think, in detail, can help us to understand what we're doing. </interviewee>
<interviewer>Do you think, once we build a RoboCup team that can beat the world cup team, that will diminish our appreciation for soccer? </interviewer>
<interviewee>Diminish appreciation for, no, I don't think so. I don't think-- I mean, if it turned out that somebody said, oh my gosh, you know, there's this-- we just didn't think of it, we should have been using left handed screws instead of right handed screws and then everything is simple, you know, unless it's something really stupid like that, or like, you know, oh, Frankenstein, he hit the dead body with electricity, that's the secret of life, right? If it turns out to be something that simple, then I guess that diminishes our appreciation, but like most people, I don't think knowing the nature of stars actually diminishes our appreciation of stars, and I think human beings are going to be way more interesting than stars, already are. </interviewee>
<interviewer>Great. Thank you. I think there's somebody</interviewer>
</interview>
</subject>
