<?xml version="1.0" encoding="UTF-8" ?>
<subject>
<name>Bob Mcgee</name>
<interview>
<interviewer>You know the various people you collaborated with, the projects you worked on. That kind of thing. So you can start and then we can ask you questions.</interviewer>
<interviewee>Right. It will be highly rigged [ph?] and you ask anything you like.</interviewee>
<interviewer>Okay.</interviewer>
<interviewee>Okay. I was born in Detroit, Michigan in 1929. I grew up in that area and in northern Ohio around Toledo, Ohio. I did my undergraduate work at the University of Michigan, graduating in February of 1952. I got married on that date and after a few months I was called to active duty as an ordinance core officers with the United States Army. I served as a guided missile maintenance officer for three years and then I was fortunate to get a scholarship for my graduate program from Hughes Aircraft company. I moved to California, started studying at the University of Southern California and I received my Master's degree in 1957. And then with further help from Hughes and their PhD program I completed a PhD in 1963. I joined the faculty at University of Southern California at that time and in 1968 I moved to Ohio State University in the Department of Electrical Engineering in both cases. And I was at Ohio State University until 1986 when I moved to the Naval Postgraduate School. I retired from the Naval Postgraduate School in 19--no, in 2005- 2005. So that's my educational background. My research-- my mainline of research arose from my curiosity at a very early age to try to understand animals as machines, animals and humans as machines. And that aspect of my research interest got going in a really solid way in 1964 when I was at the University of Southern California. Professor Rajko Tomovic of the University of Belgrade was visiting and he got me very interested in the use of electronics to build improved lower extremity prosthesis with electronic joint coordination. That led to a general interest in human and animal locomotion and to a series of walking robots, which carried me until about 1990 I stopped working on walking robots. After that, my research was centered on unmanned submarines and especially on navigation and mission specification and control for unmanned submarines. So I have-- there are many collaborators I have not mentioned at all of these institutions. And I received outstanding support from the National Science Foundation over a long period of time for my research and also from the defense projects-- Defense Advance Research Project Agency as well as many other smaller grants and support from the universities I worked for.</interviewee>
<interviewer>So when was the first time that you became interested in robots?</interviewer>
<interviewee>In what we normally call robots, walking robots, 1964. But before that guided missiles, in those days, were considered to be a kind of robot. So I became interested in guided missiles when I went into the army in 1952 and I worked in that field at Hughes Aircraft Company and what I learned about avionics and dynamics as it related to missiles carried directly over into studies of walking.</interviewee>
<interviewer>Is there something particular that got you interested when you were working in the army about the guided missiles? What kind of--</interviewer>
<interviewee>No, I was just generally fascinated by how it was possible to imitate human function in a machine. I was involved in-- while in the army, I was involved in ballistic missiles, which got me interested in inertial guidance while working at Hughes Aircraft Company I worked on air-to-air and i-tank [ph?] missiles. I found that fascinating and everything I learned carried over to the study of human posture and human walking and animal walking.</interviewee>
<interviewer>Were you aware of cybernetics and, if so, were you interested in that?</interviewer>
<interviewee>Yes. Yes. There was a book called "Cybernetics" that appeared with a very well-known author from Cal Tech, a Chinese gentleman who's name has flown out of my head. And that was engineering cybernetics and Norbet Wiener's book called, "Cybernetics," was read by a lot of people then. Yeah, that was inspirational definitely.</interviewee>
<interviewer>Chen [ph?] I think.</interviewer>
<interviewee>Chen, right. Wonderful book.</interviewee>
<interviewer>And what was the first robotics system that you worked on or the first thing that you called a robot.</interviewer>
<interviewee>If-- yeah, the first thing we called a robot was a machine called the phony pony at USC and actually George Becky [ph?] and I worked on that project together along with a wonderful graduate student Andrew Frank whose now on the faculty at UC Davis and the phony pony was, I believe, the world's first electronically coordinated walking vehicle. It walked in 1966. </interviewee>
<interviewer>Why was it a pony?</interviewer>
<interviewee>Because it wasn't real. </interviewee>
<interviewer>So what's your definition of a robot?</interviewer>
<interviewee>The definition Dr. Becky used today and his talk was rather good, I think, a machine that senses, processes information, and acts- acts physically within the environment, interacts with the physical world. That's good enough.</interviewee>
<interviewer>I was curious have you seen kind of the definition of robotics change at all through time?</interviewer>
<interviewee>Yes, I think I have. I think when I first began working in the field robots were thought of as humanoid machines they appeared in science fiction and the, of course, the word originates from Capek's play, "R.U.R." And it-- then as industrial robots came into being the term acquired a broader meaning and I think Dr. Becky's definition is as good as any for what the contemporary notion of a robot is.</interviewee>
<interviewer>And so after the phony pony what other projects did you work on?</interviewer>
<interviewee>Okay. The phony pony was a very successful project in the sense that it established that a finite state [ph?] machine could coordinate the motions of a walking vehicle and that machine could be either synchronous or a-synchronous. It also showed us that that wasn't enough for any kind of useful vehicle. We thought it would be enough to control lower extremity prosthesis and that's turned out to be the case. Those prosthesis have come into widespread using all in the past couple of years. They do use finite-state controls so far as I can tell. Very much like what we postulated in 1966, but in terms of a vehicle that's not enough. We realize right away that underneath the finite-state control we needed some kind of coordination. No, that's not precise enough. We needed to have continuous state space taken into account and we needed kinematic and dynamic control of leg motion in order to create any-- create a walking vehicle that might be useful for something. The phony pony was nothing more than a technology demonstration, very important. It showed that finite state was sufficient to coordinate walking, but doesn't get very good results all by itself. So the next machine built based on the phony pony experience and with wonderful financing from the national science foundation was dubbed the bionic bug. It was a six-legged, 300 pound walking machine that had supervisory control, continuous state space control of foot trajectories and which, very importantly, utilized horse [ph?] feedback to achieve artificial compliance-- electronic compliance and used gyros for attitude stabilization of the body. It was a supervisor control machine controlled by a joystick, but all of the leg coordination was accomplished by a computer that was the next machine. And that machine produced a lot of basic results and a number of PhD dissertations and provided the basis for the next project, which was the DARPA [ph?] Adaptive Suspension Vehicle.</interviewee>
<interviewer>People _________________ that one. Who worked on the bionic bug with you?</interviewer>
<interviewee>Oh, lots and lots of people. It's impossible to give everyone credit. Mostly graduate students. Mostly myself and graduate students. One person comes out as a standout, in my mind, and that effort-- that's Professor David Orin of Ohio State. He did some of the most basic work, but there were many other graduate students who contributed to various aspects of the project.</interviewee>
<interviewer>And the next one?</interviewer>
<interviewee>So the success of the bionic bug, which by the way I got the Center Proxmire [ph?] Annual Award, Golden Fleece award because of that name. It was not well thought out and because of that experience we didn't call-- we didn't use the word walking at all in the description of the Adaptive Suspension Vehicle. We wanted a dull name and we found it and we were never investigate. The purpose of the Adaptive Suspension Vehicle was to scale up the bionic bug to a useful size and what DARPA asked us to do was to see if we could produce a walking vehicle, capable of keeping up with infantry and carrying a thousand pound-- 2,000 pounds, pardon me. So because of the payload requirement and it was intended to have a human driver. Because of the payload requirement, it had to be a big machine and it was. It weighed 7,000 pounds and that was a really big effort. That effort produced 30 PhDs and about an equal number of Master's degrees. And I had-- my most important collaborator in that work was Dr. Kenneth Waldron who is now at Stanford and who still works on walking vehicles. </interviewee>
<interviewer>What were some of the main challenges, both technical and in terms of the intellectual side?</interviewer>
<interviewee>The biggest challenge perhaps was finding an efficient means of applying torques to the-- or actually force as it turns out linear actuators of applying with sufficient bandwidth and energy efficiency controlling the motion of 18 joints. And it required very innovative developments in hydraulic system design and we succeeded. We operated 18 joints with a motorcycle engine. That was the biggest challenge. The second biggest challenge was integrating information from an optical radar system to coordinate stepping motions and on even terrain. We succeeded in doing that also. And then there were many challenges that we can say were technological rather than scientific. Personal computers had just appeared and that made the project feasible. We built the Adaptive Suspension Vehicle just as soon as it was technologically feasible. It had, as I recall, 16 PC boards in it and one special purpose computer. So that was a big technological challenge and that all worked.</interviewee>
<interviewer>So before it all worked and you came to the tests, were there some avenues that you turned to that weren't quite as successful?</interviewer>
<interviewee>Oh, sure. We tried everything. Oh, we tried everything. There are many alternatives for mechanical design and we settled on a particular design that was Dr. Waldron's idea that worked out very well. And there were many approaches to coordination. We didn't understand at the beginning that legs in a supporting phase should be operated on pure force feedback mode. The bionic bug had used electronic compliance, artificial compliance. But the Adaptive Suspension Vehicle used what, I think, Mark Raibert "hybrid control" for legs and contact with the ground. They were operated on pure force feedback mode. The position of the supporting leg didn't matter. If it slipped, it didn't matter. But legs in the-- of the ground were operated in position feedback mode, velocity and position feedback. And we used Jacobian [ph?] control. We never used inverse dynamics on-- that was a big accomplishment in the bionic bug. We did not use inverse dynamic-- inverse kinematics, pardon me. We used Jacobian control.</interviewee>
<interviewer>And so how did that and feedback feed into?</interviewer>
<interviewee>The ASV?</interviewee>
<interviewer>Yeah.</interviewer>
<interviewee>Same way except the-- except it applied-- it was simpler. The ASV kinematics were simpler. It used a linkage mechanism, which the bionic bug didn't. But-- well, I think that's enough on that subject.</interviewee>
<interviewer>And so you had mentioned in the beginning this whole notion of looking at animals and humans as key. </interviewer>
<interviewee>Right.</interviewee>
<interviewer>And how did those ideas feed into some of the work that you are describing?</interviewer>
<interviewee>Okay. Very much so. Our experience with the phony pony showed us that if we wanted a heavy-lift walking machine and if it were going to be so big that it couldn't crash. If you have a 7,000-pound vehicle that's 10 feet tall, it won't sustain a crash. So this not a laboratory experiment. This was an outdoor vehicle and so from studying animal locomotion we understood that the requirements for dynamic balancing in four-legged creatures was not something we could match at that point and time. It's too demanding. So that told us clearly we should go to six legs. The question was what gates to use, so we studied animal gates to get some idea on that subject. And prior to that some Russians, Basonoff [ph?] in particular had shown the optimality of a class of gates called wave gates. And we used those exclusively on our-- on the ASV except for walking through obstacle fields. And there we used what we a free gate online optimization, not periodic.</interviewee>
<interviewer>What particular animals did you?</interviewer>
<interviewee>We looked at grasshoppers and-- they're the only animals in which we actually did original research. And we discovered, which was not known to biologists. We discovered that grasshoppers switch gates when they encounter obstacles. They tend to pair their legs when dealing with obstacles. And in ordinary walking on smooth services they typically use tripod gates or some other wave gate. So we adapted that to our walking machine gates.</interviewee>
<interviewer>And were some of the places where you tested out the machine?</interviewer>
<interviewee>Oh, it was tested in an outdoor environment at Ohio State University. We also took it to, in the latter stages of the project, to the Piedmont area of Virginia and tested its capabilities on the soft soils found there.</interviewee>
<interviewer>And did it end up going in-- was it applied?</interviewer>
<interviewee>Never applied. Never applied. John Deere Corporation advertised a six-legged walking vehicle that I think was designed in Finland. I think was-- I think Professor Hallmay [ph?] was and the University of Helsinki was involved in that design but no one bought any. The only successful applications I know of up to the present time of walking machines in the most general sense is the very great success achieve in the past couple of years in powered-lower extremity prosthesis. They're now accepted. Now, paid for by Medicare and the Veteran's Administration. So that was our original mode-- motivation. That's what I started out with Tomovic. Our first paper dealt with coordination of motion for powered lower extremity prosthesis and our position was we thought that neuro-feedback was not required. That the interface between a powered, lower extremity prosthesis and a human being could be purely mechanical. Turned out to be true.</interviewee>
<interviewer>And so after the ASV, what came?</interviewer>
<interviewee>Submarines.  The ASV had a human driver or was more like a pilot. Driving it was like flying a fly-by wire airplane. And it was very easy to drive, but we required a pilot. And I became interested in how we could automate the pilot's function. So I got a good offer from the Naval Postgraduate School and I came here to work on submarines. And I worked in two areas on submarines, submerged navigation and mission specification and mission control. So we did succeed in replacing all of the functions of a human crew in a unmanned submarine. I think we were the first to do. I think we were the first to include explicit mission planning and control. And I think we-- well, we did it because we're a naval institution. We replicated the division of responsibilities on a submarine, electronically. And it led us to a tri-lingual software system. An imperative language for the-- for what amounts to the work of the crew physically controlling parts of a submarine. Lisp [ph?] or some functional language for coordination of the activities of the members of the crew, so the bottom level we call the execution level. Middle level, we call the tactical level. And then at the top level, we use Prologue [ph?] to specify an operational doctrine and to write mission orders. Reason for choosing Prologue is we felt and I feel that it's a language that a naval officer can read without being a programmer.</interviewee>
<interviewer>So did you work with the Naval officers while you were developing this?</interviewer>
<interviewee>Oh, yes. Submarine officers were the primary people who worked in our project here and there were many of them, 30 or 40. It was a perfect environment for that work and we did operate our submarine in Monterey Bay with, I don't-- tri-lingual paradigm, a sun spark workstation running Prologue on top. We didn't use Lisp in the Bay, I don't think. I don't think so, but we used Prologue at the top level and then functional programming at the next level, and imperative programming running a separate processor. We separated the real-time-- the hard real-time parts ran on its own processor written in C++, I think. And the strategic level, the function of the captain, was written in Prologue and ran on real time with no problems.</interviewee>
<interviewer>What was the hardest kind of officer human task to automate through your system?</interviewer>
<interviewee>Good question. Probably-- I don't know.  It was a very big team effort. It was hard to get two processor-- at that time, to get two processors with different operating systems running different languages, it was hard to get them all to work together. That's the difficulty I was most aware of. Not hard now. I'm still playing with this and Lisp and Prologue run together fine on my $300 netbook and at that level, the physical submarine just looks like a line printer or a mouse or something else. It's very natural. </interviewee>
<interviewer>So who were some of the people who worked with you on this particular part of the project. You mentioned there were a lot of officers?</interviewer>
<interviewee>The submarine project? Yeah, I can really only mention faculty in that case. My co-investigator and most of the time the leader of the project, in fact, all of the time the leader of the project was-- of the main project, was Dr. Anthony Healey of the Mechanical Engineering Department who's now retired.So besides that, a very important person up to the present time is Professor Brutzman, who was at that time a naval officer and is now a faculty member, Profession Donald Brutzman, who is a faculty member in the moves curriculum at the Naval Postgraduate School, and many other faculty and technicians, too many to name.</interviewee>
<interviewer>And so that let you to what's the next?</interviewer>
<interviewee>Okay.  Well, it led me to retirement, but I didn't stop at retirement.  On a volunteer basis I still work with the postgraduate school.  Most of all in the lab where we are and what we've done in this lab is adapt submarine inertial navigation technology to human foot tracking and that's an area that shows great promise and I'm very interested in right now.  Recently I've been trying to revive our work on trilingual, we call it rational behavior architecture, trilingual control approach as a means of achieving transparency and accountability in military robots.  I still believe that a naval officer can learn to read prolog in less than a day and would be able, as a naval officer, to say, "yes, this operational doctrine is correct.  Yes, this mission is correct.  I accept responsibility for it".  That's what I want to achieve.  If we field lethal robots, military officers should be able to assume the same responsibilities as they assume with respect to human soldiers or human sailors, and I think that requires a language that can be understood by any naval officer during court-martial proceedings or whatever ensues.  </interviewee>
<interviewer>For a normal officer, they would have to know human fallibilities.  Would an officer, even if they were able to prolog, wouldn't they also need to learn the type of fallibilities?  </interviewer>
<interviewee>I think all naval officers know about human fallibility.    Go ahead.</interviewee>
<interviewer>What about the technical fallibilities of the robots?</interviewer>
<interviewee>Sure.  They have to know something about that.  That's a very good question.  Knowing something about fallibilities is different from knowing the details of how a task is accomplished.  I suspect-- well, I don't know how naval officers are trained.  Probably they, I'm sure they put their hands on the submarine and they drive the submarine themselves.  So I think any naval officer who would be involved in using autonomous submarines would know about the physical fallibilities of such a submarine.  He wouldn't typically know all the details about say, what could go wrong with execution level software.  He might not understand real time systems.  But the whole idea of task abstraction and language abstraction in this setting is to allow people with different specialties to assume responsibility at different levels.  So a senior officer would, in an ideal world from my perspective, and prolog is just the current state of the art as far as I'm concerned, no doubt better languages will appear.  But an officer at the level of a submarine commander would say, "I accept responsibility for mission specification and mission control written in prolog".  Then an officer at the level of officer of the deck would have to learn LISP, or whatever language was involved, and say, "I accept responsibility for the LISP code.  It does correctly implement functions like, go to the surface, return home, find a target".  I sign off on that and assume responsibility for it, and then another person at a different level would have to say, "yes, we've tested the real time control system in the laboratory.  The control surfaces moved like they're supposed to.  We've done at-sea trials.  The GPS works."  I sign off on that.  It would be three different people at least and each of them would understand functionality at their level of responsibility.  </interviewee>
<interviewer>How far do you feel that you've gotten towards this goal?</interviewer>
<interviewee>I think we're ready to do it.  We've done it.  We did it in the bay in the late '90s and then things happened in my life so that I disappeared for a while.  Family problems took me out of circulation for a while and now I hope we can get something going again at that level.  NPS has a very successful and active program in unmanned, undersea vehicles.  But at this time, the focus is not on mission control.  </interviewee>
<interviewer>What are they focusing on?</interviewer>
<interviewee>I'm not well-informed.  It would be better to talk to somebody in that area.  But I know they have more advanced submarines, that in the past few months they took delivery of a larger, more-effective submarine, and their concern is from the perspective of irrational behavior architecture, their concern is with the tactical level and the execution level, not with the strategic level, so far as I can tell.  It's not a criticism.  They know what they're doing and they're pursuing their goals effectively.</interviewee>
<interviewer>What were some of the reactions when you succeeded and actually--</interviewer>
<interviewee>When I did what?</interviewee>
<interviewer>What were the reactions to your success of actually getting things working?</interviewer>
<interviewee>Boredom.  No one has picked it up.  It's been lying there for ten years and I would like to get work going again.  Well, that's not quite true.  I am aware that there's a large Air Force program to standardize natural military language across the branches of the service and I have forgotten the name of the program exactly, but I-- right.  Okay, let's come back to that.  Are we ready?</interviewee>
<interviewee>Okay.  As to why this didn't catch on, first of all, I dropped the ball.  It was for personal reasons.  Things happened in my family.  I had to take time out, very serious things.  So I dropped the ball.  Another thing was there were hardware problems.  It wasn't very easy to combine a hard real time JUSPAQ [ph?] computer operating under OS-9.  It wasn't easy to combine that with a Sparkworks station running UNIX and it was only because of the skill of our officer students and Don Brutzman that we managed to make it work.  So then Quintus Prolog went out of business and until five years ago, or six years ago, there was no, in my opinion, no really viable PC prolog around that had the capabilities of Quintus Prolog.  Now there is and it's wonderfully combined seamlessly with common LISP.  Alegra Prolog and Common Lisp work together beautifully.  So I've been doing simulation studies in the past few, about a year.  </interviewee>
<interviewer>And do you have a feeling maybe for how the officers felt about it?</interviewer>
<interviewee>They were very enthusiastic and then they went back to their normal duties, except for Don Brutzman who's still here.  So no doubt there are other reasons that it didn't succeed.  Prolog generally wasn't accepted any place and so it fell out of fashion.  That's a factor.</interviewee>
<interviewer>What do you think it wasn't accepted?</interviewer>
<interviewee>Well, the Japanese Fifth Generation Computer Project failed spectacularly and that kind of poisoned the well for prolog for quite a while.  I don't think prolog is the be-all and end-all.  It's just the best language I know that I believe can be read with a person with no programming experience.  </interviewee>
<interviewer>And that's been in terms of when you've tried it with people and your experience proves that to be so?  But this is what you've learned from your experience of actually working with--</interviewer>
<interviewee>Working with naval officers...</interviewee>
<interviewer>Yeah.</interviewer>
<interviewee>..I found they could read prolog code.  It's hard to write.  It's not hard to read.  Prolog has only about 50 primitive functions.  When you learn that, that's it, and those are English words.  They're words like abolish-- now why am I having trouble with it?  Is, you know, what is the meaning of is?  Well, we know what is means in prolog.  They're words like assert.  They're words with common English meanings.  It's remarkably easy to read, not to write— remarkably easy to read and has a built-in inferencing capability.  </interviewee>
<interviewer>Going back a little bit.  Why did you decide to go to Ohio?  </interviewer>
<interviewee>Ah, yeah.  Good question.  They made me an offer I couldn't refuse.    Really, they gave me an opportunity to become head of a research laboratory, which I was then able to use to greatly broaden by, not only my interest in robots, but other interests, pattern recognition and those were the two main areas, robotics and pattern recognition.  So I was very well-supported physically and financially.  </interviewee>
<interviewer>Was there anyone else doing robots or vision at Ohio when you got there?</interviewer>
<interviewee>No, not when I got there.  I was able to attract some good people but not at the time I got there.</interviewee>
<interviewer>Well, who are some of the PhD students who trained while you were at Ohio?</interviewer>
<interviewee>Oh, wow.  There are too many of them.  First and second person whose name comes to my mind is V.J. Jazwa [ph?], who did not go into academia.  He went into robotics for General Motors.  But V.J. was responsible for the mechanical design and construction of the bionic bug.  He was an electrical engineering PhD student who apprenticed himself to a machinist for a year.  Then he physically constructed a rather complex machine and wrote the first real time software.  So he played a absolutely crucial role.  There were many others.  There was a masters degree student names James Bucket who did a wonderful design of the onboard electronics.  The bionic bug was already very energy-efficient.  It used A/C drill motors to power 18 joints and it ran 18 of them on about three kilowatts, which was very efficient and that was due to James Bucket.  There are many others I could mention, too many to try to recall.  </interviewee>
<interviewer>And what kind of computational hardware were you using for the bionic bug?</interviewer>
<interviewee>At first a PDP-9 computer and then a PDP-10.  No, not a 10, 1170, from the PDP-90 we went to a PDP-11 something and we ended up with an 1170, and that was in about 1980 and we had a whole megabyte of memory, which was stunning to everyone.  </interviewee>
<interviewer>And how much of the processing was, you know, real time versus offline?</interviewer>
<interviewee>All real time.</interviewee>
<interviewer>All real time, and what was the hardest part of achieving that kind of real time processing ?</interviewer>
<interviewee>Properly partitioning the tasks and I didn't make any contributions there.  The PDP-1170 memory was partitioned into 64K sections, and those computations had to be coordinated and I made no contribution there.  </interviewee>
<interviewer>That was your students?</interviewer>
<interviewee>Students did it, right.</interviewee>
<interviewer>What kind of vision systems were integrated?</interviewer>
<interviewee>The bionic bug had two CCD cameras, low-resolution, about 100X100 pixels in each camera, and it had limited vision capabilities.  We used a laser pointer to indicate points on the terrain, by hand, where we wanted it to step and it did.  So that was a way of coordinating its motion over uneven terrain, and that then was generalized in the ASV where we had a real optical radar and could classify terrain.  That's where I first encountered prolog by the way, and I think I have not mentioned another very important student, Sayoung [ph?] Kwak, K-W-A-K.  Sayoung was the person, who in his PhD dissertation, showed the effectiveness of prolog in solving the problem of non-periodic gates, in online optimization of foot placements in rough terrain.  So I've forgotten the question, but I'm sure glad I mentioned his name.  I learned about prolog from him.  </interviewee>
<interviewer>Just how you're doing the visual processing at that time?</interviewer>
<interviewee>In the ASV?  Okay.  As I said, we used an optical radar.  It was made for us by ERIM Corporation and it gave us, roughly as I remember it, 100X100 range image at a two hertz rate and we processed the range information to derive average terrain slopes so that the vehicle could adapt its body orientation to terrain in advance without waiting for forced feedback.  That did a lot to give it a smooth ride and it was remarkably affective.  We also were able to classify terrain cells as suitable foot holes or not, but only in a laboratory environment.  We never tested that in an outdoor environment.  So if we put cardboard boxes on the floor, the scanner we called it, the laser scanner could find the boxes and we could walk through them without stepping on one.  We ran out of time, ran out of money, I left, everything changed and we never got further than that with the vision aspects of the problem.  But the free gate problem is logically very complicated and we were never able to explain what we were doing to anyone except by writing it in prolog, then we published it.  It was in about 1988 or thereabouts. </interviewee>
<interviewer>Where did you publish?</interviewer>
<interviewee>In the Advanced Robotics, the journal of the robotics society of Japan.  </interviewee>
<interviewer>What were some of the other important journals and conferences where robots was being done?</interviewer>
<interviewee>Okay, IEEE Transactions, most important of all in my opinion, Transactions on Systems, Man, and Cybernetics.  Then later the Robotics Transactions after that society was formed.  That was maybe the most important place to publish.  But before that, in biomedical engineering journals, my gosh, what was that one called?  Well, there was the IEEE Transactions on Biomedical Engineering and other journals.  Those are the most important ones.  </interviewee>
<interviewer>And going back to the 1960s, like, what were the conferences that you were going to and where people were discussing robotics, and did they even call it robotics then?</interviewer>
<interviewee>No.  The first conference of which I presented any results in robotics was held in Yugoslavia and the organizer was Professor Rico Tomovich [ph?] and it was a conference on, what was it called, Robots, Man and Systems, ROMONSI [ph?] I think it was called, or at least it came to be called that and first work I presented there was on models for human postural control.  That was another whole branch of research.  I did work with the otolaryngology department at Ohio State and that was published in the IEEE Biomedical Engineering Journal.  It dealt with a potential diagnostic tool for vestibular dysfunction using a multi-linked dynamic model for postural control.  It worked, but better means were found.  It's not used today, as far as I know.</interviewee>
<interviewer>So were there any other really interesting robotics projects that ?</interviewer>
<interviewee>Oh, many, many.  That's where I became aware of Russian work, especially Russian work on gates and I had the very good fortune of going to the Soviet Union twice.  In 1974 and in 1976 I visited Professor Oketsimpski's [ph?] laboratory at Moscow State University.  I gave a talk there and he and I adopted common configuration for our walking machines so we could share results.  That worked very well.  </interviewee>
<interviewer>And what was some of the work that he was doing, or some of the other Russians that you encountered while working?</interviewer>
<interviewee>Oketsimpski was definitely doing basic research.  He wanted to demonstrate that computer coordination of a six-legged walking machine was feasible and hoped that there would be an application.  He did succeed in such a demonstration.  He was hampered by the very poor quality of Soviet computers at that point in time.  To control their walking machine, they used in part a very large analog computer, huge analog computer and it was limited in adaptability by that constraint.  So I guess that's the answer to that question.</interviewee>
<interviewer>Were there other Russians?</interviewer>
<interviewee>Yes.  Yes, there was group in Leningrad who I also visited, Professor Ignatiaf [ph?].  I never saw one of his machines walk.  So I don't know what happened to his work.  Olketsimpski's efforts were successful, and there was a group in Tbilisi who was interested in walking machines for forestry applications.  They did have a small scale model walking, but with mechanical coordination, not electronic.  After the late '70s I lost contact and I don't think that they were very seriously involved in walking machines after that.  I never heard of a project in the Soviet Union comparable to the adaptive suspension vehicle program in the United States.  </interviewee>
<interviewer>What about elsewhere in Europe?</interviewer>
<interviewee>In Finland Professor Halmay [ph?] at the University of Helsinki, I believe.  I know he worked with Rama Repila [ph?], I believe is the firm and I think it was that work, as far as I know, that led to the-- at the same time.  We were both assistant professors and he invited Rajko Tomovich from University of Belgrade because he knew of Tomovich's work on artificial hands.  Purely by chance, when I took my language exams for my PhD, I took a French exam and a Russian exam, and for the French exam, I used a translation of one of Tomovich's books called, Repetitive Analog Computers.  So I already knew about him when he came to USC and because of that, we became acquainted and he had just published a paper on creeping gates for the possibility of using caterpillar kind of creeping gates for a robot, a machine, and I was very interested in that.  So he said, do you think we could build a quadropad?  I said, I think we could.  Well, first he said a bipad.  I said, no.  That's too hard.  He said, how about a quadropad?  I said, I think so.  So we started working together and that's how it got started. </interviewee>
<interviewer>And what were some of the other works that were influential-- that had an influence on you and how you approached </interviewer>
<interviewee>Okay.   There wasn't much going on at that time.  I had a connection with Rancho Los Amigos Rehabilitation Hospital and through that connection I became better aware of the existing state of prosthesis, Lord [ph?], Germany Prosthesis and the functional requirements.  That was important, and it's very pleasing to me that that's come to fruition now in clinical applications.  Much later, Japanese research-- I became aware of Japanese research and had a joint research project, NSF project with the Porton [ph?] Harbor Research Institute.  This was in about 1992.  The Japanese had a machine called Aqua robot, which they constructed specifically for the inspection of seawall foundations and they wanted to improve their machine and we wanted to work with them and we did work together and it looked promising until the Japanese economy tanked and they lost their funding.  So we had several years of good cooperation, including at that time, a Japanese professor at the post graduate school, Yutaka Katayama [ph?].  So we did have a good cooperation going with the Japanese, but they couldn't get anymore money.  So that was the end of that.  However, I learned things from them.  </interviewee>
<interviewer>What are the future challenges in robotics?  Where do you think the field is going?</interviewer>
<interviewee>Right.  Right.  That's a very hard question.  Robots are here to stay.  They'll become more pervasive.  So it might turn out that the biggest challenge is what Dr. Bekey was talking about today.  There does not exist a field called robot ethics.  We don't understand very well how to assign responsibility for the mistakes that are bound to occur.  So I think the biggest challenges is the interface between humans and robots.  Very, very big challenge there.  Of course, there are many others.  And technologically speaking, I think I see actuators as the most serious challenge.  We have nothing approximating, natural human muscle fiber or animal muscle fiber.  That's lacking altogether.  So that's a huge challenge.  I don't see anything on the horizon really, that I know about.  Those are the two problems I would single out.</interviewee>
<interviewer>What do you see as the most promising kinds of applications and the kinds of things we'll see robots doing more commonly?</interviewer>
<interviewee>I think it's pervasive.  Again, I like what George said today.  Robots will be everywhere.  We're going to have vehicles operating on highways without human drivers.  I'm sure of it.  And that's a very dangerous kind of robot.  So liability questions have to be resolved there.  Military robots is obviously going to continue.  I understand that this year the United States Air Force spent more money on a procurement of unmanned aircraft than it did of manned aircraft for the first time.  Those aren't robots yet, but they will be increasingly so.  So I see explosive growth in military robotics and explosive growth in civilian applications.  I really like the idea of robots as assistance for home healthcare, but I think it's very far off.  I think that's a really hard problem.</interviewee>
<interviewer>What do you think are some of the potential social implications of all these different types of robots and these different kinds of _________?</interviewer>
<interviewee>Huge.  Huge.  They could make us redundant.  They could.  If we assign enough responsibility to robots, and if we give them enough independence, which is a very, very dangerous subject, we could become redundant.  I think we probably will.</interviewee>
<interviewer>Do you see that as something, has that been something, this knowledge, been something that you've been able to work into how you develop your work at all?</interviewer>
<interviewee>No.  I don't think it has anything to do with anything I've done.  No.</interviewee>
<interviewer>Do you think, I mean, today one of the questions that Professor Bekey brought up was this notion of engineering education and how some of these ideas about the societal aspects of it or the ethical aspects of it to be brought into education and design, how would you see that?</interviewer>
<interviewee>I think it's a legal problem.</interviewee>
<interviewer>Okay.</interviewer>
<interviewee>I don't see engineers doing the job of lawyers and judges.  I think, my feeling is, the engineering community has a responsibility to escalate the means by which we communicate with robots so that it approaches natural language.  I think that's not hard to do.  I think we can do it right now, if we decide it's important.  Of course, I'm speaking only of text.  I'm not talking about spoken communication.</interviewee>
<interviewer>So you mentioned this notion of robot ethics as being something that could be a very important aspect of robotics in the future.</interviewer>
<interviewee>Right.</interviewee>
<interviewer>So how would you see it, so in the sense then, the engineers would be interacting more with judges or some other people or--</interviewer>
<interviewee>Like any other product.</interviewee>
<interviewer>--they would be in a sense separate?  Mm-hm?</interviewer>
<interviewee>Like any other product.</interviewee>
<interviewer>Okay.</interviewer>
<interviewee>It's lawyers who work with juries and judges to determine liability for injuries or death of human beings as a consequence of the function of machinery.  I don't see robots as being much different in that regard, except for the ability of robots to act more pervasively and more autonomously.</interviewee>
<interviewer>Is there anything that you'd like to add before we end that you think we missed or--</interviewer>
<interviewee>Yeah.</interviewee>
<interviewer>[Blank Node]</interviewer>
<interviewee>I think it's vitally important when dealing with potentially lethal robots, whether they're automobiles or military machines or robotics surgery, I think it's very important to have the top level of software written in a way that can be discussed in a courtroom.  And I think it's doable today.</interviewee>
<interviewer>Do you see a lot of work going in that direction?</interviewer>
<interviewee>No.  I'd like to see a lot. </interviewee>
<interviewer>Why not?  Why do you think it's not a majority?</interviewer>
<interviewee>It hasn't become a real issue until just now.</interviewee>
<interviewer>Okay.</interviewer>
<interviewee>And as Dr. Bekey pointed out, the drones in Afghanistan aren't robots, but they could become robots at any time the Air Force and the government decide to do so.  And that causes that to jump right out in our faces.  We must face issues of transparency and accountability involving human lives or injury to humans.  We have to face it right now, and I think we're not.  I think it's too new.</interviewee>
<interviewer>Well, good luck with your work.</interviewer>
<interviewee>Thank you.</interviewee>
</interview>
</subject>
