<?xml version="1.0" encoding="UTF-8" ?>
<subject>
<name>John McCarthy</name>
<interview>
<interviewer>Tell us where you were born and grew up and your early education.</interviewer>
<interviewee>Okay, go ask them.  Boston.  </interviewee>
<interviewer>And where did you start your education?</interviewer>
<interviewee>In Boston public schools.  </interviewee>
<interviewer>Where did you do your undergraduate work?</interviewer>
<interviewee>Caltech.</interviewee>
<interviewer>And what did you study there?</interviewer>
<interviewee>Mathematics. </interviewee>
<interviewer>When did you start to become interested in artificial intelligence?</interviewer>
<interviewee>In the fall of 1948 there was a conference at Caltech called Hixon, H-I-X-O-N, Symposium on Cerebral Mechanisms and Behavior and they compared the brain and the computer and it gave me the idea of using computers for-- to behave intelligently and many years later when I got the Kyoto Prize and was asked that my lecture be autobiographical I went back there to look up who had talked about using computers to behave intelligently and discovered that no one had.  That I had simply jumped to the conclusion that people were interested in that.</interviewee>
<interviewer>Both John von Neumann and Warren McCulloch were at that symposium, do you recall hearing either of them?</interviewer>
<interviewee>Well, I've had subsequent interaction with von Neumann.  I never had any personal interaction with McCulloch.  </interviewee>
<interviewer>And was that interaction on theory of computation or automaton theory? </interviewer>
<interviewee>No, on artificial intelligence, but so this was in 1948, I had just graduated from Caltech in mathematics and spent an additional year at Caltech as a graduate student and then I went to Princeton as a graduate student in mathematics and when I went to Princeton, I went to see von Neumann at the Institute for Advanced Study and told him about some ideas that I'd had.  And he said, "Write it up, write it up."  And after just a little bit of further consideration, I decided that the ideas that I'd explained to him were not very good.  So, I didn't write them up.  I should have, but because they were reinvented by other people or at least some of them were.  And my judgment that they were not good ideas, they were probabilistic model of automaton connected to a brain.  And the problem with it was that there was no way in that model of putting particular facts, that is of the braining learning particular facts or representing the brain having learned particular facts and so that was 1949.  And it was 1958 before I could write a paper in which I did discuss how to make the brain learn particular facts such as representing facts and mathematical logic.  And that was a paper called "Programs with Common Sense" and I think that did play an important role in starting off the field of logical AI.  </interviewee>
<interviewer>Did you continue your conversations with von Neumann on these topics?</interviewer>
<interviewee>No, I didn't which was dumb of me.  When I organized the Dartmouth conference on artificial intelligence I wanted to invite von Neumann as a participant but he was already dying.  I kind of doubt that he would have liked my subsequent ideas because Newell told me about his negative reaction to Newell's ideas on the chess program.  And wasn't quite the same thing but it allowed me to feel that, of course this is many years later, that he might have had a positive reaction to my ideas. </interviewee>
<interviewer>What was his objections with the chess program?</interviewer>
<interviewee>I don't know.  Maybe Newell told me and I don't remember or maybe Newell only had it second hand, that is Newell was a consultant to Rand Corporation and so was von Neumann and maybe von Neumann discouraged the Rand Corporation from supporting Newell's work in that area which is bad advice which Rand Corporation fortunately did not take. </interviewee>
<interviewer>So what led you to organize the conference at Dartmouth? </interviewer>
<interviewee>I'm not a very good organizer, but I have quite good initiative in deciding that something should be organized.  And previously, I got together with Claude Shannon and we sent out invitations to contribute papers to something that later was published as "Theory of Automata".  I think that was it.  Maybe it was published as "Automata Studies," anyway it was published by Princeton University Press in the Annals of Mathematics Studies. </interviewee>
<interviewer>And did you know most of the contributors before you issued the call or did you meet them through the process of the conference and the publication?</interviewer>
<interviewee>I think I knew less than half of them.  Now, I knew Minsky because he was a fellow graduate student at Princeton, but in general I didn't, unlike Minsky who has a big talent for knowing everybody, I don't have that talent and when I was at MIT, I never went to see McCulloch although I should have.  And actually, attempted to avoid Norbert Weiner because, having read his book, I didn't think he would like my ideas.  </interviewee>
<interviewer>The cybernetics book?</interviewer>
<interviewee>Yeah. </interviewee>
<interviewer>Why did you think your ideas weren't compatible with his?</interviewer>
<interviewee>He was wedded to the idea of direct feedback and mathematical feedback in the sense that there was numerical measure of the difference between where you were and where you wanted to get to.  And my ideas were quite different, were interested in logical deduction from facts that you had about how to achieve a goal.  Now you could put that in a pseudo-cybernetic form but neither I nor anybody else ever did.  I talked about it from time to time but never did it.  Now cybernetics was very popular, particularly in the Soviet Union as soon as they were allowed to stop attacking it.  As long as Stalin was alive, they had to attack it.  </interviewee>
<interviewer>How did you meet Claude Shannon?</interviewer>
<interviewee>I spent the summer of 1952 at Bell Labs.  That was after I got my Ph.D. in 1951.  </interviewee>
<interviewer>What was your Ph.D. thesis on?</interviewer>
<interviewee>It was on solving differential equations by projecting between a space of gradients and a space of vector fields that satisfied an algebraic condition.  </interviewee>
<interviewer>When did you arrive at MIT?</interviewer>
<interviewee>What?</interviewee>
<interviewer>When did you start at MIT?</interviewer>
<interviewee>Excuse me?</interviewee>
<interviewer>When did you go to MIT?</interviewer>
<interviewee>When I got my Ph.D. I stayed two years at Princeton as an instructor then I went to Stanford and after a year, Stanford decided they had three acting assistant professors and they keep two of them and I was the third and I went to Dartmouth.  And then IBM set up the New England Computation Center and it was physically at MIT and a third of its time went to MIT directly and a third of its time was available to New England colleges and I ended up being the Dartmouth representative on that.  And somehow, I picked up computing very fast.  That was because I had a spent a summer at IBM, summer of '55.  </interviewee>
<interviewer>And what kind of projects were you working on in those years between '51 and '55?</interviewer>
<interviewee>Still most of my time was in pure mathematics.  And in my opinion, considering pure mathematics, which is what Stanford did, and they made quite reasonable decision in deciding they'd keep the other two guys and let me go.  Partly that was because while I was a pure mathematician I tended to be distracted by thinking about AI, but at that time not really getting far enough in my major ideas to publish.  I only got that far in 1958.</interviewee>
<interviewer>Now when did you start actually programming computers with what you considered to be AI?</interviewer>
<interviewee>Well, the first thing I did was start to write a chess program which I wrote in FORTRAN and I wrote the easy part, which were the legal move routines and so forth and then I was stuck on the main strategy and dithered about that, but I turned the program over to some MIT students, undergraduates, who completed it and they first completed it for the IMB 704 and then redid it for the DEC PDP-6 and they called it in, in their version, Mac Hex 6.  But I noticed that it still had even in that PDP-6 version a lot of my symbols in it.  </interviewee>
<interviewer>And why did you choose to do a chess program? </interviewer>
<interviewee>What?</interviewee>
<interviewer>Where others were talking about mathematics of chess?</interviewer>
<interviewee>No, it was actually about the second program that played a full game, the second American program played a full game.  I don't know when the Russian program came along but it might have been a little earlier.  Turing had all the ideas even earlier, but never had sufficient computer access even on computers of which he was the main person who designed.  Now I had a new idea or at least it was new in the West, the Russians also invented it independently, although I was first.  At least their paper on it was 1963 and I was haranguing people on it in probably even in 1956.  That was the alpha beta heuristic, but alpha beta heuristic was complicated by thinking of optimistic and pessimistic evaluations.  So, the fact if you gave up that notion and just took a simple evaluation, the fact that it gave the same result as Minimax was discovered by Mike Levin and Dan Edwards who actually wrote a paper on that fact.  The person who disentangled who did what was Don Kunoth who wrote a paper for artificial intelligence in which he interviewed people, but I was the first person outside of, no, I think I was the first person to try to identify that was a kind of separate thing.  Arthur Samuel had something like it in his checker program, but he never sort of picked it out as a separate intellectual object. </interviewee>
<interviewer>When did you come to understand that AI would become a field of its own?</interviewer>
<interviewee>Well, okay in one sense you can say on particular date which was August 31, 1955.  No, maybe earlier, maybe 1952, I wrote this call for these papers on the automatous studies and when the papers came in, I was disappointed, too many of them were about automata and I remember having a discussion with Claude Shannon where I was interested in machine intelligence and he thought any such title was much too flashy.  And so we picked this automata theory or something like that as being the title.  No, actually, that we should have suggestion was made to me by a Princeton graduate student by the name of Jerry Rain which was just a purely oral suggestion made in conversation.  But anyway, the August 31 was when I wrote the proposal for the Dartmouth summer study.  I got three other people to go in with me on it, Minsky and Shannon and I'm forgetting who else.  And we proposed to the Rockefeller Foundation for a summer study where some number of people, like, ten, would devote the entire summer to thinking about artificial intelligence.  And I introduced the term of artificial intelligence on that date when I wrote the proposal.  I had to think of a name to call it and I called it artificial intelligence.  Now, later Donald Michie used the term machine intelligence and my opinion is that that was a better choice.  </interviewee>
<interviewer>Who ended up coming to the conference?</interviewer>
<interviewee>Well, my idea that a bunch of people would devote the entire summer to it didn't work.  In the first place, the Rockefeller Foundation didn't give us anywhere near enough money, but the second place hardly any of the people who did come were willing to devote that much time.  It was more like they were willing to come for a few days and tell us what they were doing and they would go off and do it.  Now, the only people who were seriously devoted to artificial intelligence at the time were myself, Minsky, Newell and Simon and I'd say Ray Solomon.  Now, of these the furthest advanced were Newell and Simon.  And I got the idea of this processing from them.  But they used an absolutely terrible language were the IPL which they stuck with for quite a long time and finally a sea of new people switched to LISP or maybe that's not quite true.  Anyway, IPL was abandoned and LISP took the idea of list processing from them and then for the form of the language took Fortran as its model.  But then it turned out that to write a program for symbolic differentiation would go well if the algorithm was allowed to be the function of differentiation from-- first of all, if differentiation was considered to be a function applied to the symbolic expressions.  And secondly, if that function was allowed to be recursive, in the sense of, in the computer science sense of calling itself.  And so I think that LISP, which was introduced, or I started on it in the fall of 1958, was maybe the first language.  No.  That's not quite true.  I think IBL, the functions could call themselves, but not through an automatic mechanism built into the structure of the language.  So anyway, that was-- started programming LISP.  But the curious thing is that I wrote a report in the beginning of '59, in which I wanted to show that LISP was universal as a computational means, and so I wrote universal function, and I wanted to show that compared to a universal Turing machine, which took Turing about six pages to describe in his 1936 paper, was only a few lines, and LISP was functioning well.  Well, the thing that I wrote down had a bug in it.  But in any case, one of the programmers, Steve Russell, saw my report and programmed me that, in the sense of what we were doing then with LISP is we were hoping to have a compiler, but we didn't have a compiler, so we were doing hand compiling, and he hand compiled.  Alan said, "No.  We have an interpreter for this."  And after a little, I put up a little resistance and then had to agree that Steve was right.  And, okay, well, enough of that.  Let's go.</interviewee>
<interviewer>Tell me about the AI lab at MIT.  </interviewer>
<interviewee>Well, Minsky and I started that.  Now, here's my version, which may not be entirely correct.  That is that I encountered Minsky in the corridor and said, "We really ought to have an artificial intelligence laboratory."  And he said, "That's a good idea.  Let's do that."  And then along came Jerry Wiesner, who was the head of the Research Laboratory of Electronics.  And I said, "Marvin and I want to have an artificial intelligence laboratory."  And he said, "All right.  What do you need?"  And I said, "We need a room, and a secretary, and a keypunch, and two programmers."  And Wiesner said, "And how about six graduate students?"  And we said, "Yes."  And that was it.  And the reason why that was it was that MIT had just received a Joint Services contract, and what MIT had done was that it had divided the prize up among various departments, and the Mathematics Department's share was support for six graduate students, but it wasn't clear what this Joint Services contract, would do with the six graduate students.  So when Minsky came along, when he and I came along, Wiesner had a solution to his problem, and sent over his six graduate students, so somehow the resources were suddenly available.  So it spoiled me in the sense that I felt that that's the model of a proposal and its acceptance.  You meet the guy in the corridor and ask him, and he says, "Yes."  He says, "What else do you need?"</interviewee>
<interviewer>So who were some of the first graduate students that you trained?</interviewer>
<interviewee>There was David Lucketim [ph?] and David Park.  They were both Englishmen, and they wrote theses in pure mathematics, but they later switched to a topic they had resisted when I proposed it, which was proving programs correct.  Both of them did that.  A guy by the name of Braiten [ph?], I've forgotten his first name.  He subsequently went to work for IBM.  Now, there was Jim Slagel [ph?], but I forget whether he was one of the six, or not.  He was a mathematics graduate student.  </interviewee>
<interviewee>In the spring of 1962, by then MIT had promoted me to-- oh, I hadn't finished confessed to double crossing Dartmouth.  John Kamine [ph?], who had hired me at Dartmouth-- sorry, was Dartmouth's representative on this thing, and I got a Sloan Foundation Fellowship, which I spent at MIT, that is for one year.  And MIT was willing to hire me as an Assistant Professor of Communication Sciences in the Electrical Engineering Department, and so gave up the Dartmouth appointment, and went to MIT.  And by the spring of '62, I had been promoted to Associate Professor at MIT, and I got, quite out of the blue, a telephone call from George Forsythe at Stanford, who asked me if I'd be willing to come to Stanford, and being slightly miffed by Stanford having previously decided not to keep me, I said, "Well, I've been at Stanford before.  I could only come as a full professor."  And I thought that would turn him off, but he said, "I think I can manage that."  And I was very startled, because I'd been just made an associate professor at MIT, and that would be a jump in one year to full professor.  And I'd never heard of Forsythe before, and later on, when I looked him up, he's a numerical analyst, and he would have had no occasion to have ever read a paper of mine in the course of his work, but he had the ambition to have a computer science department, and I already had developed some reputation there.  I don't know precisely what their reputation was.  It certainly was connected with AI, and also with proving facts about computer programs.  But anyway, MIT was willing to-- there was also a jump in salary associated with the Stanford offer.  Now, MIT was willing to more than match the salary, which was startling to me.  From nine thousand, MIT was willing to go to fifteen thousand, but they weren't willing to make me a full professor right away, because they considered Minsky and me to be a pair, and couldn't promote-- didn't feel they could promote one without the other.  We were in different departments, and the Math Department would have had to agree to promote Minsky.  So they were willing to make me Director of Research for the Computer Science Department, and so forth.  But I really did like California and wanted to go back to California, so I ended up accepting the Stanford offer.  I hate shoveling snow out of my driveway.  </interviewee>
<interviewer>So was anybody else working in computer science at Stanford when you arrived here, or was anybody else working on artificial intelligence?  </interviewer>
<interviewee>Well, Forsythe was a numerical analyst, and he considered numerical analysis to be part of computer science.  I was the first person he hired, and then the second person was a young numerical analyst, Gene Gollen [ph?], and he launched a great campaign and eventually got Donald Knufe [ph?] to come to Stanford.  So Forsythe has a real talent for building a department, so we were the second computer science department in the country, and maybe in the world.  Purdue was ahead of us by a few months.  </interviewee>
<interviewer>When were you able to set up an AI lab?</interviewer>
<interviewee>Well, the students who worked for me, or one of them, who worked for me on the chess program, on Kotok, went to work for DEC, and was one of the designers of the PDP-6.  And one of the ideas that he and the other people at DEC took from me, the idea of timesharing, which I hadn't mentioned before.  Somewhere at MIT there's a big set of oral interviews with me on the subject of timesharing.  But anyway, PDP-6 had in it an interrupt system designed for timesharing, and also some instructions that were suitable for LISP.  It didn't require much, or rather it didn't make LISP much better.  Without it they were half word manipulation instructions.  But, oh, it did give a big advantage over any other computer that existed at the time in any country.  It had an 18-bit address, and the IBM 704, and its successors, could have had an 18-bit address, but the engineers could not build such a big memory at the time, and so they designed it so that a 15-bit address was the maximum a 704 could have.  And when the Soviets copied American computers, they also did a 15-bit address, but the Soviets copied the 15-bit address just about the time when IBM had decided that, no, a 15-bit address was too small, and the Soviet BESM-6 had a 15-bit address.  So anyway, let's see, what's relevant here.  Oh, we want to make the path to the Stanford AI lab.  Well, DEC gave me, or you know, Stanford a PDP-1 computer.  Oh, I had designed a timesharing system for a PDP-1 computer, and the one day a week consultant at BBN, and it was programmed by Sheldon Boyland [ph?], who just graduated as a history major.  I forget from where.  So the actual programming of it was a one-man effort.  He never did anything else in computing after that, maybe I wore him out.  Jack Dennis at MIT did another timesharing system for the PDP-1, because the PDP-1 that DEC gave MIT was more limited than the one that BBN bought, so it couldn't have the same timesharing system.  So now the Stanford AI lab-- okay.  I read a book called, "A Study of Thinking," by Jerome Bruner, and it had a notion of concept in it.  And the notion of concept was a bullion combination of elementary concepts, and I thought that was wrong, because it didn't allow for relations, and they were particularly interested in vision.  So you could consider the concepts of the shapes of the letters.  That is, is it convex?  Does it have a hole in it, and so forth.  If you think of enough elementary concepts, then you can make enough combinations to discriminate the alphabet, but my complaint is it wouldn't enable you to draw a letter.  You should consider, for example, a letter that has a vertical line segment and three horizontal line segments, which point to the right from the top middle and bottom vertical, and each about two-thirds the length of the vertical.  Now you can tell somebody that over the telephone, and they can draw it, and it'll turn out to be a capital "E."  Or you can take the same thing and rotate it counterclockwise by ninety degrees, and it's the Russian letter, "Sha."  So my slogan was, "Description not discrimination."  And in particular, I pointed out that if you wanted to do manipulation, then description was what you needed of the objects that you were going to manipulate.  So if you were going to do robotics then you needed description.  So I asked for money for the Stanford AI lab to get a PDP-6 computer, not being satisfied with the PDP-1 computer that DEC had given me, and that I got beefed up by programs and sharing with Patrick Simpese [ph?].  And so we did get this AI lab, and now I'm not sure when the word, "robotics" came in.  Now, of course, the word, "robot" came up in science fiction long before it came up in any science.  Are you familiar with the history of that?</interviewee>
<interviewer>Yeah, the topic.</interviewer>
<interviewee>Yeah, right.  Now, I was certainly not interested in undertaking a complete robot, and it was-- I might not have believe it at the time, but it turned out not to be possible with the resources that we had even for just the mechanical part of it.  What was possible was arms, that is to build a single arm, and that was possible, because there was a graduate student at Stanford, Victor Scheinman, who was, I would say, a real genius as a mechanical engineer and designer, and he designed several mechanical arms.  He designed one.  The first one he designed was a hydraulic arm, and it had, I remember, these plastics tubes that had the high pressure, hydraulic fluid in them.  And it was decided, not by me.  I didn't do any close supervision of that, but if one of those tubes ever broke, that arm would swing and anybody who was in the way would really get hurt.  So it was put into a little house that was built around it, but it was never used, and Scheinman designed some much smaller and weaker arms that were electrically powered, and those were the ones that were used by the Stanford AI lab.  </interviewee>
<interviewer>When did you first meet?</interviewer>
<interviewee>Let's see.  I came to Stanford in the fall of '62.  It seems to me we got the Stanford AI lab, and our big increase in money from DARPA that enabled us to buy the PDP-6 computer, was '65.  And when I thought we needed an arm, my first idea about that was I'd read about these remote arms that had been used during World War II, to handle radioactive material, and I said, "Ah, that must have led to further developments."  And I discovered, no.  They had simply been abandoned at the end of World War Two, so that we were going to have to design our own.</interviewee>
<interviewer>I got DARPA to write some letters saying it really wouldn't be a good idea if someone with her training went back to Czechoslovakia.  That didn't help, but what did help was that her-- the University of Pennsylvania, which is where she was after she got her Stanford PhD, got a congressman to intervene, anyway.  Well, if you're going to interview her, she knows, I'm sure, her story more correctly.</interviewer>
<interviewer>What was she like as a student to work with?</interviewer>
<interviewee>Hardworking.  She worked on vision.  </interviewee>
<interviewer>Who were some of the other early students that were interested in robotics?</interviewer>
<interviewee>Well, there were a couple of other faculty members who did it, younger faculty members.  One of them was Raj Reddy.  Are you interviewing him?</interviewee>
<interviewer>Yeah.</interviewer>
<interviewee>And Jerry Feldman.  He invented this language called SAIL, which in his original naming stood for Stanford Artificial Intelligence Language.  And I objected to that on the grounds that LISP was senior to SAIL.  And so he said, "All right, it just stands for SAIL."  Well, LISP survives and SAIL is dead, so.  And now I'm trying to remember the student who did most of the programming of the arm.  He was an electrical engineering student, not a computer science department student.  Now, from a robotics point of view, let's see, there's-- from a robotics point of view, a key thing is that there were a number of PhD theses that were associated with what you would call today components of a robot, rather than complete robots.  So there was Bruce Baumgart who-- now, I think it was he who wrote the one about driving the cart around the lab.  We inherited from the mechanical engineering department a cart that could be radio-controlled, so we radio-controlled it from our computer.  It had first been built as a prototype of a cart that could be driven on the moon, with a two-and-a-half-second delay.  So it might have been an ancient prototype.  The vehicle, it was driven on the moon sometimes, with the two-and-a-half-second delay.  So I think it was Baumgart who did that, but maybe he did something else.  Then there's a guy who did a thesis on face recognition.  Who else are you going to interview?  </interviewee>
<interviewer>Well, somewhat later students were Hans Moravec and Rodney Brooks.  We've talked to several people at Stanford-- , Ken Salisbury, Vic Scheinman.</interviewer>
<interviewee>No, I was thinking of those people-- the one whom I'm sure would know what everybody did is Baumgart.  Now, if I were, so to speak, a normal professor and hadn't lost bit amounts of memory through getting old, I'd remember all of those names, and maybe I'll remember them tomorrow, but-- well, the names I remember-- most of the names I remember, but who did which thesis.  All, the topics are the cart-- now, the question is who did the actual programs in which the-- all right, there was the block-stacking program.  So somebody did that one.  It was-- then there was the assembly of an automobile water pump.  That was somebody's thesis.  Baumgart would know that.  And then there was some speech recognition that Reddy supervised.  Reddy's thesis that he had done on the PDP-1 was speech recognition.  So we never made a complete robot.  That is, we could have, in principle, have put the arm on the cart, and so forth, but remember that all of these things were done on a PDP-6 computer in a timesharing mode on-- well, it was possible to sign up for time for wee small hours of the morning, in which it would get-- oh, there was a complicated sign-up in which you would sign up for whams and bams [ph?].  I don't think I remember that because I never bothered with it because my own use of the computer was not CPU-intensive.  I never did use it for anything but typewriter, for writing papers.  </interviewee>
<interviewer>What would you say was the relationship between artificial intelligence and robotics, particularly at Stanford?</interviewer>
<interviewee>Well, as I say, my motivation for starting the robotics was having this slogan about concepts, which is, after all, an AI idea.  But I never even met Brunner, so I didn't get into an argument with him.  I should have, and he was there at Harvard when I was at MIT, but I didn't do it.  Though I suspect he-- I didn't write a paper about that, but I suspect that the point was in my proposal to DARPA that got us the large sum of money that permitted me to hire quite a large number of graduate students in computer science and electrical engineering, and permitted us to get our own PDP-6 computer, and to keep updating it to a PDP-10 and a KA10.  We also-- Deck [ph?] gave us big discounts on the-- all of our upgrades.  And I never really tried to figure out to what extent they were matters of gratitude for what we had done for them, and to what extent they were merely making the sale.  I don't know.  But they certainly did a lot of-- gave us a lot of credit, and they used our drawing program to write the drawings for the-- I think maybe the KA10.  At some point, one of the guys had a project to design our own PDP-10-like computer, only much faster, and prepared the design and got sent off to DARPA.  And DARPA said yes.  I had a bunch of consultants look at it.  They said, "Yeah, it will probably work," and then DARPA decided, "No, we don't want to be in that business."  Didn't support it.  Well, _______ Park designed their own PDP-10, built it.  So the robotics was, in some sense, an illustration of this argument about AI, but of course it was useful, or led to things being useful, and certainly-- let's put it this way: When Walter Cronkite came to interview me, I did not try to make him understand this more abstract notion of discrimination versus description.  But there was quite a bit of industrial robotics already.  But they were even less likely, or they were-- to write papers about it than the academic part.  So we did, I remember, pay a visit to a Ford plant.  They showed us where they were doing assembly.  And also I once paid a visit to IBM, where they were doing some automatic assembly-- partial automatic assembly.  It was very interesting there because you could see things being assembled automatically, and then there was some part of the work where it would suddenly expand out to a part where it couldn't be done automatically.  And you had a department of 40 women doing a manual assembly of some part of it.  Now, let's see.  So the AI lab I think moved to campus from-- it seems to me in 1989, and then we had a lot of trouble getting funding from DARPA and dissolved it.  We didn't get the space on campus that we were promised.  If you want a lot of detail, have you interviewed or are you going to interview Lester Earnest?</interviewee>
<interviewer>We should.</interviewer>
<interviewee>Lester Earnest is the executive officer of the AI lab, and he did a lot of our interaction with DARPA and with suppliers and a lot of the supervision of projects.  He had a fair amount of initiative on projects.  I once remember Larry Roberts asking me what the relation was-- he said, "Can you fire him, or can he fire you?"  And I said, "Well, I believe I can fire him.  Would you like me to try?"   several years when the shortage of funds became sufficiently acute, I had to do that.  </interviewee>
<interviewer>So what do you think AI gained from the ventures into robotics research?</interviewer>
<interviewee>Well, a lot of the specific pieces of research contributed to AI-- the face recognition, the speech recognition, the driving the cart around the lab, the mechanical assembly and so forth.  These things, they established a sort of boundary of what was relatively easy to do.  Yeah.  I think Earnest is the guy you should definitely interview.</interviewee>
<interviewer>Did you have much interaction with the people at SRI, like Nils Nilsson, and their robotic work?</interviewer>
<interviewee>I guess the basic answer is no, and my hesitation is that I'm trying to figure out why.  Are you going to interview Nils Nilsson?</interviewee>
<interviewer>Yeah, next week.</interviewer>
<interviewee>Now, Engelbart said something in which he contrasted his motivations and mine, and I think he misrepresented mine in order to get a contrast.  He was interested in man-machine interaction, and I was interested, he said, in what a machine can do all by itself.  And of course I was also interested in man-machine interaction.  Timesharing was my biggest work in that area, as well as being interested in what a machine could do by itself.  I remember being very skeptical of a mouse because it was one more device, having following the light pen and so forth.  It took me a while to realize, yes, but the mouse was much better.  </interviewee>
<interviewer>Do you have any stories you'd like to share about working with Marvin Minsky?</interviewer>
<interviewee>No, basically Minsky and I worked separately.</interviewee>
<interviewer>What were Newell and Simon like to interact with as colleagues?</interviewer>
<interviewee>What?</interviewee>
<interviewer>What was it like interacting with Newell and Simon in the early days of AI?</interviewer>
<interviewee>Well, I annoyed them  on a specific occasion.  And they were justifiably annoyed, though not necessarily with me.  In September of 1956, there was a meeting maybe of IEEE or maybe it was called IRE in those days, in Boston, and I was invited to give a talk on the Dartmouth summer project and the state of AI.  And I told what I knew, but in terms of actual implement of AI, they were ahead of us.  </interviewee>
<interviewer>If there were young people interested in pursuing careers in artificial intelligence or robotics, what would you recommend to them to study to pursue a career?  What kind of advice would you give them?</interviewer>
<interviewee>It depends on how good they are.  If they're as self-confident as I was, then I would recommend to them don't pay any attention to anybody's advice.  Think about it for yourself.  I think AI needs new ideas and it's most likely to come from new people.  The probability that it will come from someone who is 83 is very unlikely, although I just read in the New York Times an obituary of someone who died at the age of 97 who is most famous for something that he did after the age of 90.  </interviewee>
<interviewer>Could you tell us just a little bit about some of the challenges in AI and robotics that you think are the most important ones you've seen solved, and others that are pending?</interviewer>
<interviewee>No.  Sometimes I feel-- or maybe I do feel what Harrison Schmitt said about NASA.  Did you read that?</interviewee>
<interviewer>No.</interviewer>
<interviewee>Know who he is?</interviewee>
<interviewer>Harrison Schmitt?</interviewer>
<interviewee>The only scientist to ever walk on the moon.  He was a geologist.  He said NASA should be abolished and restarted with-- well, now I'm forgetting exactly what he said and what I think-- started with new people.  Because it was started with young people, and now they've grown old.   </interviewee>
<interviewer>You think robotics is a sort of new way to restart some of what AI was aiming towards in the beginning?</interviewer>
<interviewee>I don't even know how old the leading people in robotics are, so I can't even say that thing, because I don't know.  There was just a big conference on monotonic reasoning held in Kentucky, and I should have gone, but I'm not very mobile these days and didn't go.  I got a greeting from it signed by about 100 people.  About half of the names I recognized, which worries me it may be too many.  </interviewee>
<interviewer>Well, I think that just about does it, unless there's anything you'd like to add.</interviewer>
<interviewee>No, that's fine.</interviewee>
<interviewer>Thank you very much.</interviewer>
<interviewee>Uh-huh.  Print or publish or include in your program very little of this interview.   </interviewee>
<interviewee>There's a guy  who said he invented it, the term artificial intelligence.  Well, I was quite prepared to believe that, because when I wrote the thing down in this August 31, 1955 proposal, I wasn't absolutely sure that I hadn't heard the term somewhere else.  And at least in something I wrote later on I said I wasn't sure of that, would anybody who knew it-- so he said he'd invented it.  But then he said he invented it in the spring of 1956, which was of course quite a long time after the call for the Dartmouth conference had gone out and all sorts of people had accepted the invitation and so forth.  And I said, "Well, look, maybe you invented it earlier," but he absolutely could not be persuaded in that he might have invented it earlier.  So he didn't invent it earlier, and-- but somebody might have.  But I did-- at least as far as anybody knows-- invent the term artificial intelligence.  And I did propose logical AI, the way to do it.  And now I wouldn't be certain about , whether I was the first to _____ vision, computer vision, towards description.  I was certainly one of the first who did that.  </interviewee>
<interviewer>Did the fact that the robots were embodied and can move in space help-- and manipulate-- help with the notion of description, or change the notion of description at all?</interviewer>
<interviewee>Well, yeah, because-- okay, now, here's an unsolved problem.  The description of objects with flat surfaces is reasonably understood.  Geometry provides us with that.  The description of irregular objects is not well understood, and is almost not done, or I don't know anybody who does it because it is-- anyone who can describe, say, a cat as a solid object, or a person even.</interviewee>
<interviewer>Thank you.</interviewer>
</interview>
</subject>
